**简易全连接层的神经网络案例**：

- 1、**数据加载**

  - mnist手写数字图片数据，每一张图片都是28*28的大小，训练集有60000个样本，测试集有10000个样本

  - ```python
    from tensorflow.keras.datasets import mnist
    mnist.load_data()
    ```

- 2、**数据处理**

  - 首先，因为我们使用的是全连接层，所以要将特征向量展开成一维的特征向量，使用reshape改变特征向量的形状
  - 然后将数据类型变成浮点型
  - 最后对数据进行归一化，减少计算量

- 3、**模型构建**

- 4、**模型训练**

  - 引入Tensorboard实现模型训练过程参数的可视化以及模型计算过程的可视化
  - 先进入到对应的虚拟环境，然后使用命令行启动tensorboard服务，使用浏览器访问它提供的链接，即可看到可视化后的结果

- 5、**模型评估**

  - model.evaluate()

- 6、**模型的保存与加载**

  - 保存：model.save()，一般以h5的格式保存模型文件
  - 加载：tf.keras.models.load_model()

- **全连接网络的局限性**：

  - 数据量大，造成模型的训练效率比较低下
  - 无法正确表示特征之间的关联，对于模型去提取一些关键特征来说影响较大

- **卷积神经网络**：

  - 提高模型的训练效率，同时更好的去提取和表征原始数据的特征

  - **主要组成结构**：

    - 卷积层、池化层、全连接层、激活层

    - 1、卷积层：提取特征

      - 卷积核：就是前面OpenCV中提到的滤波器，是带有权重的一种计算结构

      - padding：当我们需要指定输出的feature map的大小是可以指定padding的大小，一般的选择是‘same’或者‘valid’。

      - stride：卷积核进行滑动扫描提取特征时的步长是多少

      - 多通道卷积：对应通道的卷积核与特征图进行卷积操作，然后将所有通道的卷积结果按位置相加，即得最后的输出feature map

      - 多卷积核卷积：最后得到的feature map的通道数只与卷积核的个数相等

      - 输出的feature map大小的计算方式：

        - 输入的图片：H1 x  W1 X C1

        - 卷积操作：

          - 卷积核个数K
          - 卷积核的大小F
          - 步长S
          - 零填充大小P

        - 输出的feature map的大小：

          - 高：H2 = （H1 - F + 2P）/ S    +  1
          - 宽：W2 = （W1 - F + 2P）/ S    +  1
          - 通道数：C2 = K 

        - API 实现：

          ```python
          tf.keras.layers.Conv2D(
              filters, kernel_size, strides=(1, 1), padding='valid', 
               activation=None
          )
          ```

    - 2、激活层：获取非线性输出，让模型具有非线性样本的处理能力

    - 3、池化层：对提取后的特征进行降维

      - 最大池化

        - 通过扫描窗口扫描特征图，在窗口内的最大值作为最终的输出结果

        - API：

          ```python
          tf.keras.layers.MaxPool2D(
              pool_size=(2, 2), strides=None, padding='valid'
          )
          ```

      - 平均池化

        - 通过扫描窗口扫描特征图，在窗口内的所有特征的平均值作为最终的输出结果

        - API：

          ```python
          tf.keras.layers.AveragePooling2D(
              pool_size=(2, 2), strides=None, padding='valid'
          )
          ```

    - 4、全连接层：一般用来输出结果，将最后得到的feature map展开成一维的特征向量，然后进行分类或者回归操作

- 图像分类

  - 目的：为了给输入的图片贴上类别标签
  - 常用的数据集：mnist、cifar系列、ImageNet
  - 经典分类模型：
    - 1、AlexNet：在深度学习中具有里程碑意义的模型，识别错误率比第二名少了大概10个百分点
    - 2、VGG，现在使用也是非常广泛的一个模型
    - 3、GoogLeNet，在分类里面效果出众，而且计算量小
    - 4、ResNet，通过残差块发挥出深度的神经网络的性能
  - AlexNet:
    - 特性：包含5层卷积，2层隐藏层全连接层，1层全连接输出
      - 卷积核形状，第一层卷积大小是11x11，接下来分别使用5x5和3x3的卷积核大小进行卷积操作
      - 将激活函数从sigmoid变成了RELU
      - 添加了Dropout层，防止过拟合
      - 引入了图像增强，让模型提取的特征更加丰富