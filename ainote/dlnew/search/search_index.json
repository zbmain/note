{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u6df1\u5ea6\u5b66\u4e60\u4e0eCV \u00b6 \u4e3b\u8981\u5185\u5bb9 : \u5728\u8be5\u8bfe\u7a0b\u4e2d\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdtensorFlow,\u56fe\u50cf\u5206\u7c7b,\u68c0\u6d4b\u548c\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9","title":"\u6df1\u5ea6\u5b66\u4e60\u4e0eCV"},{"location":"#cv","text":"\u4e3b\u8981\u5185\u5bb9 : \u5728\u8be5\u8bfe\u7a0b\u4e2d\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdtensorFlow,\u56fe\u50cf\u5206\u7c7b,\u68c0\u6d4b\u548c\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9","title":"\u6df1\u5ea6\u5b66\u4e60\u4e0eCV"},{"location":"deeplearning/","text":"\u56fe\u50cf\u5206\u7c7b1(Image Classification) \u00b6 \u4e86\u89e3\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4ee5\u53ca\u6311\u6218 \u77e5\u9053\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\u7279\u70b9\u3001L1\u4e0eL2\u8ddd\u79bb\u7684\u7279\u70b9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u5b9a\u4e49 \u4e86\u89e3\u611f\u77e5\u673a\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u7cfb \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u5c55\u5386\u53f2 \u77e5\u9053\u57fa\u4e8e\u56fe\u50cf\u50cf\u7d20\u6620\u5c04\u7684\u5206\u7c7b\u8bc4\u5206\u51fd\u6570 \u8bf4\u660eSVM\u548cSoftmax\u7ebf\u6027\u5206\u7c7b\u5668\u53ca\u5176\u635f\u5931\u51fd\u6570\u7279\u70b9\u539f\u7406 \u77e5\u9053\u6700\u4f18\u5316\u7684\u5b9a\u4e49 \u638c\u63e1\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \u638c\u63e1\u8ba1\u7b97\u56fe\u7684\u5411\u91cf\u8ba1\u7b97\u65b9\u5f0f \u5e94\u7528\u5b8c\u6210\u5355\u795e\u7ecf\u5143\u795e\u7ecf\u7f51\u7edc \u77e5\u9053\u6d45\u5c42/\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u548c\u53cd\u5411\u8ba1\u7b97\u8fc7\u7a0b \u638c\u63e1\u6fc0\u6d3b\u51fd\u6570\u7684\u4f7f\u7528\u4ee5\u53ca\u9009\u62e9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u548c\u8d85\u53c2\u6570","title":"\u56fe\u50cf\u5206\u7c7b1(Image Classification)"},{"location":"deeplearning/#1image-classification","text":"\u4e86\u89e3\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4ee5\u53ca\u6311\u6218 \u77e5\u9053\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\u7279\u70b9\u3001L1\u4e0eL2\u8ddd\u79bb\u7684\u7279\u70b9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u5b9a\u4e49 \u4e86\u89e3\u611f\u77e5\u673a\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u7cfb \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u5c55\u5386\u53f2 \u77e5\u9053\u57fa\u4e8e\u56fe\u50cf\u50cf\u7d20\u6620\u5c04\u7684\u5206\u7c7b\u8bc4\u5206\u51fd\u6570 \u8bf4\u660eSVM\u548cSoftmax\u7ebf\u6027\u5206\u7c7b\u5668\u53ca\u5176\u635f\u5931\u51fd\u6570\u7279\u70b9\u539f\u7406 \u77e5\u9053\u6700\u4f18\u5316\u7684\u5b9a\u4e49 \u638c\u63e1\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \u638c\u63e1\u8ba1\u7b97\u56fe\u7684\u5411\u91cf\u8ba1\u7b97\u65b9\u5f0f \u5e94\u7528\u5b8c\u6210\u5355\u795e\u7ecf\u5143\u795e\u7ecf\u7f51\u7edc \u77e5\u9053\u6d45\u5c42/\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u548c\u53cd\u5411\u8ba1\u7b97\u8fc7\u7a0b \u638c\u63e1\u6fc0\u6d3b\u51fd\u6570\u7684\u4f7f\u7528\u4ee5\u53ca\u9009\u62e9 \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u548c\u8d85\u53c2\u6570","title":"\u56fe\u50cf\u5206\u7c7b1(Image Classification)"},{"location":"deeplearning/section1/","text":"2.1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9 1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb \u00b6 \u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u8fd9\u5e45\u56fe\uff1a\u4eba\u5de5\u667a\u80fd>\u673a\u5668\u5b66\u4e60>\u6df1\u5ea6\u5b66\u4e60 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\uff0c\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7**\u62e5\u6709\u4f17\u591a\u5c42\u6570\u795e\u7ecf\u7f51\u7edc(Neural Network)**\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6765\u770b\u5e38\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5305\u62ec\uff1a \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(Convolutional Neural Network) \u5faa\u73af\u795e\u7ecf\u7f51\u7edc(Recurrent Neural Network) \u751f\u6210\u5bf9\u6297\u7f51\u7edc(Generative Adversarial Networks) **\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(Deep Reinforcement Learning)**\u7b49\u3002 2 \u4ec0\u4e48\u662f\u795e\u7ecf\u7f51\u7edc \u00b6 \u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08 Artificial Neural Network\uff0c \u7b80\u5199\u4e3aANN\uff09\u4e5f\u7b80\u79f0\u4e3a\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09 \uff0c\u662f\u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u3002\u4eba\u8111\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u751f\u7269\u795e\u7ecf\u7f51\u7edc\uff0c\u7531\u4f17\u591a\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u800c\u6210\u3002\u5404\u4e2a\u795e\u7ecf\u5143\u4f20\u9012\u590d\u6742\u7684\u7535\u4fe1\u53f7\uff0c\u6811\u7a81\u63a5\u6536\u5230\u8f93\u5165\u4fe1\u53f7\uff0c\u7136\u540e\u5bf9\u4fe1\u53f7\u8fdb\u884c\u5904\u7406\uff0c\u901a\u8fc7\u8f74\u7a81\u8f93\u51fa\u4fe1\u53f7\u3002\u4e0b\u56fe\u662f\u751f\u7269\u795e\u7ecf\u5143\u793a\u610f\u56fe\uff1a \u90a3\u600e\u4e48\u6784\u5efa\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u795e\u7ecf\u5143\u5462\uff1f \u53d7\u751f\u7269\u795e\u7ecf\u5143\u7684\u542f\u53d1\uff0c\u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u6765\u81ea\u5176\u4ed6\u795e\u7ecf\u5143\u6216\u5916\u90e8\u6e90\u7684\u8f93\u5165\uff0c\u6bcf\u4e2a\u8f93\u5165\u90fd\u6709\u4e00\u4e2a\u76f8\u5173\u7684\u6743\u503c(w)\uff0c\u5b83\u662f\u6839\u636e\u8be5\u8f93\u5165\u5bf9\u5f53\u524d\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\u6765\u786e\u5b9a\u7684\uff0c\u5bf9\u8be5\u8f93\u5165\u52a0\u6743\u5e76\u4e0e\u5176\u4ed6\u8f93\u5165\u6c42\u548c\u540e\uff0c\u7ecf\u8fc7\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570f\uff0c\u8ba1\u7b97\u5f97\u5230\u8be5\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u3002 \u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5229\u7528\u795e\u7ecf\u5143\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u90bb\u5c42\u4e4b\u95f4\u7684\u795e\u7ecf\u5143\u76f8\u4e92\u8fde\u63a5\uff0c\u5e76\u7ed9\u6bcf\u4e00\u4e2a\u8fde\u63a5\u5206\u914d\u4e00\u4e2a\u5f3a\u5ea6\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u795e\u7ecf\u7f51\u7edc\u4e2d\u4fe1\u606f\u53ea\u5411\u4e00\u4e2a\u65b9\u5411\u79fb\u52a8\uff0c\u5373\u4ece\u8f93\u5165\u8282\u70b9\u5411\u524d\u79fb\u52a8\uff0c\u901a\u8fc7\u9690\u85cf\u8282\u70b9\uff0c\u518d\u5411\u8f93\u51fa\u8282\u70b9\u79fb\u52a8\uff0c\u7f51\u7edc\u4e2d\u6ca1\u6709\u5faa\u73af\u6216\u8005\u73af\u3002\u5176\u4e2d\u7684\u57fa\u672c\u6784\u4ef6\u662f\uff1a \u8f93\u5165\u5c42 \uff1a\u5373\u8f93\u5165x\u7684\u90a3\u4e00\u5c42 \u8f93\u51fa\u5c42 \uff1a\u5373\u8f93\u51fay\u7684\u90a3\u4e00\u5c42 \u9690\u85cf\u5c42 \uff1a\u8f93\u5165\u5c42\u548c\u8f93\u51fa\u5c42\u4e4b\u95f4\u90fd\u662f\u9690\u85cf\u5c42 \u7279\u70b9\u662f\uff1a \u540c\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u4e4b\u95f4\u6ca1\u6709\u8fde\u63a5\u3002 \u7b2cN\u5c42\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u548c\u7b2cN-1\u5c42\u7684\u6240\u6709\u795e\u7ecf\u5143\u76f8\u8fde(\u8fd9\u5c31\u662ffull connected\u7684\u542b\u4e49)\uff0c\u7b2cN-1\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u5c31\u662f\u7b2cN\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u5165\u3002 \u6bcf\u4e2a\u8fde\u63a5\u90fd\u6709\u4e00\u4e2a\u6743\u503c\u3002 3 \u795e\u7ecf\u5143\u662f\u5982\u4f55\u5de5\u4f5c\u7684\uff1f \u00b6 \u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u8f93\u5165\uff0c\u5bf9\u4ed6\u4eec\u8fdb\u884c\u52a0\u6743\u5e76\u76f8\u52a0\uff0c\u603b\u548c\u901a\u8fc7\u4e00\u4e2a\u975e\u7ebf\u6027\u51fd\u6570\u4ea7\u751f\u8f93\u51fa\u3002 \u6240\u6709\u7684\u8f93\u5165xi\uff0c\u4e0e\u76f8\u5e94\u7684\u6743\u91cdwi\u76f8\u4e58\u5e76\u6c42\u548c\uff1a \u5c06\u6c42\u548c\u7ed3\u679c\u9001\u5165\u5230\u6fc0\u6d3b\u51fd\u6570\u4e2d\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u7ed3\u679c\uff1a 3.1 \u6fc0\u6d3b\u51fd\u6570 \u00b6 \u5728\u795e\u7ecf\u5143\u4e2d\u5f15\u5165\u4e86\u6fc0\u6d3b\u51fd\u6570\uff0c\u5b83\u7684\u672c\u8d28\u662f\u5411\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f15\u5165\u975e\u7ebf\u6027\u56e0\u7d20\u7684\uff0c\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\u5c31\u53ef\u4ee5\u62df\u5408\u5404\u79cd\u66f2\u7ebf\u3002\u5982\u679c\u4e0d\u7528\u6fc0\u6d3b\u51fd\u6570\uff0c\u6bcf\u4e00\u5c42\u8f93\u51fa\u90fd\u662f\u4e0a\u5c42\u8f93\u5165\u7684\u7ebf\u6027\u51fd\u6570\uff0c\u65e0\u8bba\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c11\u5c42\uff0c\u8f93\u51fa\u90fd\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5f15\u5165\u975e\u7ebf\u6027\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u8f93\u51fa\u4e0d\u518d\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u53ef\u4ee5\u903c\u8fd1\u4efb\u610f\u51fd\u6570\u3002\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u6709\uff1a 3.1.1.Sigmoid/logistics\u51fd\u6570 \u00b6 \u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a sigmoid \u5728\u5b9a\u4e49\u57df\u5185\u5904\u5904\u53ef\u5bfc\uff0c\u4e14\u4e24\u4fa7\u5bfc\u6570\u9010\u6e10\u8d8b\u8fd1\u4e8e0\u3002\u5982\u679cX\u7684\u503c\u5f88\u5927\u6216\u8005\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u51fd\u6570\u7684\u68af\u5ea6\uff08\u51fd\u6570\u7684\u659c\u7387\uff09\u4f1a\u975e\u5e38\u5c0f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5bfc\u81f4\u4e86\u5411\u4f4e\u5c42\u4f20\u9012\u7684\u68af\u5ea6\u4e5f\u53d8\u5f97\u975e\u5e38\u5c0f\u3002\u6b64\u65f6\uff0c\u7f51\u7edc\u53c2\u6570\u5f88\u96be\u5f97\u5230\u6709\u6548\u8bad\u7ec3\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u68af\u5ea6\u6d88\u5931\u3002\u4e00\u822c\u6765\u8bf4\uff0c sigmoid \u7f51\u7edc\u5728 5 \u5c42\u4e4b\u5185\u5c31\u4f1a\u4ea7\u751f\u68af\u5ea6\u6d88\u5931\u73b0\u8c61\u3002\u800c\u4e14\uff0c\u8be5\u6fc0\u6d3b\u51fd\u6570\u5e76\u4e0d\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u6240\u4ee5\u5728\u5b9e\u8df5\u4e2d\u8fd9\u79cd\u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528\u7684\u5f88\u5c11\u3002sigmoid\u51fd\u6570\u4e00\u822c\u53ea\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u8f93\u51fa\u5c42\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . sigmoid ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a 3.1.2.tanh(\u53cc\u66f2\u6b63\u5207\u66f2\u7ebf) \u00b6 \u6570\u5b66\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a tanh\u4e5f\u662f\u4e00\u79cd\u975e\u5e38\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u4e0esigmoid\u76f8\u6bd4\uff0c\u5b83\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u4f7f\u5f97\u5176\u6536\u655b\u901f\u5ea6\u8981\u6bd4sigmoid\u5feb\uff0c\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002\u7136\u800c\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0ctanh\u4e24\u4fa7\u7684\u5bfc\u6570\u4e5f\u4e3a0\uff0c\u540c\u6837\u4f1a\u9020\u6210\u68af\u5ea6\u6d88\u5931\u3002 \u82e5\u4f7f\u7528\u65f6\u53ef\u5728\u9690\u85cf\u5c42\u4f7f\u7528tanh\u51fd\u6570\uff0c\u5728\u8f93\u51fa\u5c42\u4f7f\u7528sigmoid\u51fd\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . tanh ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a 3.1.3.RELU \u00b6 \u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a ReLU\u662f\u76ee\u524d\u6700\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c\u5f53x<0\u65f6\uff0cReLU\u5bfc\u6570\u4e3a0\uff0c\u800c\u5f53x>0\u65f6\uff0c\u5219\u4e0d\u5b58\u5728\u9971\u548c\u95ee\u9898\u3002\u6240\u4ee5\uff0cReLU \u80fd\u591f\u5728x>0\u65f6\u4fdd\u6301\u68af\u5ea6\u4e0d\u8870\u51cf\uff0c\u4ece\u800c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u7136\u800c\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u63a8\u8fdb\uff0c\u90e8\u5206\u8f93\u5165\u4f1a\u843d\u5165\u5c0f\u4e8e0\u533a\u57df\uff0c\u5bfc\u81f4\u5bf9\u5e94\u6743\u91cd\u65e0\u6cd5\u66f4\u65b0\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u795e\u7ecf\u5143\u6b7b\u4ea1\u201d\u3002 \u4e0esigmoid\u76f8\u6bd4\uff0cRELU\u7684\u4f18\u52bf\u662f\uff1a \u91c7\u7528sigmoid\u51fd\u6570\uff0c\u8ba1\u7b97\u91cf\u5927\uff08\u6307\u6570\u8fd0\u7b97\uff09\uff0c\u53cd\u5411\u4f20\u64ad\u6c42\u8bef\u5dee\u68af\u5ea6\u65f6\uff0c\u6c42\u5bfc\u6d89\u53ca\u9664\u6cd5\uff0c\u8ba1\u7b97\u91cf\u76f8\u5bf9\u5927\uff0c\u800c\u91c7\u7528Relu\u6fc0\u6d3b\u51fd\u6570\uff0c\u6574\u4e2a\u8fc7\u7a0b\u7684\u8ba1\u7b97\u91cf\u8282\u7701\u5f88\u591a\u3002 sigmoid\u51fd\u6570\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5f88\u5bb9\u6613\u5c31\u4f1a\u51fa\u73b0\u68af\u5ea6\u6d88\u5931\u7684\u60c5\u51b5\uff0c\u4ece\u800c\u65e0\u6cd5\u5b8c\u6210\u6df1\u5c42\u7f51\u7edc\u7684\u8bad\u7ec3\u3002 Relu\u4f1a\u4f7f\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u4e3a0\uff0c\u8fd9\u6837\u5c31\u9020\u6210\u4e86\u7f51\u7edc\u7684\u7a00\u758f\u6027\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u53c2\u6570\u7684\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\uff0c\u7f13\u89e3\u4e86\u8fc7\u62df\u5408\u95ee\u9898\u7684\u53d1\u751f\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a 3.1.4.LeakReLu \u00b6 \u8be5\u6fc0\u6d3b\u51fd\u6570\u662f\u5bf9RELU\u7684\u6539\u8fdb\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u6240\u793a\uff1a \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . leaky_relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () 3.1.5. SoftMax \u00b6 softmax\u7528\u4e8e\u591a\u5206\u7c7b\u8fc7\u7a0b\u4e2d\uff0c\u5b83\u662f\u4e8c\u5206\u7c7b\u51fd\u6570sigmoid\u5728\u591a\u5206\u7c7b\u4e0a\u7684\u63a8\u5e7f\uff0c\u76ee\u7684\u662f\u5c06\u591a\u5206\u7c7b\u7684\u7ed3\u679c\u4ee5\u6982\u7387\u7684\u5f62\u5f0f\u5c55\u73b0\u51fa\u6765\u3002 \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f7f\u7528\u65b9\u6cd5\uff1a softmax\u76f4\u767d\u6765\u8bf4\u5c31\u662f\u5c06\u7f51\u7edc\u8f93\u51fa\u7684logits\u901a\u8fc7softmax\u51fd\u6570\uff0c\u5c31\u6620\u5c04\u6210\u4e3a(0,1)\u7684\u503c\uff0c\u800c\u8fd9\u4e9b\u503c\u7684\u7d2f\u548c\u4e3a1\uff08\u6ee1\u8db3\u6982\u7387\u7684\u6027\u8d28\uff09\uff0c\u90a3\u4e48\u6211\u4eec\u5c06\u5b83\u7406\u89e3\u6210\u6982\u7387\uff0c\u9009\u53d6\u6982\u7387\u6700\u5927\uff08\u4e5f\u5c31\u662f\u503c\u5bf9\u5e94\u6700\u5927\u7684\uff09\u63a5\u70b9\uff0c\u4f5c\u4e3a\u6211\u4eec\u7684\u9884\u6d4b\u76ee\u6807\u7c7b\u522b\u3002 \u5b9e\u73b0\uff0c\u4ee5\u4e0a\u56fe\u4e2d\u6570\u5b579\u7684\u5206\u7c7b\u7ed3\u679c\u4e3a\u4f8b\u7ed9\u5927\u5bb6\u8fdb\u884c\u6f14\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u6570\u5b57\u4e2d\u7684score x = tf . constant ([ 0.2 , 0.02 , 0.15 , 1.3 , 0.5 , 0.06 , 1.1 , 0.05 , 3.75 ]) # \u5c06\u5176\u9001\u5165\u5230softmax\u4e2d\u8ba1\u7b97\u5206\u7c7b\u7ed3\u679c y = tf . nn . softmax ( x ) # \u5c06\u7ed3\u679c\u8fdb\u884c\u6253\u5370 print ( y ) \u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [ 0.02167152 0.01810157 0.02061459 0.06510484 0.02925349 0.01884031 0.05330333 0.01865285 0.75445753 ], shape = ( 9 ,), dtype = float32 ) 3.1.6. \u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570 \u00b6 3.1.7.\u5982\u4f55\u9009\u62e9\u6fc0\u6d3b\u51fd\u6570 \u00b6 \u9690\u85cf\u5c42 \u00b6 \u4f18\u5148\u9009\u62e9RELU\u6fc0\u6d3b\u51fd\u6570 \u5982\u679cReLu\u6548\u679c\u4e0d\u597d\uff0c\u90a3\u4e48\u5c1d\u8bd5\u5176\u4ed6\u6fc0\u6d3b\uff0c\u5982Leaky ReLu\u7b49\u3002 \u5982\u679c\u4f60\u4f7f\u7528\u4e86Relu\uff0c \u9700\u8981\u6ce8\u610f\u4e00\u4e0bDead Relu\u95ee\u9898\uff0c \u907f\u514d\u51fa\u73b0\u5927\u7684\u68af\u5ea6\u4ece\u800c\u5bfc\u81f4\u8fc7\u591a\u7684\u795e\u7ecf\u5143\u6b7b\u4ea1\u3002 \u4e0d\u8981\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528tanh\u6fc0\u6d3b\u51fd\u6570 \u8f93\u51fa\u5c42 \u00b6 \u4e8c\u5206\u7c7b\u95ee\u9898\u9009\u62e9sigmoid\u6fc0\u6d3b\u51fd\u6570 \u591a\u5206\u7c7b\u95ee\u9898\u9009\u62e9softmax\u6fc0\u6d3b\u51fd\u6570 \u56de\u5f52\u95ee\u9898\u9009\u62e9identity\u6fc0\u6d3b\u51fd\u6570 3.2 \u53c2\u6570\u521d\u59cb\u5316 \u00b6 \u5bf9\u4e8e\u67d0\u4e00\u4e2a\u795e\u7ecf\u5143\u6765\u8bf4\uff0c\u9700\u8981\u521d\u59cb\u5316\u7684\u53c2\u6570\u6709\u4e24\u7c7b\uff1a\u4e00\u7c7b\u662f\u6743\u91cdW\uff0c\u8fd8\u6709\u4e00\u7c7b\u662f\u504f\u7f6eb,\u504f\u7f6eb\u521d\u59cb\u5316\u4e3a0\u5373\u53ef\u3002\u800c\u6743\u91cdW\u7684\u521d\u59cb\u5316\u6bd4\u8f83\u91cd\u8981\uff0c\u6211\u4eec\u7740\u91cd\u6765\u4ecb\u7ecd\u5e38\u89c1\u7684\u521d\u59cb\u5316\u65b9\u5f0f\u3002 3.2.1.\u968f\u673a\u521d\u59cb\u5316 \u00b6 \u968f\u673a\u521d\u59cb\u5316\u4ece\u5747\u503c\u4e3a0\uff0c\u6807\u51c6\u5dee\u662f1\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u53d6\u6837\uff0c\u4f7f\u7528\u4e00\u4e9b\u5f88\u5c0f\u7684\u503c\u5bf9\u53c2\u6570W\u8fdb\u884c\u521d\u59cb\u5316\u3002 3.2.2.\u6807\u51c6\u521d\u59cb\u5316 \u00b6 \u6743\u91cd\u53c2\u6570\u521d\u59cb\u5316\u4ece\u533a\u95f4\u5747\u5300\u968f\u673a\u53d6\u503c\u3002\u5373\u5728(-1/\u221ad,1/\u221ad)\u5747\u5300\u5206\u5e03\u4e2d\u751f\u6210\u5f53\u524d\u795e\u7ecf\u5143\u7684\u6743\u91cd\uff0c\u5176\u4e2dd\u4e3a\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u8f93\u5165\u6570\u91cf\u3002 3.2.3.Xavier\u521d\u59cb\u5316 \u00b6 \u8be5\u65b9\u6cd5\u7684\u57fa\u672c\u601d\u60f3\u662f\u5404\u5c42\u7684\u6fc0\u6d3b\u503c\u548c\u68af\u5ea6\u7684\u65b9\u5dee\u5728\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e00\u81f4\uff0c\u4e5f\u53eb\u505aGlorot\u521d\u59cb\u5316\u3002\u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316Xavier\u521d\u59cb\u5316\uff1a Glorot \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / (fan_in + fan_out)) \u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.71967787 ] [ 0.56188506 ] [ - 0.7327265 ] [ - 0.05581591 ] [ - 0.05519835 ] [ 0.11283273 ] [ 0.8377778 ] [ 0.5832906 ] [ 0.10221979 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316Xavier\u521d\u59cb\u5316 Glorot \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / (fan_in + fan_out)) \uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.59119344 ] [ 0.06239486 ] [ 0.65161395 ] [ - 0.30347362 ] [ - 0.5407096 ] [ 0.35138106 ] [ 0.41150713 ] [ 0.32143414 ] [ - 0.57354397 ]], shape = ( 9 , 1 ), dtype = float32 ) 3.2.4.He\u521d\u59cb\u5316 \u00b6 he\u521d\u59cb\u5316\uff0c\u4e5f\u79f0\u4e3aKaiming\u521d\u59cb\u5316\uff0c\u51fa\u81ea\u5927\u795e\u4f55\u607a\u660e\u4e4b\u624b\uff0c\u5b83\u7684\u57fa\u672c\u601d\u60f3\u662f\u6b63\u5411\u4f20\u64ad\u65f6\uff0c\u6fc0\u6d3b\u503c\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\uff1b\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5173\u4e8e\u72b6\u6001\u503c\u7684\u68af\u5ea6\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\u3002\u5728tf.keras\u4e2d\u4e5f\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316\u7684he\u521d\u59cb\u5316 He \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u662f\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / fan_in) \u7684\u622a\u65ad\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c\u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.1488019 ] [ - 0.12102155 ] [ - 0.0163257 ] [ - 0.36920077 ] [ - 0.89464396 ] [ - 0.28749225 ] [ - 0.5467023 ] [ 0.27031776 ] [ - 0.1831588 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316\u7684he\u521d\u59cb\u5316 He \u5747\u5300\u65b9\u5dee\u7f29\u653e\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / fan_in) \uff0c \u5176\u4e2d fan_in \u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\u3002\u5b9e\u73b0\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.80033934 ] [ - 0.18773115 ] [ 0.6726284 ] [ - 0.23672342 ] [ - 0.6323329 ] [ 0.6048162 ] [ 0.1637358 ] [ 0.60797024 ] [ - 0.46316862 ]], shape = ( 9 , 1 ), dtype = float32 ) 4 \u795e\u7ecf\u7f51\u7edc\u7684\u642d\u5efa \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u6784\u5efa\u5982\u4e0b\u56fe\u6240\u793a\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a tf.Keras\u4e2d\u6784\u5efa\u6a21\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Sequential\u6784\u5efa\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Model\u7c7b\u6784\u5efa\u3002\u524d\u8005\u662f\u6309\u4e00\u5b9a\u7684\u987a\u5e8f\u5bf9\u5c42\u8fdb\u884c\u5806\u53e0\uff0c\u800c\u540e\u8005\u53ef\u4ee5\u7528\u6765\u6784\u5efa\u8f83\u590d\u6742\u7684\u7f51\u7edc\u6a21\u578b\u3002\u9996\u5148\u6211\u4eec\u4ecb\u7ecd\u4e0b\u7528\u6765\u6784\u5efa\u7f51\u7edc\u7684\u5168\u8fde\u63a5\u5c42\uff1a tf . keras . layers . Dense ( units , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' ) \u4e3b\u8981\u53c2\u6570\uff1a units: \u5f53\u524d\u5c42\u4e2d\u5305\u542b\u7684\u795e\u7ecf\u5143\u4e2a\u6570 Activation: \u6fc0\u6d3b\u51fd\u6570\uff0crelu,sigmoid\u7b49 use_bias: \u662f\u5426\u4f7f\u7528\u504f\u7f6e\uff0c\u9ed8\u8ba4\u4f7f\u7528\u504f\u7f6e Kernel_initializer: \u6743\u91cd\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u662fXavier\u521d\u59cb\u5316 bias_initializer: \u504f\u7f6e\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u4e3a0 4.1\u901a\u8fc7Sequential\u6784\u5efa \u00b6 Sequential() \u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u5feb\u901f\u5730\u5efa\u7acb\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # \u5b9a\u4e49\u4e00\u4e2aSequential\u6a21\u578b\uff0c\u5305\u542b3\u5c42 model = keras . Sequential ( [ # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)), # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ), # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ), ], name = \"my_Sequential\" ) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u5982\u4e0b\u6240\u793a\uff1a Model : \"my_Sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u901a\u8fc7\u8fd9\u79cdsequential\u7684\u65b9\u5f0f\u53ea\u80fd\u6784\u5efa\u7b80\u5355\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u8f83\u590d\u6742\u7684\u6a21\u578b\u6ca1\u6709\u529e\u6cd5\u5b9e\u73b0\u3002 4.2 \u5229\u7528function API\u6784\u5efa \u00b6 tf.keras \u63d0\u4f9b\u4e86 Functional API\uff0c\u5efa\u7acb\u66f4\u4e3a\u590d\u6742\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u65b9\u6cd5\u662f\u5c06\u5c42\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u5e76\u8fd4\u56de\u5f20\u91cf\uff0c\u5e76\u5c06\u8f93\u5165\u5411\u91cf\u548c\u8f93\u51fa\u5411\u91cf\u63d0\u4f9b\u7ed9 tf.keras.Model \u7684 inputs \u548c outputs \u53c2\u6570\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 3 ,), name = \"input\" ) # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 3 , activation = \"relu\" , name = \"layer1\" )( inputs ) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 2 , activation = \"relu\" , name = \"layer2\" )( x ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid outputs = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , name = \"layer3\" )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = outputs , name = \"my_model\" ) \u540c\u6837\u901a\u8fc7\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a Model : \"my_model\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 3 )] 0 _________________________________________________________________ layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u53e6\u5916\u4e5f\u53ef\u4ee5\u901a\u8fc7\uff1a # \u6a21\u578b\u5c55\u793a keras . utils . plot_model ( model , show_shapes = True ) 4.3 \u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa \u00b6 \u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa\u6a21\u578b\uff0c\u6b64\u65f6\u9700\u8981\u5728__init__\u4e2d\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\uff0c\u5728call\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49model\u7684\u5b50\u7c7b class MyModel ( tf . keras . Model ): # \u5728init\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u5c42\u7ed3\u6784 def __init__ ( self ): super ( MyModel , self ) . __init__ () # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer1 = tf . keras . layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer2 = tf . keras . layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer3 = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ) # \u5728call\u65b9\u6cd5\u4e2d\u4e07\u5b8c\u6210\u524d\u5411\u4f20\u64ad def call ( self , inputs ): x = self . layer1 ( inputs ) x = self . layer2 ( x ) return self . layer3 ( x ) # \u5b9e\u4f8b\u5316\u6a21\u578b model = MyModel () # \u8bbe\u7f6e\u4e00\u4e2a\u8f93\u5165\uff0c\u8c03\u7528\u6a21\u578b\uff08\u5426\u5219\u65e0\u6cd5\u4f7f\u7528summay()\uff09 x = tf . ones (( 1 , 3 )) y = model ( x ) \u540c\u6837\u7684\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7summay\u65b9\u6cd5\u6765\u67e5\u770b\u6a21\u578b\u6784\u5efa\u7684\u7ed3\u679c 5 \u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9 \u00b6 1.\u4f18\u70b9 \u00b6 \u7cbe\u5ea6\u9ad8\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u9886\u57df\u8d85\u8fc7\u4e86\u4eba\u7c7b \u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u7684\u975e\u7ebf\u6027\u51fd\u6570 \u968f\u4e4b\u8ba1\u7b97\u673a\u786c\u4ef6\u7684\u53d1\u5c55\uff0c\u8fd1\u5e74\u6765\u5728\u5b66\u754c\u548c\u4e1a\u754c\u53d7\u5230\u4e86\u70ed\u6367\uff0c\u6709\u5927\u91cf\u7684\u6846\u67b6\u548c\u5e93\u53ef\u4f9b\u8c03\u7528 2.\u7f3a\u70b9 \u00b6 \u9ed1\u7bb1\uff0c\u5f88\u96be\u89e3\u91ca\u6a21\u578b\u662f\u600e\u4e48\u5de5\u4f5c\u7684 \u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u529b \u7f51\u7edc\u7ed3\u6784\u590d\u6742\uff0c\u9700\u8981\u8c03\u6574\u8d85\u53c2\u6570 \u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u53d1\u751f\u8fc7\u62df\u5408 \u603b\u7ed3 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e3b\u8981\u533a\u522b\u5728\u662f\u5426\u5305\u542b\u7279\u5f81\u5de5\u7a0b \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u9ed8\u8ba4\u4f7f\u7528relu\uff0c\u4e8c\u5206\u7c7b\u662fsigmoid, \u591a\u5206\u7c7b\u662fsoftmaxs \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u968f\u673a\u521d\u59cb\u5316\uff0c\u6807\u51c6\u521d\u59cb\u5316\uff0cXavier\u521d\u59cb\u5316\uff0cHe\u521d\u59cb\u5316 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b Sequential\u7684\u65b9\u6cd5\uff0cModel\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\uff0c\u6784\u5efamodel\u7684\u5b50\u7c7b\u5b9e\u73b0 \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","title":"\u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb"},{"location":"deeplearning/section1/#21","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","title":"2.1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb"},{"location":"deeplearning/section1/#1","text":"\u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u8fd9\u5e45\u56fe\uff1a\u4eba\u5de5\u667a\u80fd>\u673a\u5668\u5b66\u4e60>\u6df1\u5ea6\u5b66\u4e60 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\uff0c\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7**\u62e5\u6709\u4f17\u591a\u5c42\u6570\u795e\u7ecf\u7f51\u7edc(Neural Network)**\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6765\u770b\u5e38\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5305\u62ec\uff1a \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(Convolutional Neural Network) \u5faa\u73af\u795e\u7ecf\u7f51\u7edc(Recurrent Neural Network) \u751f\u6210\u5bf9\u6297\u7f51\u7edc(Generative Adversarial Networks) **\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(Deep Reinforcement Learning)**\u7b49\u3002","title":"1 \u6df1\u5ea6\u5b66\u4e60\u7b80\u4ecb"},{"location":"deeplearning/section1/#2","text":"\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08 Artificial Neural Network\uff0c \u7b80\u5199\u4e3aANN\uff09\u4e5f\u7b80\u79f0\u4e3a\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09 \uff0c\u662f\u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u3002\u4eba\u8111\u53ef\u4ee5\u770b\u505a\u662f\u4e00\u4e2a\u751f\u7269\u795e\u7ecf\u7f51\u7edc\uff0c\u7531\u4f17\u591a\u7684\u795e\u7ecf\u5143\u8fde\u63a5\u800c\u6210\u3002\u5404\u4e2a\u795e\u7ecf\u5143\u4f20\u9012\u590d\u6742\u7684\u7535\u4fe1\u53f7\uff0c\u6811\u7a81\u63a5\u6536\u5230\u8f93\u5165\u4fe1\u53f7\uff0c\u7136\u540e\u5bf9\u4fe1\u53f7\u8fdb\u884c\u5904\u7406\uff0c\u901a\u8fc7\u8f74\u7a81\u8f93\u51fa\u4fe1\u53f7\u3002\u4e0b\u56fe\u662f\u751f\u7269\u795e\u7ecf\u5143\u793a\u610f\u56fe\uff1a \u90a3\u600e\u4e48\u6784\u5efa\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u795e\u7ecf\u5143\u5462\uff1f \u53d7\u751f\u7269\u795e\u7ecf\u5143\u7684\u542f\u53d1\uff0c\u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u6765\u81ea\u5176\u4ed6\u795e\u7ecf\u5143\u6216\u5916\u90e8\u6e90\u7684\u8f93\u5165\uff0c\u6bcf\u4e2a\u8f93\u5165\u90fd\u6709\u4e00\u4e2a\u76f8\u5173\u7684\u6743\u503c(w)\uff0c\u5b83\u662f\u6839\u636e\u8be5\u8f93\u5165\u5bf9\u5f53\u524d\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\u6765\u786e\u5b9a\u7684\uff0c\u5bf9\u8be5\u8f93\u5165\u52a0\u6743\u5e76\u4e0e\u5176\u4ed6\u8f93\u5165\u6c42\u548c\u540e\uff0c\u7ecf\u8fc7\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570f\uff0c\u8ba1\u7b97\u5f97\u5230\u8be5\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u3002 \u90a3\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5229\u7528\u795e\u7ecf\u5143\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u90bb\u5c42\u4e4b\u95f4\u7684\u795e\u7ecf\u5143\u76f8\u4e92\u8fde\u63a5\uff0c\u5e76\u7ed9\u6bcf\u4e00\u4e2a\u8fde\u63a5\u5206\u914d\u4e00\u4e2a\u5f3a\u5ea6\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u795e\u7ecf\u7f51\u7edc\u4e2d\u4fe1\u606f\u53ea\u5411\u4e00\u4e2a\u65b9\u5411\u79fb\u52a8\uff0c\u5373\u4ece\u8f93\u5165\u8282\u70b9\u5411\u524d\u79fb\u52a8\uff0c\u901a\u8fc7\u9690\u85cf\u8282\u70b9\uff0c\u518d\u5411\u8f93\u51fa\u8282\u70b9\u79fb\u52a8\uff0c\u7f51\u7edc\u4e2d\u6ca1\u6709\u5faa\u73af\u6216\u8005\u73af\u3002\u5176\u4e2d\u7684\u57fa\u672c\u6784\u4ef6\u662f\uff1a \u8f93\u5165\u5c42 \uff1a\u5373\u8f93\u5165x\u7684\u90a3\u4e00\u5c42 \u8f93\u51fa\u5c42 \uff1a\u5373\u8f93\u51fay\u7684\u90a3\u4e00\u5c42 \u9690\u85cf\u5c42 \uff1a\u8f93\u5165\u5c42\u548c\u8f93\u51fa\u5c42\u4e4b\u95f4\u90fd\u662f\u9690\u85cf\u5c42 \u7279\u70b9\u662f\uff1a \u540c\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u4e4b\u95f4\u6ca1\u6709\u8fde\u63a5\u3002 \u7b2cN\u5c42\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u548c\u7b2cN-1\u5c42\u7684\u6240\u6709\u795e\u7ecf\u5143\u76f8\u8fde(\u8fd9\u5c31\u662ffull connected\u7684\u542b\u4e49)\uff0c\u7b2cN-1\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u5c31\u662f\u7b2cN\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u5165\u3002 \u6bcf\u4e2a\u8fde\u63a5\u90fd\u6709\u4e00\u4e2a\u6743\u503c\u3002","title":"2 \u4ec0\u4e48\u662f\u795e\u7ecf\u7f51\u7edc"},{"location":"deeplearning/section1/#3","text":"\u4eba\u5de5\u795e\u7ecf\u5143\u63a5\u6536\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u8f93\u5165\uff0c\u5bf9\u4ed6\u4eec\u8fdb\u884c\u52a0\u6743\u5e76\u76f8\u52a0\uff0c\u603b\u548c\u901a\u8fc7\u4e00\u4e2a\u975e\u7ebf\u6027\u51fd\u6570\u4ea7\u751f\u8f93\u51fa\u3002 \u6240\u6709\u7684\u8f93\u5165xi\uff0c\u4e0e\u76f8\u5e94\u7684\u6743\u91cdwi\u76f8\u4e58\u5e76\u6c42\u548c\uff1a \u5c06\u6c42\u548c\u7ed3\u679c\u9001\u5165\u5230\u6fc0\u6d3b\u51fd\u6570\u4e2d\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u7ed3\u679c\uff1a","title":"3 \u795e\u7ecf\u5143\u662f\u5982\u4f55\u5de5\u4f5c\u7684\uff1f"},{"location":"deeplearning/section1/#31","text":"\u5728\u795e\u7ecf\u5143\u4e2d\u5f15\u5165\u4e86\u6fc0\u6d3b\u51fd\u6570\uff0c\u5b83\u7684\u672c\u8d28\u662f\u5411\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f15\u5165\u975e\u7ebf\u6027\u56e0\u7d20\u7684\uff0c\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\u5c31\u53ef\u4ee5\u62df\u5408\u5404\u79cd\u66f2\u7ebf\u3002\u5982\u679c\u4e0d\u7528\u6fc0\u6d3b\u51fd\u6570\uff0c\u6bcf\u4e00\u5c42\u8f93\u51fa\u90fd\u662f\u4e0a\u5c42\u8f93\u5165\u7684\u7ebf\u6027\u51fd\u6570\uff0c\u65e0\u8bba\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c11\u5c42\uff0c\u8f93\u51fa\u90fd\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5f15\u5165\u975e\u7ebf\u6027\u51fd\u6570\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u8f93\u51fa\u4e0d\u518d\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u53ef\u4ee5\u903c\u8fd1\u4efb\u610f\u51fd\u6570\u3002\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u6709\uff1a","title":"3.1 \u6fc0\u6d3b\u51fd\u6570"},{"location":"deeplearning/section1/#311sigmoidlogistics","text":"\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a sigmoid \u5728\u5b9a\u4e49\u57df\u5185\u5904\u5904\u53ef\u5bfc\uff0c\u4e14\u4e24\u4fa7\u5bfc\u6570\u9010\u6e10\u8d8b\u8fd1\u4e8e0\u3002\u5982\u679cX\u7684\u503c\u5f88\u5927\u6216\u8005\u5f88\u5c0f\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u51fd\u6570\u7684\u68af\u5ea6\uff08\u51fd\u6570\u7684\u659c\u7387\uff09\u4f1a\u975e\u5e38\u5c0f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5bfc\u81f4\u4e86\u5411\u4f4e\u5c42\u4f20\u9012\u7684\u68af\u5ea6\u4e5f\u53d8\u5f97\u975e\u5e38\u5c0f\u3002\u6b64\u65f6\uff0c\u7f51\u7edc\u53c2\u6570\u5f88\u96be\u5f97\u5230\u6709\u6548\u8bad\u7ec3\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u68af\u5ea6\u6d88\u5931\u3002\u4e00\u822c\u6765\u8bf4\uff0c sigmoid \u7f51\u7edc\u5728 5 \u5c42\u4e4b\u5185\u5c31\u4f1a\u4ea7\u751f\u68af\u5ea6\u6d88\u5931\u73b0\u8c61\u3002\u800c\u4e14\uff0c\u8be5\u6fc0\u6d3b\u51fd\u6570\u5e76\u4e0d\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u6240\u4ee5\u5728\u5b9e\u8df5\u4e2d\u8fd9\u79cd\u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528\u7684\u5f88\u5c11\u3002sigmoid\u51fd\u6570\u4e00\u822c\u53ea\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u8f93\u51fa\u5c42\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . sigmoid ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a","title":"3.1.1.Sigmoid/logistics\u51fd\u6570"},{"location":"deeplearning/section1/#312tanh","text":"\u6570\u5b66\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a tanh\u4e5f\u662f\u4e00\u79cd\u975e\u5e38\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u4e0esigmoid\u76f8\u6bd4\uff0c\u5b83\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff0c\u4f7f\u5f97\u5176\u6536\u655b\u901f\u5ea6\u8981\u6bd4sigmoid\u5feb\uff0c\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002\u7136\u800c\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0ctanh\u4e24\u4fa7\u7684\u5bfc\u6570\u4e5f\u4e3a0\uff0c\u540c\u6837\u4f1a\u9020\u6210\u68af\u5ea6\u6d88\u5931\u3002 \u82e5\u4f7f\u7528\u65f6\u53ef\u5728\u9690\u85cf\u5c42\u4f7f\u7528tanh\u51fd\u6570\uff0c\u5728\u8f93\u51fa\u5c42\u4f7f\u7528sigmoid\u51fd\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . tanh ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a","title":"3.1.2.tanh(\u53cc\u66f2\u6b63\u5207\u66f2\u7ebf)"},{"location":"deeplearning/section1/#313relu","text":"\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a ReLU\u662f\u76ee\u524d\u6700\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c\u5f53x<0\u65f6\uff0cReLU\u5bfc\u6570\u4e3a0\uff0c\u800c\u5f53x>0\u65f6\uff0c\u5219\u4e0d\u5b58\u5728\u9971\u548c\u95ee\u9898\u3002\u6240\u4ee5\uff0cReLU \u80fd\u591f\u5728x>0\u65f6\u4fdd\u6301\u68af\u5ea6\u4e0d\u8870\u51cf\uff0c\u4ece\u800c\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u7136\u800c\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u63a8\u8fdb\uff0c\u90e8\u5206\u8f93\u5165\u4f1a\u843d\u5165\u5c0f\u4e8e0\u533a\u57df\uff0c\u5bfc\u81f4\u5bf9\u5e94\u6743\u91cd\u65e0\u6cd5\u66f4\u65b0\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u795e\u7ecf\u5143\u6b7b\u4ea1\u201d\u3002 \u4e0esigmoid\u76f8\u6bd4\uff0cRELU\u7684\u4f18\u52bf\u662f\uff1a \u91c7\u7528sigmoid\u51fd\u6570\uff0c\u8ba1\u7b97\u91cf\u5927\uff08\u6307\u6570\u8fd0\u7b97\uff09\uff0c\u53cd\u5411\u4f20\u64ad\u6c42\u8bef\u5dee\u68af\u5ea6\u65f6\uff0c\u6c42\u5bfc\u6d89\u53ca\u9664\u6cd5\uff0c\u8ba1\u7b97\u91cf\u76f8\u5bf9\u5927\uff0c\u800c\u91c7\u7528Relu\u6fc0\u6d3b\u51fd\u6570\uff0c\u6574\u4e2a\u8fc7\u7a0b\u7684\u8ba1\u7b97\u91cf\u8282\u7701\u5f88\u591a\u3002 sigmoid\u51fd\u6570\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5f88\u5bb9\u6613\u5c31\u4f1a\u51fa\u73b0\u68af\u5ea6\u6d88\u5931\u7684\u60c5\u51b5\uff0c\u4ece\u800c\u65e0\u6cd5\u5b8c\u6210\u6df1\u5c42\u7f51\u7edc\u7684\u8bad\u7ec3\u3002 Relu\u4f1a\u4f7f\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u4e3a0\uff0c\u8fd9\u6837\u5c31\u9020\u6210\u4e86\u7f51\u7edc\u7684\u7a00\u758f\u6027\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u53c2\u6570\u7684\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\uff0c\u7f13\u89e3\u4e86\u8fc7\u62df\u5408\u95ee\u9898\u7684\u53d1\u751f\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid () \u7ed8\u5236\u7ed3\u679c\u4e3a\uff1a","title":"3.1.3.RELU"},{"location":"deeplearning/section1/#314leakrelu","text":"\u8be5\u6fc0\u6d3b\u51fd\u6570\u662f\u5bf9RELU\u7684\u6539\u8fdb\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a\uff1a \u66f2\u7ebf\u5982\u4e0b\u6240\u793a\uff1a \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u5b9a\u4e49x\u7684\u53d6\u503c\u8303\u56f4 x = np . linspace ( - 10 , 10 , 100 ) # \u76f4\u63a5\u4f7f\u7528tensorflow\u5b9e\u73b0 y = tf . nn . leaky_relu ( x ) # \u7ed8\u56fe plt . plot ( x , y ) plt . grid ()","title":"3.1.4.LeakReLu"},{"location":"deeplearning/section1/#315-softmax","text":"softmax\u7528\u4e8e\u591a\u5206\u7c7b\u8fc7\u7a0b\u4e2d\uff0c\u5b83\u662f\u4e8c\u5206\u7c7b\u51fd\u6570sigmoid\u5728\u591a\u5206\u7c7b\u4e0a\u7684\u63a8\u5e7f\uff0c\u76ee\u7684\u662f\u5c06\u591a\u5206\u7c7b\u7684\u7ed3\u679c\u4ee5\u6982\u7387\u7684\u5f62\u5f0f\u5c55\u73b0\u51fa\u6765\u3002 \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f7f\u7528\u65b9\u6cd5\uff1a softmax\u76f4\u767d\u6765\u8bf4\u5c31\u662f\u5c06\u7f51\u7edc\u8f93\u51fa\u7684logits\u901a\u8fc7softmax\u51fd\u6570\uff0c\u5c31\u6620\u5c04\u6210\u4e3a(0,1)\u7684\u503c\uff0c\u800c\u8fd9\u4e9b\u503c\u7684\u7d2f\u548c\u4e3a1\uff08\u6ee1\u8db3\u6982\u7387\u7684\u6027\u8d28\uff09\uff0c\u90a3\u4e48\u6211\u4eec\u5c06\u5b83\u7406\u89e3\u6210\u6982\u7387\uff0c\u9009\u53d6\u6982\u7387\u6700\u5927\uff08\u4e5f\u5c31\u662f\u503c\u5bf9\u5e94\u6700\u5927\u7684\uff09\u63a5\u70b9\uff0c\u4f5c\u4e3a\u6211\u4eec\u7684\u9884\u6d4b\u76ee\u6807\u7c7b\u522b\u3002 \u5b9e\u73b0\uff0c\u4ee5\u4e0a\u56fe\u4e2d\u6570\u5b579\u7684\u5206\u7c7b\u7ed3\u679c\u4e3a\u4f8b\u7ed9\u5927\u5bb6\u8fdb\u884c\u6f14\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import tensorflow.keras as keras import matplotlib.pyplot as plt import numpy as np # \u6570\u5b57\u4e2d\u7684score x = tf . constant ([ 0.2 , 0.02 , 0.15 , 1.3 , 0.5 , 0.06 , 1.1 , 0.05 , 3.75 ]) # \u5c06\u5176\u9001\u5165\u5230softmax\u4e2d\u8ba1\u7b97\u5206\u7c7b\u7ed3\u679c y = tf . nn . softmax ( x ) # \u5c06\u7ed3\u679c\u8fdb\u884c\u6253\u5370 print ( y ) \u5206\u7c7b\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [ 0.02167152 0.01810157 0.02061459 0.06510484 0.02925349 0.01884031 0.05330333 0.01865285 0.75445753 ], shape = ( 9 ,), dtype = float32 )","title":"3.1.5. SoftMax"},{"location":"deeplearning/section1/#316","text":"","title":"3.1.6. \u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570"},{"location":"deeplearning/section1/#317","text":"","title":"3.1.7.\u5982\u4f55\u9009\u62e9\u6fc0\u6d3b\u51fd\u6570"},{"location":"deeplearning/section1/#_1","text":"\u4f18\u5148\u9009\u62e9RELU\u6fc0\u6d3b\u51fd\u6570 \u5982\u679cReLu\u6548\u679c\u4e0d\u597d\uff0c\u90a3\u4e48\u5c1d\u8bd5\u5176\u4ed6\u6fc0\u6d3b\uff0c\u5982Leaky ReLu\u7b49\u3002 \u5982\u679c\u4f60\u4f7f\u7528\u4e86Relu\uff0c \u9700\u8981\u6ce8\u610f\u4e00\u4e0bDead Relu\u95ee\u9898\uff0c \u907f\u514d\u51fa\u73b0\u5927\u7684\u68af\u5ea6\u4ece\u800c\u5bfc\u81f4\u8fc7\u591a\u7684\u795e\u7ecf\u5143\u6b7b\u4ea1\u3002 \u4e0d\u8981\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528tanh\u6fc0\u6d3b\u51fd\u6570","title":"\u9690\u85cf\u5c42"},{"location":"deeplearning/section1/#_2","text":"\u4e8c\u5206\u7c7b\u95ee\u9898\u9009\u62e9sigmoid\u6fc0\u6d3b\u51fd\u6570 \u591a\u5206\u7c7b\u95ee\u9898\u9009\u62e9softmax\u6fc0\u6d3b\u51fd\u6570 \u56de\u5f52\u95ee\u9898\u9009\u62e9identity\u6fc0\u6d3b\u51fd\u6570","title":"\u8f93\u51fa\u5c42"},{"location":"deeplearning/section1/#32","text":"\u5bf9\u4e8e\u67d0\u4e00\u4e2a\u795e\u7ecf\u5143\u6765\u8bf4\uff0c\u9700\u8981\u521d\u59cb\u5316\u7684\u53c2\u6570\u6709\u4e24\u7c7b\uff1a\u4e00\u7c7b\u662f\u6743\u91cdW\uff0c\u8fd8\u6709\u4e00\u7c7b\u662f\u504f\u7f6eb,\u504f\u7f6eb\u521d\u59cb\u5316\u4e3a0\u5373\u53ef\u3002\u800c\u6743\u91cdW\u7684\u521d\u59cb\u5316\u6bd4\u8f83\u91cd\u8981\uff0c\u6211\u4eec\u7740\u91cd\u6765\u4ecb\u7ecd\u5e38\u89c1\u7684\u521d\u59cb\u5316\u65b9\u5f0f\u3002","title":"3.2 \u53c2\u6570\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#321","text":"\u968f\u673a\u521d\u59cb\u5316\u4ece\u5747\u503c\u4e3a0\uff0c\u6807\u51c6\u5dee\u662f1\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u53d6\u6837\uff0c\u4f7f\u7528\u4e00\u4e9b\u5f88\u5c0f\u7684\u503c\u5bf9\u53c2\u6570W\u8fdb\u884c\u521d\u59cb\u5316\u3002","title":"3.2.1.\u968f\u673a\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#322","text":"\u6743\u91cd\u53c2\u6570\u521d\u59cb\u5316\u4ece\u533a\u95f4\u5747\u5300\u968f\u673a\u53d6\u503c\u3002\u5373\u5728(-1/\u221ad,1/\u221ad)\u5747\u5300\u5206\u5e03\u4e2d\u751f\u6210\u5f53\u524d\u795e\u7ecf\u5143\u7684\u6743\u91cd\uff0c\u5176\u4e2dd\u4e3a\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u8f93\u5165\u6570\u91cf\u3002","title":"3.2.2.\u6807\u51c6\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#323xavier","text":"\u8be5\u65b9\u6cd5\u7684\u57fa\u672c\u601d\u60f3\u662f\u5404\u5c42\u7684\u6fc0\u6d3b\u503c\u548c\u68af\u5ea6\u7684\u65b9\u5dee\u5728\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e00\u81f4\uff0c\u4e5f\u53eb\u505aGlorot\u521d\u59cb\u5316\u3002\u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316Xavier\u521d\u59cb\u5316\uff1a Glorot \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / (fan_in + fan_out)) \u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 \u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.71967787 ] [ 0.56188506 ] [ - 0.7327265 ] [ - 0.05581591 ] [ - 0.05519835 ] [ 0.11283273 ] [ 0.8377778 ] [ 0.5832906 ] [ 0.10221979 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316Xavier\u521d\u59cb\u5316 Glorot \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\uff0c\u4e5f\u79f0\u4e3a Xavier \u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / (fan_in + fan_out)) \uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c fan_out \u662f\u8f93\u51fa\u7684\u795e\u7ecf\u5143\u4e2a\u6570\u3002 # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . glorot_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.59119344 ] [ 0.06239486 ] [ 0.65161395 ] [ - 0.30347362 ] [ - 0.5407096 ] [ 0.35138106 ] [ 0.41150713 ] [ 0.32143414 ] [ - 0.57354397 ]], shape = ( 9 , 1 ), dtype = float32 )","title":"3.2.3.Xavier\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#324he","text":"he\u521d\u59cb\u5316\uff0c\u4e5f\u79f0\u4e3aKaiming\u521d\u59cb\u5316\uff0c\u51fa\u81ea\u5927\u795e\u4f55\u607a\u660e\u4e4b\u624b\uff0c\u5b83\u7684\u57fa\u672c\u601d\u60f3\u662f\u6b63\u5411\u4f20\u64ad\u65f6\uff0c\u6fc0\u6d3b\u503c\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\uff1b\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u5173\u4e8e\u72b6\u6001\u503c\u7684\u68af\u5ea6\u7684\u65b9\u5dee\u4fdd\u6301\u4e0d\u53d8\u3002\u5728tf.keras\u4e2d\u4e5f\u6709\u4e24\u79cd\uff1a \u6b63\u6001\u5316\u7684he\u521d\u59cb\u5316 He \u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u662f\u4ee5 0 \u4e3a\u4e2d\u5fc3\uff0c\u6807\u51c6\u5dee\u4e3a stddev = sqrt(2 / fan_in) \u7684\u622a\u65ad\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d fan_in \u662f\u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c\u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_normal () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ - 0.1488019 ] [ - 0.12102155 ] [ - 0.0163257 ] [ - 0.36920077 ] [ - 0.89464396 ] [ - 0.28749225 ] [ - 0.5467023 ] [ 0.27031776 ] [ - 0.1831588 ]], shape = ( 9 , 1 ), dtype = float32 ) \u6807\u51c6\u5316\u7684he\u521d\u59cb\u5316 He \u5747\u5300\u65b9\u5dee\u7f29\u653e\u521d\u59cb\u5316\u5668\u3002\u5b83\u4ece [-limit\uff0climit] \u4e2d\u7684\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c\uff0c \u5176\u4e2d limit \u662f sqrt(6 / fan_in) \uff0c \u5176\u4e2d fan_in \u8f93\u5165\u795e\u7ecf\u5143\u7684\u4e2a\u6570\u3002\u5b9e\u73b0\u4e3a\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u8fdb\u884c\u5b9e\u4f8b\u5316 initializer = tf . keras . initializers . he_uniform () # \u91c7\u6837\u5f97\u5230\u6743\u91cd\u503c values = initializer ( shape = ( 9 , 1 )) # \u6253\u5370\u7ed3\u679c print ( values ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 0.80033934 ] [ - 0.18773115 ] [ 0.6726284 ] [ - 0.23672342 ] [ - 0.6323329 ] [ 0.6048162 ] [ 0.1637358 ] [ 0.60797024 ] [ - 0.46316862 ]], shape = ( 9 , 1 ), dtype = float32 )","title":"3.2.4.He\u521d\u59cb\u5316"},{"location":"deeplearning/section1/#4","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u6765\u6784\u5efa\u5982\u4e0b\u56fe\u6240\u793a\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a tf.Keras\u4e2d\u6784\u5efa\u6a21\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Sequential\u6784\u5efa\uff0c\u4e00\u79cd\u662f\u901a\u8fc7Model\u7c7b\u6784\u5efa\u3002\u524d\u8005\u662f\u6309\u4e00\u5b9a\u7684\u987a\u5e8f\u5bf9\u5c42\u8fdb\u884c\u5806\u53e0\uff0c\u800c\u540e\u8005\u53ef\u4ee5\u7528\u6765\u6784\u5efa\u8f83\u590d\u6742\u7684\u7f51\u7edc\u6a21\u578b\u3002\u9996\u5148\u6211\u4eec\u4ecb\u7ecd\u4e0b\u7528\u6765\u6784\u5efa\u7f51\u7edc\u7684\u5168\u8fde\u63a5\u5c42\uff1a tf . keras . layers . Dense ( units , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' ) \u4e3b\u8981\u53c2\u6570\uff1a units: \u5f53\u524d\u5c42\u4e2d\u5305\u542b\u7684\u795e\u7ecf\u5143\u4e2a\u6570 Activation: \u6fc0\u6d3b\u51fd\u6570\uff0crelu,sigmoid\u7b49 use_bias: \u662f\u5426\u4f7f\u7528\u504f\u7f6e\uff0c\u9ed8\u8ba4\u4f7f\u7528\u504f\u7f6e Kernel_initializer: \u6743\u91cd\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u662fXavier\u521d\u59cb\u5316 bias_initializer: \u504f\u7f6e\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u4e3a0","title":"4 \u795e\u7ecf\u7f51\u7edc\u7684\u642d\u5efa"},{"location":"deeplearning/section1/#41sequential","text":"Sequential() \u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u5feb\u901f\u5730\u5efa\u7acb\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # \u5b9a\u4e49\u4e00\u4e2aSequential\u6a21\u578b\uff0c\u5305\u542b3\u5c42 model = keras . Sequential ( [ # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)), # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ), # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ), ], name = \"my_Sequential\" ) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u5982\u4e0b\u6240\u793a\uff1a Model : \"my_Sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u901a\u8fc7\u8fd9\u79cdsequential\u7684\u65b9\u5f0f\u53ea\u80fd\u6784\u5efa\u7b80\u5355\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u8f83\u590d\u6742\u7684\u6a21\u578b\u6ca1\u6709\u529e\u6cd5\u5b9e\u73b0\u3002","title":"4.1\u901a\u8fc7Sequential\u6784\u5efa"},{"location":"deeplearning/section1/#42-function-api","text":"tf.keras \u63d0\u4f9b\u4e86 Functional API\uff0c\u5efa\u7acb\u66f4\u4e3a\u590d\u6742\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u65b9\u6cd5\u662f\u5c06\u5c42\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u5e76\u8fd4\u56de\u5f20\u91cf\uff0c\u5e76\u5c06\u8f93\u5165\u5411\u91cf\u548c\u8f93\u51fa\u5411\u91cf\u63d0\u4f9b\u7ed9 tf.keras.Model \u7684 inputs \u548c outputs \u53c2\u6570\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 3 ,), name = \"input\" ) # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 3 , activation = \"relu\" , name = \"layer1\" )( inputs ) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\uff0c\u5176\u4ed6\u9ed8\u8ba4 x = tf . keras . layers . Dense ( 2 , activation = \"relu\" , name = \"layer2\" )( x ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid outputs = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , name = \"layer3\" )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = outputs , name = \"my_model\" ) \u540c\u6837\u901a\u8fc7\uff1a # \u5c55\u793a\u6a21\u578b\u7ed3\u679c model . summary () \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a Model : \"my_model\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 3 )] 0 _________________________________________________________________ layer1 ( Dense ) ( None , 3 ) 12 _________________________________________________________________ layer2 ( Dense ) ( None , 2 ) 8 _________________________________________________________________ layer3 ( Dense ) ( None , 2 ) 6 ================================================================= Total params : 26 Trainable params : 26 Non - trainable params : 0 _________________________________________________________________ \u53e6\u5916\u4e5f\u53ef\u4ee5\u901a\u8fc7\uff1a # \u6a21\u578b\u5c55\u793a keras . utils . plot_model ( model , show_shapes = True )","title":"4.2 \u5229\u7528function API\u6784\u5efa"},{"location":"deeplearning/section1/#43-model","text":"\u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa\u6a21\u578b\uff0c\u6b64\u65f6\u9700\u8981\u5728__init__\u4e2d\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\uff0c\u5728call\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf # \u5b9a\u4e49model\u7684\u5b50\u7c7b class MyModel ( tf . keras . Model ): # \u5728init\u65b9\u6cd5\u4e2d\u5b9a\u4e49\u7f51\u7edc\u7684\u5c42\u7ed3\u6784 def __init__ ( self ): super ( MyModel , self ) . __init__ () # \u7b2c\u4e00\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer1 = tf . keras . layers . Dense ( 3 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer1\" , input_shape = ( 3 ,)) # \u7b2c\u4e8c\u5c42\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer2 = tf . keras . layers . Dense ( 2 , activation = \"relu\" , kernel_initializer = \"he_normal\" , name = \"layer2\" ) # \u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\uff1a\u6fc0\u6d3b\u51fd\u6570\u4e3asigmoid,\u6743\u91cd\u521d\u59cb\u5316\u4e3ahe_normal self . layer3 = tf . keras . layers . Dense ( 2 , activation = \"sigmoid\" , kernel_initializer = \"he_normal\" , name = \"layer3\" ) # \u5728call\u65b9\u6cd5\u4e2d\u4e07\u5b8c\u6210\u524d\u5411\u4f20\u64ad def call ( self , inputs ): x = self . layer1 ( inputs ) x = self . layer2 ( x ) return self . layer3 ( x ) # \u5b9e\u4f8b\u5316\u6a21\u578b model = MyModel () # \u8bbe\u7f6e\u4e00\u4e2a\u8f93\u5165\uff0c\u8c03\u7528\u6a21\u578b\uff08\u5426\u5219\u65e0\u6cd5\u4f7f\u7528summay()\uff09 x = tf . ones (( 1 , 3 )) y = model ( x ) \u540c\u6837\u7684\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7summay\u65b9\u6cd5\u6765\u67e5\u770b\u6a21\u578b\u6784\u5efa\u7684\u7ed3\u679c","title":"4.3 \u901a\u8fc7model\u7684\u5b50\u7c7b\u6784\u5efa"},{"location":"deeplearning/section1/#5","text":"","title":"5 \u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9"},{"location":"deeplearning/section1/#1_1","text":"\u7cbe\u5ea6\u9ad8\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u9886\u57df\u8d85\u8fc7\u4e86\u4eba\u7c7b \u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u7684\u975e\u7ebf\u6027\u51fd\u6570 \u968f\u4e4b\u8ba1\u7b97\u673a\u786c\u4ef6\u7684\u53d1\u5c55\uff0c\u8fd1\u5e74\u6765\u5728\u5b66\u754c\u548c\u4e1a\u754c\u53d7\u5230\u4e86\u70ed\u6367\uff0c\u6709\u5927\u91cf\u7684\u6846\u67b6\u548c\u5e93\u53ef\u4f9b\u8c03\u7528","title":"1.\u4f18\u70b9"},{"location":"deeplearning/section1/#2_1","text":"\u9ed1\u7bb1\uff0c\u5f88\u96be\u89e3\u91ca\u6a21\u578b\u662f\u600e\u4e48\u5de5\u4f5c\u7684 \u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u529b \u7f51\u7edc\u7ed3\u6784\u590d\u6742\uff0c\u9700\u8981\u8c03\u6574\u8d85\u53c2\u6570 \u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u53d1\u751f\u8fc7\u62df\u5408 \u603b\u7ed3 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5173\u7cfb \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e3b\u8981\u533a\u522b\u5728\u662f\u5426\u5305\u542b\u7279\u5f81\u5de5\u7a0b \u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u662f\u4ec0\u4e48 \u4e00\u79cd\u6a21\u4eff\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u529f\u80fd\u7684 \u8ba1\u7b97\u6a21\u578b \u77e5\u9053\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570 \u9ed8\u8ba4\u4f7f\u7528relu\uff0c\u4e8c\u5206\u7c7b\u662fsigmoid, \u591a\u5206\u7c7b\u662fsoftmaxs \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7684\u5e38\u89c1\u65b9\u6cd5 \u968f\u673a\u521d\u59cb\u5316\uff0c\u6807\u51c6\u521d\u59cb\u5316\uff0cXavier\u521d\u59cb\u5316\uff0cHe\u521d\u59cb\u5316 \u80fd\u591f\u5229\u7528tf.keras\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b Sequential\u7684\u65b9\u6cd5\uff0cModel\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\uff0c\u6784\u5efamodel\u7684\u5b50\u7c7b\u5b9e\u73b0 \u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","title":"2.\u7f3a\u70b9"},{"location":"deeplearning/section2/","text":"2.2 \u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d, \u635f\u5931\u51fd\u6570\u662f\u7528\u6765\u8861\u91cf\u6a21\u578b\u53c2\u6570\u7684\u8d28\u91cf\u7684\u51fd\u6570, \u8861\u91cf\u7684\u65b9\u5f0f\u662f\u6bd4\u8f83\u7f51\u7edc\u8f93\u51fa\u548c\u771f\u5b9e\u8f93\u51fa\u7684\u5dee\u5f02\uff0c\u635f\u5931\u51fd\u6570\u5728\u4e0d\u540c\u7684\u6587\u732e\u4e2d\u540d\u79f0\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4e3b\u8981\u6709\u4ee5\u4e0b\u51e0\u79cd\u547d\u540d\u65b9\u5f0f\uff1a 1.\u5206\u7c7b\u4efb\u52a1 \u00b6 \u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f7f\u7528\u6700\u591a\u7684\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u4ee5\u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u79cd\u635f\u5931\u51fd\u6570\u3002 1.1 \u591a\u5206\u7c7b\u4efb\u52a1 \u00b6 \u5728\u591a\u5206\u7c7b\u4efb\u52a1\u901a\u5e38\u4f7f\u7528softmax\u5c06logits\u8f6c\u6362\u4e3a\u6982\u7387\u7684\u5f62\u5f0f\uff0c\u6240\u4ee5\u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e5f\u53eb\u505asoftmax\u635f\u5931\uff0c\u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cf(x)\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff0cS\u662fsoftmax\u51fd\u6570\uff0cL\u7528\u6765\u8861\u91cfp,q\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u4f8b\u5b50\uff1a \u4e0a\u56fe\u4e2d\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e3a\uff1a \u4ece\u6982\u7387\u89d2\u5ea6\u7406\u89e3\uff0c\u6211\u4eec\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u6b63\u786e\u7c7b\u522b\u6240\u5bf9\u5e94\u7684\u9884\u6d4b\u6982\u7387\u7684\u5bf9\u6570\u7684\u8d1f\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u4f7f\u7528CategoricalCrossentropy\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # \u5b9e\u4f8b\u5316\u4ea4\u53c9\u71b5\u635f\u5931 cce = tf . keras . losses . CategoricalCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c cce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.176939 1.2 \u4e8c\u5206\u7c7b\u4efb\u52a1 \u00b6 \u5728\u5904\u7406\u4e8c\u5206\u7c7b\u4efb\u52a1\u65f6\uff0c\u6211\u4eec\u4e0d\u5728\u4f7f\u7528softmax\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u662f\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u635f\u5931\u51fd\u6570\u4e5f\u76f8\u5e94\u7684\u8fdb\u884c\u8c03\u6574\uff0c\u4f7f\u7528\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cy^\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0cL\u7528\u6765\u8861\u91cf\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528BinaryCrossentropy()\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.4 ], [ 0.6 ]] # \u5b9e\u4f8b\u5316\u4e8c\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931 bce = tf . keras . losses . BinaryCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c bce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5108254 2.\u56de\u5f52\u4efb\u52a1 \u00b6 \u56de\u5f52\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u79cd\uff1a 2.1 MAE\u635f\u5931 \u00b6 Mean absolute loss(MAE)\u4e5f\u88ab\u79f0\u4e3aL1 Loss\uff0c\u662f\u4ee5\u7edd\u5bf9\u8bef\u5dee\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1a\u7531\u4e8eL1 loss\u5177\u6709\u7a00\u758f\u6027\uff0c\u4e3a\u4e86\u60e9\u7f5a\u8f83\u5927\u7684\u503c\uff0c\u56e0\u6b64\u5e38\u5e38\u5c06\u5176\u4f5c\u4e3a\u6b63\u5219\u9879\u6dfb\u52a0\u5230\u5176\u4ed6loss\u4e2d\u4f5c\u4e3a\u7ea6\u675f\u3002L1 loss\u7684\u6700\u5927\u95ee\u9898\u662f\u68af\u5ea6\u5728\u96f6\u70b9\u4e0d\u5e73\u6ed1\uff0c\u5bfc\u81f4\u4f1a\u8df3\u8fc7\u6781\u5c0f\u503c\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528MeanAbsoluteError\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 0. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MAE\u635f\u5931 mae = tf . keras . losses . MeanAbsoluteError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mae ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.0 2.2 MSE\u635f\u5931 \u00b6 Mean Squared Loss/ Quadratic Loss(MSE loss)\u4e5f\u88ab\u79f0\u4e3aL2 loss\uff0c\u6216\u6b27\u6c0f\u8ddd\u79bb\uff0c\u5b83\u4ee5\u8bef\u5dee\u7684\u5e73\u65b9\u548c\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1aL2 loss\u4e5f\u5e38\u5e38\u4f5c\u4e3a\u6b63\u5219\u9879\u3002\u5f53\u9884\u6d4b\u503c\u4e0e\u76ee\u6807\u503c\u76f8\u5dee\u5f88\u5927\u65f6, \u68af\u5ea6\u5bb9\u6613\u7206\u70b8\u3002 \u5728tf.keras\u4e2d\u901a\u8fc7MeanSquaredError\u5b9e\u73b0\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 1. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MSE\u635f\u5931 mse = tf . keras . losses . MeanSquaredError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mse ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5 2.3 smooth L1 \u635f\u5931 \u00b6 Smooth L1\u635f\u5931\u51fd\u6570\u5982\u4e0b\u5f0f\u6240\u793a\uff1a \u5176\u4e2d\uff1a\ud835\udc65=f(x)\u2212y \u4e3a\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c\u7684\u5dee\u503c\u3002 \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u8be5\u51fd\u6570\u5b9e\u9645\u4e0a\u5c31\u662f\u4e00\u4e2a\u5206\u6bb5\u51fd\u6570\uff0c\u5728[-1,1]\u4e4b\u95f4\u5b9e\u9645\u4e0a\u5c31\u662fL2\u635f\u5931\uff0c\u8fd9\u6837\u89e3\u51b3\u4e86L1\u7684\u4e0d\u5149\u6ed1\u95ee\u9898\uff0c\u5728[-1,1]\u533a\u95f4\u5916\uff0c\u5b9e\u9645\u4e0a\u5c31\u662fL1\u635f\u5931\uff0c\u8fd9\u6837\u5c31\u89e3\u51b3\u4e86\u79bb\u7fa4\u70b9\u68af\u5ea6\u7206\u70b8\u7684\u95ee\u9898\u3002\u901a\u5e38\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u4f7f\u7528\u8be5\u635f\u5931\u51fd\u6570\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Huber\u8ba1\u7b97\u8be5\u635f\u5931\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.6 ], [ 0.4 ]] # \u5b9e\u4f8b\u5316smooth L1\u635f\u5931 h = tf . keras . losses . Huber () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c h ( y_true , y_pred ) . numpy () \u7ed3\u679c\uff1a 0.18 \u603b\u7ed3 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u548c\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 MAE\uff0cMSE\uff0csmooth L1\u635f\u5931\u51fd\u6570","title":"\u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570"},{"location":"deeplearning/section2/#22","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d, \u635f\u5931\u51fd\u6570\u662f\u7528\u6765\u8861\u91cf\u6a21\u578b\u53c2\u6570\u7684\u8d28\u91cf\u7684\u51fd\u6570, \u8861\u91cf\u7684\u65b9\u5f0f\u662f\u6bd4\u8f83\u7f51\u7edc\u8f93\u51fa\u548c\u771f\u5b9e\u8f93\u51fa\u7684\u5dee\u5f02\uff0c\u635f\u5931\u51fd\u6570\u5728\u4e0d\u540c\u7684\u6587\u732e\u4e2d\u540d\u79f0\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4e3b\u8981\u6709\u4ee5\u4e0b\u51e0\u79cd\u547d\u540d\u65b9\u5f0f\uff1a","title":"2.2 \u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570"},{"location":"deeplearning/section2/#1","text":"\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f7f\u7528\u6700\u591a\u7684\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u4ee5\u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u79cd\u635f\u5931\u51fd\u6570\u3002","title":"1.\u5206\u7c7b\u4efb\u52a1"},{"location":"deeplearning/section2/#11","text":"\u5728\u591a\u5206\u7c7b\u4efb\u52a1\u901a\u5e38\u4f7f\u7528softmax\u5c06logits\u8f6c\u6362\u4e3a\u6982\u7387\u7684\u5f62\u5f0f\uff0c\u6240\u4ee5\u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e5f\u53eb\u505asoftmax\u635f\u5931\uff0c\u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cf(x)\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff0cS\u662fsoftmax\u51fd\u6570\uff0cL\u7528\u6765\u8861\u91cfp,q\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u4f8b\u5b50\uff1a \u4e0a\u56fe\u4e2d\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u4e3a\uff1a \u4ece\u6982\u7387\u89d2\u5ea6\u7406\u89e3\uff0c\u6211\u4eec\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u6b63\u786e\u7c7b\u522b\u6240\u5bf9\u5e94\u7684\u9884\u6d4b\u6982\u7387\u7684\u5bf9\u6570\u7684\u8d1f\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u4f7f\u7528CategoricalCrossentropy\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # \u5b9e\u4f8b\u5316\u4ea4\u53c9\u71b5\u635f\u5931 cce = tf . keras . losses . CategoricalCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c cce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.176939","title":"1.1 \u591a\u5206\u7c7b\u4efb\u52a1"},{"location":"deeplearning/section2/#12","text":"\u5728\u5904\u7406\u4e8c\u5206\u7c7b\u4efb\u52a1\u65f6\uff0c\u6211\u4eec\u4e0d\u5728\u4f7f\u7528softmax\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u662f\u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u90a3\u635f\u5931\u51fd\u6570\u4e5f\u76f8\u5e94\u7684\u8fdb\u884c\u8c03\u6574\uff0c\u4f7f\u7528\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff1a \u5176\u4e2d\uff0cy\u662f\u6837\u672cx\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u771f\u5b9e\u6982\u7387\uff0c\u800cy^\u662f\u6837\u672c\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0cL\u7528\u6765\u8861\u91cf\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u635f\u5931\u7ed3\u679c\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528BinaryCrossentropy()\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.4 ], [ 0.6 ]] # \u5b9e\u4f8b\u5316\u4e8c\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931 bce = tf . keras . losses . BinaryCrossentropy () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c bce ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5108254","title":"1.2 \u4e8c\u5206\u7c7b\u4efb\u52a1"},{"location":"deeplearning/section2/#2","text":"\u56de\u5f52\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u79cd\uff1a","title":"2.\u56de\u5f52\u4efb\u52a1"},{"location":"deeplearning/section2/#21-mae","text":"Mean absolute loss(MAE)\u4e5f\u88ab\u79f0\u4e3aL1 Loss\uff0c\u662f\u4ee5\u7edd\u5bf9\u8bef\u5dee\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1a\u7531\u4e8eL1 loss\u5177\u6709\u7a00\u758f\u6027\uff0c\u4e3a\u4e86\u60e9\u7f5a\u8f83\u5927\u7684\u503c\uff0c\u56e0\u6b64\u5e38\u5e38\u5c06\u5176\u4f5c\u4e3a\u6b63\u5219\u9879\u6dfb\u52a0\u5230\u5176\u4ed6loss\u4e2d\u4f5c\u4e3a\u7ea6\u675f\u3002L1 loss\u7684\u6700\u5927\u95ee\u9898\u662f\u68af\u5ea6\u5728\u96f6\u70b9\u4e0d\u5e73\u6ed1\uff0c\u5bfc\u81f4\u4f1a\u8df3\u8fc7\u6781\u5c0f\u503c\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528MeanAbsoluteError\u5b9e\u73b0\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 0. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MAE\u635f\u5931 mae = tf . keras . losses . MeanAbsoluteError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mae ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 1.0","title":"2.1 MAE\u635f\u5931"},{"location":"deeplearning/section2/#22-mse","text":"Mean Squared Loss/ Quadratic Loss(MSE loss)\u4e5f\u88ab\u79f0\u4e3aL2 loss\uff0c\u6216\u6b27\u6c0f\u8ddd\u79bb\uff0c\u5b83\u4ee5\u8bef\u5dee\u7684\u5e73\u65b9\u548c\u4f5c\u4e3a\u8ddd\u79bb\uff1a \u66f2\u7ebf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7279\u70b9\u662f\uff1aL2 loss\u4e5f\u5e38\u5e38\u4f5c\u4e3a\u6b63\u5219\u9879\u3002\u5f53\u9884\u6d4b\u503c\u4e0e\u76ee\u6807\u503c\u76f8\u5dee\u5f88\u5927\u65f6, \u68af\u5ea6\u5bb9\u6613\u7206\u70b8\u3002 \u5728tf.keras\u4e2d\u901a\u8fc7MeanSquaredError\u5b9e\u73b0\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0. ], [ 1. ]] y_pred = [[ 1. ], [ 1. ]] # \u5b9e\u4f8b\u5316MSE\u635f\u5931 mse = tf . keras . losses . MeanSquaredError () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c mse ( y_true , y_pred ) . numpy () \u7ed3\u679c\u4e3a\uff1a 0.5","title":"2.2 MSE\u635f\u5931"},{"location":"deeplearning/section2/#23-smooth-l1","text":"Smooth L1\u635f\u5931\u51fd\u6570\u5982\u4e0b\u5f0f\u6240\u793a\uff1a \u5176\u4e2d\uff1a\ud835\udc65=f(x)\u2212y \u4e3a\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c\u7684\u5dee\u503c\u3002 \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u8be5\u51fd\u6570\u5b9e\u9645\u4e0a\u5c31\u662f\u4e00\u4e2a\u5206\u6bb5\u51fd\u6570\uff0c\u5728[-1,1]\u4e4b\u95f4\u5b9e\u9645\u4e0a\u5c31\u662fL2\u635f\u5931\uff0c\u8fd9\u6837\u89e3\u51b3\u4e86L1\u7684\u4e0d\u5149\u6ed1\u95ee\u9898\uff0c\u5728[-1,1]\u533a\u95f4\u5916\uff0c\u5b9e\u9645\u4e0a\u5c31\u662fL1\u635f\u5931\uff0c\u8fd9\u6837\u5c31\u89e3\u51b3\u4e86\u79bb\u7fa4\u70b9\u68af\u5ea6\u7206\u70b8\u7684\u95ee\u9898\u3002\u901a\u5e38\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u4f7f\u7528\u8be5\u635f\u5931\u51fd\u6570\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Huber\u8ba1\u7b97\u8be5\u635f\u5931\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5305 import tensorflow as tf # \u8bbe\u7f6e\u771f\u5b9e\u503c\u548c\u9884\u6d4b\u503c y_true = [[ 0 ], [ 1 ]] y_pred = [[ 0.6 ], [ 0.4 ]] # \u5b9e\u4f8b\u5316smooth L1\u635f\u5931 h = tf . keras . losses . Huber () # \u8ba1\u7b97\u635f\u5931\u7ed3\u679c h ( y_true , y_pred ) . numpy () \u7ed3\u679c\uff1a 0.18 \u603b\u7ed3 \u77e5\u9053\u5206\u7c7b\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 \u591a\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u548c\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 \u77e5\u9053\u56de\u5f52\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570 MAE\uff0cMSE\uff0csmooth L1\u635f\u5931\u51fd\u6570","title":"2.3 smooth L1 \u635f\u5931"},{"location":"deeplearning/section3/","text":"2.3 \u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b 1.\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u3010\u56de\u987e\u3011 \u00b6 \u68af\u5ea6\u4e0b\u964d\u6cd5\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\u3002\u5927\u5bb6\u5728\u673a\u5668\u5b66\u4e60\u9636\u6bb5\u5df2\u7ecf\u5b66\u8fc7\u8be5\u7b97\u6cd5\uff0c\u6240\u4ee5\u6211\u4eec\u5728\u8fd9\u91cc\u5c31\u7b80\u5355\u7684\u56de\u987e\u4e0b\uff0c\u4ece\u6570\u5b66\u4e0a\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u68af\u5ea6\u7684\u65b9\u5411\u662f\u51fd\u6570\u589e\u957f\u901f\u5ea6\u6700\u5feb\u7684\u65b9\u5411\uff0c\u90a3\u4e48\u68af\u5ea6\u7684\u53cd\u65b9\u5411\u5c31\u662f\u51fd\u6570\u51cf\u5c11\u6700\u5feb\u7684\u65b9\u5411\uff0c\u6240\u4ee5\u6709\uff1a \u5176\u4e2d\uff0c\u03b7\u662f\u5b66\u4e60\u7387\uff0c\u5982\u679c\u5b66\u4e60\u7387\u592a\u5c0f\uff0c\u90a3\u4e48\u6bcf\u6b21\u8bad\u7ec3\u4e4b\u540e\u5f97\u5230\u7684\u6548\u679c\u90fd\u592a\u5c0f\uff0c\u589e\u5927\u8bad\u7ec3\u7684\u65f6\u95f4\u6210\u672c\u3002\u5982\u679c\uff0c\u5b66\u4e60\u7387\u592a\u5927\uff0c\u90a3\u5c31\u6709\u53ef\u80fd\u76f4\u63a5\u8df3\u8fc7\u6700\u4f18\u89e3\uff0c\u8fdb\u5165\u65e0\u9650\u7684\u8bad\u7ec3\u4e2d\u3002\u89e3\u51b3\u7684\u65b9\u6cd5\u5c31\u662f\uff0c\u5b66\u4e60\u7387\u4e5f\u9700\u8981\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u800c\u53d8\u5316\u3002 \u5728\u4e0a\u56fe\u4e2d\u6211\u4eec\u5c55\u793a\u4e86\u4e00\u7ef4\u548c\u591a\u7ef4\u7684\u635f\u5931\u51fd\u6570\uff0c\u635f\u5931\u51fd\u6570\u5448\u7897\u72b6\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u5bf9\u6743\u91cd\u7684\u504f\u5bfc\u6570\u5c31\u662f\u635f\u5931\u51fd\u6570\u5728\u8be5\u4f4d\u7f6e\u70b9\u7684\u68af\u5ea6\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u6cbf\u7740\u8d1f\u68af\u5ea6\u65b9\u5411\u79fb\u52a8\uff0c\u5c31\u53ef\u4ee5\u5230\u8fbe\u635f\u5931\u51fd\u6570\u5e95\u90e8\uff0c\u4ece\u800c\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u3002\u8fd9\u79cd\u5229\u7528\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u8fed\u4ee3\u5730\u5bfb\u627e\u5c40\u90e8\u6700\u5c0f\u503c\u7684\u8fc7\u7a0b\u5c31\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u8fc7\u7a0b\u3002 \u6839\u636e\u5728\u8fdb\u884c\u8fed\u4ee3\u65f6\u4f7f\u7528\u7684\u6837\u672c\u91cf\uff0c\u5c06\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5206\u4e3a\u4ee5\u4e0b\u4e09\u7c7b\uff1a \u5b9e\u9645\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u662f\u5c0f\u6279\u91cf\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff0c\u5728tf.keras\u4e2d\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u5b9e\u73b0\uff1a tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False , name = 'SGD' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c loss = lambda : ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u66f4\u65b0\u7ed3\u679c\u4e3a\uff1a # 1-0.1*1=0.9 0.9 \u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6709\u4e09\u4e2a\u57fa\u7840\u7684\u6982\u5ff5\uff1a \u5b9e\u9645\u4e0a\uff0c\u68af\u5ea6\u4e0b\u964d\u7684\u51e0\u79cd\u65b9\u5f0f\u7684\u6839\u672c\u533a\u522b\u5c31\u5728\u4e8e Batch Size\u4e0d\u540c,\uff0c\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6ce8\uff1a\u4e0a\u8868\u4e2d Mini-Batch \u7684 Batch \u4e2a\u6570\u4e3a N / B + 1 \u662f\u9488\u5bf9\u672a\u6574\u9664\u7684\u60c5\u51b5\u3002\u6574\u9664\u5219\u662f N / B\u3002 \u5047\u8bbe\u6570\u636e\u96c6\u6709 50000 \u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u73b0\u5728\u9009\u62e9 Batch Size = 256 \u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002 \u6bcf\u4e2a Epoch \u8981\u8bad\u7ec3\u7684\u56fe\u7247\u6570\u91cf\uff1a50000 \u8bad\u7ec3\u96c6\u5177\u6709\u7684 Batch \u4e2a\u6570\uff1a50000/256+1=196 \u6bcf\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a196 10\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a1960 2.\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u00b6 \u5229\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u4e0e\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u7ed3\u5408\uff0c\u5bf9\u7f51\u7edc\u4e2d\u6240\u6709\u6743\u91cd\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\uff0c\u5e76\u5229\u7528\u68af\u5ea6\u503c\u6765\u66f4\u65b0\u6743\u503c\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u3002\u5728\u4ecb\u7ecdBP\u7b97\u6cd5\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u524d\u5411\u4f20\u64ad\u4e0e\u94fe\u5f0f\u6cd5\u5219\u7684\u5185\u5bb9\u3002 2.1 \u524d\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad \u00b6 \u524d\u5411\u4f20\u64ad\u6307\u7684\u662f\u6570\u636e\u8f93\u5165\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u9010\u5c42\u5411\u524d\u4f20\u8f93\uff0c\u4e00\u76f4\u5230\u8fd0\u7b97\u5230\u8f93\u51fa\u5c42\u4e3a\u6b62\u3002 \u5728\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u8fc7\u524d\u5411\u4f20\u64ad\u540e\u5f97\u5230\u7684\u6700\u7ec8\u7ed3\u679c\u8ddf\u8bad\u7ec3\u6837\u672c\u7684\u771f\u5b9e\u503c\u603b\u662f\u5b58\u5728\u4e00\u5b9a\u8bef\u5dee\uff0c\u8fd9\u4e2a\u8bef\u5dee\u4fbf\u662f\u635f\u5931\u51fd\u6570\u3002\u60f3\u8981\u51cf\u5c0f\u8fd9\u4e2a\u8bef\u5dee\uff0c\u5c31\u7528\u635f\u5931\u51fd\u6570ERROR\uff0c\u4ece\u540e\u5f80\u524d\uff0c\u4f9d\u6b21\u6c42\u5404\u4e2a\u53c2\u6570\u7684\u504f\u5bfc\uff0c\u8fd9\u5c31\u662f\u53cd\u5411\u4f20\u64ad\uff08Back Propagation\uff09\u3002 2.2 \u94fe\u5f0f\u6cd5\u5219 \u00b6 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u8fdb\u884c\u68af\u5ea6\u6c42\u89e3\u53ca\u6743\u91cd\u66f4\u65b0\u7684\u3002\u5bf9\u4e8e\u590d\u6742\u7684\u590d\u5408\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u5176\u62c6\u5206\u4e3a\u4e00\u7cfb\u5217\u7684\u52a0\u51cf\u4e58\u9664\u6216\u6307\u6570\uff0c\u5bf9\u6570\uff0c\u4e09\u89d2\u51fd\u6570\u7b49\u521d\u7b49\u51fd\u6570\uff0c\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u5b8c\u6210\u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc\u3002\u4e3a\u7b80\u5355\u8d77\u89c1\uff0c\u8fd9\u91cc\u4ee5\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u590d\u5408\u51fd\u6570\u7684\u4f8b\u5b50\u6765\u8bf4\u660e \u8fd9\u4e2a\u8fc7\u7a0b. \u4ee4\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e3a: \u5176\u4e2dx\u662f\u8f93\u5165\u6570\u636e\uff0cw\u662f\u6743\u91cd\uff0cb\u662f\u504f\u7f6e\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u8be5\u590d\u5408\u51fd\u6570\u5206\u89e3\u4e3a\uff1a \u5e76\u8fdb\u884c\u56fe\u5f62\u5316\u8868\u793a\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6574\u4e2a\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u5173\u4e8e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u7684\u5bfc\u6570\u53ef\u4ee5\u901a\u8fc7 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e0e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u4e4b\u95f4\u8def\u5f84\u4e0a\u6240\u6709\u7684\u5bfc\u6570\u8fde\u4e58\u6765\u5f97\u5230\uff0c\u5373\uff1a \u4ee5w\u4e3a\u4f8b\uff0c\u5f53 \ud835\udc65 = 1, \ud835\udc64 = 0, \ud835\udc4f = 0 \u65f6\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \u6ce8\u610f\uff1a\u5e38\u7528\u51fd\u6570\u7684\u5bfc\u6570\uff1a 2.3 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \u00b6 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u5bf9\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u5404\u4e2a\u8282\u70b9\u7684\u6743\u91cd\u8fdb\u884c\u66f4\u65b0\u3002\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u6574\u4e2a\u6d41\u7a0b\uff0c\u5047\u8bbe\u5f53\u524d\u524d\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u4ee5\uff1a \u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5e76\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff1a \u8ba1\u7b97\u68af\u5ea6\u503c\uff1a \u8f93\u51fa\u5c42\u68af\u5ea6\u503c\uff1a \u9690\u85cf\u5c42\u68af\u5ea6\u503c\uff1a \u504f\u7f6e\u7684\u68af\u5ea6\u503c\uff1a \u53c2\u6570\u66f4\u65b0\uff1a \u8f93\u51fa\u5c42\u6743\u91cd\uff1a \u9690\u85cf\u5c42\u6743\u91cd\uff1a \u504f\u7f6e\u66f4\u65b0\uff1a \u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u5b8c\u6210\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6574\u4e2a\u6d41\u7a0b\u5982\u4e0b\u8868\u6240\u793a\uff1a 3.\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5 \u00b6 \u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5728\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u4f1a\u9047\u5230\u978d\u70b9\uff0c\u5c40\u90e8\u6781\u5c0f\u503c\u8fd9\u4e9b\u95ee\u9898\uff0c\u90a3\u6211\u4eec\u600e\u4e48\u6539\u8fdbSGD\u5462\uff1f\u5728\u8fd9\u91cc\u6211\u4eec\u4ecb\u7ecd\u51e0\u4e2a\u6bd4\u8f83\u5e38\u7528\u7684 3.1 \u52a8\u91cf\u7b97\u6cd5\uff08Momentum\uff09 \u00b6 \u52a8\u91cf\u7b97\u6cd5\u4e3b\u8981\u89e3\u51b3\u978d\u70b9\u95ee\u9898\u3002\u5728\u4ecb\u7ecd\u52a8\u91cf\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u6765\u770b\u4e0b\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002 \u6307\u6570\u52a0\u6743\u5e73\u5747 \u00b6 \u5047\u8bbe\u7ed9\u5b9a\u4e00\u4e2a\u5e8f\u5217\uff0c\u4f8b\u5982\u5317\u4eac\u4e00\u5e74\u6bcf\u5929\u7684\u6c14\u6e29\u503c\uff0c\u56fe\u4e2d\u84dd\u8272\u7684\u70b9\u4ee3\u8868\u771f\u5b9e\u6570\u636e\uff0c \u8fd9\u65f6\u6e29\u5ea6\u503c\u6ce2\u52a8\u6bd4\u8f83\u5927\uff0c\u90a3\u6211\u4eec\u5c31\u4f7f\u7528\u52a0\u6743\u5e73\u5747\u503c\u6765\u8fdb\u884c\u5e73\u6ed1\uff0c\u5982\u4e0b\u56fe\u7ea2\u7ebf\u5c31\u662f\u5e73\u6ed1\u540e\u7684\u7ed3\u679c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2dYt\u4e3a t \u65f6\u523b\u65f6\u7684\u771f\u5b9e\u503c\uff0cSt\u4e3at\u52a0\u6743\u5e73\u5747\u540e\u7684\u503c\uff0c\u03b2\u4e3a\u6743\u91cd\u503c\u3002\u7ea2\u7ebf\u5373\u662f\u6307\u6570\u52a0\u6743\u5e73\u5747\u540e\u7684\u7ed3\u679c\u3002 \u4e0a\u56fe\u4e2d\u03b2\u8bbe\u4e3a0.9\uff0c\u90a3\u4e48\u6307\u6570\u52a0\u6743\u5e73\u5747\u7684\u8ba1\u7b97\u7ed3\u679c\u4e3a\uff1a \u90a3\u4e48\u7b2c100\u5929\u7684\u7ed3\u679c\u5c31\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a \u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u00b6 \u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\uff08Gradient Descent with Momentum\uff09\u8ba1\u7b97\u68af\u5ea6\u7684\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\uff0c\u5e76\u5229\u7528\u8be5\u503c\u6765\u66f4\u65b0\u53c2\u6570\u503c\u3002\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e3a\uff0c\u5176\u4e2d\u03b2\u901a\u5e38\u8bbe\u7f6e\u4e3a0.9\uff1a \u4e0e\u539f\u59cb\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5b83\u7684\u4e0b\u964d\u8d8b\u52bf\u66f4\u5e73\u6ed1\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Momentum\u7b97\u6cd5\u4ecd\u4f7f\u7528\u529f\u80fdSGD\u65b9\u6cd5\uff0c\u4f46\u8981\u8bbe\u7f6emomentum\u53c2\u6570\uff0c\u5b9e\u73b0\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD \u6307\u5b9a\u53c2\u6570beta=0.9 opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 , momentum = 0.9 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570\uff0c\u521d\u59cb\u503c var = tf . Variable ( 1.0 ) val0 = var . value () # \u5b9a\u4e49\u635f\u5931\u51fd\u6570 loss = lambda : ( var ** 2 ) / 2.0 #\u7b2c\u4e00\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () val1 = var . value () # \u7b2c\u4e8c\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u56e0\u4e3a\u52a0\u5165\u4e86momentum,\u6b65\u957f\u4f1a\u589e\u52a0 opt . minimize ( loss , [ var ]) . numpy () val2 = var . value () # \u6253\u5370\u4e24\u6b21\u66f4\u65b0\u7684\u6b65\u957f print ( \"\u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f={}\" . format (( val0 - val1 ) . numpy ())) print ( \"\u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f={}\" . format (( val1 - val2 ) . numpy ())) \u7ed3\u679c\u4e3a\uff1a \u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f = 0.10000002384185791 \u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f = 0.18000000715255737 \u53e6\u5916\u8fd8\u6709\u4e00\u79cd\u52a8\u91cf\u7b97\u6cd5Nesterov accelerated gradient(NAG)\uff0c\u4f7f\u7528\u4e86\u6839\u636e\u52a8\u91cf\u9879**\u9884\u5148\u4f30\u8ba1**\u7684\u53c2\u6570\uff0c\u5728Momentum\u7684\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u52a0\u5feb\u6536\u655b\uff0c\u63d0\u9ad8\u54cd\u5e94\u6027\uff0c\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4f9d\u7136\u4f7f\u7528SGD\u65b9\u6cd5\uff0c\u8981\u8bbe\u7f6enesterov\u8bbe\u7f6e\u4e3atrue. 3.2 AdaGrad \u00b6 AdaGrad\u7b97\u6cd5\u4f1a\u4f7f\u7528\u4e00\u4e2a\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6 g_t g_t <span><span class=\"MathJax_Preview\">g_t</span><script type=\"math/tex\">g_t \u6309\u5143\u7d20\u5e73\u65b9\u7684\u7d2f\u52a0\u53d8\u91cfst\u3002\u5728\u9996\u6b21\u8fed\u4ee3\u65f6\uff0cAdaGrad\u5c06s0\u4e2d\u6bcf\u4e2a\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002\u5728t\u6b21\u8fed\u4ee3\uff0c\u9996\u5148\u5c06\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u540e\u7d2f\u52a0\u5230\u53d8\u91cfst\uff1a \u5176\u4e2d\u2299\u662f\u6309\u5143\u7d20\u76f8\u4e58\u3002\u63a5\u7740\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u901a\u8fc7\u6309\u5143\u7d20\u8fd0\u7b97\u91cd\u65b0\u8c03\u6574\u4e00\u4e0b\uff1a \u5176\u4e2d\u03b1\u662f\u5b66\u4e60\u7387\uff0c\u03f5\u662f\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u6027\u800c\u6dfb\u52a0\u7684\u5e38\u6570\uff0c\u5982 10^{-6} 10^{-6} <span><span class=\"MathJax_Preview\">10^{-6}</span><script type=\"math/tex\">10^{-6} \u3002\u8fd9\u91cc\u5f00\u65b9\u3001\u9664\u6cd5\u548c\u4e58\u6cd5\u7684\u8fd0\u7b97\u90fd\u662f\u6309\u5143\u7d20\u8fd0\u7b97\u7684\u3002\u8fd9\u4e9b\u6309\u5143\u7d20\u8fd0\u7b97\u4f7f\u5f97\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u90fd\u5206\u522b\u62e5\u6709\u81ea\u5df1\u7684\u5b66\u4e60\u7387\u3002 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adagrad ( learning_rate = 0.001 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) \u4f8b\u5b50\u662f\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . Adagrad ( learning_rate = 0.1 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () 3.3 RMSprop \u00b6 AdaGrad\u7b97\u6cd5\u5728\u8fed\u4ee3\u540e\u671f\u7531\u4e8e\u5b66\u4e60\u7387\u8fc7\u5c0f,\u80fd\u8f83\u96be\u627e\u5230\u6700\u4f18\u89e3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0cRMSProp\u7b97\u6cd5\u5bf9AdaGrad\u7b97\u6cd5\u505a\u4e86\u4e00\u70b9\u5c0f\u5c0f\u7684\u4fee\u6539\u3002 \u4e0d\u540c\u4e8eAdaGrad\u7b97\u6cd5\u91cc\u72b6\u6001\u53d8\u91cfst\u662f\u622a\u81f3\u65f6\u95f4\u6b65t\u6240\u6709\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u548c\uff0cRMSProp\uff08Root Mean Square Prop\uff09\u7b97\u6cd5\u5c06\u8fd9\u4e9b\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u505a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747 \u5176\u4e2d\u03f5\u662f\u4e00\u6837\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u4e00\u4e2a\u5e38\u6570\u3002\u6700\u7ec8\u81ea\u53d8\u91cf\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u5c31\u4e0d\u518d\u4e00\u76f4\u964d\u4f4e\u3002RMSProp \u6709\u52a9\u4e8e\u51cf\u5c11\u62b5\u8fbe\u6700\u5c0f\u503c\u8def\u5f84\u4e0a\u7684\u6446\u52a8\uff0c\u5e76\u5141\u8bb8\u4f7f\u7528\u4e00\u4e2a\u66f4\u5927\u7684\u5b66\u4e60\u7387 \u03b1\uff0c\u4ece\u800c\u52a0\u5feb\u7b97\u6cd5\u5b66\u4e60\u901f\u5ea6\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\uff0c\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . RMSprop ( learning_rate = 0.001 , rho = 0.9 , momentum = 0.0 , epsilon = 1e-07 , centered = False , name = 'RMSprop' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5RMSprop opt = tf . keras . optimizers . RMSprop ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a 0.6837723 3.4 Adam \u00b6 Adam \u4f18\u5316\u7b97\u6cd5\uff08Adaptive Moment Estimation\uff0c\u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\uff09\u5c06 Momentum \u548c RMSProp \u7b97\u6cd5\u7ed3\u5408\u5728\u4e00\u8d77\u3002Adam\u7b97\u6cd5\u5728RMSProp\u7b97\u6cd5\u57fa\u7840\u4e0a\u5bf9\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e5f\u505a\u4e86\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u3002 \u5047\u8bbe\u7528\u6bcf\u4e00\u4e2a mini-batch \u8ba1\u7b97 dW\u3001db\uff0c\u7b2ct\u6b21\u8fed\u4ee3\u65f6\uff1a \u5176\u4e2dl\u4e3a\u67d0\u4e00\u5c42\uff0ct\u4e3a\u79fb\u52a8\u5e73\u5747\u7b2c\u6b21\u7684\u503c Adam \u7b97\u6cd5\u7684\u53c2\u6570\u66f4\u65b0\uff1a \u5efa\u8bae\u7684\u53c2\u6570\u8bbe\u7f6e\u7684\u503c\uff1a \u5b66\u4e60\u7387\u03b1\uff1a \u9700\u8981\u5c1d\u8bd5\u4e00\u7cfb\u5217\u7684\u503c\uff0c\u6765\u5bfb\u627e\u6bd4\u8f83\u5408\u9002\u7684 \u03b21\uff1a\u5e38\u7528\u7684\u7f3a\u7701\u503c\u4e3a 0.9 \u03b22\uff1a\u5efa\u8bae\u4e3a 0.999 \u03f5\uff1a\u9ed8\u8ba4\u503c1e-8 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5Adam opt = tf . keras . optimizers . Adam ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u7ed3\u679c\u4e3a\uff1a 0.90000033 4.\u5b66\u4e60\u7387\u9000\u706b \u00b6 \u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5b66\u4e60\u7387\u90fd\u4f1a\u968f\u7740\u8bad\u7ec3\u800c\u53d8\u5316\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u540e\u671f\uff0c\u5982\u679c\u5b66\u4e60\u7387\u8fc7\u9ad8\uff0c\u4f1a\u9020\u6210loss\u7684\u632f\u8361\uff0c\u4f46\u662f\u5982\u679c\u5b66\u4e60\u7387\u51cf\u5c0f\u7684\u8fc7\u5feb\uff0c\u53c8\u4f1a\u9020\u6210\u6536\u655b\u53d8\u6162\u7684\u60c5\u51b5\u3002 4.1 \u5206\u6bb5\u5e38\u6570\u8870\u51cf \u00b6 \u5206\u6bb5\u5e38\u6570\u8870\u51cf\u662f\u5728\u4e8b\u5148\u5b9a\u4e49\u597d\u7684\u8bad\u7ec3\u6b21\u6570\u533a\u95f4\u4e0a\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u5e38\u6570\u3002\u521a\u5f00\u59cb\u5b66\u4e60\u7387\u5927\u4e00\u4e9b\uff0c\u4e4b\u540e\u8d8a\u6765\u8d8a\u5c0f\uff0c\u533a\u95f4\u7684\u8bbe\u7f6e\u9700\u8981\u6839\u636e\u6837\u672c\u91cf\u8c03\u6574\uff0c\u4e00\u822c\u6837\u672c\u91cf\u8d8a\u5927\u533a\u95f4\u95f4\u9694\u5e94\u8be5\u8d8a\u5c0f\u3002 \u5728tf.keras\u4e2d\u5bf9\u5e94\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) \u53c2\u6570\uff1a Boundaries: \u8bbe\u7f6e\u5206\u6bb5\u66f4\u65b0\u7684step\u503c Values: \u9488\u5bf9\u4e0d\u7528\u5206\u6bb5\u7684\u5b66\u4e60\u7387\u503c \u4f8b\u5b50\uff1a\u5bf9\u4e8e\u524d100000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a1.0\uff0c\u5bf9\u4e8e\u63a5\u4e0b\u6765\u7684100000-110000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a0.5\uff0c\u4e4b\u540e\u7684\u6b65\u9aa4\u5b66\u4e60\u7387\u4e3a0.1 # \u8bbe\u7f6e\u7684\u5206\u6bb5\u7684step\u503c boundaries = [ 100000 , 110000 ] # \u4e0d\u540c\u7684step\u5bf9\u5e94\u7684\u5b66\u4e60\u7387 values = [ 1.0 , 0.5 , 0.1 ] # \u5b9e\u4f8b\u5316\u8fdb\u884c\u5b66\u4e60\u7684\u66f4\u65b0 learning_rate_fn = keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) 4.2 \u6307\u6570\u8870\u51cf \u00b6 \u6307\u6570\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a, \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate * decay_rate ^ ( step / decay_steps ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_steps: k\u503c decay_rate: \u6307\u6570\u7684\u5e95 4.3 1/t\u8870\u51cf \u00b6 1/t\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a\uff1a \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * step / decay_step ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_step/decay_steps: k\u503c \u603b\u7ed3 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\uff1a\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\u7684\u65b9\u6cd5 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u52a8\u91cf\u7b97\u6cd5\uff0cadaGrad,RMSProp,Adam \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b \u5206\u6bb5\u5e38\u6570\u8870\u51cf\uff0c\u6307\u6570\u8870\u51cf\uff0c1/t\u8870\u51cf","title":"\u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5"},{"location":"deeplearning/section3/#23","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b","title":"2.3 \u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5"},{"location":"deeplearning/section3/#1","text":"\u68af\u5ea6\u4e0b\u964d\u6cd5\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\u3002\u5927\u5bb6\u5728\u673a\u5668\u5b66\u4e60\u9636\u6bb5\u5df2\u7ecf\u5b66\u8fc7\u8be5\u7b97\u6cd5\uff0c\u6240\u4ee5\u6211\u4eec\u5728\u8fd9\u91cc\u5c31\u7b80\u5355\u7684\u56de\u987e\u4e0b\uff0c\u4ece\u6570\u5b66\u4e0a\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u68af\u5ea6\u7684\u65b9\u5411\u662f\u51fd\u6570\u589e\u957f\u901f\u5ea6\u6700\u5feb\u7684\u65b9\u5411\uff0c\u90a3\u4e48\u68af\u5ea6\u7684\u53cd\u65b9\u5411\u5c31\u662f\u51fd\u6570\u51cf\u5c11\u6700\u5feb\u7684\u65b9\u5411\uff0c\u6240\u4ee5\u6709\uff1a \u5176\u4e2d\uff0c\u03b7\u662f\u5b66\u4e60\u7387\uff0c\u5982\u679c\u5b66\u4e60\u7387\u592a\u5c0f\uff0c\u90a3\u4e48\u6bcf\u6b21\u8bad\u7ec3\u4e4b\u540e\u5f97\u5230\u7684\u6548\u679c\u90fd\u592a\u5c0f\uff0c\u589e\u5927\u8bad\u7ec3\u7684\u65f6\u95f4\u6210\u672c\u3002\u5982\u679c\uff0c\u5b66\u4e60\u7387\u592a\u5927\uff0c\u90a3\u5c31\u6709\u53ef\u80fd\u76f4\u63a5\u8df3\u8fc7\u6700\u4f18\u89e3\uff0c\u8fdb\u5165\u65e0\u9650\u7684\u8bad\u7ec3\u4e2d\u3002\u89e3\u51b3\u7684\u65b9\u6cd5\u5c31\u662f\uff0c\u5b66\u4e60\u7387\u4e5f\u9700\u8981\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u800c\u53d8\u5316\u3002 \u5728\u4e0a\u56fe\u4e2d\u6211\u4eec\u5c55\u793a\u4e86\u4e00\u7ef4\u548c\u591a\u7ef4\u7684\u635f\u5931\u51fd\u6570\uff0c\u635f\u5931\u51fd\u6570\u5448\u7897\u72b6\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u5bf9\u6743\u91cd\u7684\u504f\u5bfc\u6570\u5c31\u662f\u635f\u5931\u51fd\u6570\u5728\u8be5\u4f4d\u7f6e\u70b9\u7684\u68af\u5ea6\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u6cbf\u7740\u8d1f\u68af\u5ea6\u65b9\u5411\u79fb\u52a8\uff0c\u5c31\u53ef\u4ee5\u5230\u8fbe\u635f\u5931\u51fd\u6570\u5e95\u90e8\uff0c\u4ece\u800c\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u3002\u8fd9\u79cd\u5229\u7528\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u8fed\u4ee3\u5730\u5bfb\u627e\u5c40\u90e8\u6700\u5c0f\u503c\u7684\u8fc7\u7a0b\u5c31\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u8fc7\u7a0b\u3002 \u6839\u636e\u5728\u8fdb\u884c\u8fed\u4ee3\u65f6\u4f7f\u7528\u7684\u6837\u672c\u91cf\uff0c\u5c06\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5206\u4e3a\u4ee5\u4e0b\u4e09\u7c7b\uff1a \u5b9e\u9645\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u662f\u5c0f\u6279\u91cf\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff0c\u5728tf.keras\u4e2d\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u5b9e\u73b0\uff1a tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False , name = 'SGD' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c loss = lambda : ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u66f4\u65b0\u7ed3\u679c\u4e3a\uff1a # 1-0.1*1=0.9 0.9 \u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6709\u4e09\u4e2a\u57fa\u7840\u7684\u6982\u5ff5\uff1a \u5b9e\u9645\u4e0a\uff0c\u68af\u5ea6\u4e0b\u964d\u7684\u51e0\u79cd\u65b9\u5f0f\u7684\u6839\u672c\u533a\u522b\u5c31\u5728\u4e8e Batch Size\u4e0d\u540c,\uff0c\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6ce8\uff1a\u4e0a\u8868\u4e2d Mini-Batch \u7684 Batch \u4e2a\u6570\u4e3a N / B + 1 \u662f\u9488\u5bf9\u672a\u6574\u9664\u7684\u60c5\u51b5\u3002\u6574\u9664\u5219\u662f N / B\u3002 \u5047\u8bbe\u6570\u636e\u96c6\u6709 50000 \u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u73b0\u5728\u9009\u62e9 Batch Size = 256 \u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002 \u6bcf\u4e2a Epoch \u8981\u8bad\u7ec3\u7684\u56fe\u7247\u6570\u91cf\uff1a50000 \u8bad\u7ec3\u96c6\u5177\u6709\u7684 Batch \u4e2a\u6570\uff1a50000/256+1=196 \u6bcf\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a196 10\u4e2a Epoch \u5177\u6709\u7684 Iteration \u4e2a\u6570\uff1a1960","title":"1.\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u3010\u56de\u987e\u3011"},{"location":"deeplearning/section3/#2bp","text":"\u5229\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u4e0e\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u7ed3\u5408\uff0c\u5bf9\u7f51\u7edc\u4e2d\u6240\u6709\u6743\u91cd\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\uff0c\u5e76\u5229\u7528\u68af\u5ea6\u503c\u6765\u66f4\u65b0\u6743\u503c\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u3002\u5728\u4ecb\u7ecdBP\u7b97\u6cd5\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u524d\u5411\u4f20\u64ad\u4e0e\u94fe\u5f0f\u6cd5\u5219\u7684\u5185\u5bb9\u3002","title":"2.\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09"},{"location":"deeplearning/section3/#21","text":"\u524d\u5411\u4f20\u64ad\u6307\u7684\u662f\u6570\u636e\u8f93\u5165\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u9010\u5c42\u5411\u524d\u4f20\u8f93\uff0c\u4e00\u76f4\u5230\u8fd0\u7b97\u5230\u8f93\u51fa\u5c42\u4e3a\u6b62\u3002 \u5728\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u8fc7\u524d\u5411\u4f20\u64ad\u540e\u5f97\u5230\u7684\u6700\u7ec8\u7ed3\u679c\u8ddf\u8bad\u7ec3\u6837\u672c\u7684\u771f\u5b9e\u503c\u603b\u662f\u5b58\u5728\u4e00\u5b9a\u8bef\u5dee\uff0c\u8fd9\u4e2a\u8bef\u5dee\u4fbf\u662f\u635f\u5931\u51fd\u6570\u3002\u60f3\u8981\u51cf\u5c0f\u8fd9\u4e2a\u8bef\u5dee\uff0c\u5c31\u7528\u635f\u5931\u51fd\u6570ERROR\uff0c\u4ece\u540e\u5f80\u524d\uff0c\u4f9d\u6b21\u6c42\u5404\u4e2a\u53c2\u6570\u7684\u504f\u5bfc\uff0c\u8fd9\u5c31\u662f\u53cd\u5411\u4f20\u64ad\uff08Back Propagation\uff09\u3002","title":"2.1 \u524d\u5411\u4f20\u64ad\u4e0e\u53cd\u5411\u4f20\u64ad"},{"location":"deeplearning/section3/#22","text":"\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u8fdb\u884c\u68af\u5ea6\u6c42\u89e3\u53ca\u6743\u91cd\u66f4\u65b0\u7684\u3002\u5bf9\u4e8e\u590d\u6742\u7684\u590d\u5408\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u5176\u62c6\u5206\u4e3a\u4e00\u7cfb\u5217\u7684\u52a0\u51cf\u4e58\u9664\u6216\u6307\u6570\uff0c\u5bf9\u6570\uff0c\u4e09\u89d2\u51fd\u6570\u7b49\u521d\u7b49\u51fd\u6570\uff0c\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u5b8c\u6210\u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc\u3002\u4e3a\u7b80\u5355\u8d77\u89c1\uff0c\u8fd9\u91cc\u4ee5\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u590d\u5408\u51fd\u6570\u7684\u4f8b\u5b50\u6765\u8bf4\u660e \u8fd9\u4e2a\u8fc7\u7a0b. \u4ee4\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e3a: \u5176\u4e2dx\u662f\u8f93\u5165\u6570\u636e\uff0cw\u662f\u6743\u91cd\uff0cb\u662f\u504f\u7f6e\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u8be5\u590d\u5408\u51fd\u6570\u5206\u89e3\u4e3a\uff1a \u5e76\u8fdb\u884c\u56fe\u5f62\u5316\u8868\u793a\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6574\u4e2a\u590d\u5408\u51fd\u6570 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u5173\u4e8e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u7684\u5bfc\u6570\u53ef\u4ee5\u901a\u8fc7 \ud835\udc53(\ud835\udc65; \ud835\udc64, \ud835\udc4f) \u4e0e\u53c2\u6570 \ud835\udc64 \u548c \ud835\udc4f \u4e4b\u95f4\u8def\u5f84\u4e0a\u6240\u6709\u7684\u5bfc\u6570\u8fde\u4e58\u6765\u5f97\u5230\uff0c\u5373\uff1a \u4ee5w\u4e3a\u4f8b\uff0c\u5f53 \ud835\udc65 = 1, \ud835\udc64 = 0, \ud835\udc4f = 0 \u65f6\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a \u6ce8\u610f\uff1a\u5e38\u7528\u51fd\u6570\u7684\u5bfc\u6570\uff1a","title":"2.2 \u94fe\u5f0f\u6cd5\u5219"},{"location":"deeplearning/section3/#23_1","text":"\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5229\u7528\u94fe\u5f0f\u6cd5\u5219\u5bf9\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u5404\u4e2a\u8282\u70b9\u7684\u6743\u91cd\u8fdb\u884c\u66f4\u65b0\u3002\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u6574\u4e2a\u6d41\u7a0b\uff0c\u5047\u8bbe\u5f53\u524d\u524d\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u4ee5\uff1a \u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5e76\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff1a \u8ba1\u7b97\u68af\u5ea6\u503c\uff1a \u8f93\u51fa\u5c42\u68af\u5ea6\u503c\uff1a \u9690\u85cf\u5c42\u68af\u5ea6\u503c\uff1a \u504f\u7f6e\u7684\u68af\u5ea6\u503c\uff1a \u53c2\u6570\u66f4\u65b0\uff1a \u8f93\u51fa\u5c42\u6743\u91cd\uff1a \u9690\u85cf\u5c42\u6743\u91cd\uff1a \u504f\u7f6e\u66f4\u65b0\uff1a \u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u5b8c\u6210\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6574\u4e2a\u6d41\u7a0b\u5982\u4e0b\u8868\u6240\u793a\uff1a","title":"2.3 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5"},{"location":"deeplearning/section3/#3","text":"\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5728\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u4f1a\u9047\u5230\u978d\u70b9\uff0c\u5c40\u90e8\u6781\u5c0f\u503c\u8fd9\u4e9b\u95ee\u9898\uff0c\u90a3\u6211\u4eec\u600e\u4e48\u6539\u8fdbSGD\u5462\uff1f\u5728\u8fd9\u91cc\u6211\u4eec\u4ecb\u7ecd\u51e0\u4e2a\u6bd4\u8f83\u5e38\u7528\u7684","title":"3.\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5"},{"location":"deeplearning/section3/#31-momentum","text":"\u52a8\u91cf\u7b97\u6cd5\u4e3b\u8981\u89e3\u51b3\u978d\u70b9\u95ee\u9898\u3002\u5728\u4ecb\u7ecd\u52a8\u91cf\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u6765\u770b\u4e0b\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002","title":"3.1 \u52a8\u91cf\u7b97\u6cd5\uff08Momentum\uff09"},{"location":"deeplearning/section3/#_1","text":"\u5047\u8bbe\u7ed9\u5b9a\u4e00\u4e2a\u5e8f\u5217\uff0c\u4f8b\u5982\u5317\u4eac\u4e00\u5e74\u6bcf\u5929\u7684\u6c14\u6e29\u503c\uff0c\u56fe\u4e2d\u84dd\u8272\u7684\u70b9\u4ee3\u8868\u771f\u5b9e\u6570\u636e\uff0c \u8fd9\u65f6\u6e29\u5ea6\u503c\u6ce2\u52a8\u6bd4\u8f83\u5927\uff0c\u90a3\u6211\u4eec\u5c31\u4f7f\u7528\u52a0\u6743\u5e73\u5747\u503c\u6765\u8fdb\u884c\u5e73\u6ed1\uff0c\u5982\u4e0b\u56fe\u7ea2\u7ebf\u5c31\u662f\u5e73\u6ed1\u540e\u7684\u7ed3\u679c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2dYt\u4e3a t \u65f6\u523b\u65f6\u7684\u771f\u5b9e\u503c\uff0cSt\u4e3at\u52a0\u6743\u5e73\u5747\u540e\u7684\u503c\uff0c\u03b2\u4e3a\u6743\u91cd\u503c\u3002\u7ea2\u7ebf\u5373\u662f\u6307\u6570\u52a0\u6743\u5e73\u5747\u540e\u7684\u7ed3\u679c\u3002 \u4e0a\u56fe\u4e2d\u03b2\u8bbe\u4e3a0.9\uff0c\u90a3\u4e48\u6307\u6570\u52a0\u6743\u5e73\u5747\u7684\u8ba1\u7b97\u7ed3\u679c\u4e3a\uff1a \u90a3\u4e48\u7b2c100\u5929\u7684\u7ed3\u679c\u5c31\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a","title":"\u6307\u6570\u52a0\u6743\u5e73\u5747"},{"location":"deeplearning/section3/#_2","text":"\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\uff08Gradient Descent with Momentum\uff09\u8ba1\u7b97\u68af\u5ea6\u7684\u6307\u6570\u52a0\u6743\u5e73\u5747\u6570\uff0c\u5e76\u5229\u7528\u8be5\u503c\u6765\u66f4\u65b0\u53c2\u6570\u503c\u3002\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e3a\uff0c\u5176\u4e2d\u03b2\u901a\u5e38\u8bbe\u7f6e\u4e3a0.9\uff1a \u4e0e\u539f\u59cb\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5b83\u7684\u4e0b\u964d\u8d8b\u52bf\u66f4\u5e73\u6ed1\u3002 \u5728tf.keras\u4e2d\u4f7f\u7528Momentum\u7b97\u6cd5\u4ecd\u4f7f\u7528\u529f\u80fdSGD\u65b9\u6cd5\uff0c\u4f46\u8981\u8bbe\u7f6emomentum\u53c2\u6570\uff0c\u5b9e\u73b0\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD \u6307\u5b9a\u53c2\u6570beta=0.9 opt = tf . keras . optimizers . SGD ( learning_rate = 0.1 , momentum = 0.9 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570\uff0c\u521d\u59cb\u503c var = tf . Variable ( 1.0 ) val0 = var . value () # \u5b9a\u4e49\u635f\u5931\u51fd\u6570 loss = lambda : ( var ** 2 ) / 2.0 #\u7b2c\u4e00\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u6b65\u957f\u4e3a `- learning_rate * grad` opt . minimize ( loss , [ var ]) . numpy () val1 = var . value () # \u7b2c\u4e8c\u6b21\u66f4\u65b0\uff1a\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u56e0\u4e3a\u52a0\u5165\u4e86momentum,\u6b65\u957f\u4f1a\u589e\u52a0 opt . minimize ( loss , [ var ]) . numpy () val2 = var . value () # \u6253\u5370\u4e24\u6b21\u66f4\u65b0\u7684\u6b65\u957f print ( \"\u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f={}\" . format (( val0 - val1 ) . numpy ())) print ( \"\u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f={}\" . format (( val1 - val2 ) . numpy ())) \u7ed3\u679c\u4e3a\uff1a \u7b2c\u4e00\u6b21\u66f4\u65b0\u6b65\u957f = 0.10000002384185791 \u7b2c\u4e8c\u6b21\u66f4\u65b0\u6b65\u957f = 0.18000000715255737 \u53e6\u5916\u8fd8\u6709\u4e00\u79cd\u52a8\u91cf\u7b97\u6cd5Nesterov accelerated gradient(NAG)\uff0c\u4f7f\u7528\u4e86\u6839\u636e\u52a8\u91cf\u9879**\u9884\u5148\u4f30\u8ba1**\u7684\u53c2\u6570\uff0c\u5728Momentum\u7684\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u52a0\u5feb\u6536\u655b\uff0c\u63d0\u9ad8\u54cd\u5e94\u6027\uff0c\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4f9d\u7136\u4f7f\u7528SGD\u65b9\u6cd5\uff0c\u8981\u8bbe\u7f6enesterov\u8bbe\u7f6e\u4e3atrue.","title":"\u52a8\u91cf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5"},{"location":"deeplearning/section3/#32-adagrad","text":"AdaGrad\u7b97\u6cd5\u4f1a\u4f7f\u7528\u4e00\u4e2a\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6 g_t g_t <span><span class=\"MathJax_Preview\">g_t</span><script type=\"math/tex\">g_t \u6309\u5143\u7d20\u5e73\u65b9\u7684\u7d2f\u52a0\u53d8\u91cfst\u3002\u5728\u9996\u6b21\u8fed\u4ee3\u65f6\uff0cAdaGrad\u5c06s0\u4e2d\u6bcf\u4e2a\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002\u5728t\u6b21\u8fed\u4ee3\uff0c\u9996\u5148\u5c06\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u540e\u7d2f\u52a0\u5230\u53d8\u91cfst\uff1a \u5176\u4e2d\u2299\u662f\u6309\u5143\u7d20\u76f8\u4e58\u3002\u63a5\u7740\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u901a\u8fc7\u6309\u5143\u7d20\u8fd0\u7b97\u91cd\u65b0\u8c03\u6574\u4e00\u4e0b\uff1a \u5176\u4e2d\u03b1\u662f\u5b66\u4e60\u7387\uff0c\u03f5\u662f\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u6027\u800c\u6dfb\u52a0\u7684\u5e38\u6570\uff0c\u5982 10^{-6} 10^{-6} <span><span class=\"MathJax_Preview\">10^{-6}</span><script type=\"math/tex\">10^{-6} \u3002\u8fd9\u91cc\u5f00\u65b9\u3001\u9664\u6cd5\u548c\u4e58\u6cd5\u7684\u8fd0\u7b97\u90fd\u662f\u6309\u5143\u7d20\u8fd0\u7b97\u7684\u3002\u8fd9\u4e9b\u6309\u5143\u7d20\u8fd0\u7b97\u4f7f\u5f97\u76ee\u6807\u51fd\u6570\u81ea\u53d8\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u90fd\u5206\u522b\u62e5\u6709\u81ea\u5df1\u7684\u5b66\u4e60\u7387\u3002 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adagrad ( learning_rate = 0.001 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) \u4f8b\u5b50\u662f\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5\uff1aSGD opt = tf . keras . optimizers . Adagrad ( learning_rate = 0.1 , initial_accumulator_value = 0.1 , epsilon = 1e-07 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy ()","title":"3.2 AdaGrad"},{"location":"deeplearning/section3/#33-rmsprop","text":"AdaGrad\u7b97\u6cd5\u5728\u8fed\u4ee3\u540e\u671f\u7531\u4e8e\u5b66\u4e60\u7387\u8fc7\u5c0f,\u80fd\u8f83\u96be\u627e\u5230\u6700\u4f18\u89e3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0cRMSProp\u7b97\u6cd5\u5bf9AdaGrad\u7b97\u6cd5\u505a\u4e86\u4e00\u70b9\u5c0f\u5c0f\u7684\u4fee\u6539\u3002 \u4e0d\u540c\u4e8eAdaGrad\u7b97\u6cd5\u91cc\u72b6\u6001\u53d8\u91cfst\u662f\u622a\u81f3\u65f6\u95f4\u6b65t\u6240\u6709\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6gt\u6309\u5143\u7d20\u5e73\u65b9\u548c\uff0cRMSProp\uff08Root Mean Square Prop\uff09\u7b97\u6cd5\u5c06\u8fd9\u4e9b\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u505a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747 \u5176\u4e2d\u03f5\u662f\u4e00\u6837\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u4e00\u4e2a\u5e38\u6570\u3002\u6700\u7ec8\u81ea\u53d8\u91cf\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u5c31\u4e0d\u518d\u4e00\u76f4\u964d\u4f4e\u3002RMSProp \u6709\u52a9\u4e8e\u51cf\u5c11\u62b5\u8fbe\u6700\u5c0f\u503c\u8def\u5f84\u4e0a\u7684\u6446\u52a8\uff0c\u5e76\u5141\u8bb8\u4f7f\u7528\u4e00\u4e2a\u66f4\u5927\u7684\u5b66\u4e60\u7387 \u03b1\uff0c\u4ece\u800c\u52a0\u5feb\u7b97\u6cd5\u5b66\u4e60\u901f\u5ea6\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u65f6\uff0c\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . RMSprop ( learning_rate = 0.001 , rho = 0.9 , momentum = 0.0 , epsilon = 1e-07 , centered = False , name = 'RMSprop' , ** kwargs ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5RMSprop opt = tf . keras . optimizers . RMSprop ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a 0.6837723","title":"3.3 RMSprop"},{"location":"deeplearning/section3/#34-adam","text":"Adam \u4f18\u5316\u7b97\u6cd5\uff08Adaptive Moment Estimation\uff0c\u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\uff09\u5c06 Momentum \u548c RMSProp \u7b97\u6cd5\u7ed3\u5408\u5728\u4e00\u8d77\u3002Adam\u7b97\u6cd5\u5728RMSProp\u7b97\u6cd5\u57fa\u7840\u4e0a\u5bf9\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e5f\u505a\u4e86\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u3002 \u5047\u8bbe\u7528\u6bcf\u4e00\u4e2a mini-batch \u8ba1\u7b97 dW\u3001db\uff0c\u7b2ct\u6b21\u8fed\u4ee3\u65f6\uff1a \u5176\u4e2dl\u4e3a\u67d0\u4e00\u5c42\uff0ct\u4e3a\u79fb\u52a8\u5e73\u5747\u7b2c\u6b21\u7684\u503c Adam \u7b97\u6cd5\u7684\u53c2\u6570\u66f4\u65b0\uff1a \u5efa\u8bae\u7684\u53c2\u6570\u8bbe\u7f6e\u7684\u503c\uff1a \u5b66\u4e60\u7387\u03b1\uff1a \u9700\u8981\u5c1d\u8bd5\u4e00\u7cfb\u5217\u7684\u503c\uff0c\u6765\u5bfb\u627e\u6bd4\u8f83\u5408\u9002\u7684 \u03b21\uff1a\u5e38\u7528\u7684\u7f3a\u7701\u503c\u4e3a 0.9 \u03b22\uff1a\u5efa\u8bae\u4e3a 0.999 \u03f5\uff1a\u9ed8\u8ba4\u503c1e-8 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . Adam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 ) \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf # \u5b9e\u4f8b\u5316\u4f18\u5316\u65b9\u6cd5Adam opt = tf . keras . optimizers . Adam ( learning_rate = 0.1 ) # \u5b9a\u4e49\u8981\u8c03\u6574\u7684\u53c2\u6570 var = tf . Variable ( 1.0 ) # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff1a\u65e0\u53c2\u4f46\u6709\u8fd4\u56de\u503c def loss (): return ( var ** 2 ) / 2.0 # \u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c opt . minimize ( loss , [ var ]) . numpy () # \u5c55\u793a\u53c2\u6570\u66f4\u65b0\u7ed3\u679c var . numpy () \u7ed3\u679c\u4e3a\uff1a 0.90000033","title":"3.4 Adam"},{"location":"deeplearning/section3/#4","text":"\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5b66\u4e60\u7387\u90fd\u4f1a\u968f\u7740\u8bad\u7ec3\u800c\u53d8\u5316\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u540e\u671f\uff0c\u5982\u679c\u5b66\u4e60\u7387\u8fc7\u9ad8\uff0c\u4f1a\u9020\u6210loss\u7684\u632f\u8361\uff0c\u4f46\u662f\u5982\u679c\u5b66\u4e60\u7387\u51cf\u5c0f\u7684\u8fc7\u5feb\uff0c\u53c8\u4f1a\u9020\u6210\u6536\u655b\u53d8\u6162\u7684\u60c5\u51b5\u3002","title":"4.\u5b66\u4e60\u7387\u9000\u706b"},{"location":"deeplearning/section3/#41","text":"\u5206\u6bb5\u5e38\u6570\u8870\u51cf\u662f\u5728\u4e8b\u5148\u5b9a\u4e49\u597d\u7684\u8bad\u7ec3\u6b21\u6570\u533a\u95f4\u4e0a\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u5e38\u6570\u3002\u521a\u5f00\u59cb\u5b66\u4e60\u7387\u5927\u4e00\u4e9b\uff0c\u4e4b\u540e\u8d8a\u6765\u8d8a\u5c0f\uff0c\u533a\u95f4\u7684\u8bbe\u7f6e\u9700\u8981\u6839\u636e\u6837\u672c\u91cf\u8c03\u6574\uff0c\u4e00\u822c\u6837\u672c\u91cf\u8d8a\u5927\u533a\u95f4\u95f4\u9694\u5e94\u8be5\u8d8a\u5c0f\u3002 \u5728tf.keras\u4e2d\u5bf9\u5e94\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) \u53c2\u6570\uff1a Boundaries: \u8bbe\u7f6e\u5206\u6bb5\u66f4\u65b0\u7684step\u503c Values: \u9488\u5bf9\u4e0d\u7528\u5206\u6bb5\u7684\u5b66\u4e60\u7387\u503c \u4f8b\u5b50\uff1a\u5bf9\u4e8e\u524d100000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a1.0\uff0c\u5bf9\u4e8e\u63a5\u4e0b\u6765\u7684100000-110000\u6b65\uff0c\u5b66\u4e60\u7387\u4e3a0.5\uff0c\u4e4b\u540e\u7684\u6b65\u9aa4\u5b66\u4e60\u7387\u4e3a0.1 # \u8bbe\u7f6e\u7684\u5206\u6bb5\u7684step\u503c boundaries = [ 100000 , 110000 ] # \u4e0d\u540c\u7684step\u5bf9\u5e94\u7684\u5b66\u4e60\u7387 values = [ 1.0 , 0.5 , 0.1 ] # \u5b9e\u4f8b\u5316\u8fdb\u884c\u5b66\u4e60\u7684\u66f4\u65b0 learning_rate_fn = keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values )","title":"4.1 \u5206\u6bb5\u5e38\u6570\u8870\u51cf"},{"location":"deeplearning/section3/#42","text":"\u6307\u6570\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a, \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate * decay_rate ^ ( step / decay_steps ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_steps: k\u503c decay_rate: \u6307\u6570\u7684\u5e95","title":"4.2 \u6307\u6570\u8870\u51cf"},{"location":"deeplearning/section3/#43-1t","text":"1/t\u8870\u51cf\u53ef\u4ee5\u7528\u5982\u4e0b\u7684\u6570\u5b66\u516c\u5f0f\u8868\u793a\uff1a \u5176\u4e2d\uff0ct\u8868\u793a\u8fed\u4ee3\u6b21\u6570\uff0c\u03b10,k\u662f\u8d85\u53c2\u6570 \u5728tf.keras\u4e2d\u7684\u5b9e\u73b0\u662f\uff1a tf . keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate ) \u5177\u4f53\u7684\u5b9e\u73b0\u662f\uff1a def decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * step / decay_step ) \u53c2\u6570\uff1a Initial_learning_rate: \u521d\u59cb\u5b66\u4e60\u7387\uff0c\u03b10 decay_step/decay_steps: k\u503c \u603b\u7ed3 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u4e00\u79cd\u5bfb\u627e\u4f7f\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\uff1a\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d \u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u94fe\u5f0f\u6cd5\u5219 \u590d\u5408\u51fd\u6570\u7684\u6c42\u5bfc \u638c\u63e1\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08BP\u7b97\u6cd5\uff09 \u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\u7684\u65b9\u6cd5 \u77e5\u9053\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316\u65b9\u6cd5 \u52a8\u91cf\u7b97\u6cd5\uff0cadaGrad,RMSProp,Adam \u4e86\u89e3\u5b66\u4e60\u7387\u9000\u706b \u5206\u6bb5\u5e38\u6570\u8870\u51cf\uff0c\u6307\u6570\u8870\u51cf\uff0c1/t\u8870\u51cf","title":"4.3 1/t\u8870\u51cf"},{"location":"deeplearning/section4/","text":"2.4 \u6df1\u5ea6\u5b66\u4e60\u6b63\u5219\u5316 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5728\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u65f6\u4e0d\u4ec5\u8981\u6c42\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bef\u5dee\u5c0f\uff0c\u800c\u4e14\u5e0c\u671b\u5728\u65b0\u6837\u672c\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u5f3a\u3002\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u90fd\u91c7\u7528\u76f8\u5173\u7684\u7b56\u7565\u6765\u51cf\u5c0f\u6d4b\u8bd5\u8bef\u5dee\uff0c\u8fd9\u4e9b\u7b56\u7565\u88ab\u7edf\u79f0\u4e3a\u6b63\u5219\u5316\u3002\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\u7ecf\u5e38\u9047\u5230\u8fc7\u62df\u5408\uff0c\u6240\u4ee5\u9700\u8981\u4f7f\u7528\u4e0d\u540c\u5f62\u5f0f\u7684\u6b63\u5219\u5316\u7b56\u7565\u3002 \u6b63\u5219\u5316\u901a\u8fc7\u5bf9\u7b97\u6cd5\u7684\u4fee\u6539\u6765\u51cf\u5c11\u6cdb\u5316\u8bef\u5dee\uff0c\u76ee\u524d\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u7b56\u7565\u6709\u53c2\u6570\u8303\u6570\u60e9\u7f5a\uff0c\u63d0\u524d\u7ec8\u6b62\uff0cDropOut\u7b49\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5bf9\u5176\u8fdb\u884c\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002 1. L1\u4e0eL2\u6b63\u5219\u5316(\u56de\u987e) \u00b6 L1\u548cL2\u662f\u6700\u5e38\u89c1\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u5b83\u4eec\u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b\u3002 \u56e0\u6b64\uff0c\u5b83\u4e5f\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u51cf\u5c11\u8fc7\u62df\u5408\u3002\u7136\u800c\uff0c\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\u5728L1\u548cL2\u4e2d\u662f\u4e0d\u540c\u7684\u3002 L2\u6b63\u5219\u5316 \u8fd9\u91cc\u7684\u03bb\u662f\u6b63\u5219\u5316\u53c2\u6570\uff0c\u5b83\u662f\u4e00\u4e2a\u9700\u8981\u4f18\u5316\u7684\u8d85\u53c2\u6570\u3002L2\u6b63\u5219\u5316\u53c8\u79f0\u4e3a\u6743\u91cd\u8870\u51cf\uff0c\u56e0\u4e3a\u5176\u5bfc\u81f4\u6743\u91cd\u8d8b\u5411\u4e8e0\uff08\u4f46\u4e0d\u5168\u662f0\uff09 L1\u6b63\u5219\u5316 \u8fd9\u91cc\uff0c\u6211\u4eec\u60e9\u7f5a\u6743\u91cd\u77e9\u9635\u7684\u7edd\u5bf9\u503c\u3002\u5176\u4e2d\uff0c\u03bb \u4e3a\u6b63\u5219\u5316\u53c2\u6570\uff0c\u662f\u8d85\u53c2\u6570\uff0c\u4e0d\u540c\u4e8eL2\uff0c\u6743\u91cd\u503c\u53ef\u80fd\u88ab\u51cf\u5c11\u52300.\u56e0\u6b64\uff0cL1\u5bf9\u4e8e\u538b\u7f29\u6a21\u578b\u5f88\u6709\u7528\u3002\u5176\u5b83\u60c5\u51b5\u4e0b\uff0c\u4e00\u822c\u9009\u62e9\u4f18\u5148\u9009\u62e9L2\u6b63\u5219\u5316\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a L1\u6b63\u5219\u5316 tf . keras . regularizers . L1 ( l1 = 0.01 ) \u0015L2\u6b63\u5219\u5316 tf . keras . regularizers . L2 ( l2 = 0.01 ) L1L2\u6b63\u5219\u5316 tf . keras . regularizers . L1L2 ( l1 = 0.0 , l2 = 0.0 ) \u6211\u4eec\u76f4\u63a5\u5728\u67d0\u4e00\u5c42\u7684layers\u4e2d\u6307\u660e\u6b63\u5219\u5316\u7c7b\u578b\u548c\u8d85\u53c2\u6570\u5373\u53ef\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import regularizers # \u521b\u5efa\u6a21\u578b model = tf . keras . models . Sequential () # L2\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l2 ( 0.001 ), activation = 'relu' , input_shape = ( 10 ,))) # L1\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l1 ( 0.001 ), activation = 'relu' )) # L1L2\u6b63\u5219\u5316\uff0clambda1\u4e3a0.01,lambda2\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . L1L2 ( 0.001 , 0.01 ), activation = 'relu' )) 2.Dropout\u6b63\u5219\u5316 \u00b6 dropout\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u6700\u5e38\u7528\u7684\u6b63\u5219\u5316\u6280\u672f\u3002Dropout\u7684\u539f\u7406\u5f88\u7b80\u5355\uff1a\u5047\u8bbe\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff0c\u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u90fd\u4f1a\u6709\u4e0d\u540c\u7684\u8282\u70b9\u7ec4\u5408\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u540c\u7684\u8f93\u51fa\uff0c\u8fd9\u53ef\u4ee5\u770b\u6210\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u96c6\u6210\u65b9\u6cd5\uff08ensemble technique\uff09\u3002\u96c6\u6210\u6a21\u578b\u4e00\u822c\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u6355\u83b7\u66f4\u591a\u7684\u968f\u673a\u6027\u3002\u76f8\u4f3c\u5730\uff0cdropout\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f18\u4e8e\u6b63\u5e38\u7684\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662fdropout\uff1a tf . keras . layers . Dropout ( rate ) \u53c2\u6570\uff1a rate\uff1a \u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u88ab\u4e22\u5f03\u7684\u6982\u7387 \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5e93 import numpy as np import tensorflow as tf # \u5b9a\u4e49dropout\u5c42,\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u67090.2\u7684\u6982\u7387\u88ab\u5931\u6d3b\uff0c\u672a\u88ab\u5931\u6d3b\u7684\u8f93\u5165\u5c06\u63091 /\uff081-rate\uff09\u653e\u5927 layer = tf . keras . layers . Dropout ( 0.2 , input_shape = ( 2 ,)) # \u5b9a\u4e49\u4e94\u4e2a\u6279\u6b21\u7684\u6570\u636e data = np . arange ( 1 , 11 ) . reshape ( 5 , 2 ) . astype ( np . float32 ) # \u539f\u59cb\u6570\u636e\u8fdb\u884c\u6253\u5370 print ( data ) # \u8fdb\u884c\u968f\u673a\u5931\u6d3b\uff1a\u5728training\u6a21\u5f0f\u4e2d\uff0c\u8fd4\u56de\u5e94\u7528dropout\u540e\u7684\u8f93\u51fa\uff1b\u6216\u8005\u5728\u975etraining\u6a21\u5f0f\u4e0b\uff0c\u6b63\u5e38\u8fd4\u56de\u8f93\u51fa\uff08\u6ca1\u6709dropout\uff09 outputs = layer ( data , training = True ) # \u6253\u5370\u5931\u6d3b\u540e\u7684\u7ed3\u679c print ( outputs ) \u7ed3\u679c\u4e3a\uff1a [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ] [ 7. 8. ] [ 9. 10. ]] tf . Tensor ( [[ 1.25 2.5 ] [ 0. 5. ] [ 6.25 7.5 ] [ 8.75 10. ] [ 0. 12.5 ]], shape = ( 5 , 2 ), dtype = float32 ) 3.\u63d0\u524d\u505c\u6b62 \u00b6 \u63d0\u524d\u505c\u6b62\uff08early stopping\uff09\u662f\u5c06\u4e00\u90e8\u5206\u8bad\u7ec3\u96c6\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff08validation set\uff09\u3002 \u5f53\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u5219\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u3002 \u8fd9\u88ab\u79f0\u4e3a\u63d0\u524d\u505c\u6b62\u3002 \u5728\u4e0a\u56fe\u4e2d\uff0c\u5728\u865a\u7ebf\u5904\u505c\u6b62\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6b64\u65f6\u6a21\u578b\u5f00\u59cb\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528callbacks\u51fd\u6570\u5b9e\u73b0\u65e9\u671f\u505c\u6b62: tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 5 ) \u4e0a\u9762\uff0cmonitor\u53c2\u6570\u8868\u793a\u76d1\u6d4b\u91cf\uff0c\u8fd9\u91ccval_loss\u8868\u793a\u9a8c\u8bc1\u96c6\u635f\u5931\u3002\u800cpatience\u53c2\u6570epochs\u6570\u91cf\uff0c\u5f53\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u6027\u80fd\u65e0\u63d0\u5347\u65f6\u4f1a\u505c\u6b62\u8bad\u7ec3\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u518d\u770b\u770b\u4e0a\u9762\u7684\u56fe\u7247\u3002 \u5728\u865a\u7ebf\u4e4b\u540e\uff0c\u6bcf\u4e2aepoch\u90fd\u4f1a\u5bfc\u81f4\u66f4\u9ad8\u7684\u9a8c\u8bc1\u96c6\u8bef\u5dee\u3002 \u56e0\u6b64\uff0c\u865a\u7ebf\u540epatience\u4e2aepoch\uff0c\u6a21\u578b\u5c06\u505c\u6b62\u8bad\u7ec3\uff0c\u56e0\u4e3a\u6ca1\u6709\u8fdb\u4e00\u6b65\u7684\u6539\u5584\u3002 # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import numpy as np # \u5f53\u8fde\u7eed3\u4e2aepoch loss\u4e0d\u4e0b\u964d\u5219\u505c\u6b62\u8bad\u7ec3 callback = tf . keras . callbacks . EarlyStopping ( monitor = 'loss' , patience = 3 ) # \u5b9a\u4e49\u53ea\u6709\u4e00\u5c42\u7684\u795e\u7ecf\u7f51\u7edc model = tf . keras . models . Sequential ([ tf . keras . layers . Dense ( 10 )]) # \u8bbe\u7f6e\u635f\u5931\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 model . compile ( tf . keras . optimizers . SGD (), loss = 'mse' ) # \u6a21\u578b\u8bad\u7ec3 history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . array ([ 0 , 1 , 2 , 1 , 2 ]), epochs = 10 , batch_size = 1 , callbacks = [ callback ], verbose = 1 ) # \u6253\u5370\u8fd0\u884c\u7684epoch len ( history . history [ 'loss' ]) \u8f93\u51fa\uff1a Epoch 1 / 10 5 / 5 [ ============================== ] - 0 s 600 us / step - loss : 145774557280600064.0000 Epoch 2 / 10 5 / 5 [ ============================== ] - 0 s 522 us / step - loss : 10077891596456623723194184833695744.0000 Epoch 3 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf Epoch 4 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf # \u53ea\u8fd0\u884c\u4e864\u6b21 4 4. \u6279\u6807\u51c6\u5316 \u00b6 \u6279\u6807\u51c6\u5316(BN\u5c42,Batch Normalization)\u662f2015\u5e74\u63d0\u51fa\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5728\u8fdb\u884c\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u5927\u591a\u4f1a\u91c7\u53d6\u8fd9\u79cd\u7b97\u6cd5\uff0c\u4e0e\u5168\u8fde\u63a5\u5c42\u4e00\u6837\uff0cBN\u5c42\u4e5f\u662f\u5c5e\u4e8e\u7f51\u7edc\u4e2d\u7684\u4e00\u5c42\u3002 BN\u5c42\u662f\u9488\u5bf9\u5355\u4e2a\u795e\u7ecf\u5143\u8fdb\u884c\uff0c\u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization\u3002\u5728\u6bcf\u4e00\u5c42\u8f93\u5165\u4e4b\u524d\uff0c\u5c06\u6570\u636e\u8fdb\u884cBN\uff0c\u7136\u540e\u518d\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5b66\u4e60\uff1a \u9996\u5148\u6211\u4eec\u5bf9\u67d0\u4e00\u6279\u6b21\u7684\u6570\u636e\u7684\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u8fdb\u884c\u6807\u51c6\u5316\uff0c \u7136\u540e\u5728\u4f7f\u7528\u53d8\u6362\u91cd\u6784\uff0c\u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u53c2\u6570\u03b3\u3001\u03b2\uff0c\u5982\u679c\u5404\u9690\u85cf\u5c42\u7684\u8f93\u5165\u5747\u503c\u5728\u9760\u8fd10\u7684\u533a\u57df\uff0c\u5373\u5904\u4e8e\u6fc0\u6d3b\u51fd\u6570\u7684\u7ebf\u6027\u533a\u57df\uff0c\u4e0d\u5229\u4e8e\u8bad\u7ec3\u975e\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\uff0c\u4ece\u800c\u5f97\u5230\u6548\u679c\u8f83\u5dee\u7684\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7528 \u03b3 \u548c \u03b2 \u5bf9\u6807\u51c6\u5316\u540e\u7684\u7ed3\u679c\u505a\u8fdb\u4e00\u6b65\u5904\u7406\uff1a \u8fd9\u5c31\u662fBN\u5c42\u6700\u540e\u7684\u7ed3\u679c\u3002\u6574\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\uff1a # \u76f4\u63a5\u5c06\u5176\u653e\u5165\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u4e2d\u5373\u53ef tf . keras . layers . BatchNormalization ( epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , ) 3.2.8 \u603b\u7ed3 \u00b6 \u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u5f53\u770b\u5230\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization","title":"\u6df1\u5ea6\u5b66\u4e60\u7684\u6b63\u5219\u5316"},{"location":"deeplearning/section4/#24","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5728\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u65f6\u4e0d\u4ec5\u8981\u6c42\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bef\u5dee\u5c0f\uff0c\u800c\u4e14\u5e0c\u671b\u5728\u65b0\u6837\u672c\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u5f3a\u3002\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u90fd\u91c7\u7528\u76f8\u5173\u7684\u7b56\u7565\u6765\u51cf\u5c0f\u6d4b\u8bd5\u8bef\u5dee\uff0c\u8fd9\u4e9b\u7b56\u7565\u88ab\u7edf\u79f0\u4e3a\u6b63\u5219\u5316\u3002\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\u7ecf\u5e38\u9047\u5230\u8fc7\u62df\u5408\uff0c\u6240\u4ee5\u9700\u8981\u4f7f\u7528\u4e0d\u540c\u5f62\u5f0f\u7684\u6b63\u5219\u5316\u7b56\u7565\u3002 \u6b63\u5219\u5316\u901a\u8fc7\u5bf9\u7b97\u6cd5\u7684\u4fee\u6539\u6765\u51cf\u5c11\u6cdb\u5316\u8bef\u5dee\uff0c\u76ee\u524d\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f7f\u7528\u8f83\u591a\u7684\u7b56\u7565\u6709\u53c2\u6570\u8303\u6570\u60e9\u7f5a\uff0c\u63d0\u524d\u7ec8\u6b62\uff0cDropOut\u7b49\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5bf9\u5176\u8fdb\u884c\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002","title":"2.4 \u6df1\u5ea6\u5b66\u4e60\u6b63\u5219\u5316"},{"location":"deeplearning/section4/#1-l1l2","text":"L1\u548cL2\u662f\u6700\u5e38\u89c1\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u5b83\u4eec\u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b\u3002 \u56e0\u6b64\uff0c\u5b83\u4e5f\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u51cf\u5c11\u8fc7\u62df\u5408\u3002\u7136\u800c\uff0c\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\u5728L1\u548cL2\u4e2d\u662f\u4e0d\u540c\u7684\u3002 L2\u6b63\u5219\u5316 \u8fd9\u91cc\u7684\u03bb\u662f\u6b63\u5219\u5316\u53c2\u6570\uff0c\u5b83\u662f\u4e00\u4e2a\u9700\u8981\u4f18\u5316\u7684\u8d85\u53c2\u6570\u3002L2\u6b63\u5219\u5316\u53c8\u79f0\u4e3a\u6743\u91cd\u8870\u51cf\uff0c\u56e0\u4e3a\u5176\u5bfc\u81f4\u6743\u91cd\u8d8b\u5411\u4e8e0\uff08\u4f46\u4e0d\u5168\u662f0\uff09 L1\u6b63\u5219\u5316 \u8fd9\u91cc\uff0c\u6211\u4eec\u60e9\u7f5a\u6743\u91cd\u77e9\u9635\u7684\u7edd\u5bf9\u503c\u3002\u5176\u4e2d\uff0c\u03bb \u4e3a\u6b63\u5219\u5316\u53c2\u6570\uff0c\u662f\u8d85\u53c2\u6570\uff0c\u4e0d\u540c\u4e8eL2\uff0c\u6743\u91cd\u503c\u53ef\u80fd\u88ab\u51cf\u5c11\u52300.\u56e0\u6b64\uff0cL1\u5bf9\u4e8e\u538b\u7f29\u6a21\u578b\u5f88\u6709\u7528\u3002\u5176\u5b83\u60c5\u51b5\u4e0b\uff0c\u4e00\u822c\u9009\u62e9\u4f18\u5148\u9009\u62e9L2\u6b63\u5219\u5316\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\uff1a L1\u6b63\u5219\u5316 tf . keras . regularizers . L1 ( l1 = 0.01 ) \u0015L2\u6b63\u5219\u5316 tf . keras . regularizers . L2 ( l2 = 0.01 ) L1L2\u6b63\u5219\u5316 tf . keras . regularizers . L1L2 ( l1 = 0.0 , l2 = 0.0 ) \u6211\u4eec\u76f4\u63a5\u5728\u67d0\u4e00\u5c42\u7684layers\u4e2d\u6307\u660e\u6b63\u5219\u5316\u7c7b\u578b\u548c\u8d85\u53c2\u6570\u5373\u53ef\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import regularizers # \u521b\u5efa\u6a21\u578b model = tf . keras . models . Sequential () # L2\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l2 ( 0.001 ), activation = 'relu' , input_shape = ( 10 ,))) # L1\u6b63\u5219\u5316\uff0clambda\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . l1 ( 0.001 ), activation = 'relu' )) # L1L2\u6b63\u5219\u5316\uff0clambda1\u4e3a0.01,lambda2\u4e3a0.01 model . add ( tf . keras . layers . Dense ( 16 , kernel_regularizer = regularizers . L1L2 ( 0.001 , 0.01 ), activation = 'relu' ))","title":"1. L1\u4e0eL2\u6b63\u5219\u5316(\u56de\u987e)"},{"location":"deeplearning/section4/#2dropout","text":"dropout\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u6700\u5e38\u7528\u7684\u6b63\u5219\u5316\u6280\u672f\u3002Dropout\u7684\u539f\u7406\u5f88\u7b80\u5355\uff1a\u5047\u8bbe\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff0c\u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u90fd\u4f1a\u6709\u4e0d\u540c\u7684\u8282\u70b9\u7ec4\u5408\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u540c\u7684\u8f93\u51fa\uff0c\u8fd9\u53ef\u4ee5\u770b\u6210\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u96c6\u6210\u65b9\u6cd5\uff08ensemble technique\uff09\u3002\u96c6\u6210\u6a21\u578b\u4e00\u822c\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u6355\u83b7\u66f4\u591a\u7684\u968f\u673a\u6027\u3002\u76f8\u4f3c\u5730\uff0cdropout\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f18\u4e8e\u6b63\u5e38\u7684\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u65b9\u6cd5\u662fdropout\uff1a tf . keras . layers . Dropout ( rate ) \u53c2\u6570\uff1a rate\uff1a \u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u88ab\u4e22\u5f03\u7684\u6982\u7387 \u4f8b\u5b50\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5e93 import numpy as np import tensorflow as tf # \u5b9a\u4e49dropout\u5c42,\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u67090.2\u7684\u6982\u7387\u88ab\u5931\u6d3b\uff0c\u672a\u88ab\u5931\u6d3b\u7684\u8f93\u5165\u5c06\u63091 /\uff081-rate\uff09\u653e\u5927 layer = tf . keras . layers . Dropout ( 0.2 , input_shape = ( 2 ,)) # \u5b9a\u4e49\u4e94\u4e2a\u6279\u6b21\u7684\u6570\u636e data = np . arange ( 1 , 11 ) . reshape ( 5 , 2 ) . astype ( np . float32 ) # \u539f\u59cb\u6570\u636e\u8fdb\u884c\u6253\u5370 print ( data ) # \u8fdb\u884c\u968f\u673a\u5931\u6d3b\uff1a\u5728training\u6a21\u5f0f\u4e2d\uff0c\u8fd4\u56de\u5e94\u7528dropout\u540e\u7684\u8f93\u51fa\uff1b\u6216\u8005\u5728\u975etraining\u6a21\u5f0f\u4e0b\uff0c\u6b63\u5e38\u8fd4\u56de\u8f93\u51fa\uff08\u6ca1\u6709dropout\uff09 outputs = layer ( data , training = True ) # \u6253\u5370\u5931\u6d3b\u540e\u7684\u7ed3\u679c print ( outputs ) \u7ed3\u679c\u4e3a\uff1a [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ] [ 7. 8. ] [ 9. 10. ]] tf . Tensor ( [[ 1.25 2.5 ] [ 0. 5. ] [ 6.25 7.5 ] [ 8.75 10. ] [ 0. 12.5 ]], shape = ( 5 , 2 ), dtype = float32 )","title":"2.Dropout\u6b63\u5219\u5316"},{"location":"deeplearning/section4/#3","text":"\u63d0\u524d\u505c\u6b62\uff08early stopping\uff09\u662f\u5c06\u4e00\u90e8\u5206\u8bad\u7ec3\u96c6\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff08validation set\uff09\u3002 \u5f53\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u5219\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u3002 \u8fd9\u88ab\u79f0\u4e3a\u63d0\u524d\u505c\u6b62\u3002 \u5728\u4e0a\u56fe\u4e2d\uff0c\u5728\u865a\u7ebf\u5904\u505c\u6b62\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u6b64\u65f6\u6a21\u578b\u5f00\u59cb\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528callbacks\u51fd\u6570\u5b9e\u73b0\u65e9\u671f\u505c\u6b62: tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 5 ) \u4e0a\u9762\uff0cmonitor\u53c2\u6570\u8868\u793a\u76d1\u6d4b\u91cf\uff0c\u8fd9\u91ccval_loss\u8868\u793a\u9a8c\u8bc1\u96c6\u635f\u5931\u3002\u800cpatience\u53c2\u6570epochs\u6570\u91cf\uff0c\u5f53\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u6027\u80fd\u65e0\u63d0\u5347\u65f6\u4f1a\u505c\u6b62\u8bad\u7ec3\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u518d\u770b\u770b\u4e0a\u9762\u7684\u56fe\u7247\u3002 \u5728\u865a\u7ebf\u4e4b\u540e\uff0c\u6bcf\u4e2aepoch\u90fd\u4f1a\u5bfc\u81f4\u66f4\u9ad8\u7684\u9a8c\u8bc1\u96c6\u8bef\u5dee\u3002 \u56e0\u6b64\uff0c\u865a\u7ebf\u540epatience\u4e2aepoch\uff0c\u6a21\u578b\u5c06\u505c\u6b62\u8bad\u7ec3\uff0c\u56e0\u4e3a\u6ca1\u6709\u8fdb\u4e00\u6b65\u7684\u6539\u5584\u3002 # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import tensorflow as tf import numpy as np # \u5f53\u8fde\u7eed3\u4e2aepoch loss\u4e0d\u4e0b\u964d\u5219\u505c\u6b62\u8bad\u7ec3 callback = tf . keras . callbacks . EarlyStopping ( monitor = 'loss' , patience = 3 ) # \u5b9a\u4e49\u53ea\u6709\u4e00\u5c42\u7684\u795e\u7ecf\u7f51\u7edc model = tf . keras . models . Sequential ([ tf . keras . layers . Dense ( 10 )]) # \u8bbe\u7f6e\u635f\u5931\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 model . compile ( tf . keras . optimizers . SGD (), loss = 'mse' ) # \u6a21\u578b\u8bad\u7ec3 history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . array ([ 0 , 1 , 2 , 1 , 2 ]), epochs = 10 , batch_size = 1 , callbacks = [ callback ], verbose = 1 ) # \u6253\u5370\u8fd0\u884c\u7684epoch len ( history . history [ 'loss' ]) \u8f93\u51fa\uff1a Epoch 1 / 10 5 / 5 [ ============================== ] - 0 s 600 us / step - loss : 145774557280600064.0000 Epoch 2 / 10 5 / 5 [ ============================== ] - 0 s 522 us / step - loss : 10077891596456623723194184833695744.0000 Epoch 3 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf Epoch 4 / 10 5 / 5 [ ============================== ] - 0 s 1 ms / step - loss : inf # \u53ea\u8fd0\u884c\u4e864\u6b21 4","title":"3.\u63d0\u524d\u505c\u6b62"},{"location":"deeplearning/section4/#4","text":"\u6279\u6807\u51c6\u5316(BN\u5c42,Batch Normalization)\u662f2015\u5e74\u63d0\u51fa\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5728\u8fdb\u884c\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u65f6\uff0c\u5927\u591a\u4f1a\u91c7\u53d6\u8fd9\u79cd\u7b97\u6cd5\uff0c\u4e0e\u5168\u8fde\u63a5\u5c42\u4e00\u6837\uff0cBN\u5c42\u4e5f\u662f\u5c5e\u4e8e\u7f51\u7edc\u4e2d\u7684\u4e00\u5c42\u3002 BN\u5c42\u662f\u9488\u5bf9\u5355\u4e2a\u795e\u7ecf\u5143\u8fdb\u884c\uff0c\u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization\u3002\u5728\u6bcf\u4e00\u5c42\u8f93\u5165\u4e4b\u524d\uff0c\u5c06\u6570\u636e\u8fdb\u884cBN\uff0c\u7136\u540e\u518d\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5b66\u4e60\uff1a \u9996\u5148\u6211\u4eec\u5bf9\u67d0\u4e00\u6279\u6b21\u7684\u6570\u636e\u7684\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u8fdb\u884c\u6807\u51c6\u5316\uff0c \u7136\u540e\u5728\u4f7f\u7528\u53d8\u6362\u91cd\u6784\uff0c\u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u53c2\u6570\u03b3\u3001\u03b2\uff0c\u5982\u679c\u5404\u9690\u85cf\u5c42\u7684\u8f93\u5165\u5747\u503c\u5728\u9760\u8fd10\u7684\u533a\u57df\uff0c\u5373\u5904\u4e8e\u6fc0\u6d3b\u51fd\u6570\u7684\u7ebf\u6027\u533a\u57df\uff0c\u4e0d\u5229\u4e8e\u8bad\u7ec3\u975e\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\uff0c\u4ece\u800c\u5f97\u5230\u6548\u679c\u8f83\u5dee\u7684\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7528 \u03b3 \u548c \u03b2 \u5bf9\u6807\u51c6\u5316\u540e\u7684\u7ed3\u679c\u505a\u8fdb\u4e00\u6b65\u5904\u7406\uff1a \u8fd9\u5c31\u662fBN\u5c42\u6700\u540e\u7684\u7ed3\u679c\u3002\u6574\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5b9e\u73b0\u4f7f\u7528\uff1a # \u76f4\u63a5\u5c06\u5176\u653e\u5165\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u4e2d\u5373\u53ef tf . keras . layers . BatchNormalization ( epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , )","title":"4. \u6279\u6807\u51c6\u5316"},{"location":"deeplearning/section4/#328","text":"\u77e5\u9053L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u65b9\u6cd5 \u5728\u635f\u5931\u51fd\u6570\uff08cost function\uff09\u4e2d\u589e\u52a0\u4e00\u4e2a\u6b63\u5219\u9879\uff0c\u7531\u4e8e\u6dfb\u52a0\u4e86\u8fd9\u4e2a\u6b63\u5219\u5316\u9879\uff0c\u6743\u91cd\u77e9\u9635\u7684\u503c\u51cf\u5c0f\uff0c\u56e0\u4e3a\u5b83\u5047\u5b9a\u5177\u6709\u66f4\u5c0f\u6743\u91cd\u77e9\u9635\u7684\u795e\u7ecf\u7f51\u7edc\u5bfc\u81f4\u66f4\u7b80\u5355\u7684\u6a21\u578b \u77e5\u9053\u968f\u673a\u5931\u6d3bdroupout\u7684\u5e94\u7528 \u5728\u6bcf\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u67d0\u4e9b\u8282\u70b9\uff0c\u5e76\u4e14\u5220\u9664\u524d\u5411\u548c\u540e\u5411\u8fde\u63a5 \u77e5\u9053\u63d0\u524d\u505c\u6b62\u7684\u4f7f\u7528\u65b9\u6cd5 \u5f53\u770b\u5230\u9a8c\u8bc1\u96c6\u7684\u6027\u80fd\u8d8a\u6765\u8d8a\u5dee\u65f6\u6216\u8005\u6027\u80fd\u4e0d\u518d\u63d0\u5347\uff0c\u7acb\u5373\u505c\u6b62\u5bf9\u8be5\u6a21\u578b\u7684\u8bad\u7ec3 \u77e5\u9053BN\u5c42\u7684\u4f7f\u7528\u65b9\u6cd5 \u5229\u7528\u7f51\u7edc\u8bad\u7ec3\u65f6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\u6765\u8ba1\u7b97\u8be5\u795e\u7ecf\u5143xi \u7684\u5747\u503c\u548c\u65b9\u5dee,\u5f52\u4e00\u5316\u540e\u5e76\u91cd\u6784\uff0c\u56e0\u800c\u79f0\u4e3a Batch Normalization","title":"3.2.8 \u603b\u7ed3"},{"location":"deeplearning/section5/","text":"2.5 \u795e\u7ecf\u7f51\u7edc\u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6 \u80fd\u591f\u7f51\u7edc\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 \u4f7f\u7528\u624b\u5199\u6570\u5b57\u7684MNIST\u6570\u636e\u96c6\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b60,000\u4e2a\u7528\u4e8e\u8bad\u7ec3\u7684\u6837\u672c\u548c10,000\u4e2a\u7528\u4e8e\u6d4b\u8bd5\u7684\u6837\u672c\uff0c\u56fe\u50cf\u662f\u56fa\u5b9a\u5927\u5c0f(28x28\u50cf\u7d20)\uff0c\u5176\u503c\u4e3a0\u5230255\u3002 \u6574\u4e2a\u6848\u4f8b\u7684\u5b9e\u73b0\u6d41\u7a0b\u662f\uff1a \u6570\u636e\u52a0\u8f7d \u6570\u636e\u5904\u7406 \u6a21\u578b\u6784\u5efa \u6a21\u578b\u8bad\u7ec3 \u6a21\u578b\u6d4b\u8bd5 \u6a21\u578b\u4fdd\u5b58 \u9996\u5148\u8981\u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import numpy as np import matplotlib.pyplot as plt plt . rcParams [ 'figure.figsize' ] = ( 7 , 7 ) # Make the figures a bit bigger import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist # \u6784\u5efa\u5e8f\u5217\u6a21\u578b from tensorflow.keras.models import Sequential # \u5bfc\u5165\u9700\u8981\u7684\u5c42 from tensorflow.keras.layers import Dense , Dropout , Activation , BatchNormalization # \u5bfc\u5165\u8f85\u52a9\u5de5\u5177\u5305 from tensorflow.keras import utils # \u6b63\u5219\u5316 from tensorflow.keras import regularizers 1.\u6570\u636e\u52a0\u8f7d \u00b6 \u9996\u5148\u52a0\u8f7d\u624b\u5199\u6570\u5b57\u56fe\u50cf # \u7c7b\u522b\u603b\u6570 nb_classes = 10 # \u52a0\u8f7d\u6570\u636e\u96c6 ( X_train , y_train ), ( X_test , y_test ) = mnist . load_data () # \u6253\u5370\u8f93\u51fa\u6570\u636e\u96c6\u7684\u7ef4\u5ea6 print ( \"\u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6\" , X_train . shape ) print ( \"\u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6\" , y_train . shape ) \u7ed3\u679c\u4e3a\uff1a \u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6 ( 60000 , 28 , 28 ) \u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6 ( 60000 ,) \u6570\u636e\u5c55\u793a\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( X_train [ i ], cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57{}\" . format ( y_train [ i ])) \u6548\u679c\u5982\u4e0b\u6240\u793a\uff1a 2.\u6570\u636e\u5904\u7406 \u00b6 \u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8f93\u5165\u8fdb\u884c\u91cd\u5851\uff0c\u4f7f\u6bcf\u4e2a28x28\u7684\u56fe\u50cf\u6210\u4e3a\u4e00\u4e2a\u7684784\u7ef4\u5411\u91cf\u3002\u53e6\u5916\uff0c\u5c06\u8f93\u5165\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u4ece0-255\u8c03\u6574\u52300-1\u3002 # \u8c03\u6574\u6570\u636e\u7ef4\u5ea6\uff1a\u6bcf\u4e00\u4e2a\u6570\u5b57\u8f6c\u6362\u6210\u4e00\u4e2a\u5411\u91cf X_train = X_train . reshape ( 60000 , 784 ) X_test = X_test . reshape ( 10000 , 784 ) # \u683c\u5f0f\u8f6c\u6362 X_train = X_train . astype ( 'float32' ) X_test = X_test . astype ( 'float32' ) # \u5f52\u4e00\u5316 X_train /= 255 X_test /= 255 # \u7ef4\u5ea6\u8c03\u6574\u540e\u7684\u7ed3\u679c print ( \"\u8bad\u7ec3\u96c6\uff1a\" , X_train . shape ) print ( \"\u6d4b\u8bd5\u96c6\uff1a\" , X_test . shape \uff09 \u8f93\u51fa\u4e3a\uff1a \u8bad\u7ec3\u96c6\uff1a ( 60000 , 784 ) \u6d4b\u8bd5\u96c6\uff1a ( 10000 , 784 ) \u53e6\u5916\u5bf9\u4e8e\u76ee\u6807\u503c\u6211\u4eec\u4e5f\u9700\u8981\u8fdb\u884c\u5904\u7406\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f\uff1a \u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5c06\u76ee\u6807\u503c\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f Y_train = utils . to_categorical ( y_train , nb_classes ) Y_test = utils . to_categorical ( y_test , nb_classes ) 3.\u6a21\u578b\u6784\u5efa \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u6784\u5efa\u53ea\u67093\u5c42\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u5904\u7406\uff1a \u6784\u5efa\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5229\u7528\u5e8f\u5217\u6a21\u578b\u6765\u6784\u5efa\u6a21\u578b model = Sequential () # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143\uff0c\u8f93\u5165\u7ef4\u5ea6\u5927\u5c0f\u4e3a784 model . add ( Dense ( 512 , input_shape = ( 784 ,))) # \u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528relu model . add ( Activation ( 'relu' )) # \u4f7f\u7528\u6b63\u5219\u5316\u65b9\u6cd5drouout model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143,\u5e76\u52a0\u5165L2\u6b63\u5219\u5316 model . add ( Dense ( 512 , kernel_regularizer = regularizers . l2 ( 0.001 ))) # BN\u5c42 model . add ( BatchNormalization ()) # \u6fc0\u6d3b\u51fd\u6570 model . add ( Activation ( 'relu' )) model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u51fa\u5c42\u517110\u4e2a\u795e\u7ecf\u5143 model . add ( Dense ( 10 )) # softmax\u5c06\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684score\u8f6c\u6362\u4e3a\u6982\u7387\u503c model . add ( Activation ( 'softmax' )) \u6211\u4eec\u901a\u8fc7model.summay\u6765\u770b\u4e0b\u7ed3\u679c\uff1a Model : \"sequential_6\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= dense_13 ( Dense ) ( None , 512 ) 401920 _________________________________________________________________ activation_8 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_7 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_14 ( Dense ) ( None , 512 ) 262656 _________________________________________________________________ batch_normalization ( BatchNo ( None , 512 ) 2048 _________________________________________________________________ activation_9 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_8 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_15 ( Dense ) ( None , 10 ) 5130 _________________________________________________________________ activation_10 ( Activation ) ( None , 10 ) 0 ================================================================= Total params : 671 , 754 Trainable params : 670 , 730 Non - trainable params : 1 , 024 _________________________________________________________________ 4.\u6a21\u578b\u7f16\u8bd1 \u00b6 \u8bbe\u7f6e\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f18\u5316\u65b9\u6cd5adam\uff0c\u635f\u5931\u51fd\u6570\u7528\u6765\u8861\u91cf\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4f18\u5316\u5668\u7528\u6765\u4f7f\u7528\u635f\u5931\u51fd\u6570\u8fbe\u5230\u6700\u4f18\uff1a # \u6a21\u578b\u7f16\u8bd1\uff0c\u6307\u660e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\uff0c\u8bc4\u4f30\u6307\u6807 model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) 5.\u6a21\u578b\u8bad\u7ec3 \u00b6 # batch_size\u662f\u6bcf\u6b21\u9001\u5165\u6a21\u578b\u4e2d\u6837\u672c\u4e2a\u6570\uff0cepochs\u662f\u6240\u6709\u6837\u672c\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u5e76\u6307\u660e\u9a8c\u8bc1\u6570\u636e\u96c6 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , validation_data = ( X_test , Y_test )) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a Epoch 1/4 469/469 [==============================] - 2s 4ms/step - loss: 0.5273 - accuracy: 0.9291 - val_loss: 0.2686 - val_accuracy: 0.9664 Epoch 2/4 469/469 [==============================] - 2s 4ms/step - loss: 0.2213 - accuracy: 0.9662 - val_loss: 0.1672 - val_accuracy: 0.9720 Epoch 3/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9734 - val_loss: 0.1462 - val_accuracy: 0.9735 Epoch 4/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9768 - val_loss: 0.1292 - val_accuracy: 0.9777 \u5c06\u635f\u5931\u7ed8\u5236\u6210\u66f2\u7ebf\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u635f\u5931\u51fd\u6570\u53d8\u6362 plt . plot ( history . history [ \"loss\" ], label = \"train_loss\" ) # \u9a8c\u8bc1\u96c6\u635f\u5931\u51fd\u6570\u53d8\u5316 plt . plot ( history . history [ \"val_loss\" ], label = \"val_loss\" ) plt . legend () plt . grid () \u5c06\u8bad\u7ec3\u7684\u51c6\u786e\u7387\u7ed8\u5236\u4e3a\u66f2\u7ebf\uff1a # \u7ed8\u5236\u51c6\u786e\u7387\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"accuracy\" ], label = \"train_acc\" ) # \u9a8c\u8bc1\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"val_accuracy\" ], label = \"val_acc\" ) plt . legend () plt . grid () \u53e6\u5916\u53ef\u901a\u8fc7tensorboard\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd9\u65f6\u6211\u4eec\u6307\u5b9a\u56de\u8c03\u51fd\u6570\uff1a # \u6dfb\u52a0tensoboard\u89c2\u5bdf tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) \u5728\u8fdb\u884c\u8bad\u7ec3\uff1a # \u8bad\u7ec3 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , callbacks = [ tensorboard ], validation_data = ( X_test , Y_test )) \u6253\u5f00\u7ec8\u7aef\uff1a # \u6307\u5b9a\u5b58\u5728\u6587\u4ef6\u7684\u76ee\u5f55\uff0c\u6253\u5f00\u4e0b\u9762\u547d\u4ee4 tensorboard -- logdir = \"./\" \u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00\u6307\u5b9a\u7f51\u5740\uff0c\u53ef\u67e5\u770b\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387\u7684\u53d8\u5316\uff0c\u56fe\u7ed3\u6784\u7b49\u3002 6.\u6a21\u578b\u6d4b\u8bd5 \u00b6 # \u6a21\u578b\u6d4b\u8bd5 score = model . evaluate ( X_test , Y_test , verbose = 1 ) # \u6253\u5370\u7ed3\u679c print ( '\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387:' , score ) \u7ed3\u679c\uff1a 313 / 313 [ ============================== ] - 0 s 1 ms / step - loss : 0.1292 - accuracy : 0.9777 Test accuracy : 0.9776999950408936 7.\u6a21\u578b\u4fdd\u5b58 \u00b6 # \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = tf . keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6\uff1a load_data() \u80fd\u591f\u8fdb\u884c\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa dense,\u6fc0\u6d3b\u51fd\u6570\uff0cdropout,BN\u5c42\u7b49 \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 fit\uff0c\u56de\u8c03\u51fd\u6570\uff0cevaluate, \u4fdd\u5b58\u6a21\u578b","title":"\u795e\u7ecf\u7f51\u7edc\u6848\u4f8b"},{"location":"deeplearning/section5/#25","text":"\u5b66\u4e60\u76ee\u6807 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6 \u80fd\u591f\u7f51\u7edc\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 \u4f7f\u7528\u624b\u5199\u6570\u5b57\u7684MNIST\u6570\u636e\u96c6\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b60,000\u4e2a\u7528\u4e8e\u8bad\u7ec3\u7684\u6837\u672c\u548c10,000\u4e2a\u7528\u4e8e\u6d4b\u8bd5\u7684\u6837\u672c\uff0c\u56fe\u50cf\u662f\u56fa\u5b9a\u5927\u5c0f(28x28\u50cf\u7d20)\uff0c\u5176\u503c\u4e3a0\u5230255\u3002 \u6574\u4e2a\u6848\u4f8b\u7684\u5b9e\u73b0\u6d41\u7a0b\u662f\uff1a \u6570\u636e\u52a0\u8f7d \u6570\u636e\u5904\u7406 \u6a21\u578b\u6784\u5efa \u6a21\u578b\u8bad\u7ec3 \u6a21\u578b\u6d4b\u8bd5 \u6a21\u578b\u4fdd\u5b58 \u9996\u5148\u8981\u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\uff1a # \u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305 import numpy as np import matplotlib.pyplot as plt plt . rcParams [ 'figure.figsize' ] = ( 7 , 7 ) # Make the figures a bit bigger import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist # \u6784\u5efa\u5e8f\u5217\u6a21\u578b from tensorflow.keras.models import Sequential # \u5bfc\u5165\u9700\u8981\u7684\u5c42 from tensorflow.keras.layers import Dense , Dropout , Activation , BatchNormalization # \u5bfc\u5165\u8f85\u52a9\u5de5\u5177\u5305 from tensorflow.keras import utils # \u6b63\u5219\u5316 from tensorflow.keras import regularizers","title":"2.5 \u795e\u7ecf\u7f51\u7edc\u6848\u4f8b"},{"location":"deeplearning/section5/#1","text":"\u9996\u5148\u52a0\u8f7d\u624b\u5199\u6570\u5b57\u56fe\u50cf # \u7c7b\u522b\u603b\u6570 nb_classes = 10 # \u52a0\u8f7d\u6570\u636e\u96c6 ( X_train , y_train ), ( X_test , y_test ) = mnist . load_data () # \u6253\u5370\u8f93\u51fa\u6570\u636e\u96c6\u7684\u7ef4\u5ea6 print ( \"\u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6\" , X_train . shape ) print ( \"\u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6\" , y_train . shape ) \u7ed3\u679c\u4e3a\uff1a \u8bad\u7ec3\u6837\u672c\u521d\u59cb\u7ef4\u5ea6 ( 60000 , 28 , 28 ) \u8bad\u7ec3\u6837\u672c\u76ee\u6807\u503c\u521d\u59cb\u7ef4\u5ea6 ( 60000 ,) \u6570\u636e\u5c55\u793a\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( X_train [ i ], cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57{}\" . format ( y_train [ i ])) \u6548\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"1.\u6570\u636e\u52a0\u8f7d"},{"location":"deeplearning/section5/#2","text":"\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8f93\u5165\u8fdb\u884c\u91cd\u5851\uff0c\u4f7f\u6bcf\u4e2a28x28\u7684\u56fe\u50cf\u6210\u4e3a\u4e00\u4e2a\u7684784\u7ef4\u5411\u91cf\u3002\u53e6\u5916\uff0c\u5c06\u8f93\u5165\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u4ece0-255\u8c03\u6574\u52300-1\u3002 # \u8c03\u6574\u6570\u636e\u7ef4\u5ea6\uff1a\u6bcf\u4e00\u4e2a\u6570\u5b57\u8f6c\u6362\u6210\u4e00\u4e2a\u5411\u91cf X_train = X_train . reshape ( 60000 , 784 ) X_test = X_test . reshape ( 10000 , 784 ) # \u683c\u5f0f\u8f6c\u6362 X_train = X_train . astype ( 'float32' ) X_test = X_test . astype ( 'float32' ) # \u5f52\u4e00\u5316 X_train /= 255 X_test /= 255 # \u7ef4\u5ea6\u8c03\u6574\u540e\u7684\u7ed3\u679c print ( \"\u8bad\u7ec3\u96c6\uff1a\" , X_train . shape ) print ( \"\u6d4b\u8bd5\u96c6\uff1a\" , X_test . shape \uff09 \u8f93\u51fa\u4e3a\uff1a \u8bad\u7ec3\u96c6\uff1a ( 60000 , 784 ) \u6d4b\u8bd5\u96c6\uff1a ( 10000 , 784 ) \u53e6\u5916\u5bf9\u4e8e\u76ee\u6807\u503c\u6211\u4eec\u4e5f\u9700\u8981\u8fdb\u884c\u5904\u7406\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f\uff1a \u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5c06\u76ee\u6807\u503c\u8f6c\u6362\u4e3a\u70ed\u7f16\u7801\u7684\u5f62\u5f0f Y_train = utils . to_categorical ( y_train , nb_classes ) Y_test = utils . to_categorical ( y_test , nb_classes )","title":"2.\u6570\u636e\u5904\u7406"},{"location":"deeplearning/section5/#3","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u6784\u5efa\u53ea\u67093\u5c42\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u5904\u7406\uff1a \u6784\u5efa\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a # \u5229\u7528\u5e8f\u5217\u6a21\u578b\u6765\u6784\u5efa\u6a21\u578b model = Sequential () # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143\uff0c\u8f93\u5165\u7ef4\u5ea6\u5927\u5c0f\u4e3a784 model . add ( Dense ( 512 , input_shape = ( 784 ,))) # \u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528relu model . add ( Activation ( 'relu' )) # \u4f7f\u7528\u6b63\u5219\u5316\u65b9\u6cd5drouout model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u5171512\u4e2a\u795e\u7ecf\u5143,\u5e76\u52a0\u5165L2\u6b63\u5219\u5316 model . add ( Dense ( 512 , kernel_regularizer = regularizers . l2 ( 0.001 ))) # BN\u5c42 model . add ( BatchNormalization ()) # \u6fc0\u6d3b\u51fd\u6570 model . add ( Activation ( 'relu' )) model . add ( Dropout ( 0.2 )) # \u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u51fa\u5c42\u517110\u4e2a\u795e\u7ecf\u5143 model . add ( Dense ( 10 )) # softmax\u5c06\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684score\u8f6c\u6362\u4e3a\u6982\u7387\u503c model . add ( Activation ( 'softmax' )) \u6211\u4eec\u901a\u8fc7model.summay\u6765\u770b\u4e0b\u7ed3\u679c\uff1a Model : \"sequential_6\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= dense_13 ( Dense ) ( None , 512 ) 401920 _________________________________________________________________ activation_8 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_7 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_14 ( Dense ) ( None , 512 ) 262656 _________________________________________________________________ batch_normalization ( BatchNo ( None , 512 ) 2048 _________________________________________________________________ activation_9 ( Activation ) ( None , 512 ) 0 _________________________________________________________________ dropout_8 ( Dropout ) ( None , 512 ) 0 _________________________________________________________________ dense_15 ( Dense ) ( None , 10 ) 5130 _________________________________________________________________ activation_10 ( Activation ) ( None , 10 ) 0 ================================================================= Total params : 671 , 754 Trainable params : 670 , 730 Non - trainable params : 1 , 024 _________________________________________________________________","title":"3.\u6a21\u578b\u6784\u5efa"},{"location":"deeplearning/section5/#4","text":"\u8bbe\u7f6e\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f18\u5316\u65b9\u6cd5adam\uff0c\u635f\u5931\u51fd\u6570\u7528\u6765\u8861\u91cf\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4f18\u5316\u5668\u7528\u6765\u4f7f\u7528\u635f\u5931\u51fd\u6570\u8fbe\u5230\u6700\u4f18\uff1a # \u6a21\u578b\u7f16\u8bd1\uff0c\u6307\u660e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\uff0c\u8bc4\u4f30\u6307\u6807 model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ])","title":"4.\u6a21\u578b\u7f16\u8bd1"},{"location":"deeplearning/section5/#5","text":"# batch_size\u662f\u6bcf\u6b21\u9001\u5165\u6a21\u578b\u4e2d\u6837\u672c\u4e2a\u6570\uff0cepochs\u662f\u6240\u6709\u6837\u672c\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u5e76\u6307\u660e\u9a8c\u8bc1\u6570\u636e\u96c6 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , validation_data = ( X_test , Y_test )) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a Epoch 1/4 469/469 [==============================] - 2s 4ms/step - loss: 0.5273 - accuracy: 0.9291 - val_loss: 0.2686 - val_accuracy: 0.9664 Epoch 2/4 469/469 [==============================] - 2s 4ms/step - loss: 0.2213 - accuracy: 0.9662 - val_loss: 0.1672 - val_accuracy: 0.9720 Epoch 3/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9734 - val_loss: 0.1462 - val_accuracy: 0.9735 Epoch 4/4 469/469 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9768 - val_loss: 0.1292 - val_accuracy: 0.9777 \u5c06\u635f\u5931\u7ed8\u5236\u6210\u66f2\u7ebf\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u635f\u5931\u51fd\u6570\u53d8\u6362 plt . plot ( history . history [ \"loss\" ], label = \"train_loss\" ) # \u9a8c\u8bc1\u96c6\u635f\u5931\u51fd\u6570\u53d8\u5316 plt . plot ( history . history [ \"val_loss\" ], label = \"val_loss\" ) plt . legend () plt . grid () \u5c06\u8bad\u7ec3\u7684\u51c6\u786e\u7387\u7ed8\u5236\u4e3a\u66f2\u7ebf\uff1a # \u7ed8\u5236\u51c6\u786e\u7387\u7684\u53d8\u5316\u66f2\u7ebf plt . figure () # \u8bad\u7ec3\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"accuracy\" ], label = \"train_acc\" ) # \u9a8c\u8bc1\u96c6\u51c6\u786e\u7387 plt . plot ( history . history [ \"val_accuracy\" ], label = \"val_acc\" ) plt . legend () plt . grid () \u53e6\u5916\u53ef\u901a\u8fc7tensorboard\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd9\u65f6\u6211\u4eec\u6307\u5b9a\u56de\u8c03\u51fd\u6570\uff1a # \u6dfb\u52a0tensoboard\u89c2\u5bdf tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) \u5728\u8fdb\u884c\u8bad\u7ec3\uff1a # \u8bad\u7ec3 history = model . fit ( X_train , Y_train , batch_size = 128 , epochs = 4 , verbose = 1 , callbacks = [ tensorboard ], validation_data = ( X_test , Y_test )) \u6253\u5f00\u7ec8\u7aef\uff1a # \u6307\u5b9a\u5b58\u5728\u6587\u4ef6\u7684\u76ee\u5f55\uff0c\u6253\u5f00\u4e0b\u9762\u547d\u4ee4 tensorboard -- logdir = \"./\" \u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00\u6307\u5b9a\u7f51\u5740\uff0c\u53ef\u67e5\u770b\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387\u7684\u53d8\u5316\uff0c\u56fe\u7ed3\u6784\u7b49\u3002","title":"5.\u6a21\u578b\u8bad\u7ec3"},{"location":"deeplearning/section5/#6","text":"# \u6a21\u578b\u6d4b\u8bd5 score = model . evaluate ( X_test , Y_test , verbose = 1 ) # \u6253\u5370\u7ed3\u679c print ( '\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387:' , score ) \u7ed3\u679c\uff1a 313 / 313 [ ============================== ] - 0 s 1 ms / step - loss : 0.1292 - accuracy : 0.9777 Test accuracy : 0.9776999950408936","title":"6.\u6a21\u578b\u6d4b\u8bd5"},{"location":"deeplearning/section5/#7","text":"# \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = tf . keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u80fd\u591f\u5229\u7528tf.keras\u83b7\u53d6\u6570\u636e\u96c6\uff1a load_data() \u80fd\u591f\u8fdb\u884c\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa dense,\u6fc0\u6d3b\u51fd\u6570\uff0cdropout,BN\u5c42\u7b49 \u80fd\u591f\u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30 fit\uff0c\u56de\u8c03\u51fd\u6570\uff0cevaluate, \u4fdd\u5b58\u6a21\u578b","title":"7.\u6a21\u578b\u4fdd\u5b58"},{"location":"deeplearning/section6/","text":"2.6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN) \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u77e5\u9053\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u5229\u7528\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u5b58\u5728\u4ee5\u4e0b\u4e24\u4e2a\u95ee\u9898\uff1a \u9700\u8981\u5904\u7406\u7684\u6570\u636e\u91cf\u5927\uff0c\u6548\u7387\u4f4e \u5047\u5982\u6211\u4eec\u5904\u7406\u4e00\u5f20 1000\u00d71000 \u50cf\u7d20\u7684\u56fe\u7247\uff0c\u53c2\u6570\u91cf\u5982\u4e0b\uff1a 1000\u00d71000\u00d73=3,000,000 \u8fd9\u4e48\u5927\u91cf\u7684\u6570\u636e\u5904\u7406\u8d77\u6765\u662f\u975e\u5e38\u6d88\u8017\u8d44\u6e90\u7684 \u56fe\u50cf\u5728\u7ef4\u5ea6\u8c03\u6574\u7684\u8fc7\u7a0b\u4e2d\u5f88\u96be\u4fdd\u7559\u539f\u6709\u7684\u7279\u5f81\uff0c\u5bfc\u81f4\u56fe\u50cf\u5904\u7406\u7684\u51c6\u786e\u7387\u4e0d\u9ad8 \u5047\u5982\u6709\u5706\u5f62\u662f1\uff0c\u6ca1\u6709\u5706\u5f62\u662f0\uff0c\u90a3\u4e48\u5706\u5f62\u7684\u4f4d\u7f6e\u4e0d\u540c\u5c31\u4f1a\u4ea7\u751f\u5b8c\u5168\u4e0d\u540c\u7684\u6570\u636e\u8868\u8fbe\u3002\u4f46\u662f\u4ece\u56fe\u50cf\u7684\u89d2\u5ea6\u6765\u770b\uff0c \u56fe\u50cf\u7684\u5185\u5bb9\uff08\u672c\u8d28\uff09\u5e76\u6ca1\u6709\u53d1\u751f\u53d8\u5316\uff0c\u53ea\u662f\u4f4d\u7f6e\u53d1\u751f\u4e86\u53d8\u5316 \u3002\u6240\u4ee5\u5f53\u6211\u4eec\u79fb\u52a8\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\uff0c\u7528\u5168\u8fde\u63a5\u5347\u964d\u5f97\u5230\u7684\u7ed3\u679c\u4f1a\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u662f\u4e0d\u7b26\u5408\u56fe\u50cf\u5904\u7406\u7684\u8981\u6c42\u7684\u3002 1.CNN\u7f51\u7edc\u7684\u6784\u6210 \u00b6 CNN\u7f51\u7edc\u53d7\u4eba\u7c7b\u89c6\u89c9\u795e\u7ecf\u7cfb\u7edf\u7684\u542f\u53d1\uff0c\u4eba\u7c7b\u7684\u89c6\u89c9\u539f\u7406\uff1a\u4ece\u539f\u59cb\u4fe1\u53f7\u6444\u5165\u5f00\u59cb\uff08\u77b3\u5b54\u6444\u5165\u50cf\u7d20 Pixels\uff09\uff0c\u63a5\u7740\u505a\u521d\u6b65\u5904\u7406\uff08\u5927\u8111\u76ae\u5c42\u67d0\u4e9b\u7ec6\u80de\u53d1\u73b0\u8fb9\u7f18\u548c\u65b9\u5411\uff09\uff0c\u7136\u540e\u62bd\u8c61\uff08\u5927\u8111\u5224\u5b9a\uff0c\u773c\u524d\u7684\u7269\u4f53\u7684\u5f62\u72b6\uff0c\u662f\u5706\u5f62\u7684\uff09\uff0c\u7136\u540e\u8fdb\u4e00\u6b65\u62bd\u8c61\uff08\u5927\u8111\u8fdb\u4e00\u6b65\u5224\u5b9a\u8be5\u7269\u4f53\u662f\u53ea\u4eba\u8138\uff09\u3002\u4e0b\u9762\u662f\u4eba\u8111\u8fdb\u884c\u4eba\u8138\u8bc6\u522b\u7684\u4e00\u4e2a\u793a\u4f8b\uff1a CNN\u7f51\u7edc\u4e3b\u8981\u6709\u4e09\u90e8\u5206\u6784\u6210\uff1a\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u6784\u6210\uff0c\u5176\u4e2d\u5377\u79ef\u5c42\u8d1f\u8d23\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u5c40\u90e8\u7279\u5f81\uff1b\u6c60\u5316\u5c42\u7528\u6765\u5927\u5e45\u964d\u4f4e\u53c2\u6570\u91cf\u7ea7(\u964d\u7ef4)\uff1b\u5168\u8fde\u63a5\u5c42\u7c7b\u4f3c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u90e8\u5206\uff0c\u7528\u6765\u8f93\u51fa\u60f3\u8981\u7684\u7ed3\u679c\u3002 \u6574\u4e2aCNN\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a 2. \u5377\u79ef\u5c42 \u00b6 \u5377\u79ef\u5c42\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6838\u5fc3\u6a21\u5757\uff0c\u5377\u79ef\u5c42\u7684\u76ee\u7684\u662f\u63d0\u53d6\u8f93\u5165\u7279\u5f81\u56fe\u7684\u7279\u5f81\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5377\u79ef\u6838\u53ef\u4ee5\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u8fb9\u7f18\u4fe1\u606f\u3002 2.1 \u5377\u79ef\u7684\u8ba1\u7b97\u65b9\u6cd5 \u00b6 \u90a3\u5377\u79ef\u662f\u600e\u4e48\u8fdb\u884c\u8ba1\u7b97\u7684\u5462\uff1f \u5377\u79ef\u8fd0\u7b97\u672c\u8d28\u4e0a\u5c31\u662f\u5728\u6ee4\u6ce2\u5668\u548c\u8f93\u5165\u6570\u636e\u7684\u5c40\u90e8\u533a\u57df\u95f4\u505a\u70b9\u79ef\u3002 \u5de6\u4e0a\u89d2\u7684\u70b9\u8ba1\u7b97\u65b9\u6cd5\uff1a \u540c\u7406\u53ef\u4ee5\u8ba1\u7b97\u5176\u4ed6\u5404\u70b9\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5377\u79ef\u7ed3\u679c\uff0c \u6700\u540e\u4e00\u70b9\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a 2.2 padding \u00b6 \u5728\u4e0a\u8ff0\u5377\u79ef\u8fc7\u7a0b\u4e2d\uff0c\u7279\u5f81\u56fe\u6bd4\u539f\u59cb\u56fe\u51cf\u5c0f\u4e86\u5f88\u591a\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u539f\u56fe\u50cf\u7684\u5468\u56f4\u8fdb\u884cpadding,\u6765\u4fdd\u8bc1\u5728\u5377\u79ef\u8fc7\u7a0b\u4e2d\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u53d8\u3002 2.3 stride \u00b6 \u6309\u7167\u6b65\u957f\u4e3a1\u6765\u79fb\u52a8\u5377\u79ef\u6838\uff0c\u8ba1\u7b97\u7279\u5f81\u56fe\u5982\u4e0b\u6240\u793a\uff1a \u5982\u679c\u6211\u4eec\u628astride\u589e\u5927,\u6bd4\u5982\u8bbe\u4e3a2\uff0c\u4e5f\u662f\u53ef\u4ee5\u63d0\u53d6\u7279\u5f81\u56fe\u7684\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a 2.4 \u591a\u901a\u9053\u5377\u79ef \u00b6 \u5b9e\u9645\u4e2d\u7684\u56fe\u50cf\u90fd\u662f\u591a\u4e2a\u901a\u9053\u7ec4\u6210\u7684\uff0c\u6211\u4eec\u600e\u4e48\u8ba1\u7b97\u5377\u79ef\u5462\uff1f \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a\u5f53\u8f93\u5165\u6709\u591a\u4e2a\u901a\u9053\uff08channel\uff09\u65f6(\u4f8b\u5982\u56fe\u7247\u53ef\u4ee5\u6709 RGB \u4e09\u4e2a\u901a\u9053)\uff0c\u5377\u79ef\u6838\u9700\u8981\u62e5\u6709\u76f8\u540c\u7684channel\u6570,\u6bcf\u4e2a\u5377\u79ef\u6838 channel \u4e0e\u8f93\u5165\u5c42\u7684\u5bf9\u5e94 channel \u8fdb\u884c\u5377\u79ef\uff0c\u5c06\u6bcf\u4e2a channel \u7684\u5377\u79ef\u7ed3\u679c\u6309\u4f4d\u76f8\u52a0\u5f97\u5230\u6700\u7ec8\u7684 Feature Map 2.5 \u591a\u5377\u79ef\u6838\u5377\u79ef \u00b6 \u5982\u679c\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\u600e\u4e48\u8ba1\u7b97\u5462\uff1f\u5f53\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u5b66\u4e60\u5230\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u5bf9\u5e94\u4ea7\u751f\u5305\u542b\u591a\u4e2a channel \u7684 Feature Map, \u4f8b\u5982\u4e0b\u56fe\u6709\u4e24\u4e2a filter\uff0c\u6240\u4ee5 output \u6709\u4e24\u4e2a channel\u3002 2.6 \u7279\u5f81\u56fe\u5927\u5c0f \u00b6 \u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e0e\u4ee5\u4e0b\u53c2\u6570\u606f\u606f\u76f8\u5173\uff1a * size:\u5377\u79ef\u6838/\u8fc7\u6ee4\u5668\u5927\u5c0f\uff0c\u4e00\u822c\u4f1a\u9009\u62e9\u4e3a\u5947\u6570\uff0c\u6bd4\u5982\u67091 * 1\uff0c 3 * 3\uff0c 5 * 5 * padding\uff1a\u96f6\u586b\u5145\u7684\u65b9\u5f0f * stride:\u6b65\u957f \u90a3\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165\u7279\u5f81\u56fe\u4e3a5x5\uff0c\u5377\u79ef\u6838\u4e3a3x3\uff0c\u5916\u52a0padding \u4e3a1\uff0c\u5219\u5176\u8f93\u51fa\u5c3a\u5bf8\u4e3a\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5377\u79ef\u6838\u7684\u5b9e\u73b0\u4f7f\u7528 tf . keras . layers . Conv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , activation = None ) \u4e3b\u8981\u53c2\u6570\u8bf4\u660e\u5982\u4e0b\uff1a 3 \u6c60\u5316\u5c42(Pooling) \u00b6 \u6c60\u5316\u5c42\u8fce\u6765\u964d\u4f4e\u4e86\u540e\u7eed\u7f51\u7edc\u5c42\u7684\u8f93\u5165\u7ef4\u5ea6\uff0c\u7f29\u51cf\u6a21\u578b\u5927\u5c0f\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e86Feature Map \u7684\u9c81\u68d2\u6027\uff0c\u9632\u6b62\u8fc7\u62df\u5408\uff0c \u5b83\u4e3b\u8981\u5bf9\u5377\u79ef\u5c42\u5b66\u4e60\u5230\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0b\u91c7\u6837\uff08subsampling\uff09\u5904\u7406\uff0c\u4e3b\u8981\u7531\u4e24\u79cd 3.1 \u6700\u5927\u6c60\u5316 \u00b6 Max Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u8f93\u51fa \uff0c\u8fd9\u79cd\u65b9\u5f0f\u4f7f\u7528\u8f83\u5e7f\u6cdb\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . MaxPool2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' ) \u53c2\u6570\uff1a pool_size: \u6c60\u5316\u7a97\u53e3\u7684\u5927\u5c0f strides: \u7a97\u53e3\u79fb\u52a8\u7684\u6b65\u957f\uff0c\u9ed8\u8ba4\u4e3a1 padding: \u662f\u5426\u8fdb\u884c\u586b\u5145\uff0c\u9ed8\u8ba4\u662f\u4e0d\u8fdb\u884c\u586b\u5145\u7684 3.2 \u5e73\u5747\u6c60\u5316 \u00b6 Avg Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6240\u6709\u503c\u7684\u5747\u503c\u4f5c\u4e3a\u8f93\u51fa \u5728tf.keras\u4e2d\u5b9e\u73b0\u6c60\u5316\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' ) 4. \u5168\u8fde\u63a5\u5c42 \u00b6 \u5168\u8fde\u63a5\u5c42\u4f4d\u4e8eCNN\u7f51\u7edc\u7684\u672b\u7aef\uff0c\u7ecf\u8fc7\u5377\u79ef\u5c42\u7684\u7279\u5f81\u63d0\u53d6\u4e0e\u6c60\u5316\u5c42\u7684\u964d\u7ef4\u540e\uff0c\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u6210\u4e00\u7ef4\u5411\u91cf\u9001\u5165\u5230\u5168\u8fde\u63a5\u5c42\u4e2d\u8fdb\u884c\u5206\u7c7b\u6216\u56de\u5f52\u7684\u64cd\u4f5c\u3002 \u5728tf.keras\u4e2d\u5168\u8fde\u63a5\u5c42\u4f7f\u7528tf.keras.dense\u5b9e\u73b0\u3002 5.\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa \u00b6 \u6211\u4eec\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728mnist\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5904\u7406\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1aLeNet-5\u662f\u4e00\u4e2a\u8f83\u7b80\u5355\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc, \u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\u3002 \u5bfc\u5165\u5de5\u5177\u5305\uff1a import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist 5.1 \u6570\u636e\u52a0\u8f7d \u00b6 \u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u6848\u4f8b\u4e00\u81f4\uff0c\u9996\u5148\u52a0\u8f7d\u6570\u636e\u96c6\uff1a ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () 5.2 \u6570\u636e\u5904\u7406 \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8981\u6c42\u662f\uff1aN H W C \uff0c\u5206\u522b\u662f\u56fe\u7247\u6570\u91cf\uff0c\u56fe\u7247\u9ad8\u5ea6\uff0c\u56fe\u7247\u5bbd\u5ea6\u548c\u56fe\u7247\u7684\u901a\u9053\uff0c\u56e0\u4e3a\u662f\u7070\u5ea6\u56fe\uff0c\u901a\u9053\u4e3a1. # \u6570\u636e\u5904\u7406\uff1anum,h,w,c # \u8bad\u7ec3\u96c6\u6570\u636e train_images = tf . reshape ( train_images , ( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) print ( train_images . shape ) # \u6d4b\u8bd5\u96c6\u6570\u636e test_images = tf . reshape ( test_images , ( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7ed3\u679c\u4e3a\uff1a (60000, 28, 28, 1) 5.3 \u6a21\u578b\u642d\u5efa \u00b6 Lenet-5\u6a21\u578b\u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\uff0c\u6a21\u578b\u6784\u5efa\u5982\u4e0b\uff1a # \u6a21\u578b\u6784\u5efa net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a6\u4e2a5*5\u7684\u5377\u79ef\u6838\uff0c\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 6 , kernel_size = 5 , activation = 'sigmoid' , input_shape = ( 28 , 28 , 1 )), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a16\u4e2a5*5\u7684\u5377\u79ef\u6838,\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 16 , kernel_size = 5 , activation = 'sigmoid' ), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u7ef4\u5ea6\u8c03\u6574\u4e3a1\u7ef4\u6570\u636e tf . keras . layers . Flatten (), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 120 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 84 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u901a\u8fc7net.summary()\u67e5\u770b\u7f51\u7edc\u7ed3\u6784\uff1a Model : \"sequential_11\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_4 ( Conv2D ) ( None , 24 , 24 , 6 ) 156 _________________________________________________________________ max_pooling2d_4 ( MaxPooling2 ( None , 12 , 12 , 6 ) 0 _________________________________________________________________ conv2d_5 ( Conv2D ) ( None , 8 , 8 , 16 ) 2416 _________________________________________________________________ max_pooling2d_5 ( MaxPooling2 ( None , 4 , 4 , 16 ) 0 _________________________________________________________________ flatten_2 ( Flatten ) ( None , 256 ) 0 _________________________________________________________________ dense_25 ( Dense ) ( None , 120 ) 30840 _________________________________________________________________ dense_26 ( Dense ) ( None , 84 ) 10164 _________________________________________________________________ dense_27 ( Dense ) ( None , 10 ) 850 ================================================================= Total params : 44 , 426 Trainable params : 44 , 426 Non - trainable params : 0 ______________________________________________________________ 5.4 \u6a21\u578b\u7f16\u8bd1 \u00b6 \u8bbe\u7f6e\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\uff1a # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.9 ) # \u6a21\u578b\u7f16\u8bd1\uff1a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 5.5 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u6a21\u578b\u8bad\u7ec3\uff1a # \u6a21\u578b\u8bad\u7ec3 net . fit ( train_images , train_labels , epochs = 5 , validation_split = 0.1 ) \u8bad\u7ec3\u6d41\u7a0b\uff1a Epoch 1 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.8255 - accuracy : 0.6990 - val_loss : 0.1458 - val_accuracy : 0.9543 Epoch 2 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1268 - accuracy : 0.9606 - val_loss : 0.0878 - val_accuracy : 0.9717 Epoch 3 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1054 - accuracy : 0.9664 - val_loss : 0.1025 - val_accuracy : 0.9688 Epoch 4 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0810 - accuracy : 0.9742 - val_loss : 0.0656 - val_accuracy : 0.9807 Epoch 5 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0732 - accuracy : 0.9765 - val_loss : 0.0702 - val_accuracy : 0.9807 5.6 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6a21\u578b\u8bc4\u4f30 score = net . evaluate ( test_images , test_labels , verbose = 1 ) print ( 'Test accuracy:' , score [ 1 ]) \u8f93\u51fa\u4e3a\uff1a 313 / 313 [ ============================== ] - 1 s 2 ms / step - loss : 0.0689 - accuracy : 0.9780 Test accuracy : 0.9779999852180481 \u4e0e\u4f7f\u7528\u5168\u8fde\u63a5\u7f51\u7edc\u76f8\u6bd4\uff0c\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86\u5f88\u591a\u3002 \u5377\u79ef\u795e\u7ecf\u7f51\u8def\u7684\u7ec4\u6210 \u5377\u79ef\u5c42\uff0c\u6c60\u5316\u5c42\uff0c\u5168\u8fde\u63a5\u5c42 \u5377\u79ef\u5c42 \u5377\u79ef\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0cstride,padding... \u6c60\u5316\u5c42 \u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316 CNN\u7ed3\u6784\u7684\u5b9e\u73b0\u548c\u6784\u5efa\u5b9e\u73b0\u7a0b\u5e8f","title":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edcCNN"},{"location":"deeplearning/section6/#26-cnn","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u77e5\u9053\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u5229\u7528\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u5b58\u5728\u4ee5\u4e0b\u4e24\u4e2a\u95ee\u9898\uff1a \u9700\u8981\u5904\u7406\u7684\u6570\u636e\u91cf\u5927\uff0c\u6548\u7387\u4f4e \u5047\u5982\u6211\u4eec\u5904\u7406\u4e00\u5f20 1000\u00d71000 \u50cf\u7d20\u7684\u56fe\u7247\uff0c\u53c2\u6570\u91cf\u5982\u4e0b\uff1a 1000\u00d71000\u00d73=3,000,000 \u8fd9\u4e48\u5927\u91cf\u7684\u6570\u636e\u5904\u7406\u8d77\u6765\u662f\u975e\u5e38\u6d88\u8017\u8d44\u6e90\u7684 \u56fe\u50cf\u5728\u7ef4\u5ea6\u8c03\u6574\u7684\u8fc7\u7a0b\u4e2d\u5f88\u96be\u4fdd\u7559\u539f\u6709\u7684\u7279\u5f81\uff0c\u5bfc\u81f4\u56fe\u50cf\u5904\u7406\u7684\u51c6\u786e\u7387\u4e0d\u9ad8 \u5047\u5982\u6709\u5706\u5f62\u662f1\uff0c\u6ca1\u6709\u5706\u5f62\u662f0\uff0c\u90a3\u4e48\u5706\u5f62\u7684\u4f4d\u7f6e\u4e0d\u540c\u5c31\u4f1a\u4ea7\u751f\u5b8c\u5168\u4e0d\u540c\u7684\u6570\u636e\u8868\u8fbe\u3002\u4f46\u662f\u4ece\u56fe\u50cf\u7684\u89d2\u5ea6\u6765\u770b\uff0c \u56fe\u50cf\u7684\u5185\u5bb9\uff08\u672c\u8d28\uff09\u5e76\u6ca1\u6709\u53d1\u751f\u53d8\u5316\uff0c\u53ea\u662f\u4f4d\u7f6e\u53d1\u751f\u4e86\u53d8\u5316 \u3002\u6240\u4ee5\u5f53\u6211\u4eec\u79fb\u52a8\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\uff0c\u7528\u5168\u8fde\u63a5\u5347\u964d\u5f97\u5230\u7684\u7ed3\u679c\u4f1a\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u662f\u4e0d\u7b26\u5408\u56fe\u50cf\u5904\u7406\u7684\u8981\u6c42\u7684\u3002","title":"2.6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)"},{"location":"deeplearning/section6/#1cnn","text":"CNN\u7f51\u7edc\u53d7\u4eba\u7c7b\u89c6\u89c9\u795e\u7ecf\u7cfb\u7edf\u7684\u542f\u53d1\uff0c\u4eba\u7c7b\u7684\u89c6\u89c9\u539f\u7406\uff1a\u4ece\u539f\u59cb\u4fe1\u53f7\u6444\u5165\u5f00\u59cb\uff08\u77b3\u5b54\u6444\u5165\u50cf\u7d20 Pixels\uff09\uff0c\u63a5\u7740\u505a\u521d\u6b65\u5904\u7406\uff08\u5927\u8111\u76ae\u5c42\u67d0\u4e9b\u7ec6\u80de\u53d1\u73b0\u8fb9\u7f18\u548c\u65b9\u5411\uff09\uff0c\u7136\u540e\u62bd\u8c61\uff08\u5927\u8111\u5224\u5b9a\uff0c\u773c\u524d\u7684\u7269\u4f53\u7684\u5f62\u72b6\uff0c\u662f\u5706\u5f62\u7684\uff09\uff0c\u7136\u540e\u8fdb\u4e00\u6b65\u62bd\u8c61\uff08\u5927\u8111\u8fdb\u4e00\u6b65\u5224\u5b9a\u8be5\u7269\u4f53\u662f\u53ea\u4eba\u8138\uff09\u3002\u4e0b\u9762\u662f\u4eba\u8111\u8fdb\u884c\u4eba\u8138\u8bc6\u522b\u7684\u4e00\u4e2a\u793a\u4f8b\uff1a CNN\u7f51\u7edc\u4e3b\u8981\u6709\u4e09\u90e8\u5206\u6784\u6210\uff1a\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u6784\u6210\uff0c\u5176\u4e2d\u5377\u79ef\u5c42\u8d1f\u8d23\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u5c40\u90e8\u7279\u5f81\uff1b\u6c60\u5316\u5c42\u7528\u6765\u5927\u5e45\u964d\u4f4e\u53c2\u6570\u91cf\u7ea7(\u964d\u7ef4)\uff1b\u5168\u8fde\u63a5\u5c42\u7c7b\u4f3c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u90e8\u5206\uff0c\u7528\u6765\u8f93\u51fa\u60f3\u8981\u7684\u7ed3\u679c\u3002 \u6574\u4e2aCNN\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.CNN\u7f51\u7edc\u7684\u6784\u6210"},{"location":"deeplearning/section6/#2","text":"\u5377\u79ef\u5c42\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6838\u5fc3\u6a21\u5757\uff0c\u5377\u79ef\u5c42\u7684\u76ee\u7684\u662f\u63d0\u53d6\u8f93\u5165\u7279\u5f81\u56fe\u7684\u7279\u5f81\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5377\u79ef\u6838\u53ef\u4ee5\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u8fb9\u7f18\u4fe1\u606f\u3002","title":"2. \u5377\u79ef\u5c42"},{"location":"deeplearning/section6/#21","text":"\u90a3\u5377\u79ef\u662f\u600e\u4e48\u8fdb\u884c\u8ba1\u7b97\u7684\u5462\uff1f \u5377\u79ef\u8fd0\u7b97\u672c\u8d28\u4e0a\u5c31\u662f\u5728\u6ee4\u6ce2\u5668\u548c\u8f93\u5165\u6570\u636e\u7684\u5c40\u90e8\u533a\u57df\u95f4\u505a\u70b9\u79ef\u3002 \u5de6\u4e0a\u89d2\u7684\u70b9\u8ba1\u7b97\u65b9\u6cd5\uff1a \u540c\u7406\u53ef\u4ee5\u8ba1\u7b97\u5176\u4ed6\u5404\u70b9\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5377\u79ef\u7ed3\u679c\uff0c \u6700\u540e\u4e00\u70b9\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a","title":"2.1 \u5377\u79ef\u7684\u8ba1\u7b97\u65b9\u6cd5"},{"location":"deeplearning/section6/#22-padding","text":"\u5728\u4e0a\u8ff0\u5377\u79ef\u8fc7\u7a0b\u4e2d\uff0c\u7279\u5f81\u56fe\u6bd4\u539f\u59cb\u56fe\u51cf\u5c0f\u4e86\u5f88\u591a\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u539f\u56fe\u50cf\u7684\u5468\u56f4\u8fdb\u884cpadding,\u6765\u4fdd\u8bc1\u5728\u5377\u79ef\u8fc7\u7a0b\u4e2d\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u53d8\u3002","title":"2.2 padding"},{"location":"deeplearning/section6/#23-stride","text":"\u6309\u7167\u6b65\u957f\u4e3a1\u6765\u79fb\u52a8\u5377\u79ef\u6838\uff0c\u8ba1\u7b97\u7279\u5f81\u56fe\u5982\u4e0b\u6240\u793a\uff1a \u5982\u679c\u6211\u4eec\u628astride\u589e\u5927,\u6bd4\u5982\u8bbe\u4e3a2\uff0c\u4e5f\u662f\u53ef\u4ee5\u63d0\u53d6\u7279\u5f81\u56fe\u7684\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"2.3 stride"},{"location":"deeplearning/section6/#24","text":"\u5b9e\u9645\u4e2d\u7684\u56fe\u50cf\u90fd\u662f\u591a\u4e2a\u901a\u9053\u7ec4\u6210\u7684\uff0c\u6211\u4eec\u600e\u4e48\u8ba1\u7b97\u5377\u79ef\u5462\uff1f \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a\u5f53\u8f93\u5165\u6709\u591a\u4e2a\u901a\u9053\uff08channel\uff09\u65f6(\u4f8b\u5982\u56fe\u7247\u53ef\u4ee5\u6709 RGB \u4e09\u4e2a\u901a\u9053)\uff0c\u5377\u79ef\u6838\u9700\u8981\u62e5\u6709\u76f8\u540c\u7684channel\u6570,\u6bcf\u4e2a\u5377\u79ef\u6838 channel \u4e0e\u8f93\u5165\u5c42\u7684\u5bf9\u5e94 channel \u8fdb\u884c\u5377\u79ef\uff0c\u5c06\u6bcf\u4e2a channel \u7684\u5377\u79ef\u7ed3\u679c\u6309\u4f4d\u76f8\u52a0\u5f97\u5230\u6700\u7ec8\u7684 Feature Map","title":"2.4 \u591a\u901a\u9053\u5377\u79ef"},{"location":"deeplearning/section6/#25","text":"\u5982\u679c\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\u600e\u4e48\u8ba1\u7b97\u5462\uff1f\u5f53\u6709\u591a\u4e2a\u5377\u79ef\u6838\u65f6\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u5b66\u4e60\u5230\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u5bf9\u5e94\u4ea7\u751f\u5305\u542b\u591a\u4e2a channel \u7684 Feature Map, \u4f8b\u5982\u4e0b\u56fe\u6709\u4e24\u4e2a filter\uff0c\u6240\u4ee5 output \u6709\u4e24\u4e2a channel\u3002","title":"2.5 \u591a\u5377\u79ef\u6838\u5377\u79ef"},{"location":"deeplearning/section6/#26","text":"\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e0e\u4ee5\u4e0b\u53c2\u6570\u606f\u606f\u76f8\u5173\uff1a * size:\u5377\u79ef\u6838/\u8fc7\u6ee4\u5668\u5927\u5c0f\uff0c\u4e00\u822c\u4f1a\u9009\u62e9\u4e3a\u5947\u6570\uff0c\u6bd4\u5982\u67091 * 1\uff0c 3 * 3\uff0c 5 * 5 * padding\uff1a\u96f6\u586b\u5145\u7684\u65b9\u5f0f * stride:\u6b65\u957f \u90a3\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165\u7279\u5f81\u56fe\u4e3a5x5\uff0c\u5377\u79ef\u6838\u4e3a3x3\uff0c\u5916\u52a0padding \u4e3a1\uff0c\u5219\u5176\u8f93\u51fa\u5c3a\u5bf8\u4e3a\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728tf.keras\u4e2d\u5377\u79ef\u6838\u7684\u5b9e\u73b0\u4f7f\u7528 tf . keras . layers . Conv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , activation = None ) \u4e3b\u8981\u53c2\u6570\u8bf4\u660e\u5982\u4e0b\uff1a","title":"2.6 \u7279\u5f81\u56fe\u5927\u5c0f"},{"location":"deeplearning/section6/#3-pooling","text":"\u6c60\u5316\u5c42\u8fce\u6765\u964d\u4f4e\u4e86\u540e\u7eed\u7f51\u7edc\u5c42\u7684\u8f93\u5165\u7ef4\u5ea6\uff0c\u7f29\u51cf\u6a21\u578b\u5927\u5c0f\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e86Feature Map \u7684\u9c81\u68d2\u6027\uff0c\u9632\u6b62\u8fc7\u62df\u5408\uff0c \u5b83\u4e3b\u8981\u5bf9\u5377\u79ef\u5c42\u5b66\u4e60\u5230\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0b\u91c7\u6837\uff08subsampling\uff09\u5904\u7406\uff0c\u4e3b\u8981\u7531\u4e24\u79cd","title":"3 \u6c60\u5316\u5c42(Pooling)"},{"location":"deeplearning/section6/#31","text":"Max Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6700\u5927\u503c\u4f5c\u4e3a\u8f93\u51fa \uff0c\u8fd9\u79cd\u65b9\u5f0f\u4f7f\u7528\u8f83\u5e7f\u6cdb\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . MaxPool2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' ) \u53c2\u6570\uff1a pool_size: \u6c60\u5316\u7a97\u53e3\u7684\u5927\u5c0f strides: \u7a97\u53e3\u79fb\u52a8\u7684\u6b65\u957f\uff0c\u9ed8\u8ba4\u4e3a1 padding: \u662f\u5426\u8fdb\u884c\u586b\u5145\uff0c\u9ed8\u8ba4\u662f\u4e0d\u8fdb\u884c\u586b\u5145\u7684","title":"3.1 \u6700\u5927\u6c60\u5316"},{"location":"deeplearning/section6/#32","text":"Avg Pooling,\u53d6\u7a97\u53e3\u5185\u7684\u6240\u6709\u503c\u7684\u5747\u503c\u4f5c\u4e3a\u8f93\u51fa \u5728tf.keras\u4e2d\u5b9e\u73b0\u6c60\u5316\u7684\u65b9\u6cd5\u662f\uff1a tf . keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' )","title":"3.2 \u5e73\u5747\u6c60\u5316"},{"location":"deeplearning/section6/#4","text":"\u5168\u8fde\u63a5\u5c42\u4f4d\u4e8eCNN\u7f51\u7edc\u7684\u672b\u7aef\uff0c\u7ecf\u8fc7\u5377\u79ef\u5c42\u7684\u7279\u5f81\u63d0\u53d6\u4e0e\u6c60\u5316\u5c42\u7684\u964d\u7ef4\u540e\uff0c\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u6210\u4e00\u7ef4\u5411\u91cf\u9001\u5165\u5230\u5168\u8fde\u63a5\u5c42\u4e2d\u8fdb\u884c\u5206\u7c7b\u6216\u56de\u5f52\u7684\u64cd\u4f5c\u3002 \u5728tf.keras\u4e2d\u5168\u8fde\u63a5\u5c42\u4f7f\u7528tf.keras.dense\u5b9e\u73b0\u3002","title":"4. \u5168\u8fde\u63a5\u5c42"},{"location":"deeplearning/section6/#5","text":"\u6211\u4eec\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728mnist\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5904\u7406\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1aLeNet-5\u662f\u4e00\u4e2a\u8f83\u7b80\u5355\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc, \u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\u3002 \u5bfc\u5165\u5de5\u5177\u5305\uff1a import tensorflow as tf # \u6570\u636e\u96c6 from tensorflow.keras.datasets import mnist","title":"5.\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa"},{"location":"deeplearning/section6/#51","text":"\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u6848\u4f8b\u4e00\u81f4\uff0c\u9996\u5148\u52a0\u8f7d\u6570\u636e\u96c6\uff1a ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data ()","title":"5.1 \u6570\u636e\u52a0\u8f7d"},{"location":"deeplearning/section6/#52","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8981\u6c42\u662f\uff1aN H W C \uff0c\u5206\u522b\u662f\u56fe\u7247\u6570\u91cf\uff0c\u56fe\u7247\u9ad8\u5ea6\uff0c\u56fe\u7247\u5bbd\u5ea6\u548c\u56fe\u7247\u7684\u901a\u9053\uff0c\u56e0\u4e3a\u662f\u7070\u5ea6\u56fe\uff0c\u901a\u9053\u4e3a1. # \u6570\u636e\u5904\u7406\uff1anum,h,w,c # \u8bad\u7ec3\u96c6\u6570\u636e train_images = tf . reshape ( train_images , ( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) print ( train_images . shape ) # \u6d4b\u8bd5\u96c6\u6570\u636e test_images = tf . reshape ( test_images , ( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7ed3\u679c\u4e3a\uff1a (60000, 28, 28, 1)","title":"5.2 \u6570\u636e\u5904\u7406"},{"location":"deeplearning/section6/#53","text":"Lenet-5\u6a21\u578b\u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42,\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u4f7f\u7528softmax\u5206\u7c7b\u4f5c\u4e3a\u8f93\u51fa\u5c42\uff0c\u6a21\u578b\u6784\u5efa\u5982\u4e0b\uff1a # \u6a21\u578b\u6784\u5efa net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a6\u4e2a5*5\u7684\u5377\u79ef\u6838\uff0c\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 6 , kernel_size = 5 , activation = 'sigmoid' , input_shape = ( 28 , 28 , 1 )), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a16\u4e2a5*5\u7684\u5377\u79ef\u6838,\u6fc0\u6d3b\u662fsigmoid tf . keras . layers . Conv2D ( filters = 16 , kernel_size = 5 , activation = 'sigmoid' ), # \u6700\u5927\u6c60\u5316 tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), # \u7ef4\u5ea6\u8c03\u6574\u4e3a1\u7ef4\u6570\u636e tf . keras . layers . Flatten (), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 120 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsigmoid tf . keras . layers . Dense ( 84 , activation = 'sigmoid' ), # \u5168\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3bsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u901a\u8fc7net.summary()\u67e5\u770b\u7f51\u7edc\u7ed3\u6784\uff1a Model : \"sequential_11\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_4 ( Conv2D ) ( None , 24 , 24 , 6 ) 156 _________________________________________________________________ max_pooling2d_4 ( MaxPooling2 ( None , 12 , 12 , 6 ) 0 _________________________________________________________________ conv2d_5 ( Conv2D ) ( None , 8 , 8 , 16 ) 2416 _________________________________________________________________ max_pooling2d_5 ( MaxPooling2 ( None , 4 , 4 , 16 ) 0 _________________________________________________________________ flatten_2 ( Flatten ) ( None , 256 ) 0 _________________________________________________________________ dense_25 ( Dense ) ( None , 120 ) 30840 _________________________________________________________________ dense_26 ( Dense ) ( None , 84 ) 10164 _________________________________________________________________ dense_27 ( Dense ) ( None , 10 ) 850 ================================================================= Total params : 44 , 426 Trainable params : 44 , 426 Non - trainable params : 0 ______________________________________________________________","title":"5.3 \u6a21\u578b\u642d\u5efa"},{"location":"deeplearning/section6/#54","text":"\u8bbe\u7f6e\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\uff1a # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.9 ) # \u6a21\u578b\u7f16\u8bd1\uff1a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"5.4 \u6a21\u578b\u7f16\u8bd1"},{"location":"deeplearning/section6/#55","text":"\u6a21\u578b\u8bad\u7ec3\uff1a # \u6a21\u578b\u8bad\u7ec3 net . fit ( train_images , train_labels , epochs = 5 , validation_split = 0.1 ) \u8bad\u7ec3\u6d41\u7a0b\uff1a Epoch 1 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.8255 - accuracy : 0.6990 - val_loss : 0.1458 - val_accuracy : 0.9543 Epoch 2 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1268 - accuracy : 0.9606 - val_loss : 0.0878 - val_accuracy : 0.9717 Epoch 3 / 5 1688 / 1688 [ ============================== ] - 10 s 6 ms / step - loss : 0.1054 - accuracy : 0.9664 - val_loss : 0.1025 - val_accuracy : 0.9688 Epoch 4 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0810 - accuracy : 0.9742 - val_loss : 0.0656 - val_accuracy : 0.9807 Epoch 5 / 5 1688 / 1688 [ ============================== ] - 11 s 6 ms / step - loss : 0.0732 - accuracy : 0.9765 - val_loss : 0.0702 - val_accuracy : 0.9807","title":"5.5 \u6a21\u578b\u8bad\u7ec3"},{"location":"deeplearning/section6/#56","text":"# \u6a21\u578b\u8bc4\u4f30 score = net . evaluate ( test_images , test_labels , verbose = 1 ) print ( 'Test accuracy:' , score [ 1 ]) \u8f93\u51fa\u4e3a\uff1a 313 / 313 [ ============================== ] - 1 s 2 ms / step - loss : 0.0689 - accuracy : 0.9780 Test accuracy : 0.9779999852180481 \u4e0e\u4f7f\u7528\u5168\u8fde\u63a5\u7f51\u7edc\u76f8\u6bd4\uff0c\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86\u5f88\u591a\u3002 \u5377\u79ef\u795e\u7ecf\u7f51\u8def\u7684\u7ec4\u6210 \u5377\u79ef\u5c42\uff0c\u6c60\u5316\u5c42\uff0c\u5168\u8fde\u63a5\u5c42 \u5377\u79ef\u5c42 \u5377\u79ef\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0cstride,padding... \u6c60\u5316\u5c42 \u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316 CNN\u7ed3\u6784\u7684\u5b9e\u73b0\u548c\u6784\u5efa\u5b9e\u73b0\u7a0b\u5e8f","title":"5.6 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/","text":"\u56fe\u50cf\u5206\u7c7b(Image Classification)2 \u00b6 \u77e5\u9053\u5c40\u90e8\u6700\u4f18\u95ee\u9898\u3001\u978d\u70b9\u4e0e\u6d77\u68ee\u77e9\u9635 \u8bf4\u660e\u6279\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316 \u8bf4\u660e\u4e09\u79cd\u7c7b\u578b\u7684\u4f18\u5316\u7b97\u6cd5 \u77e5\u9053\u5b66\u4e60\u7387\u9000\u706b\u7b56\u7565 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7b56\u7565\u4e0e\u8f93\u5165\u5f52\u4e00\u5316\u7b56\u7565 \u5e94\u7528\u5b8c\u6210\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7b97\u6cd5\u7684\u5b9e\u73b0 \u77e5\u9053\u504f\u5dee\u4e0e\u65b9\u5dee\u7684\u610f\u4e49 \u638c\u63e1L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u6570\u5b66\u539f\u7406 \u638c\u63e1droupout\u539f\u7406\u4ee5\u53ca\u65b9\u6cd5 \u77e5\u9053\u6b63\u5219\u5316\u7684\u4f5c\u7528\u5e94\u7528 \u5e94\u7528\u5b8c\u6210dropout\u7684\u5b9e\u73b0 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u8bb0\u5fc6\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u77e5\u9053LeNet-5\u7f51\u7edc\u7ed3\u6784 \u4e86\u89e3\u7ecf\u5178\u7684\u5206\u7c7b\u7f51\u7edc\u7ed3\u6784 \u8bf4\u660e\u4e00\u4e9b\u5e38\u89c1\u7684\u5377\u673a\u7f51\u7edc\u7ed3\u6784\u7684\u4f18\u5316 \u77e5\u9053NIN\u4e2d1x1\u5377\u79ef\u539f\u7406\u4ee5\u53ca\u4f5c\u7528 \u77e5\u9053Inception\u7684\u4f5c\u7528 \u8bf4\u660eResNet\u7684\u7ed3\u6784\u7279\u70b9 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u5185\u5bb9","title":"\u56fe\u50cf\u5206\u7c7b(Image Classification)2"},{"location":"imageClassification/#image-classification2","text":"\u77e5\u9053\u5c40\u90e8\u6700\u4f18\u95ee\u9898\u3001\u978d\u70b9\u4e0e\u6d77\u68ee\u77e9\u9635 \u8bf4\u660e\u6279\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u4f18\u5316 \u8bf4\u660e\u4e09\u79cd\u7c7b\u578b\u7684\u4f18\u5316\u7b97\u6cd5 \u77e5\u9053\u5b66\u4e60\u7387\u9000\u706b\u7b56\u7565 \u77e5\u9053\u53c2\u6570\u521d\u59cb\u5316\u7b56\u7565\u4e0e\u8f93\u5165\u5f52\u4e00\u5316\u7b56\u7565 \u5e94\u7528\u5b8c\u6210\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7b97\u6cd5\u7684\u5b9e\u73b0 \u77e5\u9053\u504f\u5dee\u4e0e\u65b9\u5dee\u7684\u610f\u4e49 \u638c\u63e1L2\u6b63\u5219\u5316\u4e0eL1\u6b63\u5219\u5316\u7684\u6570\u5b66\u539f\u7406 \u638c\u63e1droupout\u539f\u7406\u4ee5\u53ca\u65b9\u6cd5 \u77e5\u9053\u6b63\u5219\u5316\u7684\u4f5c\u7528\u5e94\u7528 \u5e94\u7528\u5b8c\u6210dropout\u7684\u5b9e\u73b0 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u6210 \u8bb0\u5fc6\u5377\u79ef\u7684\u539f\u7406\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u4e86\u89e3\u6c60\u5316\u7684\u4f5c\u7528\u4ee5\u53ca\u8ba1\u7b97\u8fc7\u7a0b \u77e5\u9053LeNet-5\u7f51\u7edc\u7ed3\u6784 \u4e86\u89e3\u7ecf\u5178\u7684\u5206\u7c7b\u7f51\u7edc\u7ed3\u6784 \u8bf4\u660e\u4e00\u4e9b\u5e38\u89c1\u7684\u5377\u673a\u7f51\u7edc\u7ed3\u6784\u7684\u4f18\u5316 \u77e5\u9053NIN\u4e2d1x1\u5377\u79ef\u539f\u7406\u4ee5\u53ca\u4f5c\u7528 \u77e5\u9053Inception\u7684\u4f5c\u7528 \u8bf4\u660eResNet\u7684\u7ed3\u6784\u7279\u70b9 \u4e86\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u5185\u5bb9","title":"\u56fe\u50cf\u5206\u7c7b(Image Classification)2"},{"location":"imageClassification/section1/","text":"3.1 \u56fe\u50cf\u5206\u7c7b\u7b80\u4ecb \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u7684\u76ee\u7684 \u77e5\u9053imageNet\u6570\u636e\u96c6 1 \u56fe\u50cf\u5206\u7c7b \u00b6 \u56fe\u50cf\u5206\u7c7b\u5b9e\u8d28\u4e0a\u5c31\u662f\u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u6807\u7b7e\u7684\u4efb\u52a1\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u4efb\u52a1\u662f\u5206\u6790\u4e00\u4e2a\u8f93\u5165\u56fe\u50cf\u5e76\u8fd4\u56de\u4e00\u4e2a\u8be5\u56fe\u50cf\u7c7b\u522b\u7684\u6807\u7b7e\u3002 \u5047\u5b9a\u7c7b\u522b\u96c6\u4e3acategories = {dog, cat, panda}\uff0c\u4e4b\u540e\u6211\u4eec\u63d0\u4f9b\u4e00\u5f20\u56fe\u7247\u7ed9\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5206\u7c7b\u6a21\u578b\u7ed9\u56fe\u50cf\u5206\u914d\u591a\u4e2a\u6807\u7b7e\uff0c\u6bcf\u4e2a\u6807\u7b7e\u7684\u6982\u7387\u503c\u4e0d\u540c\uff0c\u5982dog:95%\uff0ccat:4%\uff0cpanda:1%\uff0c\u6839\u636e\u6982\u7387\u503c\u7684\u5927\u5c0f\u5c06\u8be5\u56fe\u7247\u5206\u7c7b\u4e3adog\uff0c\u90a3\u5c31\u5b8c\u6210\u4e86\u56fe\u50cf\u5206\u7c7b\u7684\u4efb\u52a1\u3002 2 \u5e38\u7528\u6570\u636e\u96c6 \u00b6 2.1 mnist\u6570\u636e\u96c6 \u00b6 \u8be5\u6570\u636e\u96c6\u662f\u624b\u5199\u6570\u5b570-9\u7684\u96c6\u5408\uff0c\u5171\u670960k\u8bad\u7ec3\u56fe\u50cf\u300110k\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f28\u00d728\u00d71.\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7tf.keras\u76f4\u63a5\u52a0\u8f7d\u8be5\u6570\u636e\u96c6\uff1a from tensorflow.keras.datasets import mnist # \u52a0\u8f7dmnist\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () \u968f\u673a\u9009\u62e9\u56fe\u50cf\u5c55\u793a\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 2.2 CIFAR-10\u548cCIFAR-100 \u00b6 CIFAR-10\u6570\u636e\u96c65\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u6bcf\u4e2a\u7c7b\u522b\u67096k\u4e2a\u56fe\u50cf\uff0c\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002\u4e0b\u56fe\u5217\u4e3e\u4e8610\u4e2a\u7c7b\uff0c\u6bcf\u4e00\u7c7b\u968f\u673a\u5c55\u793a\u4e8610\u5f20\u56fe\u7247\uff1a CIFAR-100\u6570\u636e\u96c6\u4e5f\u662f\u67095\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u3001\u5305\u542b100\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002 \u5728tf.keras\u4e2d\u52a0\u8f7d\u6570\u636e\u96c6\u65f6\uff1a import tensorflow as tf from tensorflow.keras.datasets import cifar10 , cifar100 # \u52a0\u8f7dCifar10\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar10 . load_data () # \u52a0\u8f7dCifar100\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar100 . load_data () 2.3 ImageNet \u00b6 ImageNet\u6570\u636e\u96c6\u662fILSVRC\u7ade\u8d5b\u4f7f\u7528\u7684\u662f\u6570\u636e\u96c6\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u674e\u98de\u98de\u6559\u6388\u4e3b\u5bfc\uff0c\u5305\u542b\u4e86\u8d85\u8fc71400\u4e07\u5f20\u5168\u5c3a\u5bf8\u7684\u6709\u6807\u8bb0\u56fe\u7247\uff0c\u5927\u7ea6\u670922000\u4e2a\u7c7b\u522b\u7684\u6570\u636e\u3002ILSVRC\u5168\u79f0ImageNet Large-Scale Visual Recognition Challenge\uff0c\u662f\u89c6\u89c9\u9886\u57df\u6700\u53d7\u8ffd\u6367\u4e5f\u662f\u6700\u5177\u6743\u5a01\u7684\u5b66\u672f\u7ade\u8d5b\u4e4b\u4e00\uff0c\u4ee3\u8868\u4e86\u56fe\u50cf\u9886\u57df\u7684\u6700\u9ad8\u6c34\u5e73\u3002\u4ece2010\u5e74\u5f00\u59cb\u4e3e\u529e\u52302017\u5e74\u6700\u540e\u4e00\u5c4a\uff0c\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u603b\u5171\u67091000\u7c7b\u3002 \u8be5\u6bd4\u8d5b\u7684\u83b7\u80dc\u8005\u4ece2012\u5e74\u5f00\u59cb\u90fd\u662f\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff1a 2012\u5e74\u51a0\u519b\u662fAlexNet,\u7531\u4e8e\u51c6\u786e\u7387\u8fdc\u8d85\u4f20\u7edf\u65b9\u6cd5\u7684\u7b2c\u4e8c\u540d\uff08top5\u9519\u8bef\u7387\u4e3a15.3%\uff0c\u7b2c\u4e8c\u540d\u4e3a26.2%\uff09\uff0c\u5f15\u8d77\u4e86\u5f88\u5927\u7684\u8f70\u52a8\u3002\u81ea\u6b64\u4e4b\u540e\uff0cCNN\u6210\u4e3a\u5728\u56fe\u50cf\u8bc6\u522b\u5206\u7c7b\u7684\u6838\u5fc3\u7b97\u6cd5\u6a21\u578b\uff0c\u5e26\u6765\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u5927\u7206\u53d1\u3002 2013\u5e74\u51a0\u519b\u662fZFNet\uff0c\u7ed3\u6784\u548cAlexNet\u533a\u522b\u4e0d\u5927\uff0c\u5206\u7c7b\u6548\u679c\u4e5f\u5dee\u4e0d\u591a\u3002 2014\u5e74\u4e9a\u519b\u662fVGG\u7f51\u7edc\uff0c\u7f51\u7edc\u7ed3\u6784\u5341\u5206\u7b80\u5355\uff0c\u56e0\u6b64\u81f3\u4ecaVGG-16\u4ecd\u5728\u5e7f\u6cdb\u4f7f\u7528\u3002 2014\u5e74\u7684\u51a0\u519b\u7f51\u7edc\u662fGooLeNet \uff0c\u6838\u5fc3\u6a21\u5757\u662fInception Module\u3002Inception\u5386\u7ecf\u4e86V1\u3001V2\u3001V3\u3001V4\u7b49\u591a\u4e2a\u7248\u672c\u7684\u53d1\u5c55\uff0c\u4e0d\u65ad\u8d8b\u4e8e\u5b8c\u5584\u3002GoogLeNet\u53d6\u540d\u4e2dL\u5927\u5199\u662f\u4e3a\u4e86\u5411LeNet\u81f4\u656c\uff0c\u800cInception\u7684\u540d\u5b57\u6765\u6e90\u4e8e\u76d7\u68a6\u7a7a\u95f4\u4e2d\u7684\"we need to go deeper\"\u6897\u3002 2015\u5e74\u51a0\u519b\u7f51\u7edc\u662fResNet\u3002\u6838\u5fc3\u662f\u5e26\u77ed\u8fde\u63a5\u7684\u6b8b\u5dee\u6a21\u5757\uff0c\u5176\u4e2d\u4e3b\u8def\u5f84\u6709\u4e24\u5c42\u5377\u79ef\u6838\uff08Res34\uff09\uff0c\u77ed\u8fde\u63a5\u628a\u6a21\u5757\u7684\u8f93\u5165\u4fe1\u606f\u76f4\u63a5\u548c\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u4e4b\u540e\u7684\u4fe1\u606f\u878d\u5408\uff0c\u76f8\u5f53\u4e8e\u52a0\u4e86\u4e00\u4e2a\u6052\u7b49\u53d8\u6362\u3002\u77ed\u8fde\u63a5\u662f\u6df1\u5ea6\u5b66\u4e60\u53c8\u4e00\u91cd\u8981\u601d\u60f3\uff0c\u9664\u8ba1\u7b97\u673a\u89c6\u89c9\u5916\uff0c\u77ed\u8fde\u63a5\u601d\u60f3\u4e5f\u88ab\u7528\u5230\u4e86\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u97f3\u8bc6\u522b/\u5408\u6210\u9886\u57df 2017\u5e74\u51a0\u519bSENet\u662f\u4e00\u4e2a\u6a21\u5757\uff0c\u53ef\u4ee5\u548c\u5176\u4ed6\u7684\u7f51\u7edc\u67b6\u6784\u7ed3\u5408\uff0c\u6bd4\u5982GoogLeNet\u3001ResNet\u7b49\u3002 \u4e0a\u8ff0\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u90fd\u6bd4\u8f83\u7ecf\u5178\uff0c\u7279\u522b\u662fVGG16\u3001GoogLeNet\u548cResNet\uff0c\u73b0\u5728\u4ecd\u7136\u5728\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5bf9\u8fd9\u4e9b\u7f51\u7edc\u8fdb\u884c\u9010\u4e00\u4ecb\u7ecd\u3002 \u603b\u7ed3 1.\u56fe\u50cf\u5206\u7c7b\u662f\u4ec0\u4e48\uff1f \u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e 2.\u5e38\u7528\u7684\u6570\u636e\u96c6 Mnist,cifar\u6570\u636e\u96c6,ImageNet\u6570\u636e\u96c6","title":"\u56fe\u50cf\u5206\u7c7b\u7b80\u4ecb"},{"location":"imageClassification/section1/#31","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u7684\u76ee\u7684 \u77e5\u9053imageNet\u6570\u636e\u96c6","title":"3.1 \u56fe\u50cf\u5206\u7c7b\u7b80\u4ecb"},{"location":"imageClassification/section1/#1","text":"\u56fe\u50cf\u5206\u7c7b\u5b9e\u8d28\u4e0a\u5c31\u662f\u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u6807\u7b7e\u7684\u4efb\u52a1\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u4efb\u52a1\u662f\u5206\u6790\u4e00\u4e2a\u8f93\u5165\u56fe\u50cf\u5e76\u8fd4\u56de\u4e00\u4e2a\u8be5\u56fe\u50cf\u7c7b\u522b\u7684\u6807\u7b7e\u3002 \u5047\u5b9a\u7c7b\u522b\u96c6\u4e3acategories = {dog, cat, panda}\uff0c\u4e4b\u540e\u6211\u4eec\u63d0\u4f9b\u4e00\u5f20\u56fe\u7247\u7ed9\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5206\u7c7b\u6a21\u578b\u7ed9\u56fe\u50cf\u5206\u914d\u591a\u4e2a\u6807\u7b7e\uff0c\u6bcf\u4e2a\u6807\u7b7e\u7684\u6982\u7387\u503c\u4e0d\u540c\uff0c\u5982dog:95%\uff0ccat:4%\uff0cpanda:1%\uff0c\u6839\u636e\u6982\u7387\u503c\u7684\u5927\u5c0f\u5c06\u8be5\u56fe\u7247\u5206\u7c7b\u4e3adog\uff0c\u90a3\u5c31\u5b8c\u6210\u4e86\u56fe\u50cf\u5206\u7c7b\u7684\u4efb\u52a1\u3002","title":"1 \u56fe\u50cf\u5206\u7c7b"},{"location":"imageClassification/section1/#2","text":"","title":"2 \u5e38\u7528\u6570\u636e\u96c6"},{"location":"imageClassification/section1/#21-mnist","text":"\u8be5\u6570\u636e\u96c6\u662f\u624b\u5199\u6570\u5b570-9\u7684\u96c6\u5408\uff0c\u5171\u670960k\u8bad\u7ec3\u56fe\u50cf\u300110k\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f28\u00d728\u00d71.\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7tf.keras\u76f4\u63a5\u52a0\u8f7d\u8be5\u6570\u636e\u96c6\uff1a from tensorflow.keras.datasets import mnist # \u52a0\u8f7dmnist\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () \u968f\u673a\u9009\u62e9\u56fe\u50cf\u5c55\u793a\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"2.1 mnist\u6570\u636e\u96c6"},{"location":"imageClassification/section1/#22-cifar-10cifar-100","text":"CIFAR-10\u6570\u636e\u96c65\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u300110\u4e2a\u7c7b\u522b\u3001\u6bcf\u4e2a\u7c7b\u522b\u67096k\u4e2a\u56fe\u50cf\uff0c\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002\u4e0b\u56fe\u5217\u4e3e\u4e8610\u4e2a\u7c7b\uff0c\u6bcf\u4e00\u7c7b\u968f\u673a\u5c55\u793a\u4e8610\u5f20\u56fe\u7247\uff1a CIFAR-100\u6570\u636e\u96c6\u4e5f\u662f\u67095\u4e07\u5f20\u8bad\u7ec3\u56fe\u50cf\u30011\u4e07\u5f20\u6d4b\u8bd5\u56fe\u50cf\u3001\u5305\u542b100\u4e2a\u7c7b\u522b\u3001\u56fe\u50cf\u5927\u5c0f32\u00d732\u00d73\u3002 \u5728tf.keras\u4e2d\u52a0\u8f7d\u6570\u636e\u96c6\u65f6\uff1a import tensorflow as tf from tensorflow.keras.datasets import cifar10 , cifar100 # \u52a0\u8f7dCifar10\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar10 . load_data () # \u52a0\u8f7dCifar100\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = cifar100 . load_data ()","title":"2.2 CIFAR-10\u548cCIFAR-100"},{"location":"imageClassification/section1/#23-imagenet","text":"ImageNet\u6570\u636e\u96c6\u662fILSVRC\u7ade\u8d5b\u4f7f\u7528\u7684\u662f\u6570\u636e\u96c6\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u674e\u98de\u98de\u6559\u6388\u4e3b\u5bfc\uff0c\u5305\u542b\u4e86\u8d85\u8fc71400\u4e07\u5f20\u5168\u5c3a\u5bf8\u7684\u6709\u6807\u8bb0\u56fe\u7247\uff0c\u5927\u7ea6\u670922000\u4e2a\u7c7b\u522b\u7684\u6570\u636e\u3002ILSVRC\u5168\u79f0ImageNet Large-Scale Visual Recognition Challenge\uff0c\u662f\u89c6\u89c9\u9886\u57df\u6700\u53d7\u8ffd\u6367\u4e5f\u662f\u6700\u5177\u6743\u5a01\u7684\u5b66\u672f\u7ade\u8d5b\u4e4b\u4e00\uff0c\u4ee3\u8868\u4e86\u56fe\u50cf\u9886\u57df\u7684\u6700\u9ad8\u6c34\u5e73\u3002\u4ece2010\u5e74\u5f00\u59cb\u4e3e\u529e\u52302017\u5e74\u6700\u540e\u4e00\u5c4a\uff0c\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u603b\u5171\u67091000\u7c7b\u3002 \u8be5\u6bd4\u8d5b\u7684\u83b7\u80dc\u8005\u4ece2012\u5e74\u5f00\u59cb\u90fd\u662f\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff1a 2012\u5e74\u51a0\u519b\u662fAlexNet,\u7531\u4e8e\u51c6\u786e\u7387\u8fdc\u8d85\u4f20\u7edf\u65b9\u6cd5\u7684\u7b2c\u4e8c\u540d\uff08top5\u9519\u8bef\u7387\u4e3a15.3%\uff0c\u7b2c\u4e8c\u540d\u4e3a26.2%\uff09\uff0c\u5f15\u8d77\u4e86\u5f88\u5927\u7684\u8f70\u52a8\u3002\u81ea\u6b64\u4e4b\u540e\uff0cCNN\u6210\u4e3a\u5728\u56fe\u50cf\u8bc6\u522b\u5206\u7c7b\u7684\u6838\u5fc3\u7b97\u6cd5\u6a21\u578b\uff0c\u5e26\u6765\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u5927\u7206\u53d1\u3002 2013\u5e74\u51a0\u519b\u662fZFNet\uff0c\u7ed3\u6784\u548cAlexNet\u533a\u522b\u4e0d\u5927\uff0c\u5206\u7c7b\u6548\u679c\u4e5f\u5dee\u4e0d\u591a\u3002 2014\u5e74\u4e9a\u519b\u662fVGG\u7f51\u7edc\uff0c\u7f51\u7edc\u7ed3\u6784\u5341\u5206\u7b80\u5355\uff0c\u56e0\u6b64\u81f3\u4ecaVGG-16\u4ecd\u5728\u5e7f\u6cdb\u4f7f\u7528\u3002 2014\u5e74\u7684\u51a0\u519b\u7f51\u7edc\u662fGooLeNet \uff0c\u6838\u5fc3\u6a21\u5757\u662fInception Module\u3002Inception\u5386\u7ecf\u4e86V1\u3001V2\u3001V3\u3001V4\u7b49\u591a\u4e2a\u7248\u672c\u7684\u53d1\u5c55\uff0c\u4e0d\u65ad\u8d8b\u4e8e\u5b8c\u5584\u3002GoogLeNet\u53d6\u540d\u4e2dL\u5927\u5199\u662f\u4e3a\u4e86\u5411LeNet\u81f4\u656c\uff0c\u800cInception\u7684\u540d\u5b57\u6765\u6e90\u4e8e\u76d7\u68a6\u7a7a\u95f4\u4e2d\u7684\"we need to go deeper\"\u6897\u3002 2015\u5e74\u51a0\u519b\u7f51\u7edc\u662fResNet\u3002\u6838\u5fc3\u662f\u5e26\u77ed\u8fde\u63a5\u7684\u6b8b\u5dee\u6a21\u5757\uff0c\u5176\u4e2d\u4e3b\u8def\u5f84\u6709\u4e24\u5c42\u5377\u79ef\u6838\uff08Res34\uff09\uff0c\u77ed\u8fde\u63a5\u628a\u6a21\u5757\u7684\u8f93\u5165\u4fe1\u606f\u76f4\u63a5\u548c\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u4e4b\u540e\u7684\u4fe1\u606f\u878d\u5408\uff0c\u76f8\u5f53\u4e8e\u52a0\u4e86\u4e00\u4e2a\u6052\u7b49\u53d8\u6362\u3002\u77ed\u8fde\u63a5\u662f\u6df1\u5ea6\u5b66\u4e60\u53c8\u4e00\u91cd\u8981\u601d\u60f3\uff0c\u9664\u8ba1\u7b97\u673a\u89c6\u89c9\u5916\uff0c\u77ed\u8fde\u63a5\u601d\u60f3\u4e5f\u88ab\u7528\u5230\u4e86\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u97f3\u8bc6\u522b/\u5408\u6210\u9886\u57df 2017\u5e74\u51a0\u519bSENet\u662f\u4e00\u4e2a\u6a21\u5757\uff0c\u53ef\u4ee5\u548c\u5176\u4ed6\u7684\u7f51\u7edc\u67b6\u6784\u7ed3\u5408\uff0c\u6bd4\u5982GoogLeNet\u3001ResNet\u7b49\u3002 \u4e0a\u8ff0\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u90fd\u6bd4\u8f83\u7ecf\u5178\uff0c\u7279\u522b\u662fVGG16\u3001GoogLeNet\u548cResNet\uff0c\u73b0\u5728\u4ecd\u7136\u5728\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5bf9\u8fd9\u4e9b\u7f51\u7edc\u8fdb\u884c\u9010\u4e00\u4ecb\u7ecd\u3002 \u603b\u7ed3 1.\u56fe\u50cf\u5206\u7c7b\u662f\u4ec0\u4e48\uff1f \u4ece\u7ed9\u5b9a\u7684\u7c7b\u522b\u96c6\u5408\u4e2d\u4e3a\u56fe\u50cf\u5206\u914d\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e 2.\u5e38\u7528\u7684\u6570\u636e\u96c6 Mnist,cifar\u6570\u636e\u96c6,ImageNet\u6570\u636e\u96c6","title":"2.3 ImageNet"},{"location":"imageClassification/section2/","text":"3.2 AlexNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053AlexNet\u7f51\u7edc\u7ed3\u6784 \u80fd\u591f\u5229\u7528AlexNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2012\u5e74\uff0cAlexNet\u6a2a\u7a7a\u51fa\u4e16\uff0c\u8be5\u6a21\u578b\u7684\u540d\u5b57\u6e90\u4e8e\u8bba\u6587\u7b2c\u4e00\u4f5c\u8005\u7684\u59d3\u540dAlex Krizhevsky \u3002AlexNet\u4f7f\u7528\u4e868\u5c42\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u5f88\u5927\u7684\u4f18\u52bf\u8d62\u5f97\u4e86ImageNet 2012\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u3002\u5b83\u9996\u6b21\u8bc1\u660e\u4e86\u5b66\u4e60\u5230\u7684\u7279\u5f81\u53ef\u4ee5\u8d85\u8d8a\u624b\u5de5\u8bbe\u8ba1\u7684\u7279\u5f81\uff0c\u4ece\u800c\u4e00\u4e3e\u6253\u7834\u8ba1\u7b97\u673a\u89c6\u89c9\u7814\u7a76\u7684\u65b9\u5411\u3002 1.AlexNet\u7684\u7f51\u7edc\u67b6\u6784 \u00b6 AlexNet\u4e0eLeNet\u7684\u8bbe\u8ba1\u7406\u5ff5\u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u4e5f\u6709\u663e\u8457\u7684\u533a\u522b\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u7f51\u7edc\u7684\u7279\u70b9\u662f\uff1a AlexNet\u5305\u542b8\u5c42\u53d8\u6362\uff0c\u67095\u5c42\u5377\u79ef\u548c2\u5c42\u5168\u8fde\u63a5\u9690\u85cf\u5c42\uff0c\u4ee5\u53ca1\u4e2a\u5168\u8fde\u63a5\u8f93\u51fa\u5c42 AlexNet\u7b2c\u4e00\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u662f 11\\times11 11\\times11 \u3002\u7b2c\u4e8c\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u51cf\u5c0f\u5230 5\\times5 5\\times5 \uff0c\u4e4b\u540e\u5168\u91c7\u7528 3\\times3 3\\times3 \u3002\u6240\u6709\u7684\u6c60\u5316\u5c42\u7a97\u53e3\u5927\u5c0f\u4e3a 3\\times3 3\\times3 \u3001\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u3002 AlexNet\u5c06sigmoid\u6fc0\u6d3b\u51fd\u6570\u6539\u6210\u4e86ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f7f\u8ba1\u7b97\u66f4\u7b80\u5355\uff0c\u7f51\u7edc\u66f4\u5bb9\u6613\u8bad\u7ec3 AlexNet\u901a\u8fc7dropOut\u6765\u63a7\u5236\u5168\u8fde\u63a5\u5c42\u7684\u6a21\u578b\u590d\u6742\u5ea6\u3002 AlexNet\u5f15\u5165\u4e86\u5927\u91cf\u7684\u56fe\u50cf\u589e\u5f3a\uff0c\u5982\u7ffb\u8f6c\u3001\u88c1\u526a\u548c\u989c\u8272\u53d8\u5316\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u6269\u5927\u6570\u636e\u96c6\u6765\u7f13\u89e3\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0AlexNet\u6a21\u578b\uff1a # \u6784\u5efaAlexNet\u6a21\u578b net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a96\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a11*11\uff0c\u6b65\u5e45\u4e3a4\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 96 , kernel_size = 11 , strides = 4 , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a5*5\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 5 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u4f38\u5c55\u4e3a1\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42:4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u94fe\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u8f93\u51fa\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570softmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a227\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 227 , 227 , 1 ) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d ( Conv2D ) ( 1 , 55 , 55 , 96 ) 11712 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) ( 1 , 27 , 27 , 96 ) 0 _________________________________________________________________ conv2d_1 ( Conv2D ) ( 1 , 27 , 27 , 256 ) 614656 _________________________________________________________________ max_pooling2d_1 ( MaxPooling2 ( 1 , 13 , 13 , 256 ) 0 _________________________________________________________________ conv2d_2 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 885120 _________________________________________________________________ conv2d_3 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 1327488 _________________________________________________________________ conv2d_4 ( Conv2D ) ( 1 , 13 , 13 , 256 ) 884992 _________________________________________________________________ max_pooling2d_2 ( MaxPooling2 ( 1 , 6 , 6 , 256 ) 0 _________________________________________________________________ flatten ( Flatten ) ( 1 , 9216 ) 0 _________________________________________________________________ dense ( Dense ) ( 1 , 4096 ) 37752832 _________________________________________________________________ dropout ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_1 ( Dense ) ( 1 , 4096 ) 16781312 _________________________________________________________________ dropout_1 ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_2 ( Dense ) ( 1 , 10 ) 40970 ================================================================= Total params : 58 , 299 , 082 Trainable params : 58 , 299 , 082 Non - trainable params : 0 _________________________________________________________________ 2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b \u00b6 AlexNet\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aAlexNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230AlexNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd227\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a227*227\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57{}\" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002 2.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 2.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3003 - accuracy : 0.0913 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 2 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3069 - accuracy : 0.0957 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 3 / 3 2 / 2 [ ============================== ] - 4 s 2 s / step - loss : 2.3117 - accuracy : 0.0826 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 168 ms / step - loss : 2.3026 - accuracy : 0.0781 [ 2.3025851249694824 , 0.078125 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.4866700246334076 , 0.8395 ] \u603b\u7ed3 \u77e5\u9053AlexNet\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"AlexNet"},{"location":"imageClassification/section2/#32-alexnet","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053AlexNet\u7f51\u7edc\u7ed3\u6784 \u80fd\u591f\u5229\u7528AlexNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2012\u5e74\uff0cAlexNet\u6a2a\u7a7a\u51fa\u4e16\uff0c\u8be5\u6a21\u578b\u7684\u540d\u5b57\u6e90\u4e8e\u8bba\u6587\u7b2c\u4e00\u4f5c\u8005\u7684\u59d3\u540dAlex Krizhevsky \u3002AlexNet\u4f7f\u7528\u4e868\u5c42\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u5f88\u5927\u7684\u4f18\u52bf\u8d62\u5f97\u4e86ImageNet 2012\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u3002\u5b83\u9996\u6b21\u8bc1\u660e\u4e86\u5b66\u4e60\u5230\u7684\u7279\u5f81\u53ef\u4ee5\u8d85\u8d8a\u624b\u5de5\u8bbe\u8ba1\u7684\u7279\u5f81\uff0c\u4ece\u800c\u4e00\u4e3e\u6253\u7834\u8ba1\u7b97\u673a\u89c6\u89c9\u7814\u7a76\u7684\u65b9\u5411\u3002","title":"3.2 AlexNet"},{"location":"imageClassification/section2/#1alexnet","text":"AlexNet\u4e0eLeNet\u7684\u8bbe\u8ba1\u7406\u5ff5\u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u4e5f\u6709\u663e\u8457\u7684\u533a\u522b\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u7f51\u7edc\u7684\u7279\u70b9\u662f\uff1a AlexNet\u5305\u542b8\u5c42\u53d8\u6362\uff0c\u67095\u5c42\u5377\u79ef\u548c2\u5c42\u5168\u8fde\u63a5\u9690\u85cf\u5c42\uff0c\u4ee5\u53ca1\u4e2a\u5168\u8fde\u63a5\u8f93\u51fa\u5c42 AlexNet\u7b2c\u4e00\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u662f 11\\times11 11\\times11 \u3002\u7b2c\u4e8c\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u5f62\u72b6\u51cf\u5c0f\u5230 5\\times5 5\\times5 \uff0c\u4e4b\u540e\u5168\u91c7\u7528 3\\times3 3\\times3 \u3002\u6240\u6709\u7684\u6c60\u5316\u5c42\u7a97\u53e3\u5927\u5c0f\u4e3a 3\\times3 3\\times3 \u3001\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u3002 AlexNet\u5c06sigmoid\u6fc0\u6d3b\u51fd\u6570\u6539\u6210\u4e86ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f7f\u8ba1\u7b97\u66f4\u7b80\u5355\uff0c\u7f51\u7edc\u66f4\u5bb9\u6613\u8bad\u7ec3 AlexNet\u901a\u8fc7dropOut\u6765\u63a7\u5236\u5168\u8fde\u63a5\u5c42\u7684\u6a21\u578b\u590d\u6742\u5ea6\u3002 AlexNet\u5f15\u5165\u4e86\u5927\u91cf\u7684\u56fe\u50cf\u589e\u5f3a\uff0c\u5982\u7ffb\u8f6c\u3001\u88c1\u526a\u548c\u989c\u8272\u53d8\u5316\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u6269\u5927\u6570\u636e\u96c6\u6765\u7f13\u89e3\u8fc7\u62df\u5408\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0AlexNet\u6a21\u578b\uff1a # \u6784\u5efaAlexNet\u6a21\u578b net = tf . keras . models . Sequential ([ # \u5377\u79ef\u5c42\uff1a96\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a11*11\uff0c\u6b65\u5e45\u4e3a4\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 96 , kernel_size = 11 , strides = 4 , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a5*5\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 5 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a384\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 384 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u5377\u79ef\u5c42\uff1a256\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u4e3a3*3\uff0c\u6b65\u5e45\u4e3a1\uff0cpadding\u4e3asame\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Conv2D ( filters = 256 , kernel_size = 3 , padding = 'same' , activation = 'relu' ), # \u6c60\u5316:\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\u3001\u6b65\u5e45\u4e3a2 tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 ), # \u4f38\u5c55\u4e3a1\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42:4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u94fe\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u8f93\u51fa\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570softmax tf . keras . layers . Dense ( 10 , activation = 'softmax' ) ]) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a227\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 227 , 227 , 1 ) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d ( Conv2D ) ( 1 , 55 , 55 , 96 ) 11712 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) ( 1 , 27 , 27 , 96 ) 0 _________________________________________________________________ conv2d_1 ( Conv2D ) ( 1 , 27 , 27 , 256 ) 614656 _________________________________________________________________ max_pooling2d_1 ( MaxPooling2 ( 1 , 13 , 13 , 256 ) 0 _________________________________________________________________ conv2d_2 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 885120 _________________________________________________________________ conv2d_3 ( Conv2D ) ( 1 , 13 , 13 , 384 ) 1327488 _________________________________________________________________ conv2d_4 ( Conv2D ) ( 1 , 13 , 13 , 256 ) 884992 _________________________________________________________________ max_pooling2d_2 ( MaxPooling2 ( 1 , 6 , 6 , 256 ) 0 _________________________________________________________________ flatten ( Flatten ) ( 1 , 9216 ) 0 _________________________________________________________________ dense ( Dense ) ( 1 , 4096 ) 37752832 _________________________________________________________________ dropout ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_1 ( Dense ) ( 1 , 4096 ) 16781312 _________________________________________________________________ dropout_1 ( Dropout ) ( 1 , 4096 ) 0 _________________________________________________________________ dense_2 ( Dense ) ( 1 , 10 ) 40970 ================================================================= Total params : 58 , 299 , 082 Trainable params : 58 , 299 , 082 Non - trainable params : 0 _________________________________________________________________","title":"1.AlexNet\u7684\u7f51\u7edc\u67b6\u6784"},{"location":"imageClassification/section2/#2","text":"AlexNet\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aAlexNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230AlexNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd227\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b"},{"location":"imageClassification/section2/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a227*227\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210227*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 227 , 227 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57{}\" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section2/#22","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"2.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section2/#23","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3003 - accuracy : 0.0913 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 2 / 3 2 / 2 [ ============================== ] - 3 s 2 s / step - loss : 2.3069 - accuracy : 0.0957 - val_loss : 2.3026 - val_accuracy : 0.0000e+00 Epoch 3 / 3 2 / 2 [ ============================== ] - 4 s 2 s / step - loss : 2.3117 - accuracy : 0.0826 - val_loss : 2.3026 - val_accuracy : 0.0000e+00","title":"2.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section2/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 168 ms / step - loss : 2.3026 - accuracy : 0.0781 [ 2.3025851249694824 , 0.078125 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.4866700246334076 , 0.8395 ] \u603b\u7ed3 \u77e5\u9053AlexNet\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section3/","text":"3.3 VGG \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053VGG\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528VGG\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2014\u5e74\uff0c\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u89c6\u89c9\u7ec4\uff08Visual Geometry Group\uff09\u548cGoogle DeepMind\u516c\u53f8\u7684\u7814\u7a76\u5458\u4e00\u8d77\u7814\u53d1\u51fa\u4e86\u65b0\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1aVGGNet\uff0c\u5e76\u53d6\u5f97\u4e86ILSVRC2014\u6bd4\u8d5b\u5206\u7c7b\u9879\u76ee\u7684\u7b2c\u4e8c\u540d\uff0c\u4e3b\u8981\u8d21\u732e\u662f\u4f7f\u7528\u5f88\u5c0f\u7684\u5377\u79ef\u6838(3\u00d73)\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u80fd\u591f\u53d6\u5f97\u8f83\u597d\u7684\u8bc6\u522b\u7cbe\u5ea6\uff0c\u5e38\u7528\u6765\u63d0\u53d6\u56fe\u50cf\u7279\u5f81\u7684VGG-16\u548cVGG-19\u3002 1.VGG\u7684\u7f51\u7edc\u67b6\u6784 \u00b6 VGG\u53ef\u4ee5\u770b\u6210\u662f\u52a0\u6df1\u7248\u7684AlexNet\uff0c\u6574\u4e2a\u7f51\u7edc\u7531\u5377\u79ef\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u53e0\u52a0\u800c\u6210\uff0c\u548cAlexNet\u4e0d\u540c\u7684\u662f\uff0cVGG\u4e2d\u4f7f\u7528\u7684\u90fd\u662f\u5c0f\u5c3a\u5bf8\u7684\u5377\u79ef\u6838(3\u00d73)\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a VGGNet\u4f7f\u7528\u7684\u5168\u90e8\u90fd\u662f3x3\u7684\u5c0f\u5377\u79ef\u6838\u548c2x2\u7684\u6c60\u5316\u6838\uff0c\u901a\u8fc7\u4e0d\u65ad\u52a0\u6df1\u7f51\u7edc\u6765\u63d0\u5347\u6027\u80fd\u3002VGG\u53ef\u4ee5\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u7b80\u5355\u7684\u57fa\u7840\u5757\u6765\u6784\u5efa\u6df1\u5ea6\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0VGG\u6a21\u578b\uff0c\u9996\u5148\u6765\u5b9e\u73b0VGG\u5757\uff0c\u5b83\u7684\u7ec4\u6210\u89c4\u5f8b\u662f\uff1a\u8fde\u7eed\u4f7f\u7528\u591a\u4e2a\u76f8\u540c\u7684\u586b\u5145\u4e3a1\u3001\u5377\u79ef\u6838\u5927\u5c0f\u4e3a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u5c42\u540e\u63a5\u4e0a\u4e00\u4e2a\u6b65\u5e45\u4e3a2\u3001\u7a97\u53e3\u5f62\u72b6\u4e3a 2\\times 2 2\\times 2 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u5377\u79ef\u5c42\u4fdd\u6301\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\u4e0d\u53d8\uff0c\u800c\u6c60\u5316\u5c42\u5219\u5bf9\u5176\u51cf\u534a\u3002\u6211\u4eec\u4f7f\u7528 vgg_block \u51fd\u6570\u6765\u5b9e\u73b0\u8fd9\u4e2a\u57fa\u7840\u7684VGG\u5757\uff0c\u5b83\u53ef\u4ee5\u6307\u5b9a\u5377\u79ef\u5c42\u7684\u6570\u91cf num_convs \u548c\u6bcf\u5c42\u7684\u5377\u79ef\u6838\u4e2a\u6570num_filters\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u5757\uff1a\u5377\u79ef\u5c42\u7684\u4e2a\u6570\uff0c\u5377\u79ef\u5c42\u4e2d\u5377\u79ef\u6838\u7684\u4e2a\u6570 def vgg_block ( num_convs , num_filters ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b blk = tf . keras . models . Sequential () # \u904d\u5386\u6240\u6709\u7684\u5377\u79ef\u5c42 for _ in range ( num_convs ): # \u6bcf\u4e2a\u5377\u79ef\u5c42\uff1anum_filter\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3*3\uff0cpadding\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu blk . add ( tf . keras . layers . Conv2D ( num_filters , kernel_size = 3 , padding = 'same' , activation = 'relu' )) # \u5377\u79ef\u5757\u6700\u540e\u662f\u4e00\u4e2a\u6700\u5927\u6c60\u5316\uff0c\u7a97\u53e3\u5927\u5c0f\u4e3a2*2\uff0c\u6b65\u957f\u4e3a2 blk . add ( tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 )) return blk VGG16\u7f51\u7edc\u67095\u4e2a\u5377\u79ef\u5757\uff0c\u524d2\u5757\u4f7f\u7528\u4e24\u4e2a\u5377\u79ef\u5c42\uff0c\u800c\u540e3\u5757\u4f7f\u7528\u4e09\u4e2a\u5377\u79ef\u5c42\u3002\u7b2c\u4e00\u5757\u7684\u8f93\u51fa\u901a\u9053\u662f64\uff0c\u4e4b\u540e\u6bcf\u6b21\u5bf9\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\uff0c\u76f4\u5230\u53d8\u4e3a512\u3002 # \u5b9a\u4e495\u4e2a\u5377\u79ef\u5757\uff0c\u6307\u660e\u6bcf\u4e2a\u5377\u79ef\u5757\u4e2d\u7684\u5377\u79ef\u5c42\u4e2a\u6570\u53ca\u76f8\u5e94\u7684\u5377\u79ef\u6838\u4e2a\u6570 conv_arch = (( 2 , 64 ), ( 2 , 128 ), ( 3 , 256 ), ( 3 , 512 ), ( 3 , 512 )) \u56e0\u4e3a\u8fd9\u4e2a\u7f51\u7edc\u4f7f\u7528\u4e8613\u4e2a\u5377\u79ef\u5c42\u548c3\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u6240\u4ee5\u7ecf\u5e38\u88ab\u79f0\u4e3aVGG-16,\u901a\u8fc7\u5236\u5b9aconv_arch\u5f97\u5230\u6a21\u578b\u67b6\u6784\u540e\u6784\u5efaVGG16\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc def vgg ( conv_arch ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b net = tf . keras . models . Sequential () # \u6839\u636econv_arch\u751f\u6210\u5377\u79ef\u90e8\u5206 for ( num_convs , num_filters ) in conv_arch : net . add ( vgg_block ( num_convs , num_filters )) # \u5377\u79ef\u5757\u5e8f\u5217\u540e\u6dfb\u52a0\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . models . Sequential ([ # \u5c06\u7279\u5f81\u56fe\u5c55\u6210\u4e00\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' )])) return net # \u7f51\u7edc\u5b9e\u4f8b\u5316 net = vgg ( conv_arch ) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 224 , 224 , 1 )) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential_15\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= sequential_16 ( Sequential ) ( 1 , 112 , 112 , 64 ) 37568 _________________________________________________________________ sequential_17 ( Sequential ) ( 1 , 56 , 56 , 128 ) 221440 _________________________________________________________________ sequential_18 ( Sequential ) ( 1 , 28 , 28 , 256 ) 1475328 _________________________________________________________________ sequential_19 ( Sequential ) ( 1 , 14 , 14 , 512 ) 5899776 _________________________________________________________________ sequential_20 ( Sequential ) ( 1 , 7 , 7 , 512 ) 7079424 _________________________________________________________________ sequential_21 ( Sequential ) ( 1 , 10 ) 119586826 ================================================================= Total params : 134 , 300 , 362 Trainable params : 134 , 300 , 362 Non - trainable params : 0 __________________________________________________________________ 2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b \u00b6 \u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aVGGNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230VggNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57{}\" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002 2.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 2.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 34 s 17 s / step - loss : 2.6026 - accuracy : 0.0957 - val_loss : 2.2982 - val_accuracy : 0.0385 Epoch 2 / 3 2 / 2 [ ============================== ] - 27 s 14 s / step - loss : 2.2604 - accuracy : 0.1087 - val_loss : 2.4905 - val_accuracy : 0.1923 Epoch 3 / 3 2 / 2 [ ============================== ] - 29 s 14 s / step - loss : 2.3650 - accuracy : 0.1000 - val_loss : 2.2994 - val_accuracy : 0.1538 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 5 s 1 s / step - loss : 2.2955 - accuracy : 0.1016 [ 2.2955007553100586 , 0.1015625 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.31822608125209806 , 0.8855 ] \u603b\u7ed3 \u77e5\u9053VGG\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"VGG"},{"location":"imageClassification/section3/#33-vgg","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053VGG\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528VGG\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b 2014\u5e74\uff0c\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u89c6\u89c9\u7ec4\uff08Visual Geometry Group\uff09\u548cGoogle DeepMind\u516c\u53f8\u7684\u7814\u7a76\u5458\u4e00\u8d77\u7814\u53d1\u51fa\u4e86\u65b0\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1aVGGNet\uff0c\u5e76\u53d6\u5f97\u4e86ILSVRC2014\u6bd4\u8d5b\u5206\u7c7b\u9879\u76ee\u7684\u7b2c\u4e8c\u540d\uff0c\u4e3b\u8981\u8d21\u732e\u662f\u4f7f\u7528\u5f88\u5c0f\u7684\u5377\u79ef\u6838(3\u00d73)\u6784\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u80fd\u591f\u53d6\u5f97\u8f83\u597d\u7684\u8bc6\u522b\u7cbe\u5ea6\uff0c\u5e38\u7528\u6765\u63d0\u53d6\u56fe\u50cf\u7279\u5f81\u7684VGG-16\u548cVGG-19\u3002","title":"3.3 VGG"},{"location":"imageClassification/section3/#1vgg","text":"VGG\u53ef\u4ee5\u770b\u6210\u662f\u52a0\u6df1\u7248\u7684AlexNet\uff0c\u6574\u4e2a\u7f51\u7edc\u7531\u5377\u79ef\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u53e0\u52a0\u800c\u6210\uff0c\u548cAlexNet\u4e0d\u540c\u7684\u662f\uff0cVGG\u4e2d\u4f7f\u7528\u7684\u90fd\u662f\u5c0f\u5c3a\u5bf8\u7684\u5377\u79ef\u6838(3\u00d73)\uff0c\u5176\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a VGGNet\u4f7f\u7528\u7684\u5168\u90e8\u90fd\u662f3x3\u7684\u5c0f\u5377\u79ef\u6838\u548c2x2\u7684\u6c60\u5316\u6838\uff0c\u901a\u8fc7\u4e0d\u65ad\u52a0\u6df1\u7f51\u7edc\u6765\u63d0\u5347\u6027\u80fd\u3002VGG\u53ef\u4ee5\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u7b80\u5355\u7684\u57fa\u7840\u5757\u6765\u6784\u5efa\u6df1\u5ea6\u6a21\u578b\u3002 \u5728tf.keras\u4e2d\u5b9e\u73b0VGG\u6a21\u578b\uff0c\u9996\u5148\u6765\u5b9e\u73b0VGG\u5757\uff0c\u5b83\u7684\u7ec4\u6210\u89c4\u5f8b\u662f\uff1a\u8fde\u7eed\u4f7f\u7528\u591a\u4e2a\u76f8\u540c\u7684\u586b\u5145\u4e3a1\u3001\u5377\u79ef\u6838\u5927\u5c0f\u4e3a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u5c42\u540e\u63a5\u4e0a\u4e00\u4e2a\u6b65\u5e45\u4e3a2\u3001\u7a97\u53e3\u5f62\u72b6\u4e3a 2\\times 2 2\\times 2 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u5377\u79ef\u5c42\u4fdd\u6301\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\u4e0d\u53d8\uff0c\u800c\u6c60\u5316\u5c42\u5219\u5bf9\u5176\u51cf\u534a\u3002\u6211\u4eec\u4f7f\u7528 vgg_block \u51fd\u6570\u6765\u5b9e\u73b0\u8fd9\u4e2a\u57fa\u7840\u7684VGG\u5757\uff0c\u5b83\u53ef\u4ee5\u6307\u5b9a\u5377\u79ef\u5c42\u7684\u6570\u91cf num_convs \u548c\u6bcf\u5c42\u7684\u5377\u79ef\u6838\u4e2a\u6570num_filters\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u5757\uff1a\u5377\u79ef\u5c42\u7684\u4e2a\u6570\uff0c\u5377\u79ef\u5c42\u4e2d\u5377\u79ef\u6838\u7684\u4e2a\u6570 def vgg_block ( num_convs , num_filters ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b blk = tf . keras . models . Sequential () # \u904d\u5386\u6240\u6709\u7684\u5377\u79ef\u5c42 for _ in range ( num_convs ): # \u6bcf\u4e2a\u5377\u79ef\u5c42\uff1anum_filter\u4e2a\u5377\u79ef\u6838\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3*3\uff0cpadding\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu blk . add ( tf . keras . layers . Conv2D ( num_filters , kernel_size = 3 , padding = 'same' , activation = 'relu' )) # \u5377\u79ef\u5757\u6700\u540e\u662f\u4e00\u4e2a\u6700\u5927\u6c60\u5316\uff0c\u7a97\u53e3\u5927\u5c0f\u4e3a2*2\uff0c\u6b65\u957f\u4e3a2 blk . add ( tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 )) return blk VGG16\u7f51\u7edc\u67095\u4e2a\u5377\u79ef\u5757\uff0c\u524d2\u5757\u4f7f\u7528\u4e24\u4e2a\u5377\u79ef\u5c42\uff0c\u800c\u540e3\u5757\u4f7f\u7528\u4e09\u4e2a\u5377\u79ef\u5c42\u3002\u7b2c\u4e00\u5757\u7684\u8f93\u51fa\u901a\u9053\u662f64\uff0c\u4e4b\u540e\u6bcf\u6b21\u5bf9\u8f93\u51fa\u901a\u9053\u6570\u7ffb\u500d\uff0c\u76f4\u5230\u53d8\u4e3a512\u3002 # \u5b9a\u4e495\u4e2a\u5377\u79ef\u5757\uff0c\u6307\u660e\u6bcf\u4e2a\u5377\u79ef\u5757\u4e2d\u7684\u5377\u79ef\u5c42\u4e2a\u6570\u53ca\u76f8\u5e94\u7684\u5377\u79ef\u6838\u4e2a\u6570 conv_arch = (( 2 , 64 ), ( 2 , 128 ), ( 3 , 256 ), ( 3 , 512 ), ( 3 , 512 )) \u56e0\u4e3a\u8fd9\u4e2a\u7f51\u7edc\u4f7f\u7528\u4e8613\u4e2a\u5377\u79ef\u5c42\u548c3\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u6240\u4ee5\u7ecf\u5e38\u88ab\u79f0\u4e3aVGG-16,\u901a\u8fc7\u5236\u5b9aconv_arch\u5f97\u5230\u6a21\u578b\u67b6\u6784\u540e\u6784\u5efaVGG16\uff1a # \u5b9a\u4e49VGG\u7f51\u7edc def vgg ( conv_arch ): # \u6784\u5efa\u5e8f\u5217\u6a21\u578b net = tf . keras . models . Sequential () # \u6839\u636econv_arch\u751f\u6210\u5377\u79ef\u90e8\u5206 for ( num_convs , num_filters ) in conv_arch : net . add ( vgg_block ( num_convs , num_filters )) # \u5377\u79ef\u5757\u5e8f\u5217\u540e\u6dfb\u52a0\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . models . Sequential ([ # \u5c06\u7279\u5f81\u56fe\u5c55\u6210\u4e00\u7ef4\u5411\u91cf tf . keras . layers . Flatten (), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a4096\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu tf . keras . layers . Dense ( 4096 , activation = 'relu' ), # \u968f\u673a\u5931\u6d3b tf . keras . layers . Dropout ( 0.5 ), # \u5168\u8fde\u63a5\u5c42\uff1a10\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fsoftmax tf . keras . layers . Dense ( 10 , activation = 'softmax' )])) return net # \u7f51\u7edc\u5b9e\u4f8b\u5316 net = vgg ( conv_arch ) \u6211\u4eec\u6784\u9020\u4e00\u4e2a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u7684\u5355\u901a\u9053\u6570\u636e\u6837\u672c\u6765\u770b\u4e00\u4e0b\u6a21\u578b\u7684\u67b6\u6784\uff1a # \u6784\u9020\u8f93\u5165X\uff0c\u5e76\u5c06\u5176\u9001\u5165\u5230net\u7f51\u7edc\u4e2d X = tf . random . uniform (( 1 , 224 , 224 , 1 )) y = net ( X ) # \u901a\u8fc7net.summay()\u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6 net . summay () \u7f51\u7edc\u67b6\u6784\u5982\u4e0b\uff1a Model : \"sequential_15\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= sequential_16 ( Sequential ) ( 1 , 112 , 112 , 64 ) 37568 _________________________________________________________________ sequential_17 ( Sequential ) ( 1 , 56 , 56 , 128 ) 221440 _________________________________________________________________ sequential_18 ( Sequential ) ( 1 , 28 , 28 , 256 ) 1475328 _________________________________________________________________ sequential_19 ( Sequential ) ( 1 , 14 , 14 , 512 ) 5899776 _________________________________________________________________ sequential_20 ( Sequential ) ( 1 , 7 , 7 , 512 ) 7079424 _________________________________________________________________ sequential_21 ( Sequential ) ( 1 , 10 ) 119586826 ================================================================= Total params : 134 , 300 , 362 Trainable params : 134 , 300 , 362 Non - trainable params : 0 __________________________________________________________________","title":"1.VGG\u7684\u7f51\u7edc\u67b6\u6784"},{"location":"imageClassification/section3/#2","text":"\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aVGGNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230VggNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b"},{"location":"imageClassification/section3/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) \u4e3a\u4e86\u8ba9\u5927\u5bb6\u66f4\u597d\u7684\u7406\u89e3\uff0c\u6211\u4eec\u5c06\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u6570\u636e\u5c55\u793a\uff1a\u5c06\u6570\u636e\u96c6\u7684\u524d\u4e5d\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5c55\u793a for i in range ( 9 ): plt . subplot ( 3 , 3 , i + 1 ) # \u4ee5\u7070\u5ea6\u56fe\u663e\u793a\uff0c\u4e0d\u8fdb\u884c\u63d2\u503c plt . imshow ( train_images [ i ] . astype ( np . int8 ) . squeeze (), cmap = 'gray' , interpolation = 'none' ) # \u8bbe\u7f6e\u56fe\u7247\u7684\u6807\u9898\uff1a\u5bf9\u5e94\u7684\u7c7b\u522b plt . title ( \"\u6570\u5b57{}\" . format ( train_labels [ i ])) \u7ed3\u679c\u4e3a\uff1a \u6211\u4eec\u5c31\u4f7f\u7528\u4e0a\u8ff0\u521b\u5efa\u7684\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section3/#22","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"2.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section3/#23","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 34 s 17 s / step - loss : 2.6026 - accuracy : 0.0957 - val_loss : 2.2982 - val_accuracy : 0.0385 Epoch 2 / 3 2 / 2 [ ============================== ] - 27 s 14 s / step - loss : 2.2604 - accuracy : 0.1087 - val_loss : 2.4905 - val_accuracy : 0.1923 Epoch 3 / 3 2 / 2 [ ============================== ] - 29 s 14 s / step - loss : 2.3650 - accuracy : 0.1000 - val_loss : 2.2994 - val_accuracy : 0.1538","title":"2.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section3/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 5 s 1 s / step - loss : 2.2955 - accuracy : 0.1016 [ 2.2955007553100586 , 0.1015625 ] \u5982\u679c\u6211\u4eec\u4f7f\u7528\u6574\u4e2a\u6570\u636e\u96c6\u8bad\u7ec3\u7f51\u7edc\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\uff1a [ 0.31822608125209806 , 0.8855 ] \u603b\u7ed3 \u77e5\u9053VGG\u7684\u7f51\u7edc\u67b6\u6784 \u52a8\u624b\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section4/","text":"3.4 GoogLeNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053GoogLeNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528GoogLeNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b GoogLeNet\u7684\u540d\u5b57\u4e0d\u662fGoogleNet\uff0c\u800c\u662fGoogLeNet\uff0c\u8fd9\u662f\u4e3a\u4e86\u81f4\u656cLeNet\u3002GoogLeNet\u548cAlexNet/VGGNet\u8fd9\u7c7b\u4f9d\u9760\u52a0\u6df1\u7f51\u7edc\u7ed3\u6784\u7684\u6df1\u5ea6\u7684\u601d\u60f3\u4e0d\u5b8c\u5168\u4e00\u6837\u3002GoogLeNet\u5728\u52a0\u6df1\u5ea6\u7684\u540c\u65f6\u505a\u4e86\u7ed3\u6784\u4e0a\u7684\u521b\u65b0\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u53eb\u505aInception\u7684\u7ed3\u6784\u6765\u4ee3\u66ff\u4e4b\u524d\u7684\u5377\u79ef\u52a0\u6fc0\u6d3b\u7684\u7ecf\u5178\u7ec4\u4ef6\u3002GoogLeNet\u5728ImageNet\u5206\u7c7b\u6bd4\u8d5b\u4e0a\u7684Top-5\u9519\u8bef\u7387\u964d\u4f4e\u5230\u4e866.7%\u3002\u3002 1.Inception \u5757 \u00b6 GoogLeNet\u4e2d\u7684\u57fa\u7840\u5377\u79ef\u5757\u53eb\u4f5cInception\u5757\uff0c\u5f97\u540d\u4e8e\u540c\u540d\u7535\u5f71\u300a\u76d7\u68a6\u7a7a\u95f4\u300b\uff08Inception\uff09\u3002Inception\u5757\u5728\u7ed3\u6784\u6bd4\u8f83\u590d\u6742\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a Inception\u5757\u91cc\u67094\u6761\u5e76\u884c\u7684\u7ebf\u8def\u3002\u524d3\u6761\u7ebf\u8def\u4f7f\u7528\u7a97\u53e3\u5927\u5c0f\u5206\u522b\u662f 1\\times 1 1\\times 1 \u3001 3\\times 3 3\\times 3 \u548c 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u5c42\u6765\u62bd\u53d6\u4e0d\u540c\u7a7a\u95f4\u5c3a\u5bf8\u4e0b\u7684\u4fe1\u606f\uff0c\u5176\u4e2d\u4e2d\u95f42\u4e2a\u7ebf\u8def\u4f1a\u5bf9\u8f93\u5165\u5148\u505a 1\\times 1 1\\times 1 \u5377\u79ef\u6765\u51cf\u5c11\u8f93\u5165\u901a\u9053\u6570\uff0c\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002\u7b2c4\u6761\u7ebf\u8def\u5219\u4f7f\u7528 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\uff0c\u540e\u63a5 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u6539\u53d8\u901a\u9053\u6570\u30024\u6761\u7ebf\u8def\u90fd\u4f7f\u7528\u4e86\u5408\u9002\u7684\u586b\u5145\u6765\u4f7f\u8f93\u5165\u4e0e\u8f93\u51fa\u7684\u9ad8\u548c\u5bbd\u4e00\u81f4\u3002\u6700\u540e\u6211\u4eec\u5c06\u6bcf\u6761\u7ebf\u8def\u7684\u8f93\u51fa\u5728\u901a\u9053\u7ef4\u4e0a\u8fde\u7ed3,\u5e76\u5411\u540e\u8fdb\u884c\u4f20\u8f93\u3002 1\\times 1 1\\times 1 \u5377\u79ef \uff1a \u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u5176\u4ed6\u5377\u79ef\u6838\u4e00\u6837\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u662f\u5b83\u7684\u5927\u5c0f\u662f 1\\times1 1\\times1 \uff0c\u6ca1\u6709\u8003\u8651\u5728\u7279\u5f81\u56fe\u5c40\u90e8\u4fe1\u606f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u5b83\u7684\u4f5c\u7528\u4e3b\u8981\u662f\uff1a \u5b9e\u73b0\u8de8\u901a\u9053\u7684\u4ea4\u4e92\u548c\u4fe1\u606f\u6574\u5408 \u5377\u79ef\u6838\u901a\u9053\u6570\u7684\u964d\u7ef4\u548c\u5347\u7ef4\uff0c\u51cf\u5c11\u7f51\u7edc\u53c2\u6570 \u5728tf.keras\u4e2d\u5b9e\u73b0Inception\u6a21\u5757\uff0c\u5404\u4e2a\u5377\u79ef\u5c42\u5377\u79ef\u6838\u7684\u4e2a\u6570\u901a\u8fc7\u8f93\u5165\u53c2\u6570\u6765\u63a7\u5236\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5b9a\u4e49Inception\u6a21\u5757 class Inception ( tf . keras . layers . Layer ): # \u8f93\u5165\u53c2\u6570\u4e3a\u5404\u4e2a\u5377\u79ef\u7684\u5377\u79ef\u6838\u4e2a\u6570 def __init__ ( self , c1 , c2 , c3 , c4 ): super () . __init__ () # \u7ebf\u8def1\uff1a1 x 1\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p1_1 = tf . keras . layers . Conv2D ( c1 , kernel_size = 1 , activation = 'relu' , padding = 'same' ) # \u7ebf\u8def2\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a53 x 3\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p2_1 = tf . keras . layers . Conv2D ( c2 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p2_2 = tf . keras . layers . Conv2D ( c2 [ 1 ], kernel_size = 3 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def3\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a55 x 5\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p3_1 = tf . keras . layers . Conv2D ( c3 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p3_2 = tf . keras . layers . Conv2D ( c3 [ 1 ], kernel_size = 5 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def4\uff0c3 x 3\u6700\u5927\u6c60\u5316\u5c42\u540e\u63a51 x 1\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p4_1 = tf . keras . layers . MaxPool2D ( pool_size = 3 , padding = 'same' , strides = 1 ) self . p4_2 = tf . keras . layers . Conv2D ( c4 , kernel_size = 1 , padding = 'same' , activation = 'relu' ) # \u5b8c\u6210\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u7ebf\u8def1 p1 = self . p1_1 ( x ) # \u7ebf\u8def2 p2 = self . p2_2 ( self . p2_1 ( x )) # \u7ebf\u8def3 p3 = self . p3_2 ( self . p3_1 ( x )) # \u7ebf\u8def4 p4 = self . p4_2 ( self . p4_1 ( x )) # \u5728\u901a\u9053\u7ef4\u4e0aconcat\u8f93\u51fa outputs = tf . concat ([ p1 , p2 , p3 , p4 ], axis =- 1 ) return outputs \u6307\u5b9a\u901a\u9053\u6570\uff0c\u5bf9Inception\u6a21\u5757\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1a Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 ) 2.GoogLeNet\u6a21\u578b \u00b6 GoogLeNet\u4e3b\u8981\u7531Inception\u6a21\u5757\u6784\u6210\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7f51\u7edc\u67b6\u6784\u6211\u4eec\u5206\u4e3a\u4e94\u4e2a\u6a21\u5757\uff0c\u6bcf\u4e2a\u6a21\u5757\u4e4b\u95f4\u4f7f\u7528\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\u6765\u51cf\u5c0f\u8f93\u51fa\u9ad8\u5bbd\u3002 2.1 B1\u6a21\u5757 \u00b6 \u7b2c\u4e00\u6a21\u5757\u4f7f\u7528\u4e00\u4e2a64\u901a\u9053\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u3002 # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 224 , 224 , 3 ), name = \"input\" ) # b1 \u6a21\u5757 # \u5377\u79ef\u5c427*7\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' , activation = 'relu' )( inputs ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) # b2 \u6a21\u5757 2.2 B2\u6a21\u5757 \u00b6 \u7b2c\u4e8c\u6a21\u5757\u4f7f\u75282\u4e2a\u5377\u79ef\u5c42\uff1a\u9996\u5148\u662f64\u901a\u9053\u7684 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5c06\u901a\u9053\u589e\u59273\u500d\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002 # b2 \u6a21\u5757 # \u5377\u79ef\u5c421*1\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 1 , padding = 'same' , activation = 'relu' )( x ) # \u5377\u79ef\u5c423*3\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 192 , kernel_size = 3 , padding = 'same' , activation = 'relu' )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) 2.3 B3\u6a21\u5757 \u00b6 \u7b2c\u4e09\u6a21\u5757\u4e32\u80542\u4e2a\u5b8c\u6574\u7684Inception\u5757\u3002\u7b2c\u4e00\u4e2aInception\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\u4e3a 64+128+32+32=256 64+128+32+32=256 \u3002\u7b2c\u4e8c\u4e2aInception\u5757\u8f93\u51fa\u901a\u9053\u6570\u589e\u81f3 128+192+96+64=480 128+192+96+64=480 \u3002 # b3 \u6a21\u5757 # Inception x = Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 )( x ) # Inception x = Inception ( 128 , ( 128 , 192 ), ( 32 , 96 ), 64 )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) 2.4 B4\u6a21\u5757 \u00b6 \u7b2c\u56db\u6a21\u5757\u66f4\u52a0\u590d\u6742\u3002\u5b83\u4e32\u8054\u4e865\u4e2aInception\u5757\uff0c\u5176\u8f93\u51fa\u901a\u9053\u6570\u5206\u522b\u662f 192+208+48+64=512 192+208+48+64=512 \u3001 160+224+64+64=512 160+224+64+64=512 \u3001 128+256+64+64=512 128+256+64+64=512 \u3001 112+288+64+64=528 112+288+64+64=528 \u548c 256+320+128+128=832 256+320+128+128=832 \u3002\u5e76\u4e14\u589e\u52a0\u4e86\u8f85\u52a9\u5206\u7c7b\u5668\uff0c\u6839\u636e\u5b9e\u9a8c\u53d1\u73b0\u7f51\u7edc\u7684\u4e2d\u95f4\u5c42\u5177\u6709\u5f88\u5f3a\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4e3a\u4e86\u5229\u7528\u4e2d\u95f4\u5c42\u62bd\u8c61\u7684\u7279\u5f81\uff0c\u5728\u67d0\u4e9b\u4e2d\u95f4\u5c42\u4e2d\u6dfb\u52a0\u542b\u6709\u591a\u5c42\u7684\u5206\u7c7b\u5668\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a def aux_classifier ( x , filter_size ): #x:\u8f93\u5165\u6570\u636e\uff0cfilter_size:\u5377\u79ef\u5c42\u5377\u79ef\u6838\u4e2a\u6570\uff0c\u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143\u4e2a\u6570 # \u6c60\u5316\u5c42 x = tf . keras . layers . AveragePooling2D ( pool_size = 5 , strides = 3 , padding = 'same' )( x ) # 1x1 \u5377\u79ef\u5c42 x = tf . keras . layers . Conv2D ( filters = filter_size [ 0 ], kernel_size = 1 , strides = 1 , padding = 'valid' , activation = 'relu' )( x ) # \u5c55\u5e73 x = tf . keras . layers . Flatten ()( x ) # \u5168\u8fde\u63a5\u5c421 x = tf . keras . layers . Dense ( units = filter_size [ 1 ], activation = 'relu' )( x ) # softmax\u8f93\u51fa\u5c42 x = tf . keras . layers . Dense ( units = 10 , activation = 'softmax' )( x ) return x b4\u6a21\u5757\u7684\u5b9e\u73b0\uff1a # b4 \u6a21\u5757 # Inception x = Inception ( 192 , ( 96 , 208 ), ( 16 , 48 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa1 aux_output_1 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 160 , ( 112 , 224 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 128 , ( 128 , 256 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 112 , ( 144 , 288 ), ( 32 , 64 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa2 aux_output_2 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # \u6700\u5927\u6c60\u5316 x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) 2.5 B5\u6a21\u5757 \u00b6 \u7b2c\u4e94\u6a21\u5757\u6709\u8f93\u51fa\u901a\u9053\u6570\u4e3a 256+320+128+128=832 256+320+128+128=832 \u548c 384+384+128+128=1024 384+384+128+128=1024 \u7684\u4e24\u4e2aInception\u5757\u3002\u540e\u9762\u7d27\u8ddf\u8f93\u51fa\u5c42\uff0c\u8be5\u6a21\u5757\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u6765\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u9ad8\u548c\u5bbd\u53d8\u62101\u3002\u6700\u540e\u8f93\u51fa\u53d8\u6210\u4e8c\u7ef4\u6570\u7ec4\u540e\u63a5\u8f93\u51fa\u4e2a\u6570\u4e3a\u6807\u7b7e\u7c7b\u522b\u6570\u7684\u5168\u8fde\u63a5\u5c42\u3002 \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09 \u7528\u6765\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42\uff0c\u5c06\u7279\u5f81\u56fe\u6bcf\u4e00\u901a\u9053\u4e2d\u6240\u6709\u50cf\u7d20\u503c\u76f8\u52a0\u540e\u6c42\u5e73\u5747\uff0c\u5f97\u5230\u5c31\u662fGAP\u7684\u7ed3\u679c\uff0c\u5728\u5c06\u5176\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97 \u5b9e\u73b0\u8fc7\u7a0b\u662f\uff1a # b5 \u6a21\u5757 # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # Inception x = Inception ( 384 , ( 192 , 384 ), ( 48 , 128 ), 128 )( x ) # GAP x = tf . keras . layers . GlobalAvgPool2D ()( x ) # \u8f93\u51fa\u5c42 main_outputs = tf . keras . layers . Dense ( 10 , activation = 'softmax' )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa \u6784\u5efaGoogLeNet\u6a21\u578b\u5e76\u901a\u8fc7summary\u6765\u770b\u4e0b\u6a21\u578b\u7684\u7ed3\u6784\uff1a # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = [ main_outputs , aux_output_1 \uff0c aux_output_2 ]) model . summary () Model : \"functional_3\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 224 , 224 , 3 )] 0 _________________________________________________________________ conv2d_122 ( Conv2D ) ( None , 112 , 112 , 64 ) 9472 _________________________________________________________________ max_pooling2d_27 ( MaxPooling ( None , 56 , 56 , 64 ) 0 _________________________________________________________________ conv2d_123 ( Conv2D ) ( None , 56 , 56 , 64 ) 4160 _________________________________________________________________ conv2d_124 ( Conv2D ) ( None , 56 , 56 , 192 ) 110784 _________________________________________________________________ max_pooling2d_28 ( MaxPooling ( None , 28 , 28 , 192 ) 0 _________________________________________________________________ inception_19 ( Inception ) ( None , 28 , 28 , 256 ) 163696 _________________________________________________________________ inception_20 ( Inception ) ( None , 28 , 28 , 480 ) 388736 _________________________________________________________________ max_pooling2d_31 ( MaxPooling ( None , 14 , 14 , 480 ) 0 _________________________________________________________________ inception_21 ( Inception ) ( None , 14 , 14 , 512 ) 376176 _________________________________________________________________ inception_22 ( Inception ) ( None , 14 , 14 , 512 ) 449160 _________________________________________________________________ inception_23 ( Inception ) ( None , 14 , 14 , 512 ) 510104 _________________________________________________________________ inception_24 ( Inception ) ( None , 14 , 14 , 528 ) 605376 _________________________________________________________________ inception_25 ( Inception ) ( None , 14 , 14 , 832 ) 868352 _________________________________________________________________ max_pooling2d_37 ( MaxPooling ( None , 7 , 7 , 832 ) 0 _________________________________________________________________ inception_26 ( Inception ) ( None , 7 , 7 , 832 ) 1043456 _________________________________________________________________ inception_27 ( Inception ) ( None , 7 , 7 , 1024 ) 1444080 _________________________________________________________________ global_average_pooling2d_2 ( ( None , 1024 ) 0 _________________________________________________________________ dense_10 ( Dense ) ( None , 10 ) 10250 ================================================================= Total params : 5 , 983 , 802 Trainable params : 5 , 983 , 802 Non - trainable params : 0 ___________________________________________________________ 3.\u624b\u5199\u6570\u5b57\u8bc6\u522b \u00b6 \u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aGoogLeNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a(\u4e0eVGG\u4e2d\u662f\u4e00\u6837\u7684) # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) 3.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) # \u6a21\u578b\u67093\u4e2a\u8f93\u51fa\uff0c\u6240\u4ee5\u6307\u5b9a\u635f\u5931\u51fd\u6570\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ], loss_weights = [ 1 , 0.3 , 0.3 ]) 3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8fc7\u7a0b\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.9527 - accuracy : 0.1174 - val_loss : 3.3254 - val_accuracy : 0.1154 Epoch 2 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.8111 - accuracy : 0.0957 - val_loss : 2.2718 - val_accuracy : 0.2308 Epoch 3 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.3055 - accuracy : 0.0957 - val_loss : 2.2669 - val_accuracy : 0.2308 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 338 ms / step - loss : 2.3110 - accuracy : 0.0781 [ 2.310971260070801 , 0.078125 ] 4.\u5ef6\u4f38\u7248\u672c \u00b6 GoogLeNet\u662f\u4ee5InceptionV1\u4e3a\u57fa\u7840\u8fdb\u884c\u6784\u5efa\u7684\uff0c\u6240\u4ee5GoogLeNet\u4e5f\u53eb\u505aInceptionNet,\u5728\u968f\u540e\u7684\u2f0f\u5e74\u2fa5\uff0c\u7814\u7a76\u2f08\u5458\u5bf9GoogLeNet\u8fdb\u2f8f\u4e86\u6570\u6b21\u6539\u8fdb\uff0c \u5c31\u53c8\u4ea7\u751f\u4e86InceptionV2\uff0cV3,V4\u7b49\u7248\u672c\u3002 4.1 InceptionV2 \u00b6 \u5728InceptionV2\u4e2d\u5c06\u5927\u5377\u79ef\u6838\u62c6\u5206\u4e3a\u5c0f\u5377\u79ef\u6838\uff0c\u5c06V1\u4e2d\u7684 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u7528\u4e24\u4e2a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u66ff\u4ee3\uff0c\u4ece\u800c\u589e\u52a0\u7f51\u7edc\u7684\u6df1\u5ea6\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u3002 4.2 InceptionV3 \u00b6 \u5c06n\u00d7n\u5377\u79ef\u5206\u5272\u4e3a1\u00d7n\u548cn\u00d71\u4e24\u4e2a\u5377\u79ef\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u7684 3\\times3 3\\times3 \u5377\u79ef\u9996\u5148\u6267\u884c\u4e00\u4e2a 1\\times3 1\\times3 \u7684\u5377\u79ef\uff0c\u7136\u540e\u6267\u884c\u4e00\u4e2a 3\\times1 3\\times1 \u7684\u5377\u79ef,\u8fd9\u79cd\u65b9\u6cd5\u7684\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\u90fd\u6bd4\u539f\u6765\u964d\u4f4e\u3002 \u603b\u7ed3 \u77e5\u9053GoogLeNet\u7684\u7f51\u7edc\u67b6\u6784\uff1a\u6709\u57fa\u7840\u6a21\u5757Inception\u6784\u6210 \u80fd\u591f\u5229\u7528GoogleNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b","title":"GoogLeNet"},{"location":"imageClassification/section4/#34-googlenet","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053GoogLeNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528GoogLeNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b GoogLeNet\u7684\u540d\u5b57\u4e0d\u662fGoogleNet\uff0c\u800c\u662fGoogLeNet\uff0c\u8fd9\u662f\u4e3a\u4e86\u81f4\u656cLeNet\u3002GoogLeNet\u548cAlexNet/VGGNet\u8fd9\u7c7b\u4f9d\u9760\u52a0\u6df1\u7f51\u7edc\u7ed3\u6784\u7684\u6df1\u5ea6\u7684\u601d\u60f3\u4e0d\u5b8c\u5168\u4e00\u6837\u3002GoogLeNet\u5728\u52a0\u6df1\u5ea6\u7684\u540c\u65f6\u505a\u4e86\u7ed3\u6784\u4e0a\u7684\u521b\u65b0\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u53eb\u505aInception\u7684\u7ed3\u6784\u6765\u4ee3\u66ff\u4e4b\u524d\u7684\u5377\u79ef\u52a0\u6fc0\u6d3b\u7684\u7ecf\u5178\u7ec4\u4ef6\u3002GoogLeNet\u5728ImageNet\u5206\u7c7b\u6bd4\u8d5b\u4e0a\u7684Top-5\u9519\u8bef\u7387\u964d\u4f4e\u5230\u4e866.7%\u3002\u3002","title":"3.4 GoogLeNet"},{"location":"imageClassification/section4/#1inception","text":"GoogLeNet\u4e2d\u7684\u57fa\u7840\u5377\u79ef\u5757\u53eb\u4f5cInception\u5757\uff0c\u5f97\u540d\u4e8e\u540c\u540d\u7535\u5f71\u300a\u76d7\u68a6\u7a7a\u95f4\u300b\uff08Inception\uff09\u3002Inception\u5757\u5728\u7ed3\u6784\u6bd4\u8f83\u590d\u6742\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a Inception\u5757\u91cc\u67094\u6761\u5e76\u884c\u7684\u7ebf\u8def\u3002\u524d3\u6761\u7ebf\u8def\u4f7f\u7528\u7a97\u53e3\u5927\u5c0f\u5206\u522b\u662f 1\\times 1 1\\times 1 \u3001 3\\times 3 3\\times 3 \u548c 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u5c42\u6765\u62bd\u53d6\u4e0d\u540c\u7a7a\u95f4\u5c3a\u5bf8\u4e0b\u7684\u4fe1\u606f\uff0c\u5176\u4e2d\u4e2d\u95f42\u4e2a\u7ebf\u8def\u4f1a\u5bf9\u8f93\u5165\u5148\u505a 1\\times 1 1\\times 1 \u5377\u79ef\u6765\u51cf\u5c11\u8f93\u5165\u901a\u9053\u6570\uff0c\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002\u7b2c4\u6761\u7ebf\u8def\u5219\u4f7f\u7528 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\uff0c\u540e\u63a5 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u6539\u53d8\u901a\u9053\u6570\u30024\u6761\u7ebf\u8def\u90fd\u4f7f\u7528\u4e86\u5408\u9002\u7684\u586b\u5145\u6765\u4f7f\u8f93\u5165\u4e0e\u8f93\u51fa\u7684\u9ad8\u548c\u5bbd\u4e00\u81f4\u3002\u6700\u540e\u6211\u4eec\u5c06\u6bcf\u6761\u7ebf\u8def\u7684\u8f93\u51fa\u5728\u901a\u9053\u7ef4\u4e0a\u8fde\u7ed3,\u5e76\u5411\u540e\u8fdb\u884c\u4f20\u8f93\u3002 1\\times 1 1\\times 1 \u5377\u79ef \uff1a \u5b83\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u5176\u4ed6\u5377\u79ef\u6838\u4e00\u6837\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u662f\u5b83\u7684\u5927\u5c0f\u662f 1\\times1 1\\times1 \uff0c\u6ca1\u6709\u8003\u8651\u5728\u7279\u5f81\u56fe\u5c40\u90e8\u4fe1\u606f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u5b83\u7684\u4f5c\u7528\u4e3b\u8981\u662f\uff1a \u5b9e\u73b0\u8de8\u901a\u9053\u7684\u4ea4\u4e92\u548c\u4fe1\u606f\u6574\u5408 \u5377\u79ef\u6838\u901a\u9053\u6570\u7684\u964d\u7ef4\u548c\u5347\u7ef4\uff0c\u51cf\u5c11\u7f51\u7edc\u53c2\u6570 \u5728tf.keras\u4e2d\u5b9e\u73b0Inception\u6a21\u5757\uff0c\u5404\u4e2a\u5377\u79ef\u5c42\u5377\u79ef\u6838\u7684\u4e2a\u6570\u901a\u8fc7\u8f93\u5165\u53c2\u6570\u6765\u63a7\u5236\uff0c\u5982\u4e0b\u6240\u793a\uff1a # \u5b9a\u4e49Inception\u6a21\u5757 class Inception ( tf . keras . layers . Layer ): # \u8f93\u5165\u53c2\u6570\u4e3a\u5404\u4e2a\u5377\u79ef\u7684\u5377\u79ef\u6838\u4e2a\u6570 def __init__ ( self , c1 , c2 , c3 , c4 ): super () . __init__ () # \u7ebf\u8def1\uff1a1 x 1\u5377\u79ef\u5c42\uff0c\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p1_1 = tf . keras . layers . Conv2D ( c1 , kernel_size = 1 , activation = 'relu' , padding = 'same' ) # \u7ebf\u8def2\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a53 x 3\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p2_1 = tf . keras . layers . Conv2D ( c2 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p2_2 = tf . keras . layers . Conv2D ( c2 [ 1 ], kernel_size = 3 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def3\uff0c1 x 1\u5377\u79ef\u5c42\u540e\u63a55 x 5\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p3_1 = tf . keras . layers . Conv2D ( c3 [ 0 ], kernel_size = 1 , padding = 'same' , activation = 'relu' ) self . p3_2 = tf . keras . layers . Conv2D ( c3 [ 1 ], kernel_size = 5 , padding = 'same' , activation = 'relu' ) # \u7ebf\u8def4\uff0c3 x 3\u6700\u5927\u6c60\u5316\u5c42\u540e\u63a51 x 1\u5377\u79ef\u5c42,\u6fc0\u6d3b\u51fd\u6570\u662fRELU\uff0cpadding\u662fsame self . p4_1 = tf . keras . layers . MaxPool2D ( pool_size = 3 , padding = 'same' , strides = 1 ) self . p4_2 = tf . keras . layers . Conv2D ( c4 , kernel_size = 1 , padding = 'same' , activation = 'relu' ) # \u5b8c\u6210\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u7ebf\u8def1 p1 = self . p1_1 ( x ) # \u7ebf\u8def2 p2 = self . p2_2 ( self . p2_1 ( x )) # \u7ebf\u8def3 p3 = self . p3_2 ( self . p3_1 ( x )) # \u7ebf\u8def4 p4 = self . p4_2 ( self . p4_1 ( x )) # \u5728\u901a\u9053\u7ef4\u4e0aconcat\u8f93\u51fa outputs = tf . concat ([ p1 , p2 , p3 , p4 ], axis =- 1 ) return outputs \u6307\u5b9a\u901a\u9053\u6570\uff0c\u5bf9Inception\u6a21\u5757\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1a Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 )","title":"1.Inception \u5757"},{"location":"imageClassification/section4/#2googlenet","text":"GoogLeNet\u4e3b\u8981\u7531Inception\u6a21\u5757\u6784\u6210\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7f51\u7edc\u67b6\u6784\u6211\u4eec\u5206\u4e3a\u4e94\u4e2a\u6a21\u5757\uff0c\u6bcf\u4e2a\u6a21\u5757\u4e4b\u95f4\u4f7f\u7528\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u6700\u5927\u6c60\u5316\u5c42\u6765\u51cf\u5c0f\u8f93\u51fa\u9ad8\u5bbd\u3002","title":"2.GoogLeNet\u6a21\u578b"},{"location":"imageClassification/section4/#21-b1","text":"\u7b2c\u4e00\u6a21\u5757\u4f7f\u7528\u4e00\u4e2a64\u901a\u9053\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u3002 # \u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165 inputs = tf . keras . Input ( shape = ( 224 , 224 , 3 ), name = \"input\" ) # b1 \u6a21\u5757 # \u5377\u79ef\u5c427*7\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' , activation = 'relu' )( inputs ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x ) # b2 \u6a21\u5757","title":"2.1 B1\u6a21\u5757"},{"location":"imageClassification/section4/#22-b2","text":"\u7b2c\u4e8c\u6a21\u5757\u4f7f\u75282\u4e2a\u5377\u79ef\u5c42\uff1a\u9996\u5148\u662f64\u901a\u9053\u7684 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5c06\u901a\u9053\u589e\u59273\u500d\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002 # b2 \u6a21\u5757 # \u5377\u79ef\u5c421*1\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 64 , kernel_size = 1 , padding = 'same' , activation = 'relu' )( x ) # \u5377\u79ef\u5c423*3\u7684\u5377\u79ef\u6838\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame\uff0c\u6fc0\u6d3b\u51fd\u6570RELU x = tf . keras . layers . Conv2D ( 192 , kernel_size = 3 , padding = 'same' , activation = 'relu' )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x )","title":"2.2 B2\u6a21\u5757"},{"location":"imageClassification/section4/#23-b3","text":"\u7b2c\u4e09\u6a21\u5757\u4e32\u80542\u4e2a\u5b8c\u6574\u7684Inception\u5757\u3002\u7b2c\u4e00\u4e2aInception\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\u4e3a 64+128+32+32=256 64+128+32+32=256 \u3002\u7b2c\u4e8c\u4e2aInception\u5757\u8f93\u51fa\u901a\u9053\u6570\u589e\u81f3 128+192+96+64=480 128+192+96+64=480 \u3002 # b3 \u6a21\u5757 # Inception x = Inception ( 64 , ( 96 , 128 ), ( 16 , 32 ), 32 )( x ) # Inception x = Inception ( 128 , ( 128 , 192 ), ( 32 , 96 ), 64 )( x ) # \u6700\u5927\u6c60\u5316\uff1a\u7a97\u53e3\u5927\u5c0f\u4e3a3*3\uff0c\u6b65\u957f\u4e3a2\uff0cpad\u662fsame x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x )","title":"2.3 B3\u6a21\u5757"},{"location":"imageClassification/section4/#24-b4","text":"\u7b2c\u56db\u6a21\u5757\u66f4\u52a0\u590d\u6742\u3002\u5b83\u4e32\u8054\u4e865\u4e2aInception\u5757\uff0c\u5176\u8f93\u51fa\u901a\u9053\u6570\u5206\u522b\u662f 192+208+48+64=512 192+208+48+64=512 \u3001 160+224+64+64=512 160+224+64+64=512 \u3001 128+256+64+64=512 128+256+64+64=512 \u3001 112+288+64+64=528 112+288+64+64=528 \u548c 256+320+128+128=832 256+320+128+128=832 \u3002\u5e76\u4e14\u589e\u52a0\u4e86\u8f85\u52a9\u5206\u7c7b\u5668\uff0c\u6839\u636e\u5b9e\u9a8c\u53d1\u73b0\u7f51\u7edc\u7684\u4e2d\u95f4\u5c42\u5177\u6709\u5f88\u5f3a\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4e3a\u4e86\u5229\u7528\u4e2d\u95f4\u5c42\u62bd\u8c61\u7684\u7279\u5f81\uff0c\u5728\u67d0\u4e9b\u4e2d\u95f4\u5c42\u4e2d\u6dfb\u52a0\u542b\u6709\u591a\u5c42\u7684\u5206\u7c7b\u5668\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u5982\u4e0b\u6240\u793a\uff1a def aux_classifier ( x , filter_size ): #x:\u8f93\u5165\u6570\u636e\uff0cfilter_size:\u5377\u79ef\u5c42\u5377\u79ef\u6838\u4e2a\u6570\uff0c\u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143\u4e2a\u6570 # \u6c60\u5316\u5c42 x = tf . keras . layers . AveragePooling2D ( pool_size = 5 , strides = 3 , padding = 'same' )( x ) # 1x1 \u5377\u79ef\u5c42 x = tf . keras . layers . Conv2D ( filters = filter_size [ 0 ], kernel_size = 1 , strides = 1 , padding = 'valid' , activation = 'relu' )( x ) # \u5c55\u5e73 x = tf . keras . layers . Flatten ()( x ) # \u5168\u8fde\u63a5\u5c421 x = tf . keras . layers . Dense ( units = filter_size [ 1 ], activation = 'relu' )( x ) # softmax\u8f93\u51fa\u5c42 x = tf . keras . layers . Dense ( units = 10 , activation = 'softmax' )( x ) return x b4\u6a21\u5757\u7684\u5b9e\u73b0\uff1a # b4 \u6a21\u5757 # Inception x = Inception ( 192 , ( 96 , 208 ), ( 16 , 48 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa1 aux_output_1 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 160 , ( 112 , 224 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 128 , ( 128 , 256 ), ( 24 , 64 ), 64 )( x ) # Inception x = Inception ( 112 , ( 144 , 288 ), ( 32 , 64 ), 64 )( x ) # \u8f85\u52a9\u8f93\u51fa2 aux_output_2 = aux_classifier ( x , [ 128 , 1024 ]) # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # \u6700\u5927\u6c60\u5316 x = tf . keras . layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' )( x )","title":"2.4 B4\u6a21\u5757"},{"location":"imageClassification/section4/#25-b5","text":"\u7b2c\u4e94\u6a21\u5757\u6709\u8f93\u51fa\u901a\u9053\u6570\u4e3a 256+320+128+128=832 256+320+128+128=832 \u548c 384+384+128+128=1024 384+384+128+128=1024 \u7684\u4e24\u4e2aInception\u5757\u3002\u540e\u9762\u7d27\u8ddf\u8f93\u51fa\u5c42\uff0c\u8be5\u6a21\u5757\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u6765\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u9ad8\u548c\u5bbd\u53d8\u62101\u3002\u6700\u540e\u8f93\u51fa\u53d8\u6210\u4e8c\u7ef4\u6570\u7ec4\u540e\u63a5\u8f93\u51fa\u4e2a\u6570\u4e3a\u6807\u7b7e\u7c7b\u522b\u6570\u7684\u5168\u8fde\u63a5\u5c42\u3002 \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09 \u7528\u6765\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42\uff0c\u5c06\u7279\u5f81\u56fe\u6bcf\u4e00\u901a\u9053\u4e2d\u6240\u6709\u50cf\u7d20\u503c\u76f8\u52a0\u540e\u6c42\u5e73\u5747\uff0c\u5f97\u5230\u5c31\u662fGAP\u7684\u7ed3\u679c\uff0c\u5728\u5c06\u5176\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97 \u5b9e\u73b0\u8fc7\u7a0b\u662f\uff1a # b5 \u6a21\u5757 # Inception x = Inception ( 256 , ( 160 , 320 ), ( 32 , 128 ), 128 )( x ) # Inception x = Inception ( 384 , ( 192 , 384 ), ( 48 , 128 ), 128 )( x ) # GAP x = tf . keras . layers . GlobalAvgPool2D ()( x ) # \u8f93\u51fa\u5c42 main_outputs = tf . keras . layers . Dense ( 10 , activation = 'softmax' )( x ) # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa \u6784\u5efaGoogLeNet\u6a21\u578b\u5e76\u901a\u8fc7summary\u6765\u770b\u4e0b\u6a21\u578b\u7684\u7ed3\u6784\uff1a # \u4f7f\u7528Model\u6765\u521b\u5efa\u6a21\u578b\uff0c\u6307\u660e\u8f93\u5165\u548c\u8f93\u51fa model = tf . keras . Model ( inputs = inputs , outputs = [ main_outputs , aux_output_1 \uff0c aux_output_2 ]) model . summary () Model : \"functional_3\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= input ( InputLayer ) [( None , 224 , 224 , 3 )] 0 _________________________________________________________________ conv2d_122 ( Conv2D ) ( None , 112 , 112 , 64 ) 9472 _________________________________________________________________ max_pooling2d_27 ( MaxPooling ( None , 56 , 56 , 64 ) 0 _________________________________________________________________ conv2d_123 ( Conv2D ) ( None , 56 , 56 , 64 ) 4160 _________________________________________________________________ conv2d_124 ( Conv2D ) ( None , 56 , 56 , 192 ) 110784 _________________________________________________________________ max_pooling2d_28 ( MaxPooling ( None , 28 , 28 , 192 ) 0 _________________________________________________________________ inception_19 ( Inception ) ( None , 28 , 28 , 256 ) 163696 _________________________________________________________________ inception_20 ( Inception ) ( None , 28 , 28 , 480 ) 388736 _________________________________________________________________ max_pooling2d_31 ( MaxPooling ( None , 14 , 14 , 480 ) 0 _________________________________________________________________ inception_21 ( Inception ) ( None , 14 , 14 , 512 ) 376176 _________________________________________________________________ inception_22 ( Inception ) ( None , 14 , 14 , 512 ) 449160 _________________________________________________________________ inception_23 ( Inception ) ( None , 14 , 14 , 512 ) 510104 _________________________________________________________________ inception_24 ( Inception ) ( None , 14 , 14 , 528 ) 605376 _________________________________________________________________ inception_25 ( Inception ) ( None , 14 , 14 , 832 ) 868352 _________________________________________________________________ max_pooling2d_37 ( MaxPooling ( None , 7 , 7 , 832 ) 0 _________________________________________________________________ inception_26 ( Inception ) ( None , 7 , 7 , 832 ) 1043456 _________________________________________________________________ inception_27 ( Inception ) ( None , 7 , 7 , 1024 ) 1444080 _________________________________________________________________ global_average_pooling2d_2 ( ( None , 1024 ) 0 _________________________________________________________________ dense_10 ( Dense ) ( None , 10 ) 10250 ================================================================= Total params : 5 , 983 , 802 Trainable params : 5 , 983 , 802 Non - trainable params : 0 ___________________________________________________________","title":"2.5 B5\u6a21\u5757"},{"location":"imageClassification/section4/#3","text":"\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aGoogLeNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"3.\u624b\u5199\u6570\u5b57\u8bc6\u522b"},{"location":"imageClassification/section4/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a(\u4e0eVGG\u4e2d\u662f\u4e00\u6837\u7684) # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 )","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section4/#32","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) # \u6a21\u578b\u67093\u4e2a\u8f93\u51fa\uff0c\u6240\u4ee5\u6307\u5b9a\u635f\u5931\u51fd\u6570\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570 net . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ], loss_weights = [ 1 , 0.3 , 0.3 ])","title":"3.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section4/#33","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 net . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8fc7\u7a0b\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.9527 - accuracy : 0.1174 - val_loss : 3.3254 - val_accuracy : 0.1154 Epoch 2 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.8111 - accuracy : 0.0957 - val_loss : 2.2718 - val_accuracy : 0.2308 Epoch 3 / 3 2 / 2 [ ============================== ] - 7 s 4 s / step - loss : 2.3055 - accuracy : 0.0957 - val_loss : 2.2669 - val_accuracy : 0.2308","title":"3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section4/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e net . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 338 ms / step - loss : 2.3110 - accuracy : 0.0781 [ 2.310971260070801 , 0.078125 ]","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section4/#4","text":"GoogLeNet\u662f\u4ee5InceptionV1\u4e3a\u57fa\u7840\u8fdb\u884c\u6784\u5efa\u7684\uff0c\u6240\u4ee5GoogLeNet\u4e5f\u53eb\u505aInceptionNet,\u5728\u968f\u540e\u7684\u2f0f\u5e74\u2fa5\uff0c\u7814\u7a76\u2f08\u5458\u5bf9GoogLeNet\u8fdb\u2f8f\u4e86\u6570\u6b21\u6539\u8fdb\uff0c \u5c31\u53c8\u4ea7\u751f\u4e86InceptionV2\uff0cV3,V4\u7b49\u7248\u672c\u3002","title":"4.\u5ef6\u4f38\u7248\u672c"},{"location":"imageClassification/section4/#41-inceptionv2","text":"\u5728InceptionV2\u4e2d\u5c06\u5927\u5377\u79ef\u6838\u62c6\u5206\u4e3a\u5c0f\u5377\u79ef\u6838\uff0c\u5c06V1\u4e2d\u7684 5\\times 5 5\\times 5 \u7684\u5377\u79ef\u7528\u4e24\u4e2a 3\\times 3 3\\times 3 \u7684\u5377\u79ef\u66ff\u4ee3\uff0c\u4ece\u800c\u589e\u52a0\u7f51\u7edc\u7684\u6df1\u5ea6\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u3002","title":"4.1 InceptionV2"},{"location":"imageClassification/section4/#42-inceptionv3","text":"\u5c06n\u00d7n\u5377\u79ef\u5206\u5272\u4e3a1\u00d7n\u548cn\u00d71\u4e24\u4e2a\u5377\u79ef\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u7684 3\\times3 3\\times3 \u5377\u79ef\u9996\u5148\u6267\u884c\u4e00\u4e2a 1\\times3 1\\times3 \u7684\u5377\u79ef\uff0c\u7136\u540e\u6267\u884c\u4e00\u4e2a 3\\times1 3\\times1 \u7684\u5377\u79ef,\u8fd9\u79cd\u65b9\u6cd5\u7684\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\u90fd\u6bd4\u539f\u6765\u964d\u4f4e\u3002 \u603b\u7ed3 \u77e5\u9053GoogLeNet\u7684\u7f51\u7edc\u67b6\u6784\uff1a\u6709\u57fa\u7840\u6a21\u5757Inception\u6784\u6210 \u80fd\u591f\u5229\u7528GoogleNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b","title":"4.2 InceptionV3"},{"location":"imageClassification/section5/","text":"2.5 ResNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053ResNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528ResNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b \u7f51\u7edc\u8d8a\u6df1\uff0c\u83b7\u53d6\u7684\u4fe1\u606f\u5c31\u8d8a\u591a\uff0c\u7279\u5f81\u4e5f\u8d8a\u4e30\u5bcc\u3002\u4f46\u662f\u5728\u5b9e\u8df5\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u7684\u52a0\u6df1\uff0c\u4f18\u5316\u6548\u679c\u53cd\u800c\u8d8a\u5dee\uff0c\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\u7684\u51c6\u786e\u7387\u53cd\u800c\u964d\u4f4e\u4e86\u3002 \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u4f55\u607a\u660e\u7b49\u4eba\u63d0\u51fa\u4e86\u6b8b\u5dee\u7f51\u7edc\uff08ResNet\uff09\u57282015\u5e74\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u593a\u9b41\uff0c\u5e76\u6df1\u523b\u5f71\u54cd\u4e86\u540e\u6765\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bbe\u8ba1\u3002 1 \u6b8b\u5dee\u5757 \u00b6 \u5047\u8bbe F(x) \u4ee3\u8868\u67d0\u4e2a\u53ea\u5305\u542b\u6709\u4e24\u5c42\u7684\u6620\u5c04\u51fd\u6570\uff0c x \u662f\u8f93\u5165\uff0c F(x)\u662f\u8f93\u51fa\u3002\u5047\u8bbe\u4ed6\u4eec\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\u3002\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u4fee\u6539\u7f51\u7edc\u4e2d\u7684 w\u548cb\u53bb\u62df\u5408\u4e00\u4e2a\u7406\u60f3\u7684 H(x)(\u4ece\u8f93\u5165\u5230\u8f93\u51fa\u7684\u4e00\u4e2a\u7406\u60f3\u7684\u6620\u5c04\u51fd\u6570)\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u7684\u76ee\u6807\u662f\u4fee\u6539F(x) \u4e2d\u7684 w\u548cb\u903c\u8fd1 H(x) \u3002\u5982\u679c\u6211\u4eec\u6539\u53d8\u601d\u8def\uff0c\u7528F(x) \u6765\u903c\u8fd1 H(x)-x \uff0c\u90a3\u4e48\u6211\u4eec\u6700\u7ec8\u5f97\u5230\u7684\u8f93\u51fa\u5c31\u53d8\u4e3a F(x)+x\uff08\u8fd9\u91cc\u7684\u52a0\u6307\u7684\u662f\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u76f8\u52a0\uff0c\u4e5f\u5c31\u662felement-wise addition\uff09\uff0c\u8fd9\u91cc\u5c06\u76f4\u63a5\u4ece\u8f93\u5165\u8fde\u63a5\u5230\u8f93\u51fa\u7684\u7ed3\u6784\u4e5f\u79f0\u4e3ashortcut\uff0c\u90a3\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u6b8b\u5dee\u5757\uff0cResNet\u7684\u57fa\u7840\u6a21\u5757\u3002 ResNet\u6cbf\u7528\u4e86VGG\u5168 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u7684\u8bbe\u8ba1\u3002\u6b8b\u5dee\u5757\u91cc\u9996\u5148\u67092\u4e2a\u6709\u76f8\u540c\u8f93\u51fa\u901a\u9053\u6570\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u63a5BN\u5c42\u548cReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u7136\u540e\u5c06\u8f93\u5165\u76f4\u63a5\u52a0\u5728\u6700\u540e\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u524d\uff0c\u8fd9\u79cd\u7ed3\u6784\u7528\u4e8e\u5c42\u6570\u8f83\u5c11\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6bd4\u5982ResNet34\u3002\u82e5\u8f93\u5165\u901a\u9053\u6570\u6bd4\u8f83\u591a\uff0c\u5c31\u9700\u8981\u5f15\u5165 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u8c03\u6574\u8f93\u5165\u7684\u901a\u9053\u6570\uff0c\u8fd9\u79cd\u7ed3\u6784\u4e5f\u53eb\u4f5c\u74f6\u9888\u6a21\u5757\uff0c\u901a\u5e38\u7528\u4e8e\u7f51\u7edc\u5c42\u6570\u8f83\u591a\u7684\u7ed3\u6784\u4e2d\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe\u5de6\u4e2d\u7684\u6b8b\u5dee\u5757\u7684\u5b9e\u73b0\u5982\u4e0b\uff0c\u53ef\u4ee5\u8bbe\u5b9a\u8f93\u51fa\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u7684\u5377\u79ef\u53ca\u5377\u79ef\u5c42\u7684\u6b65\u5e45\u3002 # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import layers , activations # \u5b9a\u4e49ResNet\u7684\u6b8b\u5dee\u5757 class Residual ( tf . keras . Model ): # \u6307\u660e\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f def __init__ ( self , num_channels , use_1x1conv = False , strides = 1 ): super ( Residual , self ) . __init__ () # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv1 = layers . Conv2D ( num_channels , padding = 'same' , kernel_size = 3 , strides = strides ) # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv2 = layers . Conv2D ( num_channels , kernel_size = 3 , padding = 'same' ) if use_1x1conv : self . conv3 = layers . Conv2D ( num_channels , kernel_size = 1 , strides = strides ) else : self . conv3 = None # \u6307\u660eBN\u5c42 self . bn1 = layers . BatchNormalization () self . bn2 = layers . BatchNormalization () # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u5377\u79ef\uff0cBN\uff0c\u6fc0\u6d3b Y = activations . relu ( self . bn1 ( self . conv1 ( X ))) # \u5377\u79ef\uff0cBN Y = self . bn2 ( self . conv2 ( Y )) # \u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c1*1\u5377\u79ef\u4fdd\u8bc1\u901a\u9053\u6570\u76f8\u540c if self . conv3 : X = self . conv3 ( X ) # \u8fd4\u56de\u4e0e\u8f93\u5165\u76f8\u52a0\u540e\u6fc0\u6d3b\u7684\u7ed3\u679c return activations . relu ( Y + X ) 1*1\u5377\u79ef\u7528\u6765\u8c03\u6574\u901a\u9053\u6570\u3002 2 ResNet\u6a21\u578b \u00b6 ResNet\u6a21\u578b\u7684\u6784\u6210\u5982\u4e0b\u56fe\u6240\u793a\uff1a ResNet\u7f51\u7edc\u4e2d\u6309\u7167\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\u5206\u4e3a\u4e0d\u540c\u7684\u6a21\u5757\u3002\u7b2c\u4e00\u4e2a\u6a21\u5757\u524d\u4f7f\u7528\u4e86\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u5c42\uff0c\u6240\u4ee5\u65e0\u987b\u51cf\u5c0f\u9ad8\u548c\u5bbd\u3002\u4e4b\u540e\u7684\u6bcf\u4e2a\u6a21\u5757\u5728\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u91cc\u5c06\u4e0a\u4e00\u4e2a\u6a21\u5757\u7684\u901a\u9053\u6570\u7ffb\u500d\uff0c\u5e76\u5c06\u9ad8\u548c\u5bbd\u51cf\u534a\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u5b9e\u73b0\u8fd9\u4e9b\u6a21\u5757\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u5bf9\u7b2c\u4e00\u4e2a\u6a21\u5757\u505a\u4e86\u7279\u522b\u5904\u7406\u3002 # ResNet\u7f51\u7edc\u4e2d\u6a21\u5757\u7684\u6784\u6210 class ResnetBlock ( tf . keras . layers . Layer ): # \u7f51\u7edc\u5c42\u7684\u5b9a\u4e49\uff1a\u8f93\u51fa\u901a\u9053\u6570\uff08\u5377\u79ef\u6838\u4e2a\u6570\uff09\uff0c\u6a21\u5757\u4e2d\u5305\u542b\u7684\u6b8b\u5dee\u5757\u4e2a\u6570\uff0c\u662f\u5426\u4e3a\u7b2c\u4e00\u4e2a\u6a21\u5757 def __init__ ( self , num_channels , num_residuals , first_block = False ): super ( ResnetBlock , self ) . __init__ () # \u6a21\u5757\u4e2d\u7684\u7f51\u7edc\u5c42 self . listLayers = [] # \u904d\u5386\u6a21\u5757\u4e2d\u6240\u6709\u7684\u5c42 for i in range ( num_residuals ): # \u82e5\u4e3a\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u5e76\u4e14\u4e0d\u662f\u7b2c\u4e00\u4e2a\u6a21\u5757\uff0c\u5219\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2\uff08\u76ee\u7684\u662f\u51cf\u5c0f\u7279\u5f81\u56fe\uff0c\u5e76\u589e\u5927\u901a\u9053\u6570\uff09 if i == 0 and not first_block : self . listLayers . append ( Residual ( num_channels , use_1x1conv = True , strides = 2 )) # \u5426\u5219\u4e0d\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a1 else : self . listLayers . append ( Residual ( num_channels )) # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u6240\u6709\u5c42\u4f9d\u6b21\u5411\u524d\u4f20\u64ad\u5373\u53ef for layer in self . listLayers . layers : X = layer ( X ) return X ResNet\u7684\u524d\u4e24\u5c42\u8ddf\u4e4b\u524d\u4ecb\u7ecd\u7684GoogLeNet\u4e2d\u7684\u4e00\u6837\uff1a\u5728\u8f93\u51fa\u901a\u9053\u6570\u4e3a64\u3001\u6b65\u5e45\u4e3a2\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u540e\u63a5\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u4e0d\u540c\u4e4b\u5904\u5728\u4e8eResNet\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u589e\u52a0\u4e86BN\u5c42,\u63a5\u7740\u662f\u6240\u6709\u6b8b\u5dee\u6a21\u5757\uff0c\u6700\u540e\uff0c\u4e0eGoogLeNet\u4e00\u6837\uff0c\u52a0\u5165\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u540e\u63a5\u4e0a\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u3002 # \u6784\u5efaResNet\u7f51\u7edc class ResNet ( tf . keras . Model ): # \u521d\u59cb\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2a\u6a21\u5757\u4e2d\u7684\u6b8b\u5dee\u5feb\u7684\u4e2a\u6570 def __init__ ( self , num_blocks ): super ( ResNet , self ) . __init__ () # \u8f93\u5165\u5c42\uff1a7*7\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2 self . conv = layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' ) # BN\u5c42 self . bn = layers . BatchNormalization () # \u6fc0\u6d3b\u5c42 self . relu = layers . Activation ( 'relu' ) # \u6700\u5927\u6c60\u5316\u5c42 self . mp = layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' ) # \u7b2c\u4e00\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a64 self . resnet_block1 = ResnetBlock ( 64 , num_blocks [ 0 ], first_block = True ) # \u7b2c\u4e8c\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a128 self . resnet_block2 = ResnetBlock ( 128 , num_blocks [ 1 ]) # \u7b2c\u4e09\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a256 self . resnet_block3 = ResnetBlock ( 256 , num_blocks [ 2 ]) # \u7b2c\u56db\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a512 self . resnet_block4 = ResnetBlock ( 512 , num_blocks [ 3 ]) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 self . gap = layers . GlobalAvgPool2D () # \u5168\u8fde\u63a5\u5c42\uff1a\u5206\u7c7b self . fc = layers . Dense ( units = 10 , activation = tf . keras . activations . softmax ) # \u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u5377\u79ef x = self . conv ( x ) # BN x = self . bn ( x ) # \u6fc0\u6d3b x = self . relu ( x ) # \u6700\u5927\u6c60\u5316 x = self . mp ( x ) # \u6b8b\u5dee\u6a21\u5757 x = self . resnet_block1 ( x ) x = self . resnet_block2 ( x ) x = self . resnet_block3 ( x ) x = self . resnet_block4 ( x ) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 x = self . gap ( x ) # \u5168\u94fe\u63a5\u5c42 x = self . fc ( x ) return x # \u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2ablock\u4e2d\u7684\u6b8b\u5dee\u5757\u4e2a\u6570 mynet = ResNet ([ 2 , 2 , 2 , 2 ]) \u8fd9\u91cc\u6bcf\u4e2a\u6a21\u5757\u91cc\u67094\u4e2a\u5377\u79ef\u5c42\uff08\u4e0d\u8ba1\u7b97 1\u00d71\u5377\u79ef\u5c42\uff09\uff0c\u52a0\u4e0a\u6700\u5f00\u59cb\u7684\u5377\u79ef\u5c42\u548c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u5171\u8ba118\u5c42\u3002\u8fd9\u4e2a\u6a21\u578b\u88ab\u79f0\u4e3aResNet-18\u3002\u901a\u8fc7\u914d\u7f6e\u4e0d\u540c\u7684\u901a\u9053\u6570\u548c\u6a21\u5757\u91cc\u7684\u6b8b\u5dee\u5757\u6570\u53ef\u4ee5\u5f97\u5230\u4e0d\u540c\u7684ResNet\u6a21\u578b\uff0c\u4f8b\u5982\u66f4\u6df1\u7684\u542b152\u5c42\u7684ResNet-152\u3002\u867d\u7136ResNet\u7684\u4e3b\u4f53\u67b6\u6784\u8ddfGoogLeNet\u7684\u7c7b\u4f3c\uff0c\u4f46ResNet\u7ed3\u6784\u66f4\u7b80\u5355\uff0c\u4fee\u6539\u4e5f\u66f4\u65b9\u4fbf\u3002\u8fd9\u4e9b\u56e0\u7d20\u90fd\u5bfc\u81f4\u4e86ResNet\u8fc5\u901f\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002 \u5728\u8bad\u7ec3ResNet\u4e4b\u524d\uff0c\u6211\u4eec\u6765\u89c2\u5bdf\u4e00\u4e0b\u8f93\u5165\u5f62\u72b6\u5728ResNe\u7684\u67b6\u6784\uff1a X = tf . random . uniform ( shape = ( 1 , 224 , 224 , 1 )) y = mynet ( X ) mynet . summary () Model : \"res_net\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_2 ( Conv2D ) multiple 3200 _________________________________________________________________ batch_normalization_2 ( Batch multiple 256 _________________________________________________________________ activation ( Activation ) multiple 0 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) multiple 0 _________________________________________________________________ resnet_block ( ResnetBlock ) multiple 148736 _________________________________________________________________ resnet_block_1 ( ResnetBlock ) multiple 526976 _________________________________________________________________ resnet_block_2 ( ResnetBlock ) multiple 2102528 _________________________________________________________________ resnet_block_3 ( ResnetBlock ) multiple 8399360 _________________________________________________________________ global_average_pooling2d ( Gl multiple 0 _________________________________________________________________ dense ( Dense ) multiple 5130 ================================================================= Total params : 11 , 186 , 186 Trainable params : 11 , 178 , 378 Non - trainable params : 7 , 808 _________________________________________________________________ 2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b \u00b6 \u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aresNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230ResNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002 2.1 \u6570\u636e\u8bfb\u53d6 \u00b6 \u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 ) 2.2 \u6a21\u578b\u7f16\u8bd1 \u00b6 # \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) mynet . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) 2.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 mynet . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 10 s 5 s / step - loss : 2.7811 - accuracy : 0.1391 - val_loss : 4.7931 - val_accuracy : 0.1923 Epoch 2 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.2579 - accuracy : 0.2478 - val_loss : 2.9262 - val_accuracy : 0.2692 Epoch 3 / 3 2 / 2 [ ============================== ] - 15 s 7 s / step - loss : 2.0874 - accuracy : 0.2609 - val_loss : 2.5882 - val_accuracy : 0.2692 2.4 \u6a21\u578b\u8bc4\u4f30 \u00b6 # \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e mynet . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 370 ms / step - loss : 3.4343 - accuracy : 0.1016 [ 3.4342570304870605 , 0.1015625 ] \u603b\u7ed3 \u77e5\u9053ResNet\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u6b8b\u5dee\u5757\u7684\u6784\u6210 \u80fd\u591f\u642d\u5efaResNet\u7f51\u7edc\u7ed3\u6784","title":"ResNet"},{"location":"imageClassification/section5/#25-resnet","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053ResNet\u7f51\u7edc\u7ed3\u6784\u7684\u7279\u70b9 \u80fd\u591f\u5229\u7528ResNet\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b \u7f51\u7edc\u8d8a\u6df1\uff0c\u83b7\u53d6\u7684\u4fe1\u606f\u5c31\u8d8a\u591a\uff0c\u7279\u5f81\u4e5f\u8d8a\u4e30\u5bcc\u3002\u4f46\u662f\u5728\u5b9e\u8df5\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u7684\u52a0\u6df1\uff0c\u4f18\u5316\u6548\u679c\u53cd\u800c\u8d8a\u5dee\uff0c\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\u7684\u51c6\u786e\u7387\u53cd\u800c\u964d\u4f4e\u4e86\u3002 \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u4f55\u607a\u660e\u7b49\u4eba\u63d0\u51fa\u4e86\u6b8b\u5dee\u7f51\u7edc\uff08ResNet\uff09\u57282015\u5e74\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u593a\u9b41\uff0c\u5e76\u6df1\u523b\u5f71\u54cd\u4e86\u540e\u6765\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bbe\u8ba1\u3002","title":"2.5 ResNet"},{"location":"imageClassification/section5/#1","text":"\u5047\u8bbe F(x) \u4ee3\u8868\u67d0\u4e2a\u53ea\u5305\u542b\u6709\u4e24\u5c42\u7684\u6620\u5c04\u51fd\u6570\uff0c x \u662f\u8f93\u5165\uff0c F(x)\u662f\u8f93\u51fa\u3002\u5047\u8bbe\u4ed6\u4eec\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\u3002\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u4fee\u6539\u7f51\u7edc\u4e2d\u7684 w\u548cb\u53bb\u62df\u5408\u4e00\u4e2a\u7406\u60f3\u7684 H(x)(\u4ece\u8f93\u5165\u5230\u8f93\u51fa\u7684\u4e00\u4e2a\u7406\u60f3\u7684\u6620\u5c04\u51fd\u6570)\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u7684\u76ee\u6807\u662f\u4fee\u6539F(x) \u4e2d\u7684 w\u548cb\u903c\u8fd1 H(x) \u3002\u5982\u679c\u6211\u4eec\u6539\u53d8\u601d\u8def\uff0c\u7528F(x) \u6765\u903c\u8fd1 H(x)-x \uff0c\u90a3\u4e48\u6211\u4eec\u6700\u7ec8\u5f97\u5230\u7684\u8f93\u51fa\u5c31\u53d8\u4e3a F(x)+x\uff08\u8fd9\u91cc\u7684\u52a0\u6307\u7684\u662f\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u76f8\u52a0\uff0c\u4e5f\u5c31\u662felement-wise addition\uff09\uff0c\u8fd9\u91cc\u5c06\u76f4\u63a5\u4ece\u8f93\u5165\u8fde\u63a5\u5230\u8f93\u51fa\u7684\u7ed3\u6784\u4e5f\u79f0\u4e3ashortcut\uff0c\u90a3\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u6b8b\u5dee\u5757\uff0cResNet\u7684\u57fa\u7840\u6a21\u5757\u3002 ResNet\u6cbf\u7528\u4e86VGG\u5168 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u7684\u8bbe\u8ba1\u3002\u6b8b\u5dee\u5757\u91cc\u9996\u5148\u67092\u4e2a\u6709\u76f8\u540c\u8f93\u51fa\u901a\u9053\u6570\u7684 3\\times 3 3\\times 3 \u5377\u79ef\u5c42\u3002\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u63a5BN\u5c42\u548cReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u7136\u540e\u5c06\u8f93\u5165\u76f4\u63a5\u52a0\u5728\u6700\u540e\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u524d\uff0c\u8fd9\u79cd\u7ed3\u6784\u7528\u4e8e\u5c42\u6570\u8f83\u5c11\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6bd4\u5982ResNet34\u3002\u82e5\u8f93\u5165\u901a\u9053\u6570\u6bd4\u8f83\u591a\uff0c\u5c31\u9700\u8981\u5f15\u5165 1\\times 1 1\\times 1 \u5377\u79ef\u5c42\u6765\u8c03\u6574\u8f93\u5165\u7684\u901a\u9053\u6570\uff0c\u8fd9\u79cd\u7ed3\u6784\u4e5f\u53eb\u4f5c\u74f6\u9888\u6a21\u5757\uff0c\u901a\u5e38\u7528\u4e8e\u7f51\u7edc\u5c42\u6570\u8f83\u591a\u7684\u7ed3\u6784\u4e2d\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe\u5de6\u4e2d\u7684\u6b8b\u5dee\u5757\u7684\u5b9e\u73b0\u5982\u4e0b\uff0c\u53ef\u4ee5\u8bbe\u5b9a\u8f93\u51fa\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u7684\u5377\u79ef\u53ca\u5377\u79ef\u5c42\u7684\u6b65\u5e45\u3002 # \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305 import tensorflow as tf from tensorflow.keras import layers , activations # \u5b9a\u4e49ResNet\u7684\u6b8b\u5dee\u5757 class Residual ( tf . keras . Model ): # \u6307\u660e\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\uff0c\u662f\u5426\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f def __init__ ( self , num_channels , use_1x1conv = False , strides = 1 ): super ( Residual , self ) . __init__ () # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv1 = layers . Conv2D ( num_channels , padding = 'same' , kernel_size = 3 , strides = strides ) # \u5377\u79ef\u5c42\uff1a\u6307\u660e\u5377\u79ef\u6838\u4e2a\u6570\uff0cpadding,\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6b65\u957f self . conv2 = layers . Conv2D ( num_channels , kernel_size = 3 , padding = 'same' ) if use_1x1conv : self . conv3 = layers . Conv2D ( num_channels , kernel_size = 1 , strides = strides ) else : self . conv3 = None # \u6307\u660eBN\u5c42 self . bn1 = layers . BatchNormalization () self . bn2 = layers . BatchNormalization () # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u5377\u79ef\uff0cBN\uff0c\u6fc0\u6d3b Y = activations . relu ( self . bn1 ( self . conv1 ( X ))) # \u5377\u79ef\uff0cBN Y = self . bn2 ( self . conv2 ( Y )) # \u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c1*1\u5377\u79ef\u4fdd\u8bc1\u901a\u9053\u6570\u76f8\u540c if self . conv3 : X = self . conv3 ( X ) # \u8fd4\u56de\u4e0e\u8f93\u5165\u76f8\u52a0\u540e\u6fc0\u6d3b\u7684\u7ed3\u679c return activations . relu ( Y + X ) 1*1\u5377\u79ef\u7528\u6765\u8c03\u6574\u901a\u9053\u6570\u3002","title":"1 \u6b8b\u5dee\u5757"},{"location":"imageClassification/section5/#2-resnet","text":"ResNet\u6a21\u578b\u7684\u6784\u6210\u5982\u4e0b\u56fe\u6240\u793a\uff1a ResNet\u7f51\u7edc\u4e2d\u6309\u7167\u6b8b\u5dee\u5757\u7684\u901a\u9053\u6570\u5206\u4e3a\u4e0d\u540c\u7684\u6a21\u5757\u3002\u7b2c\u4e00\u4e2a\u6a21\u5757\u524d\u4f7f\u7528\u4e86\u6b65\u5e45\u4e3a2\u7684\u6700\u5927\u6c60\u5316\u5c42\uff0c\u6240\u4ee5\u65e0\u987b\u51cf\u5c0f\u9ad8\u548c\u5bbd\u3002\u4e4b\u540e\u7684\u6bcf\u4e2a\u6a21\u5757\u5728\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u91cc\u5c06\u4e0a\u4e00\u4e2a\u6a21\u5757\u7684\u901a\u9053\u6570\u7ffb\u500d\uff0c\u5e76\u5c06\u9ad8\u548c\u5bbd\u51cf\u534a\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u5b9e\u73b0\u8fd9\u4e9b\u6a21\u5757\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u5bf9\u7b2c\u4e00\u4e2a\u6a21\u5757\u505a\u4e86\u7279\u522b\u5904\u7406\u3002 # ResNet\u7f51\u7edc\u4e2d\u6a21\u5757\u7684\u6784\u6210 class ResnetBlock ( tf . keras . layers . Layer ): # \u7f51\u7edc\u5c42\u7684\u5b9a\u4e49\uff1a\u8f93\u51fa\u901a\u9053\u6570\uff08\u5377\u79ef\u6838\u4e2a\u6570\uff09\uff0c\u6a21\u5757\u4e2d\u5305\u542b\u7684\u6b8b\u5dee\u5757\u4e2a\u6570\uff0c\u662f\u5426\u4e3a\u7b2c\u4e00\u4e2a\u6a21\u5757 def __init__ ( self , num_channels , num_residuals , first_block = False ): super ( ResnetBlock , self ) . __init__ () # \u6a21\u5757\u4e2d\u7684\u7f51\u7edc\u5c42 self . listLayers = [] # \u904d\u5386\u6a21\u5757\u4e2d\u6240\u6709\u7684\u5c42 for i in range ( num_residuals ): # \u82e5\u4e3a\u7b2c\u4e00\u4e2a\u6b8b\u5dee\u5757\u5e76\u4e14\u4e0d\u662f\u7b2c\u4e00\u4e2a\u6a21\u5757\uff0c\u5219\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2\uff08\u76ee\u7684\u662f\u51cf\u5c0f\u7279\u5f81\u56fe\uff0c\u5e76\u589e\u5927\u901a\u9053\u6570\uff09 if i == 0 and not first_block : self . listLayers . append ( Residual ( num_channels , use_1x1conv = True , strides = 2 )) # \u5426\u5219\u4e0d\u4f7f\u75281*1\u5377\u79ef\uff0c\u6b65\u957f\u4e3a1 else : self . listLayers . append ( Residual ( num_channels )) # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , X ): # \u6240\u6709\u5c42\u4f9d\u6b21\u5411\u524d\u4f20\u64ad\u5373\u53ef for layer in self . listLayers . layers : X = layer ( X ) return X ResNet\u7684\u524d\u4e24\u5c42\u8ddf\u4e4b\u524d\u4ecb\u7ecd\u7684GoogLeNet\u4e2d\u7684\u4e00\u6837\uff1a\u5728\u8f93\u51fa\u901a\u9053\u6570\u4e3a64\u3001\u6b65\u5e45\u4e3a2\u7684 7\\times 7 7\\times 7 \u5377\u79ef\u5c42\u540e\u63a5\u6b65\u5e45\u4e3a2\u7684 3\\times 3 3\\times 3 \u7684\u6700\u5927\u6c60\u5316\u5c42\u3002\u4e0d\u540c\u4e4b\u5904\u5728\u4e8eResNet\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u589e\u52a0\u4e86BN\u5c42,\u63a5\u7740\u662f\u6240\u6709\u6b8b\u5dee\u6a21\u5757\uff0c\u6700\u540e\uff0c\u4e0eGoogLeNet\u4e00\u6837\uff0c\u52a0\u5165\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff08GAP\uff09\u540e\u63a5\u4e0a\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\u3002 # \u6784\u5efaResNet\u7f51\u7edc class ResNet ( tf . keras . Model ): # \u521d\u59cb\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2a\u6a21\u5757\u4e2d\u7684\u6b8b\u5dee\u5feb\u7684\u4e2a\u6570 def __init__ ( self , num_blocks ): super ( ResNet , self ) . __init__ () # \u8f93\u5165\u5c42\uff1a7*7\u5377\u79ef\uff0c\u6b65\u957f\u4e3a2 self . conv = layers . Conv2D ( 64 , kernel_size = 7 , strides = 2 , padding = 'same' ) # BN\u5c42 self . bn = layers . BatchNormalization () # \u6fc0\u6d3b\u5c42 self . relu = layers . Activation ( 'relu' ) # \u6700\u5927\u6c60\u5316\u5c42 self . mp = layers . MaxPool2D ( pool_size = 3 , strides = 2 , padding = 'same' ) # \u7b2c\u4e00\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a64 self . resnet_block1 = ResnetBlock ( 64 , num_blocks [ 0 ], first_block = True ) # \u7b2c\u4e8c\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a128 self . resnet_block2 = ResnetBlock ( 128 , num_blocks [ 1 ]) # \u7b2c\u4e09\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a256 self . resnet_block3 = ResnetBlock ( 256 , num_blocks [ 2 ]) # \u7b2c\u56db\u4e2ablock\uff0c\u901a\u9053\u6570\u4e3a512 self . resnet_block4 = ResnetBlock ( 512 , num_blocks [ 3 ]) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 self . gap = layers . GlobalAvgPool2D () # \u5168\u8fde\u63a5\u5c42\uff1a\u5206\u7c7b self . fc = layers . Dense ( units = 10 , activation = tf . keras . activations . softmax ) # \u524d\u5411\u4f20\u64ad\u8fc7\u7a0b def call ( self , x ): # \u5377\u79ef x = self . conv ( x ) # BN x = self . bn ( x ) # \u6fc0\u6d3b x = self . relu ( x ) # \u6700\u5927\u6c60\u5316 x = self . mp ( x ) # \u6b8b\u5dee\u6a21\u5757 x = self . resnet_block1 ( x ) x = self . resnet_block2 ( x ) x = self . resnet_block3 ( x ) x = self . resnet_block4 ( x ) # \u5168\u5c40\u5e73\u5747\u6c60\u5316 x = self . gap ( x ) # \u5168\u94fe\u63a5\u5c42 x = self . fc ( x ) return x # \u6a21\u578b\u5b9e\u4f8b\u5316\uff1a\u6307\u5b9a\u6bcf\u4e2ablock\u4e2d\u7684\u6b8b\u5dee\u5757\u4e2a\u6570 mynet = ResNet ([ 2 , 2 , 2 , 2 ]) \u8fd9\u91cc\u6bcf\u4e2a\u6a21\u5757\u91cc\u67094\u4e2a\u5377\u79ef\u5c42\uff08\u4e0d\u8ba1\u7b97 1\u00d71\u5377\u79ef\u5c42\uff09\uff0c\u52a0\u4e0a\u6700\u5f00\u59cb\u7684\u5377\u79ef\u5c42\u548c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u5171\u8ba118\u5c42\u3002\u8fd9\u4e2a\u6a21\u578b\u88ab\u79f0\u4e3aResNet-18\u3002\u901a\u8fc7\u914d\u7f6e\u4e0d\u540c\u7684\u901a\u9053\u6570\u548c\u6a21\u5757\u91cc\u7684\u6b8b\u5dee\u5757\u6570\u53ef\u4ee5\u5f97\u5230\u4e0d\u540c\u7684ResNet\u6a21\u578b\uff0c\u4f8b\u5982\u66f4\u6df1\u7684\u542b152\u5c42\u7684ResNet-152\u3002\u867d\u7136ResNet\u7684\u4e3b\u4f53\u67b6\u6784\u8ddfGoogLeNet\u7684\u7c7b\u4f3c\uff0c\u4f46ResNet\u7ed3\u6784\u66f4\u7b80\u5355\uff0c\u4fee\u6539\u4e5f\u66f4\u65b9\u4fbf\u3002\u8fd9\u4e9b\u56e0\u7d20\u90fd\u5bfc\u81f4\u4e86ResNet\u8fc5\u901f\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002 \u5728\u8bad\u7ec3ResNet\u4e4b\u524d\uff0c\u6211\u4eec\u6765\u89c2\u5bdf\u4e00\u4e0b\u8f93\u5165\u5f62\u72b6\u5728ResNe\u7684\u67b6\u6784\uff1a X = tf . random . uniform ( shape = ( 1 , 224 , 224 , 1 )) y = mynet ( X ) mynet . summary () Model : \"res_net\" _________________________________________________________________ Layer ( type ) Output Shape Param # ================================================================= conv2d_2 ( Conv2D ) multiple 3200 _________________________________________________________________ batch_normalization_2 ( Batch multiple 256 _________________________________________________________________ activation ( Activation ) multiple 0 _________________________________________________________________ max_pooling2d ( MaxPooling2D ) multiple 0 _________________________________________________________________ resnet_block ( ResnetBlock ) multiple 148736 _________________________________________________________________ resnet_block_1 ( ResnetBlock ) multiple 526976 _________________________________________________________________ resnet_block_2 ( ResnetBlock ) multiple 2102528 _________________________________________________________________ resnet_block_3 ( ResnetBlock ) multiple 8399360 _________________________________________________________________ global_average_pooling2d ( Gl multiple 0 _________________________________________________________________ dense ( Dense ) multiple 5130 ================================================================= Total params : 11 , 186 , 186 Trainable params : 11 , 178 , 378 Non - trainable params : 7 , 808 _________________________________________________________________","title":"2 ResNet\u6a21\u578b"},{"location":"imageClassification/section5/#2","text":"\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u8f83\u5927\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u4ecd\u7528\u524d\u9762\u7684MNIST\u6570\u636e\u96c6\u6765\u6f14\u793aresNet\u3002\u8bfb\u53d6\u6570\u636e\u7684\u65f6\u5c06\u56fe\u50cf\u9ad8\u548c\u5bbd\u6269\u5927\u5230ResNet\u4f7f\u7528\u7684\u56fe\u50cf\u9ad8\u548c\u5bbd224\u3002\u8fd9\u4e2a\u901a\u8fc7 tf.image.resize_with_pad \u6765\u5b9e\u73b0\u3002","title":"2.\u624b\u5199\u6570\u5b57\u52bf\u8bc6\u522b"},{"location":"imageClassification/section5/#21","text":"\u9996\u5148\u83b7\u53d6\u6570\u636e,\u5e76\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff1a import numpy as np # \u83b7\u53d6\u624b\u5199\u6570\u5b57\u6570\u636e\u96c6 ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # \u8bad\u7ec3\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C train_images = np . reshape ( train_images ,( train_images . shape [ 0 ], train_images . shape [ 1 ], train_images . shape [ 2 ], 1 )) # \u6d4b\u8bd5\u96c6\u6570\u636e\u7ef4\u5ea6\u7684\u8c03\u6574\uff1aN H W C test_images = np . reshape ( test_images ,( test_images . shape [ 0 ], test_images . shape [ 1 ], test_images . shape [ 2 ], 1 )) \u7531\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\uff0c\u6211\u4eec\u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u83b7\u53d6\u90e8\u5206\u6570\u636e\uff0c\u5e76\u5c06\u56fe\u50cf\u8c03\u6574\u4e3a224*224\u5927\u5c0f\uff0c\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u5b9a\u4e49\u4e24\u4e2a\u65b9\u6cd5\u968f\u673a\u62bd\u53d6\u90e8\u5206\u6837\u672c\u6f14\u793a # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e def get_train ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( train_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u621022*227\u5927\u5c0f resized_images = tf . image . resize_with_pad ( train_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u53d6\u7684 return resized_images . numpy (), train_labels [ index ] # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e def get_test ( size ): # \u968f\u673a\u751f\u6210\u8981\u62bd\u6837\u7684\u6837\u672c\u7684\u7d22\u5f15 index = np . random . randint ( 0 , np . shape ( test_images )[ 0 ], size ) # \u5c06\u8fd9\u4e9b\u6570\u636eresize\u6210224*224\u5927\u5c0f resized_images = tf . image . resize_with_pad ( test_images [ index ], 224 , 224 ,) # \u8fd4\u56de\u62bd\u6837\u7684\u6d4b\u8bd5\u6837\u672c return resized_images . numpy (), test_labels [ index ] \u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\uff0c\u83b7\u53d6\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff1a # \u83b7\u53d6\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c train_images , train_labels = get_train ( 256 ) test_images , test_labels = get_test ( 128 )","title":"2.1 \u6570\u636e\u8bfb\u53d6"},{"location":"imageClassification/section5/#22","text":"# \u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 ) mynet . compile ( optimizer = optimizer , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ])","title":"2.2 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageClassification/section5/#23","text":"# \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\uff0cbatchsize,epoch,\u9a8c\u8bc1\u96c6 mynet . fit ( train_images , train_labels , batch_size = 128 , epochs = 3 , verbose = 1 , validation_split = 0.1 ) \u8bad\u7ec3\u8f93\u51fa\u4e3a\uff1a Epoch 1 / 3 2 / 2 [ ============================== ] - 10 s 5 s / step - loss : 2.7811 - accuracy : 0.1391 - val_loss : 4.7931 - val_accuracy : 0.1923 Epoch 2 / 3 2 / 2 [ ============================== ] - 8 s 4 s / step - loss : 2.2579 - accuracy : 0.2478 - val_loss : 2.9262 - val_accuracy : 0.2692 Epoch 3 / 3 2 / 2 [ ============================== ] - 15 s 7 s / step - loss : 2.0874 - accuracy : 0.2609 - val_loss : 2.5882 - val_accuracy : 0.2692","title":"2.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageClassification/section5/#24","text":"# \u6307\u5b9a\u6d4b\u8bd5\u6570\u636e mynet . evaluate ( test_images , test_labels , verbose = 1 ) \u8f93\u51fa\u4e3a\uff1a 4 / 4 [ ============================== ] - 1 s 370 ms / step - loss : 3.4343 - accuracy : 0.1016 [ 3.4342570304870605 , 0.1015625 ] \u603b\u7ed3 \u77e5\u9053ResNet\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u6b8b\u5dee\u5757\u7684\u6784\u6210 \u80fd\u591f\u642d\u5efaResNet\u7f51\u7edc\u7ed3\u6784","title":"2.4 \u6a21\u578b\u8bc4\u4f30"},{"location":"imageClassification/section6/","text":"2.6 \u56fe\u50cf\u589e\u5f3a \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u589e\u5f3a\u7684\u5e38\u7528\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6765\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a \u5927\u89c4\u6a21\u6570\u636e\u96c6\u662f\u6210\u529f\u5e94\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u63d0\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e0d\u540c\u65b9\u5f0f\u7684\u88c1\u526a\uff0c\u4f7f\u611f\u5174\u8da3\u7684\u7269\u4f53\u51fa\u73b0\u5728\u4e0d\u540c\u4f4d\u7f6e\uff0c\u4ece\u800c\u51cf\u8f7b\u6a21\u578b\u5bf9\u7269\u4f53\u51fa\u73b0\u4f4d\u7f6e\u7684\u4f9d\u8d56\u6027\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u8c03\u6574\u4eae\u5ea6\u3001\u8272\u5f69\u7b49\u56e0\u7d20\u6765\u964d\u4f4e\u6a21\u578b\u5bf9\u8272\u5f69\u7684\u654f\u611f\u5ea6\u3002\u53ef\u4ee5\u8bf4\uff0c\u5728\u5f53\u5e74AlexNet\u7684\u6210\u529f\u4e2d\uff0c\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u529f\u4e0d\u53ef\u6ca1 1.\u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5 \u00b6 \u56fe\u50cf\u589e\u5f3a\uff08image augmentation\uff09\u6307\u901a\u8fc7\u526a\u5207\u3001\u65cb\u8f6c/\u53cd\u5c04/\u7ffb\u8f6c\u53d8\u6362\u3001\u7f29\u653e\u53d8\u6362\u3001\u5e73\u79fb\u53d8\u6362\u3001\u5c3a\u5ea6\u53d8\u6362\u3001\u5bf9\u6bd4\u5ea6\u53d8\u6362\u3001\u566a\u58f0\u6270\u52a8\u3001\u989c\u8272\u53d8\u6362\u7b49\u4e00\u79cd\u6216\u591a\u79cd\u7ec4\u5408\u6570\u636e\u589e\u5f3a\u53d8\u6362\u7684\u65b9\u5f0f\u6765\u589e\u52a0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002\u56fe\u50cf\u589e\u5f3a\u7684\u610f\u4e49\u662f\u901a\u8fc7\u5bf9\u8bad\u7ec3\u56fe\u50cf\u505a\u4e00\u7cfb\u5217\u968f\u673a\u6539\u53d8\uff0c\u6765\u4ea7\u751f\u76f8\u4f3c\u4f46\u53c8\u4e0d\u540c\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u4ece\u800c\u6269\u5927\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u89c4\u6a21\uff0c\u800c\u4e14\u968f\u673a\u6539\u53d8\u8bad\u7ec3\u6837\u672c\u53ef\u4ee5\u964d\u4f4e\u6a21\u578b\u5bf9\u67d0\u4e9b\u5c5e\u6027\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u5e38\u89c1\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b\uff1a\u51e0\u4f55\u53d8\u6362\u7c7b\u548c\u989c\u8272\u53d8\u6362\u7c7b \u51e0\u4f55\u53d8\u6362\u7c7b\uff0c\u4e3b\u8981\u662f\u5bf9\u56fe\u50cf\u8fdb\u884c\u51e0\u4f55\u53d8\u6362\u64cd\u4f5c\uff0c\u5305\u62ec**\u7ffb\u8f6c\uff0c\u65cb\u8f6c\uff0c\u88c1\u526a\uff0c\u53d8\u5f62\uff0c\u7f29\u653e**\u7b49\u3002 \u989c\u8272\u53d8\u6362\u7c7b\uff0c\u6307\u901a\u8fc7\u6a21\u7cca\u3001\u989c\u8272\u53d8\u6362\u3001\u64e6\u9664\u3001\u586b\u5145\u7b49\u65b9\u5f0f\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406 \u5b9e\u73b0\u56fe\u50cf\u589e\u5f3a\u53ef\u4ee5\u901a\u8fc7tf.image\u6765\u5b8c\u6210\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7tf.keras.imageGenerator\u6765\u5b8c\u6210\u3002 2.tf.image\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a \u00b6 \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\u5e76\u8bfb\u53d6\u8981\u5904\u7406\u7684\u56fe\u50cf\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt import numpy as np # \u8bfb\u53d6\u56fe\u50cf\u5e76\u663e\u793a cat = plt . imread ( './cat.jpg' ) plt . imshow ( cat ) 2.1 \u7ffb\u8f6c\u548c\u88c1\u526a \u00b6 \u5de6\u53f3\u7ffb\u8f6c\u56fe\u50cf\u662f\u6700\u65e9\u4e5f\u662f\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e00\u79cd\u56fe\u50cf\u589e\u5e7f\u65b9\u6cd5\u3002\u53ef\u4ee5\u901a\u8fc7 tf.image.random_flip_left_right \u6765\u5b9e\u73b0\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u3002 # \u5de6\u53f3\u7ffb\u8f6c\u5e76\u663e\u793a cat1 = tf . image . random_flip_left_right ( cat ) plt . imshow ( cat1 \uff09 \u521b\u5efa tf.image.random_flip_up_down \u5b9e\u4f8b\u6765\u5b9e\u73b0\u56fe\u50cf\u7684\u4e0a\u4e0b\u7ffb\u8f6c\uff0c\u4e0a\u4e0b\u7ffb\u8f6c\u4f7f\u7528\u7684\u8f83\u5c11\u3002 # \u4e0a\u4e0b\u7ffb\u8f6c cat2 = tf . image . random_flip_up_down ( cat ) plt . imshow ( cat2 ) \u968f\u673a\u88c1\u526a\u51fa\u4e00\u5757\u9762\u79ef\u4e3a\u539f\u9762\u79ef 10\\% \\sim 100\\% 10\\% \\sim 100\\% \u7684\u533a\u57df\uff0c\u4e14\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u4e4b\u6bd4\u968f\u673a\u53d6\u81ea 0.5 \\sim 2 0.5 \\sim 2 \uff0c\u7136\u540e\u518d\u5c06\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u5206\u522b\u7f29\u653e\u5230200\u50cf\u7d20\u3002 # \u968f\u673a\u88c1\u526a cat3 = tf . image . random_crop ( cat ,( 200 , 200 , 3 )) plt . imshow ( cat3 ) 2.2 \u989c\u8272\u53d8\u6362 \u00b6 \u53e6\u4e00\u7c7b\u589e\u5e7f\u65b9\u6cd5\u662f\u989c\u8272\u53d8\u6362\u3002\u6211\u4eec\u53ef\u4ee5\u4ece4\u4e2a\u65b9\u9762\u6539\u53d8\u56fe\u50cf\u7684\u989c\u8272\uff1a\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u3001\u9971\u548c\u5ea6\u548c\u8272\u8c03\u3002\u63a5\u4e0b\u6765\u5c06\u56fe\u50cf\u7684\u4eae\u5ea6\u968f\u673a\u53d8\u5316\u4e3a\u539f\u56fe\u4eae\u5ea6\u7684 50\\% 50\\% \uff08\u5373 1-0.5 1-0.5 \uff09 \\sim 150\\% \\sim 150\\% \uff08\u5373 1+0.5 1+0.5 \uff09\u3002 cat4 = tf . image . random_brightness ( cat , 0.5 ) plt . imshow ( cat4 ) \u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u968f\u673a\u53d8\u5316\u56fe\u50cf\u7684\u8272\u8c03 cat5 = tf . image . random_hue ( cat , 0.5 ) plt . imshow ( cat5 ) 3 \u4f7f\u7528ImageDataGenerator()\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a \u00b6 ImageDataGenerator()\u662fkeras.preprocessing.image\u6a21\u5757\u4e2d\u7684\u56fe\u7247\u751f\u6210\u5668\uff0c\u53ef\u4ee5\u5728batch\u4e2d\u5bf9\u6570\u636e\u8fdb\u884c\u589e\u5f3a\uff0c\u6269\u5145\u6570\u636e\u96c6\u5927\u5c0f\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6bd4\u5982\u65cb\u8f6c\uff0c\u53d8\u5f62\u7b49\uff0c\u5982\u4e0b\u6240\u793a\uff1a keras . preprocessing . image . ImageDataGenerator ( rotation_range = 0 , #\u6574\u6570\u3002\u968f\u673a\u65cb\u8f6c\u7684\u5ea6\u6570\u8303\u56f4\u3002 width_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u5bbd\u5ea6\u5e73\u79fb height_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u9ad8\u5ea6\u5e73\u79fb brightness_range = None , # \u4eae\u5ea6\u8c03\u6574 shear_range = 0.0 , # \u88c1\u526a zoom_range = 0.0 , #\u6d6e\u70b9\u6570 \u6216 [lower, upper]\u3002\u968f\u673a\u7f29\u653e\u8303\u56f4 horizontal_flip = False , # \u5de6\u53f3\u7ffb\u8f6c vertical_flip = False , # \u5782\u76f4\u7ffb\u8f6c rescale = None # \u5c3a\u5ea6\u8c03\u6574 ) \u6765\u770b\u4e0b\u6c34\u5e73\u7ffb\u8f6c\u7684\u7ed3\u679c\uff1a # \u83b7\u53d6\u6570\u636e\u96c6 ( x_train , y_train ), ( x_test , y_test ) = tf . keras . datasets . mnist . load_data () # \u5c06\u6570\u636e\u8f6c\u6362\u4e3a4\u7ef4\u7684\u5f62\u5f0f x_train = X_train . reshape ( X_train . shape [ 0 ], 28 , 28 , 1 ) x_test = X_test . reshape ( X_test . shape [ 0 ], 28 , 28 , 1 ) # \u8bbe\u7f6e\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\uff1a\u6c34\u5e73\u7ffb\u8f6c datagen = ImageDataGenerator ( horizontal_flip = True ) # \u67e5\u770b\u589e\u5f3a\u540e\u7684\u7ed3\u679c for X_batch , y_batch in datagen . flow ( x_train , y_train , batch_size = 9 ): plt . figure ( figsize = ( 8 , 8 )) # \u8bbe\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u663e\u793a\u7684\u5927\u5c0f # \u4ea7\u751f\u4e00\u4e2a3*3\u7f51\u683c\u7684\u56fe\u50cf for i in range ( 0 , 9 ): plt . subplot ( 330 + 1 + i ) plt . title ( y_batch [ i ]) plt . axis ( 'off' ) plt . imshow ( X_batch [ i ] . reshape ( 28 , 28 ), cmap = 'gray' ) plt . show () break \u603b\u7ed3 \u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\uff1a\u51e0\u4f55\u548c\u989c\u8272 \u5728tf,keras\u4e2d\u53ef\u4ee5\u901a\u8fc7\uff1atf.image\u548cImageDataGenerator()\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a","title":"\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5"},{"location":"imageClassification/section6/#26","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u589e\u5f3a\u7684\u5e38\u7528\u65b9\u6cd5 \u80fd\u591f\u5229\u7528tf.keras\u6765\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a \u5927\u89c4\u6a21\u6570\u636e\u96c6\u662f\u6210\u529f\u5e94\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u63d0\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e0d\u540c\u65b9\u5f0f\u7684\u88c1\u526a\uff0c\u4f7f\u611f\u5174\u8da3\u7684\u7269\u4f53\u51fa\u73b0\u5728\u4e0d\u540c\u4f4d\u7f6e\uff0c\u4ece\u800c\u51cf\u8f7b\u6a21\u578b\u5bf9\u7269\u4f53\u51fa\u73b0\u4f4d\u7f6e\u7684\u4f9d\u8d56\u6027\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u8c03\u6574\u4eae\u5ea6\u3001\u8272\u5f69\u7b49\u56e0\u7d20\u6765\u964d\u4f4e\u6a21\u578b\u5bf9\u8272\u5f69\u7684\u654f\u611f\u5ea6\u3002\u53ef\u4ee5\u8bf4\uff0c\u5728\u5f53\u5e74AlexNet\u7684\u6210\u529f\u4e2d\uff0c\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u529f\u4e0d\u53ef\u6ca1","title":"2.6 \u56fe\u50cf\u589e\u5f3a"},{"location":"imageClassification/section6/#1","text":"\u56fe\u50cf\u589e\u5f3a\uff08image augmentation\uff09\u6307\u901a\u8fc7\u526a\u5207\u3001\u65cb\u8f6c/\u53cd\u5c04/\u7ffb\u8f6c\u53d8\u6362\u3001\u7f29\u653e\u53d8\u6362\u3001\u5e73\u79fb\u53d8\u6362\u3001\u5c3a\u5ea6\u53d8\u6362\u3001\u5bf9\u6bd4\u5ea6\u53d8\u6362\u3001\u566a\u58f0\u6270\u52a8\u3001\u989c\u8272\u53d8\u6362\u7b49\u4e00\u79cd\u6216\u591a\u79cd\u7ec4\u5408\u6570\u636e\u589e\u5f3a\u53d8\u6362\u7684\u65b9\u5f0f\u6765\u589e\u52a0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002\u56fe\u50cf\u589e\u5f3a\u7684\u610f\u4e49\u662f\u901a\u8fc7\u5bf9\u8bad\u7ec3\u56fe\u50cf\u505a\u4e00\u7cfb\u5217\u968f\u673a\u6539\u53d8\uff0c\u6765\u4ea7\u751f\u76f8\u4f3c\u4f46\u53c8\u4e0d\u540c\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u4ece\u800c\u6269\u5927\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u89c4\u6a21\uff0c\u800c\u4e14\u968f\u673a\u6539\u53d8\u8bad\u7ec3\u6837\u672c\u53ef\u4ee5\u964d\u4f4e\u6a21\u578b\u5bf9\u67d0\u4e9b\u5c5e\u6027\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u5e38\u89c1\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b\uff1a\u51e0\u4f55\u53d8\u6362\u7c7b\u548c\u989c\u8272\u53d8\u6362\u7c7b \u51e0\u4f55\u53d8\u6362\u7c7b\uff0c\u4e3b\u8981\u662f\u5bf9\u56fe\u50cf\u8fdb\u884c\u51e0\u4f55\u53d8\u6362\u64cd\u4f5c\uff0c\u5305\u62ec**\u7ffb\u8f6c\uff0c\u65cb\u8f6c\uff0c\u88c1\u526a\uff0c\u53d8\u5f62\uff0c\u7f29\u653e**\u7b49\u3002 \u989c\u8272\u53d8\u6362\u7c7b\uff0c\u6307\u901a\u8fc7\u6a21\u7cca\u3001\u989c\u8272\u53d8\u6362\u3001\u64e6\u9664\u3001\u586b\u5145\u7b49\u65b9\u5f0f\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406 \u5b9e\u73b0\u56fe\u50cf\u589e\u5f3a\u53ef\u4ee5\u901a\u8fc7tf.image\u6765\u5b8c\u6210\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7tf.keras.imageGenerator\u6765\u5b8c\u6210\u3002","title":"1.\u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5"},{"location":"imageClassification/section6/#2tfimage","text":"\u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305\u5e76\u8bfb\u53d6\u8981\u5904\u7406\u7684\u56fe\u50cf\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt import numpy as np # \u8bfb\u53d6\u56fe\u50cf\u5e76\u663e\u793a cat = plt . imread ( './cat.jpg' ) plt . imshow ( cat )","title":"2.tf.image\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a"},{"location":"imageClassification/section6/#21","text":"\u5de6\u53f3\u7ffb\u8f6c\u56fe\u50cf\u662f\u6700\u65e9\u4e5f\u662f\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e00\u79cd\u56fe\u50cf\u589e\u5e7f\u65b9\u6cd5\u3002\u53ef\u4ee5\u901a\u8fc7 tf.image.random_flip_left_right \u6765\u5b9e\u73b0\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u3002 # \u5de6\u53f3\u7ffb\u8f6c\u5e76\u663e\u793a cat1 = tf . image . random_flip_left_right ( cat ) plt . imshow ( cat1 \uff09 \u521b\u5efa tf.image.random_flip_up_down \u5b9e\u4f8b\u6765\u5b9e\u73b0\u56fe\u50cf\u7684\u4e0a\u4e0b\u7ffb\u8f6c\uff0c\u4e0a\u4e0b\u7ffb\u8f6c\u4f7f\u7528\u7684\u8f83\u5c11\u3002 # \u4e0a\u4e0b\u7ffb\u8f6c cat2 = tf . image . random_flip_up_down ( cat ) plt . imshow ( cat2 ) \u968f\u673a\u88c1\u526a\u51fa\u4e00\u5757\u9762\u79ef\u4e3a\u539f\u9762\u79ef 10\\% \\sim 100\\% 10\\% \\sim 100\\% \u7684\u533a\u57df\uff0c\u4e14\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u4e4b\u6bd4\u968f\u673a\u53d6\u81ea 0.5 \\sim 2 0.5 \\sim 2 \uff0c\u7136\u540e\u518d\u5c06\u8be5\u533a\u57df\u7684\u5bbd\u548c\u9ad8\u5206\u522b\u7f29\u653e\u5230200\u50cf\u7d20\u3002 # \u968f\u673a\u88c1\u526a cat3 = tf . image . random_crop ( cat ,( 200 , 200 , 3 )) plt . imshow ( cat3 )","title":"2.1 \u7ffb\u8f6c\u548c\u88c1\u526a"},{"location":"imageClassification/section6/#22","text":"\u53e6\u4e00\u7c7b\u589e\u5e7f\u65b9\u6cd5\u662f\u989c\u8272\u53d8\u6362\u3002\u6211\u4eec\u53ef\u4ee5\u4ece4\u4e2a\u65b9\u9762\u6539\u53d8\u56fe\u50cf\u7684\u989c\u8272\uff1a\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u3001\u9971\u548c\u5ea6\u548c\u8272\u8c03\u3002\u63a5\u4e0b\u6765\u5c06\u56fe\u50cf\u7684\u4eae\u5ea6\u968f\u673a\u53d8\u5316\u4e3a\u539f\u56fe\u4eae\u5ea6\u7684 50\\% 50\\% \uff08\u5373 1-0.5 1-0.5 \uff09 \\sim 150\\% \\sim 150\\% \uff08\u5373 1+0.5 1+0.5 \uff09\u3002 cat4 = tf . image . random_brightness ( cat , 0.5 ) plt . imshow ( cat4 ) \u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u968f\u673a\u53d8\u5316\u56fe\u50cf\u7684\u8272\u8c03 cat5 = tf . image . random_hue ( cat , 0.5 ) plt . imshow ( cat5 )","title":"2.2 \u989c\u8272\u53d8\u6362"},{"location":"imageClassification/section6/#3-imagedatagenerator","text":"ImageDataGenerator()\u662fkeras.preprocessing.image\u6a21\u5757\u4e2d\u7684\u56fe\u7247\u751f\u6210\u5668\uff0c\u53ef\u4ee5\u5728batch\u4e2d\u5bf9\u6570\u636e\u8fdb\u884c\u589e\u5f3a\uff0c\u6269\u5145\u6570\u636e\u96c6\u5927\u5c0f\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6bd4\u5982\u65cb\u8f6c\uff0c\u53d8\u5f62\u7b49\uff0c\u5982\u4e0b\u6240\u793a\uff1a keras . preprocessing . image . ImageDataGenerator ( rotation_range = 0 , #\u6574\u6570\u3002\u968f\u673a\u65cb\u8f6c\u7684\u5ea6\u6570\u8303\u56f4\u3002 width_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u5bbd\u5ea6\u5e73\u79fb height_shift_range = 0.0 , #\u6d6e\u70b9\u6570\u3001\u9ad8\u5ea6\u5e73\u79fb brightness_range = None , # \u4eae\u5ea6\u8c03\u6574 shear_range = 0.0 , # \u88c1\u526a zoom_range = 0.0 , #\u6d6e\u70b9\u6570 \u6216 [lower, upper]\u3002\u968f\u673a\u7f29\u653e\u8303\u56f4 horizontal_flip = False , # \u5de6\u53f3\u7ffb\u8f6c vertical_flip = False , # \u5782\u76f4\u7ffb\u8f6c rescale = None # \u5c3a\u5ea6\u8c03\u6574 ) \u6765\u770b\u4e0b\u6c34\u5e73\u7ffb\u8f6c\u7684\u7ed3\u679c\uff1a # \u83b7\u53d6\u6570\u636e\u96c6 ( x_train , y_train ), ( x_test , y_test ) = tf . keras . datasets . mnist . load_data () # \u5c06\u6570\u636e\u8f6c\u6362\u4e3a4\u7ef4\u7684\u5f62\u5f0f x_train = X_train . reshape ( X_train . shape [ 0 ], 28 , 28 , 1 ) x_test = X_test . reshape ( X_test . shape [ 0 ], 28 , 28 , 1 ) # \u8bbe\u7f6e\u56fe\u50cf\u589e\u5f3a\u65b9\u5f0f\uff1a\u6c34\u5e73\u7ffb\u8f6c datagen = ImageDataGenerator ( horizontal_flip = True ) # \u67e5\u770b\u589e\u5f3a\u540e\u7684\u7ed3\u679c for X_batch , y_batch in datagen . flow ( x_train , y_train , batch_size = 9 ): plt . figure ( figsize = ( 8 , 8 )) # \u8bbe\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u663e\u793a\u7684\u5927\u5c0f # \u4ea7\u751f\u4e00\u4e2a3*3\u7f51\u683c\u7684\u56fe\u50cf for i in range ( 0 , 9 ): plt . subplot ( 330 + 1 + i ) plt . title ( y_batch [ i ]) plt . axis ( 'off' ) plt . imshow ( X_batch [ i ] . reshape ( 28 , 28 ), cmap = 'gray' ) plt . show () break \u603b\u7ed3 \u5e38\u7528\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\uff1a\u51e0\u4f55\u548c\u989c\u8272 \u5728tf,keras\u4e2d\u53ef\u4ee5\u901a\u8fc7\uff1atf.image\u548cImageDataGenerator()\u5b8c\u6210\u56fe\u50cf\u589e\u5f3a","title":"3 \u4f7f\u7528ImageDataGenerator()\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a"},{"location":"imageClassification/section7/","text":"2.7\u5fae\u8c03 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5fae\u8c03\u7684\u539f\u7406 \u80fd\u591f\u5229\u7528\u5fae\u8c03\u6a21\u578b\u6765\u5b8c\u6210\u56fe\u50cf\u7684\u5206\u7c7b\u4efb\u52a1 1.\u5fae\u8c03 \u00b6 \u5982\u4f55\u5728\u53ea\u67096\u4e07\u5f20\u56fe\u50cf\u7684MNIST\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002\u5b66\u672f\u754c\u5f53\u4e0b\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6ImageNet\uff0c\u5b83\u6709\u8d85\u8fc71,000\u4e07\u7684\u56fe\u50cf\u548c1,000\u7c7b\u7684\u7269\u4f53\u3002\u7136\u800c\uff0c\u6211\u4eec\u5e73\u5e38\u63a5\u89e6\u5230\u6570\u636e\u96c6\u7684\u89c4\u6a21\u901a\u5e38\u5728\u8fd9\u4e24\u8005\u4e4b\u95f4\u3002\u5047\u8bbe\u6211\u4eec\u60f3\u4ece\u56fe\u50cf\u4e2d\u8bc6\u522b\u51fa\u4e0d\u540c\u79cd\u7c7b\u7684\u6905\u5b50\uff0c\u7136\u540e\u5c06\u8d2d\u4e70\u94fe\u63a5\u63a8\u8350\u7ed9\u7528\u6237\u3002\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u662f\u5148\u627e\u51fa100\u79cd\u5e38\u89c1\u7684\u6905\u5b50\uff0c\u4e3a\u6bcf\u79cd\u6905\u5b50\u62cd\u64441,000\u5f20\u4e0d\u540c\u89d2\u5ea6\u7684\u56fe\u50cf\uff0c\u7136\u540e\u5728\u6536\u96c6\u5230\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u6a21\u578b\u3002\u53e6\u5916\u4e00\u79cd\u89e3\u51b3\u529e\u6cd5\u662f\u5e94\u7528\u8fc1\u79fb\u5b66\u4e60\uff08transfer learning\uff09\uff0c\u5c06\u4ece\u6e90\u6570\u636e\u96c6\u5b66\u5230\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u3002\u4f8b\u5982\uff0c\u867d\u7136ImageNet\u6570\u636e\u96c6\u7684\u56fe\u50cf\u5927\u591a\u8ddf\u6905\u5b50\u65e0\u5173\uff0c\u4f46\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u53ef\u4ee5\u62bd\u53d6\u8f83\u901a\u7528\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u4ece\u800c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u8fb9\u7f18\u3001\u7eb9\u7406\u3001\u5f62\u72b6\u548c\u7269\u4f53\u7ec4\u6210\u7b49\u3002\u8fd9\u4e9b\u7c7b\u4f3c\u7684\u7279\u5f81\u5bf9\u4e8e\u8bc6\u522b\u6905\u5b50\u4e5f\u53ef\u80fd\u540c\u6837\u6709\u6548\u3002 \u5fae\u8c03\u7531\u4ee5\u4e0b4\u6b65\u6784\u6210\u3002 \u5728\u6e90\u6570\u636e\u96c6\uff08\u5982ImageNet\u6570\u636e\u96c6\uff09\u4e0a\u9884\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u6e90\u6a21\u578b\u3002 \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u76ee\u6807\u6a21\u578b\u3002\u5b83\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u6a21\u578b\u53c2\u6570\u5305\u542b\u4e86\u6e90\u6570\u636e\u96c6\u4e0a\u5b66\u4e60\u5230\u7684\u77e5\u8bc6\uff0c\u4e14\u8fd9\u4e9b\u77e5\u8bc6\u540c\u6837\u9002\u7528\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u6e90\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u8ddf\u6e90\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7d27\u5bc6\u76f8\u5173\uff0c\u56e0\u6b64\u5728\u76ee\u6807\u6a21\u578b\u4e2d\u4e0d\u4e88\u91c7\u7528\u3002 \u4e3a\u76ee\u6807\u6a21\u578b\u6dfb\u52a0\u4e00\u4e2a\u8f93\u51fa\u5927\u5c0f\u4e3a\u76ee\u6807\u6570\u636e\u96c6\u7c7b\u522b\u4e2a\u6570\u7684\u8f93\u51fa\u5c42\uff0c\u5e76\u968f\u673a\u521d\u59cb\u5316\u8be5\u5c42\u7684\u6a21\u578b\u53c2\u6570\u3002 \u5728\u76ee\u6807\u6570\u636e\u96c6\uff08\u5982\u6905\u5b50\u6570\u636e\u96c6\uff09\u4e0a\u8bad\u7ec3\u76ee\u6807\u6a21\u578b\u3002\u6211\u4eec\u5c06\u4ece\u5934\u8bad\u7ec3\u8f93\u51fa\u5c42\uff0c\u800c\u5176\u4f59\u5c42\u7684\u53c2\u6570\u90fd\u662f\u57fa\u4e8e\u6e90\u6a21\u578b\u7684\u53c2\u6570\u5fae\u8c03\u5f97\u5230\u7684\u3002 \u5f53\u76ee\u6807\u6570\u636e\u96c6\u8fdc\u5c0f\u4e8e\u6e90\u6570\u636e\u96c6\u65f6\uff0c\u5fae\u8c03\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002 2.\u70ed\u72d7\u8bc6\u522b \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u5b9e\u8df5\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\uff1a\u70ed\u72d7\u8bc6\u522b\u3002\u5c06\u57fa\u4e8e\u4e00\u4e2a\u5c0f\u6570\u636e\u96c6\u5bf9\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684ResNet\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u8be5\u5c0f\u6570\u636e\u96c6\u542b\u6709\u6570\u5343\u5f20\u70ed\u72d7\u6216\u8005\u5176\u4ed6\u4e8b\u7269\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u5fae\u8c03\u5f97\u5230\u7684\u6a21\u578b\u6765\u8bc6\u522b\u4e00\u5f20\u56fe\u50cf\u4e2d\u662f\u5426\u5305\u542b\u70ed\u72d7\u3002 \u9996\u5148\uff0c\u5bfc\u5165\u5b9e\u9a8c\u6240\u9700\u7684\u5de5\u5177\u5305\u3002 import tensorflow as tf import numpy as np 2.1 \u83b7\u53d6\u6570\u636e\u96c6 \u00b6 \u6211\u4eec\u9996\u5148\u5c06\u6570\u636e\u96c6\u653e\u5728\u8def\u5f84hotdog/data\u4e4b\u4e0b: \u6bcf\u4e2a\u7c7b\u522b\u6587\u4ef6\u5939\u91cc\u9762\u662f\u56fe\u50cf\u6587\u4ef6\u3002 \u4e0a\u4e00\u8282\u4e2d\u6211\u4eec\u4ecb\u7ecd\u4e86ImageDataGenerator\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\uff0c\u8be5\u65b9\u6cd5\u4ee5\u6587\u4ef6\u5939\u8def\u5f84\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u56fe\u50cf\u589e\u5f3a\u540e\u7684\u7ed3\u679c\uff0c\u5e76\u4ea7\u751fbatch\u6570\u636e\uff1a flow_from_directory ( self , directory , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None \uff09 \u4e3b\u8981\u53c2\u6570\uff1a directory: \u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b\u5bf9\u5e94\u4e00\u4e2a\u5b50\u6587\u4ef6\u5939\uff0c\u8be5\u5b50\u6587\u4ef6\u5939\u4e2d\u4efb\u4f55JPG\u3001PNG\u3001BNP\u3001PPM\u7684\u56fe\u7247\u90fd\u53ef\u4ee5\u8bfb\u53d6\u3002 target_size: \u9ed8\u8ba4\u4e3a(256, 256)\uff0c\u56fe\u50cf\u5c06\u88abresize\u6210\u8be5\u5c3a\u5bf8\u3002 batch_size: batch\u6570\u636e\u7684\u5927\u5c0f\uff0c\u9ed8\u8ba432\u3002 shuffle: \u662f\u5426\u6253\u4e71\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3aTrue\u3002 \u6211\u4eec\u521b\u5efa\u4e24\u4e2a tf.keras.preprocessing.image.ImageDataGenerator \u5b9e\u4f8b\u6765\u5206\u522b\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u56fe\u50cf\u6587\u4ef6\u3002\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u5168\u90e8\u5904\u7406\u4e3a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u50cf\u7d20\u7684\u8f93\u5165\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9RGB\uff08\u7ea2\u3001\u7eff\u3001\u84dd\uff09\u4e09\u4e2a\u989c\u8272\u901a\u9053\u7684\u6570\u503c\u505a\u6807\u51c6\u5316\u3002 # \u83b7\u53d6\u6570\u636e\u96c6 import pathlib train_dir = 'transferdata/train' test_dir = 'transferdata/test' # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e train_dir = pathlib . Path ( train_dir ) train_count = len ( list ( train_dir . glob ( '*/*.jpg' ))) # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e test_dir = pathlib . Path ( test_dir ) test_count = len ( list ( test_dir . glob ( '*/*.jpg' ))) # \u521b\u5efaimageDataGenerator\u8fdb\u884c\u56fe\u50cf\u5904\u7406 image_generator = tf . keras . preprocessing . image . ImageDataGenerator ( rescale = 1. / 255 ) # \u8bbe\u7f6e\u53c2\u6570 BATCH_SIZE = 32 IMG_HEIGHT = 224 IMG_WIDTH = 224 # \u83b7\u53d6\u8bad\u7ec3\u6570\u636e train_data_gen = image_generator . flow_from_directory ( directory = str ( train_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) # \u83b7\u53d6\u6d4b\u8bd5\u6570\u636e test_data_gen = image_generator . flow_from_directory ( directory = str ( test_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) \u4e0b\u9762\u6211\u4eec\u968f\u673a\u53d61\u4e2abatch\u7684\u56fe\u7247\u7136\u540e\u7ed8\u5236\u51fa\u6765\u3002 import matplotlib.pyplot as plt # \u663e\u793a\u56fe\u50cf def show_batch ( image_batch , label_batch ): plt . figure ( figsize = ( 10 , 10 )) for n in range ( 15 ): ax = plt . subplot ( 5 , 5 , n + 1 ) plt . imshow ( image_batch [ n ] \uff09 plt . axis ( 'off' ) # \u968f\u673a\u9009\u62e9\u4e00\u4e2abatch\u7684\u56fe\u50cf image_batch , label_batch = next ( train_data_gen ) # \u56fe\u50cf\u663e\u793a show_batch ( image_batch , label_batch ) 2.2 \u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3 \u00b6 \u6211\u4eec\u4f7f\u7528\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684ResNet-50\u4f5c\u4e3a\u6e90\u6a21\u578b\u3002\u8fd9\u91cc\u6307\u5b9a weights='imagenet' \u6765\u81ea\u52a8\u4e0b\u8f7d\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u3002\u5728\u7b2c\u4e00\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8054\u7f51\u4e0b\u8f7d\u6a21\u578b\u53c2\u6570\u3002 Keras\u5e94\u7528\u7a0b\u5e8f\uff08keras.applications\uff09\u662f\u5177\u6709\u9884\u5148\u8bad\u7ec3\u6743\u503c\u7684\u56fa\u5b9a\u67b6\u6784\uff0c\u8be5\u7c7b\u5c01\u88c5\u4e86\u5f88\u591a\u91cd\u91cf\u7ea7\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u65f6\u5b9e\u4f8b\u5316\u6a21\u578b\u67b6\u6784\uff1a tf . keras . applications . ResNet50 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , ** kwargs ) \u4e3b\u8981\u53c2\u6570\uff1a include_top: \u662f\u5426\u5305\u62ec\u9876\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u3002 weights: None \u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c 'imagenet' \u4ee3\u8868\u52a0\u8f7d\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\u3002 input_shape: \u53ef\u9009\uff0c\u8f93\u5165\u5c3a\u5bf8\u5143\u7ec4\uff0c\u4ec5\u5f53 include_top=False \u65f6\u6709\u6548\uff0c\u5426\u5219\u8f93\u5165\u5f62\u72b6\u5fc5\u987b\u662f (224, 224, 3)\uff08channels_last \u683c\u5f0f\uff09\u6216 (3, 224, 224)\uff08channels_first \u683c\u5f0f\uff09\u3002\u5b83\u5fc5\u987b\u4e3a 3 \u4e2a\u8f93\u5165\u901a\u9053\uff0c\u4e14\u5bbd\u9ad8\u5fc5\u987b\u4e0d\u5c0f\u4e8e 32\uff0c\u6bd4\u5982 (200, 200, 3) \u662f\u4e00\u4e2a\u5408\u6cd5\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 \u5728\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f7f\u7528resNet50\u9884\u8bad\u7ec3\u6a21\u578b\u6784\u5efa\u6a21\u578b\uff1a # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b ResNet50 = tf . keras . applications . ResNet50 ( weights = 'imagenet' , input_shape = ( 224 , 224 , 3 )) # \u8bbe\u7f6e\u6240\u6709\u5c42\u4e0d\u53ef\u8bad\u7ec3 for layer in ResNet50 . layers : layer . trainable = False # \u8bbe\u7f6e\u6a21\u578b net = tf . keras . models . Sequential () # \u9884\u8bad\u7ec3\u6a21\u578b net . add ( ResNet50 ) # \u5c55\u5f00 net . add ( tf . keras . layers . Flatten ()) # \u4e8c\u5206\u7c7b\u7684\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . layers . Dense ( 2 , activation = 'softmax' )) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\u4e4b\u524d\u5b9a\u4e49\u597d\u7684ImageGenerator\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u9001\u5165ResNet50\u8fdb\u884c\u8bad\u7ec3\u3002 # \u6a21\u578b\u7f16\u8bd1\uff1a\u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u6570\u636e\uff0c\u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c10\u4e2a\u8fed\u4ee3\uff0c\u6307\u5b9a\u9a8c\u8bc1\u6570\u636e\u96c6 history = net . fit ( train_data_gen , steps_per_epoch = 10 , epochs = 3 , validation_data = test_data_gen , validation_steps = 10 ) Epoch 1 / 3 10 / 10 [ ============================== ] - 28 s 3 s / step - loss : 0.6931 - accuracy : 0.5031 - val_loss : 0.6930 - val_accuracy : 0.5094 Epoch 2 / 3 10 / 10 [ ============================== ] - 29 s 3 s / step - loss : 0.6932 - accuracy : 0.5094 - val_loss : 0.6935 - val_accuracy : 0.4812 Epoch 3 / 3 10 / 10 [ ============================== ] - 31 s 3 s / step - loss : 0.6935 - accuracy : 0.4844 - val_loss : 0.6933 - val_accuracy : 0.4875 \u603b\u7ed3 \u5fae\u8c03\u662f\u76ee\u6807\u6a21\u578b\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u5fae\u8c03\u8fd9\u4e9b\u53c2\u6570\u3002\u800c\u76ee\u6807\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u9700\u8981\u4ece\u5934\u8bad\u7ec3\u3002 \u5229\u7528tf.keras\u4e2d\u7684application\u5b9e\u73b0\u8fc1\u79fb\u5b66\u4e60","title":"\u6a21\u578b\u5fae\u8c03"},{"location":"imageClassification/section7/#27","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u5fae\u8c03\u7684\u539f\u7406 \u80fd\u591f\u5229\u7528\u5fae\u8c03\u6a21\u578b\u6765\u5b8c\u6210\u56fe\u50cf\u7684\u5206\u7c7b\u4efb\u52a1","title":"2.7\u5fae\u8c03"},{"location":"imageClassification/section7/#1","text":"\u5982\u4f55\u5728\u53ea\u67096\u4e07\u5f20\u56fe\u50cf\u7684MNIST\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002\u5b66\u672f\u754c\u5f53\u4e0b\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6ImageNet\uff0c\u5b83\u6709\u8d85\u8fc71,000\u4e07\u7684\u56fe\u50cf\u548c1,000\u7c7b\u7684\u7269\u4f53\u3002\u7136\u800c\uff0c\u6211\u4eec\u5e73\u5e38\u63a5\u89e6\u5230\u6570\u636e\u96c6\u7684\u89c4\u6a21\u901a\u5e38\u5728\u8fd9\u4e24\u8005\u4e4b\u95f4\u3002\u5047\u8bbe\u6211\u4eec\u60f3\u4ece\u56fe\u50cf\u4e2d\u8bc6\u522b\u51fa\u4e0d\u540c\u79cd\u7c7b\u7684\u6905\u5b50\uff0c\u7136\u540e\u5c06\u8d2d\u4e70\u94fe\u63a5\u63a8\u8350\u7ed9\u7528\u6237\u3002\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u662f\u5148\u627e\u51fa100\u79cd\u5e38\u89c1\u7684\u6905\u5b50\uff0c\u4e3a\u6bcf\u79cd\u6905\u5b50\u62cd\u64441,000\u5f20\u4e0d\u540c\u89d2\u5ea6\u7684\u56fe\u50cf\uff0c\u7136\u540e\u5728\u6536\u96c6\u5230\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u6a21\u578b\u3002\u53e6\u5916\u4e00\u79cd\u89e3\u51b3\u529e\u6cd5\u662f\u5e94\u7528\u8fc1\u79fb\u5b66\u4e60\uff08transfer learning\uff09\uff0c\u5c06\u4ece\u6e90\u6570\u636e\u96c6\u5b66\u5230\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u3002\u4f8b\u5982\uff0c\u867d\u7136ImageNet\u6570\u636e\u96c6\u7684\u56fe\u50cf\u5927\u591a\u8ddf\u6905\u5b50\u65e0\u5173\uff0c\u4f46\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u53ef\u4ee5\u62bd\u53d6\u8f83\u901a\u7528\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u4ece\u800c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u8fb9\u7f18\u3001\u7eb9\u7406\u3001\u5f62\u72b6\u548c\u7269\u4f53\u7ec4\u6210\u7b49\u3002\u8fd9\u4e9b\u7c7b\u4f3c\u7684\u7279\u5f81\u5bf9\u4e8e\u8bc6\u522b\u6905\u5b50\u4e5f\u53ef\u80fd\u540c\u6837\u6709\u6548\u3002 \u5fae\u8c03\u7531\u4ee5\u4e0b4\u6b65\u6784\u6210\u3002 \u5728\u6e90\u6570\u636e\u96c6\uff08\u5982ImageNet\u6570\u636e\u96c6\uff09\u4e0a\u9884\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u6e90\u6a21\u578b\u3002 \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5373\u76ee\u6807\u6a21\u578b\u3002\u5b83\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u6a21\u578b\u53c2\u6570\u5305\u542b\u4e86\u6e90\u6570\u636e\u96c6\u4e0a\u5b66\u4e60\u5230\u7684\u77e5\u8bc6\uff0c\u4e14\u8fd9\u4e9b\u77e5\u8bc6\u540c\u6837\u9002\u7528\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u6e90\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u8ddf\u6e90\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7d27\u5bc6\u76f8\u5173\uff0c\u56e0\u6b64\u5728\u76ee\u6807\u6a21\u578b\u4e2d\u4e0d\u4e88\u91c7\u7528\u3002 \u4e3a\u76ee\u6807\u6a21\u578b\u6dfb\u52a0\u4e00\u4e2a\u8f93\u51fa\u5927\u5c0f\u4e3a\u76ee\u6807\u6570\u636e\u96c6\u7c7b\u522b\u4e2a\u6570\u7684\u8f93\u51fa\u5c42\uff0c\u5e76\u968f\u673a\u521d\u59cb\u5316\u8be5\u5c42\u7684\u6a21\u578b\u53c2\u6570\u3002 \u5728\u76ee\u6807\u6570\u636e\u96c6\uff08\u5982\u6905\u5b50\u6570\u636e\u96c6\uff09\u4e0a\u8bad\u7ec3\u76ee\u6807\u6a21\u578b\u3002\u6211\u4eec\u5c06\u4ece\u5934\u8bad\u7ec3\u8f93\u51fa\u5c42\uff0c\u800c\u5176\u4f59\u5c42\u7684\u53c2\u6570\u90fd\u662f\u57fa\u4e8e\u6e90\u6a21\u578b\u7684\u53c2\u6570\u5fae\u8c03\u5f97\u5230\u7684\u3002 \u5f53\u76ee\u6807\u6570\u636e\u96c6\u8fdc\u5c0f\u4e8e\u6e90\u6570\u636e\u96c6\u65f6\uff0c\u5fae\u8c03\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002","title":"1.\u5fae\u8c03"},{"location":"imageClassification/section7/#2","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u6765\u5b9e\u8df5\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\uff1a\u70ed\u72d7\u8bc6\u522b\u3002\u5c06\u57fa\u4e8e\u4e00\u4e2a\u5c0f\u6570\u636e\u96c6\u5bf9\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684ResNet\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u8be5\u5c0f\u6570\u636e\u96c6\u542b\u6709\u6570\u5343\u5f20\u70ed\u72d7\u6216\u8005\u5176\u4ed6\u4e8b\u7269\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u5fae\u8c03\u5f97\u5230\u7684\u6a21\u578b\u6765\u8bc6\u522b\u4e00\u5f20\u56fe\u50cf\u4e2d\u662f\u5426\u5305\u542b\u70ed\u72d7\u3002 \u9996\u5148\uff0c\u5bfc\u5165\u5b9e\u9a8c\u6240\u9700\u7684\u5de5\u5177\u5305\u3002 import tensorflow as tf import numpy as np","title":"2.\u70ed\u72d7\u8bc6\u522b"},{"location":"imageClassification/section7/#21","text":"\u6211\u4eec\u9996\u5148\u5c06\u6570\u636e\u96c6\u653e\u5728\u8def\u5f84hotdog/data\u4e4b\u4e0b: \u6bcf\u4e2a\u7c7b\u522b\u6587\u4ef6\u5939\u91cc\u9762\u662f\u56fe\u50cf\u6587\u4ef6\u3002 \u4e0a\u4e00\u8282\u4e2d\u6211\u4eec\u4ecb\u7ecd\u4e86ImageDataGenerator\u8fdb\u884c\u56fe\u50cf\u589e\u5f3a\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\uff0c\u8be5\u65b9\u6cd5\u4ee5\u6587\u4ef6\u5939\u8def\u5f84\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u56fe\u50cf\u589e\u5f3a\u540e\u7684\u7ed3\u679c\uff0c\u5e76\u4ea7\u751fbatch\u6570\u636e\uff1a flow_from_directory ( self , directory , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None \uff09 \u4e3b\u8981\u53c2\u6570\uff1a directory: \u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b\u5bf9\u5e94\u4e00\u4e2a\u5b50\u6587\u4ef6\u5939\uff0c\u8be5\u5b50\u6587\u4ef6\u5939\u4e2d\u4efb\u4f55JPG\u3001PNG\u3001BNP\u3001PPM\u7684\u56fe\u7247\u90fd\u53ef\u4ee5\u8bfb\u53d6\u3002 target_size: \u9ed8\u8ba4\u4e3a(256, 256)\uff0c\u56fe\u50cf\u5c06\u88abresize\u6210\u8be5\u5c3a\u5bf8\u3002 batch_size: batch\u6570\u636e\u7684\u5927\u5c0f\uff0c\u9ed8\u8ba432\u3002 shuffle: \u662f\u5426\u6253\u4e71\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3aTrue\u3002 \u6211\u4eec\u521b\u5efa\u4e24\u4e2a tf.keras.preprocessing.image.ImageDataGenerator \u5b9e\u4f8b\u6765\u5206\u522b\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u56fe\u50cf\u6587\u4ef6\u3002\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u5168\u90e8\u5904\u7406\u4e3a\u9ad8\u548c\u5bbd\u5747\u4e3a224\u50cf\u7d20\u7684\u8f93\u5165\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9RGB\uff08\u7ea2\u3001\u7eff\u3001\u84dd\uff09\u4e09\u4e2a\u989c\u8272\u901a\u9053\u7684\u6570\u503c\u505a\u6807\u51c6\u5316\u3002 # \u83b7\u53d6\u6570\u636e\u96c6 import pathlib train_dir = 'transferdata/train' test_dir = 'transferdata/test' # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e train_dir = pathlib . Path ( train_dir ) train_count = len ( list ( train_dir . glob ( '*/*.jpg' ))) # \u83b7\u53d6\u6d4b\u8bd5\u96c6\u6570\u636e test_dir = pathlib . Path ( test_dir ) test_count = len ( list ( test_dir . glob ( '*/*.jpg' ))) # \u521b\u5efaimageDataGenerator\u8fdb\u884c\u56fe\u50cf\u5904\u7406 image_generator = tf . keras . preprocessing . image . ImageDataGenerator ( rescale = 1. / 255 ) # \u8bbe\u7f6e\u53c2\u6570 BATCH_SIZE = 32 IMG_HEIGHT = 224 IMG_WIDTH = 224 # \u83b7\u53d6\u8bad\u7ec3\u6570\u636e train_data_gen = image_generator . flow_from_directory ( directory = str ( train_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) # \u83b7\u53d6\u6d4b\u8bd5\u6570\u636e test_data_gen = image_generator . flow_from_directory ( directory = str ( test_dir ), batch_size = BATCH_SIZE , target_size = ( IMG_HEIGHT , IMG_WIDTH ), shuffle = True ) \u4e0b\u9762\u6211\u4eec\u968f\u673a\u53d61\u4e2abatch\u7684\u56fe\u7247\u7136\u540e\u7ed8\u5236\u51fa\u6765\u3002 import matplotlib.pyplot as plt # \u663e\u793a\u56fe\u50cf def show_batch ( image_batch , label_batch ): plt . figure ( figsize = ( 10 , 10 )) for n in range ( 15 ): ax = plt . subplot ( 5 , 5 , n + 1 ) plt . imshow ( image_batch [ n ] \uff09 plt . axis ( 'off' ) # \u968f\u673a\u9009\u62e9\u4e00\u4e2abatch\u7684\u56fe\u50cf image_batch , label_batch = next ( train_data_gen ) # \u56fe\u50cf\u663e\u793a show_batch ( image_batch , label_batch )","title":"2.1 \u83b7\u53d6\u6570\u636e\u96c6"},{"location":"imageClassification/section7/#22","text":"\u6211\u4eec\u4f7f\u7528\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684ResNet-50\u4f5c\u4e3a\u6e90\u6a21\u578b\u3002\u8fd9\u91cc\u6307\u5b9a weights='imagenet' \u6765\u81ea\u52a8\u4e0b\u8f7d\u5e76\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u3002\u5728\u7b2c\u4e00\u6b21\u4f7f\u7528\u65f6\u9700\u8981\u8054\u7f51\u4e0b\u8f7d\u6a21\u578b\u53c2\u6570\u3002 Keras\u5e94\u7528\u7a0b\u5e8f\uff08keras.applications\uff09\u662f\u5177\u6709\u9884\u5148\u8bad\u7ec3\u6743\u503c\u7684\u56fa\u5b9a\u67b6\u6784\uff0c\u8be5\u7c7b\u5c01\u88c5\u4e86\u5f88\u591a\u91cd\u91cf\u7ea7\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5b9e\u73b0\u65f6\u5b9e\u4f8b\u5316\u6a21\u578b\u67b6\u6784\uff1a tf . keras . applications . ResNet50 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , ** kwargs ) \u4e3b\u8981\u53c2\u6570\uff1a include_top: \u662f\u5426\u5305\u62ec\u9876\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u3002 weights: None \u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c 'imagenet' \u4ee3\u8868\u52a0\u8f7d\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\u3002 input_shape: \u53ef\u9009\uff0c\u8f93\u5165\u5c3a\u5bf8\u5143\u7ec4\uff0c\u4ec5\u5f53 include_top=False \u65f6\u6709\u6548\uff0c\u5426\u5219\u8f93\u5165\u5f62\u72b6\u5fc5\u987b\u662f (224, 224, 3)\uff08channels_last \u683c\u5f0f\uff09\u6216 (3, 224, 224)\uff08channels_first \u683c\u5f0f\uff09\u3002\u5b83\u5fc5\u987b\u4e3a 3 \u4e2a\u8f93\u5165\u901a\u9053\uff0c\u4e14\u5bbd\u9ad8\u5fc5\u987b\u4e0d\u5c0f\u4e8e 32\uff0c\u6bd4\u5982 (200, 200, 3) \u662f\u4e00\u4e2a\u5408\u6cd5\u7684\u8f93\u5165\u5c3a\u5bf8\u3002 \u5728\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f7f\u7528resNet50\u9884\u8bad\u7ec3\u6a21\u578b\u6784\u5efa\u6a21\u578b\uff1a # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b ResNet50 = tf . keras . applications . ResNet50 ( weights = 'imagenet' , input_shape = ( 224 , 224 , 3 )) # \u8bbe\u7f6e\u6240\u6709\u5c42\u4e0d\u53ef\u8bad\u7ec3 for layer in ResNet50 . layers : layer . trainable = False # \u8bbe\u7f6e\u6a21\u578b net = tf . keras . models . Sequential () # \u9884\u8bad\u7ec3\u6a21\u578b net . add ( ResNet50 ) # \u5c55\u5f00 net . add ( tf . keras . layers . Flatten ()) # \u4e8c\u5206\u7c7b\u7684\u5168\u8fde\u63a5\u5c42 net . add ( tf . keras . layers . Dense ( 2 , activation = 'softmax' )) \u63a5\u4e0b\u6765\u6211\u4eec\u4f7f\u7528\u4e4b\u524d\u5b9a\u4e49\u597d\u7684ImageGenerator\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u9001\u5165ResNet50\u8fdb\u884c\u8bad\u7ec3\u3002 # \u6a21\u578b\u7f16\u8bd1\uff1a\u6307\u5b9a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 net . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # \u6a21\u578b\u8bad\u7ec3\uff1a\u6307\u5b9a\u6570\u636e\uff0c\u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c10\u4e2a\u8fed\u4ee3\uff0c\u6307\u5b9a\u9a8c\u8bc1\u6570\u636e\u96c6 history = net . fit ( train_data_gen , steps_per_epoch = 10 , epochs = 3 , validation_data = test_data_gen , validation_steps = 10 ) Epoch 1 / 3 10 / 10 [ ============================== ] - 28 s 3 s / step - loss : 0.6931 - accuracy : 0.5031 - val_loss : 0.6930 - val_accuracy : 0.5094 Epoch 2 / 3 10 / 10 [ ============================== ] - 29 s 3 s / step - loss : 0.6932 - accuracy : 0.5094 - val_loss : 0.6935 - val_accuracy : 0.4812 Epoch 3 / 3 10 / 10 [ ============================== ] - 31 s 3 s / step - loss : 0.6935 - accuracy : 0.4844 - val_loss : 0.6933 - val_accuracy : 0.4875 \u603b\u7ed3 \u5fae\u8c03\u662f\u76ee\u6807\u6a21\u578b\u590d\u5236\u4e86\u6e90\u6a21\u578b\u4e0a\u9664\u4e86\u8f93\u51fa\u5c42\u5916\u7684\u6240\u6709\u6a21\u578b\u8bbe\u8ba1\u53ca\u5176\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u76ee\u6807\u6570\u636e\u96c6\u5fae\u8c03\u8fd9\u4e9b\u53c2\u6570\u3002\u800c\u76ee\u6807\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u9700\u8981\u4ece\u5934\u8bad\u7ec3\u3002 \u5229\u7528tf.keras\u4e2d\u7684application\u5b9e\u73b0\u8fc1\u79fb\u5b66\u4e60","title":"2.2 \u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3"},{"location":"imageSegmentation/","text":"\u76ee\u6807\u5206\u5272(Object Segmentation) \u00b6","title":"\u76ee\u6807\u5206\u5272(Object Segmentation)"},{"location":"imageSegmentation/#object-segmentation","text":"","title":"\u76ee\u6807\u5206\u5272(Object Segmentation)"},{"location":"imageSegmentation/section1/","text":"5.1 \u56fe\u50cf\u5206\u5272 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u76ee\u7684 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u65b9\u6cd5 \u8ba1\u7b97\u673a\u89c6\u89c9\u65e8\u5728\u8bc6\u522b\u548c\u7406\u89e3\u56fe\u50cf\u4e2d\u7684\u5185\u5bb9\uff0c\u5305\u542b\u4e09\u5927\u57fa\u672c\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b(\u56fea)\u3001\u76ee\u6807\u68c0\u6d4b(\u56feb)\u548c\u56fe\u50cf\u5206\u5272,\u5176\u4e2d\u56fe\u50cf\u5206\u5272\u53c8\u53ef\u5206\u4e3a\uff1a\u8bed\u4e49\u5206\u5272(\u56fec)\u548c\u5b9e\u4f8b\u5206\u5272(\u56fed)\u3002 \u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u56fe\u50cf\u7684\u7406\u89e3\u9010\u6b65\u6df1\u5165\u3002\u5047\u8bbe\u7ed9\u5b9a\u4e00\u5f20\u8f93\u5165\u56fe\u50cf\uff0c \u56fe\u50cf\u5206\u7c7b\u65e8\u5728\u5224\u65ad\u8be5\u56fe\u50cf\u6240\u5c5e\u7c7b\u522b\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u5728\u56fe\u50cf\u5206\u7c7b\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u5177\u4f53\u5728\u56fe\u50cf\u7684\u4ec0\u4e48\u4f4d\u7f6e\uff0c\u901a\u5e38\u662f\u4ee5\u5916\u5305\u77e9\u5f62(bounding box)\u7684\u5f62\u5f0f\u8868\u793a\u3002 \u56fe\u50cf\u5206\u5272\u662f\u76ee\u6807\u68c0\u6d4b\u66f4\u8fdb\u9636\u7684\u4efb\u52a1\uff0c\u76ee\u6807\u68c0\u6d4b\u53ea\u9700\u8981\u6846\u51fa\u6bcf\u4e2a\u76ee\u6807\u7684\u5305\u56f4\u76d2\uff0c\u8bed\u4e49\u5206\u5272\u9700\u8981\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u54ea\u4e2a\u76ee\u6807\u3002\u4f46\u662f\uff0c\u8bed\u4e49\u5206\u5272\u4e0d\u533a\u5206\u5c5e\u4e8e\u76f8\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u5b9e\u4f8b\u3002\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5f53\u56fe\u50cf\u4e2d\u6709\u591a\u4e2acube\u65f6\uff0c\u8bed\u4e49\u5206\u5272\u4f1a\u5c06\u6240\u6709\u7acb\u65b9\u4f53\u6574\u4f53\u7684\u6240\u6709\u50cf\u7d20\u9884\u6d4b\u4e3a\u201ccube\u201d\u8fd9\u4e2a\u7c7b\u522b\u3002\u4e0e\u6b64\u4e0d\u540c\u7684\u662f\uff0c**\u5b9e\u4f8b\u5206\u5272**\u9700\u8981\u533a\u5206\u51fa\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e00\u4e2acube\u3001\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e8c\u4e2acube\u2026\u2026\u3002 1.1 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49 \u00b6 \u5b9a\u4e49\uff1a\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u76ee\u6807\u5c31\u662f\u4e3a\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\u5206\u7c7b\u3002\u5e94\u7528\u9886\u57df\u975e\u5e38\u7684\u5e7f\u6cdb\uff1a\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u5f71\u50cf\uff0c\u56fe\u50cf\u7f8e\u5316\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\u7b49\u3002 \u81ea\u52a8\u9a7e\u9a76\uff08Autonomous vehicles\uff09\uff1a\u6c7d\u8f66\u9700\u8981\u5b89\u88c5\u5fc5\u8981\u7684\u611f\u77e5\u7cfb\u7edf\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u73af\u5883\uff0c\u8fd9\u6837\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u624d\u80fd\u591f\u5b89\u5168\u5730\u9a76\u5165\u73b0\u6709\u7684\u9053\u8def \u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff08Medical image diagnostics\uff09\uff1a\u673a\u5668\u5728\u5206\u6790\u80fd\u529b\u4e0a\u6bd4\u653e\u5c04\u79d1\u533b\u751f\u66f4\u5f3a\uff0c\u800c\u4e14\u53ef\u4ee5\u5927\u5927\u51cf\u5c11\u8bca\u65ad\u6240\u9700\u65f6\u95f4\u3002 \u56fe\u50cf\u5206\u5272\u662f\u4e00\u4e2a\u975e\u5e38\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u3002\u6df1\u5ea6\u5b66\u4e60\u4f7f\u5f97\u56fe\u50cf\u5206\u5272\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u5f88\u591a\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u56f4\u7ed5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u56fe\u50cf\u5206\u5272\u7684\u5185\u5bb9\u3002 1.2 \u4efb\u52a1\u7c7b\u578b \u00b6 1.2.1 \u4efb\u52a1\u63cf\u8ff0 \u00b6 \u7b80\u5355\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u8f93\u5165\u4e00\u4e2aRGB\u5f69\u8272\u56fe\u7247 \uff08height\u00d7width\u00d73\uff09 \uff08height\u00d7width\u00d73\uff09 \u6216\u8005\u4e00\u4e2a\u7070\u5ea6\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \uff0c\u7136\u540e\u8f93\u51fa\u4e00\u4e2a\u5305\u542b\u5404\u4e2a\u50cf\u7d20\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u5272\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0e\u6211\u4eec\u5904\u7406\u5206\u7c7b\u503c\u7684\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u9884\u6d4b\u76ee\u6807\u53ef\u4ee5\u91c7\u7528one-hot\u7f16\u7801\uff0c\u5373\u4e3a\u6bcf\u4e00\u4e2a\u53ef\u80fd\u7684\u7c7b\u521b\u5efa\u4e00\u4e2a\u8f93\u51fa\u901a\u9053\u3002\u901a\u8fc7\u53d6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728\u5404\u4e2achannel\u7684argmax\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u5206\u5272\u56fe\uff0c\uff08\u5982\u4e0b\u56fe\u6240\u793a\uff09\uff1a \u6bd4\u5982\uff1aperson\u7684\u7f16\u7801\u4e3a\uff1a10000\uff0c\u800cGrass\u7684\u7f16\u7801\u4e3a\uff1a00100 \u5f53\u5c06\u9884\u6d4b\u7ed3\u679c\u53e0\u52a0\u5230\u5355\u4e2achannel\u65f6\uff0c\u79f0\u8fd9\u4e3a\u4e00\u4e2a\u63a9\u819cmask\uff0c\u5b83\u53ef\u4ee5\u7ed9\u51fa\u4e00\u5f20\u56fe\u50cf\u4e2d\u67d0\u4e2a\u7279\u5b9a\u7c7b\u7684\u6240\u5728\u533a\u57df\uff1a 1.2.2 \u4efb\u52a1\u7c7b\u578b \u00b6 \u76ee\u524d\u7684\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u4e3b\u8981\u6709\u4e24\u7c7b\uff1a \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u6211\u4eec\u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0c\u6765\u4ecb\u7ecd\u8fd9\u4e24\u79cd\u5206\u5272\u65b9\u5f0f\uff1a \u8bed\u4e49\u5206\u5272\u5c31\u662f\u628a\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u8d4b\u4e88\u4e00\u4e2a\u7c7b\u522b\u6807\u7b7e\uff0c\u5982\u4e0b\u56fe\u6211\u4eec\u5c06\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u5206\u7c7b\u4e3a\u4eba\uff0c\u7f8a\uff0c\u72d7\uff0c\u8349\u5730\u5373\u53ef\u3002 \u5b9e\u4f8b\u5206\u5272\uff0c\u76f8\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272\u6765\u8bb2\uff0c\u4e0d\u4ec5\u8981\u533a\u5206\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\uff0c\u8fd8\u9700\u8981\u9700\u8981\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u533a\u5206\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0d\u4ec5\u9700\u8981\u8fdb\u884c\u7c7b\u522b\u7684\u5212\u5206\uff0c\u8fd8\u8981\u5c06\u5404\u4e2a\u4e2a\u4f53\u5212\u5206\u51fa\u6765\uff1a\u7f8a1\uff0c\u7f8a2\uff0c\u7f8a3\uff0c\u7f8a4\uff0c\u7f8a5\u7b49\u3002 \u76ee\u524d\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u4e49\u5206\u5272\uff0c\u800c\u76ee\u524d\u7684\u96be\u70b9\u4e5f\u5728\u4e8e\u201c\u8bed\u4e49\u201d\uff0c\u8868\u8fbe\u67d0\u4e00\u8bed\u4e49\u7684\u540c\u4e00\u7269\u4f53\u5e76\u4e0d\u603b\u662f\u4ee5\u76f8\u540c\u7684\u5f62\u8c61\u51fa\u73b0\uff0c\u5982\u5305\u542b\u4e0d\u540c\u7684\u989c\u8272\u3001\u7eb9\u7406\u7b49\uff0c\u8fd9\u5bf9\u7cbe\u786e\u5206\u5272\u5e26\u6765\u4e86\u5f88\u5927\u7684\u6311\u6218\u3002\u800c\u4e14\u4ee5\u76ee\u524d\u7684\u6a21\u578b\u8868\u73b0\u6765\u770b\uff0c\u5728\u51c6\u786e\u7387\u4e0a\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4\u3002\u800c\u5b9e\u4f8b\u5206\u5272\u7684\u601d\u8def\u4e3b\u8981\u662f\u76ee\u6807\u68c0\u6d4b+\u8bed\u4e49\u5206\u5272\uff0c\u5373\u7528\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5c06\u56fe\u50cf\u4e2d\u7684\u4e0d\u540c\u5b9e\u4f8b\u6846\u51fa\uff0c\u518d\u7528\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\u5728\u4e0d\u540c\u68c0\u6d4b\u7ed3\u679c\u5185\u8fdb\u884c\u9010\u50cf\u7d20\u6807\u8bb0\u3002 1.3 \u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6 \u00b6 \u56fe\u50cf\u5206\u5272\u5e38\u7528\u7684\u6570\u636e\u96c6\u662fPASCAL VOC\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49\u3002 1.3.1 VOC\u6570\u636e\u96c6 \u00b6 VOC\u6570\u636e\u96c6\u5171\u670920\u7c7b\u6570\u636e\uff0c\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u4e2a\u5728\u76ee\u6807\u68c0\u6d4b\u6982\u8ff0\u4e00\u8282\u4e2d\u5df2\u7ecf\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u8fc7\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u76ee\u6807\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9\uff1a JPEGImages\u4e2d\u5b58\u653e\u56fe\u7247\u6587\u4ef6 \u0015\u0015imagesets\u4e2d\u7684segmentation\u4e2d\u8bb0\u5f55\u4e86\u7528\u4e8e\u5206\u5272\u7684\u56fe\u50cf\u4fe1\u606f SegmentationClass\u4e2d\u662f\u8bed\u4e49\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f SegmentationObject\u4e2d\u662f\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f VOC\u4e2d\u7684\u56fe\u7247\u5e76\u4e0d\u662f\u6240\u6709\u90fd\u7528\u4e8e\u5206\u5272\uff0c\u7528\u4e8e\u5206\u5272\u6bd4\u8d5b\u7684\u56fe\u7247\u5b9e\u4f8b\u90fd\u8bb0\u5f55\u5728txt\u6587\u4ef6\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u76f8\u5173\u7684\u56fe\u50cf\u8bb0\u5f55\u5728\u76f8\u5e94\u7684\u6587\u672c\u6587\u4ef6\u4e2d\uff0c\u5982\u8bad\u7ec3\u96c6\u6570\u636e\u8bb0\u5f55\u5728train.txt\u6587\u4ef6\u4e2d\uff0c\u5176\u4e2d\u5185\u5bb9\u5982\u4e0b\uff1a \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u56fe\u50cf\u5206\u5272\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u56fe\u50cf\u7684\u6807\u6ce8\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a: \u539f\u56fe\u50cf002378.jpg\u7684\u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u7ed3\u679c\u5982\u4e0a\u6240\u793a\uff0c\u80cc\u666f\u662f\u9ed1\u8272\u7684\uff0c\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\u6807\u6ce8\u4e3a\u4e0d\u540c\u7684\u989c\u8272\u3002\u53ef\u4ee5\u770b\u51fa\uff0c\u8bed\u4e49\u5206\u5272\u53ea\u6807\u6ce8\u4e86\u50cf\u7d20\u7684\u7c7b\u522b\uff0c\u800c\u5b9e\u4f8b\u5206\u5272\u4e0d\u4ec5\u6807\u6ce8\u4e86\u7c7b\u522b\uff0c\u8fd8\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u4e86\u533a\u5206\u3002 \u5728\u5199\u7a0b\u5e8f\u7684\u65f6\u5019\u5c31\u5229\u7528 train.txt \u5bf9\u56fe\u7247\u8fdb\u884c\u6311\u9009\uff0c\u56e0\u4e3a\u4e0d\u662f\u6240\u6709\u7684\u56fe\u7247\u90fd\u6709\u5206\u5272\u771f\u5b9e\u503c\uff0c\u83b7\u53d6\u56fe\u7247\u53ca\u5176\u5bf9\u5e94\u7684\u771f\u5b9e\u503c\uff0c\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u5373\u53ef\u3002 1.3.2\u57ce\u5e02\u98ce\u5149Cityscapes\u6570\u636e\u96c6 \u00b6 Cityscapes\u662f\u7531\u5954\u9a70\u4e8e2015\u5e74\u63a8\u51fa\u7684\uff0c\u63d0\u4f9b\u65e0\u4eba\u9a7e\u9a76\u73af\u5883\u4e0b\u7684\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\u3002\u5b83\u5305\u542b50\u4e2a\u57ce\u5e02\u4e0d\u540c\u573a\u666f\u3001\u4e0d\u540c\u80cc\u666f\u3001\u4e0d\u540c\u5b63\u8282\u7684\u8857\u666f\uff0c\u63d0\u4f9b\u4e865000\u5f20\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u9a7e\u9a76\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u50cf\u7d20\u7ea7\u6ce8\u91ca\u56fe\u50cf\uff08\u5176\u4e2d 2975 for train\uff0c500 for val\uff0c1525 for test\uff09\u3002 Cityscapes\u662f\u76ee\u524d\u516c\u8ba4\u7684\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u5185\u6700\u5177\u6743\u5a01\u6027\u548c\u4e13\u4e1a\u6027\u7684\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u8bc4\u6d4b\u96c6\u4e4b\u4e00\uff0c\u5176\u5173\u6ce8\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u57ce\u533a\u9053\u8def\u73af\u5883\u7406\u89e3\uff0c\u4efb\u52a1\u96be\u5ea6\u66f4\u9ad8\u4e14\u66f4\u8d34\u8fd1\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7b49\u70ed\u95e8\u9700\u6c42\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e0b\u6570\u636e\u7684\u5185\u5bb9\uff0c\u6570\u636e\u96c6\u7684\u6587\u4ef6\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5176\u4e2dtxt\u6587\u4ef6\u4e2d\u4fdd\u5b58\u4e86\u76f8\u5173\u6837\u672c\u56fe\u7247\u7684\u8def\u5f84\u548c\u6587\u4ef6\u540d\uff0c\u4fbf\u4e8e\u67e5\u627e\u76f8\u5e94\u7684\u6570\u636e\uff0c\u6211\u4eec\u4e3b\u8981\u4f7f\u7528\u6570\u636e\u662fleftImg8bit\u548cgtFine\u4e2d\u7684\u5185\u5bb9\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u0015leftImg8bit\u6587\u4ef6\u5939\u6709\u4e09\u4e2a\u5b50\u76ee\u5f55\uff1atest\uff0c train\u4ee5\u53caval\uff0c\u5206\u522b\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u8bad\u7ec3\u96c6\u4ee5\u53ca\u9a8c\u8bc1\u96c6\u56fe\u7247\u3002\u8fd9\u4e09\u4e2a\u5b50\u76ee\u5f55\u7684\u56fe\u7247\u53c8\u4ee5\u57ce\u5e02\u4e3a\u5355\u5143\u6765\u5b58\u653e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u91cc\u89e3\u91ca\u4e0bleftImg8bit\u7684\u542b\u4e49\uff0c\u56e0\u4e3acityscapes\u5b9e\u9645\u4e0a\u6765\u6e90\u4e8e\u53cc\u6444\u50cf\u5934\u62cd\u6444\u7684\u7acb\u4f53\u89c6\u9891\u5e8f\u5217\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684leftImg\u5c31\u662f\u6765\u81ea\u4e8e\u5de6\u6444\u50cf\u5934\u7684\u56fe\u7247\uff0c\u800c8bit\u610f\u5473\u7740\u8be5\u56fe\u7247\u96c6\u90fd\u4e3aRGB\u6bcf\u4e2a\u5206\u91cf\u4e3a8bit\u7684\u56fe\u7247\u3002 gtFine\u662f\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u7684\u6807\u6ce8\u4fe1\u606f\uff0cgtFine\u4e0b\u9762\u4e5f\u662f\u5206\u4e3atrain\uff0c test\u4ee5\u53caval\uff0c\u7136\u540e\u5b83\u4eec\u7684\u5b50\u76ee\u5f55\u4e5f\u662f\u4ee5\u57ce\u5e02\u4e3a\u5355\u4f4d\u6765\u653e\u7f6e\u56fe\u7247\u3002\u8fd9\u4e9b\u90fd\u662f\u548cleftImg8bit\u7684\u4e00\u4e00\u5bf9\u5e94\u3002 \u4e0d\u540c\u7684\u662f\uff0c\u5728\u57ce\u5e02\u5b50\u76ee\u5f55\u4e0b\u9762\uff0c\u6bcf\u5f20\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u67096\u4e2a\u6807\u6ce8\u6587\u4ef6\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7cbe\u7ec6\u6807\u6ce8\u6570\u636e\u96c6\u91cc\u9762\u6bcf\u5f20\u56fe\u7247\u53ea\u5bf9\u5e94\u56db\u5f20\u6807\u6ce8\u6587\u4ef6\uff1axxx_gtFine_color.png, xxx_gtFine_instanceIds.png, xxx_gtFine_labelsIds.png\u4ee5\u53caxxx_gtFine_polygons.json\u3002 xxx_color.png\u662f\u6807\u6ce8\u7684\u53ef\u89c6\u5316\u56fe\u7247\uff0c\u771f\u6b63\u5bf9\u8bad\u7ec3\u6709\u7528\u7684\u662f\u540e\u9762\u4e09\u4e2a\u6587\u4ef6\u3002xxx_instanceIds.png\u662f\u7528\u6765\u505a\u5b9e\u4f8b\u5206\u5272\u8bad\u7ec3\u7528\u7684\uff0c\u800cxxx_labelsIds.png\u662f\u8bed\u4e49\u5206\u5272\u8bad\u7ec3\u9700\u8981\u7684\u3002\u800c\u6700\u540e\u4e00\u4e2a\u6587\u4ef6xxx_polygons.json\u4e3b\u8981\u8bb0\u5f55\u4e86\u6bcf\u4e2a\u591a\u8fb9\u5f62\u6807\u6ce8\u6846\u4e0a\u7684\u70b9\u96c6\u5750\u6807\u3002 \u8be5\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6548\u679c\u53ef\u89c6\u5316\u5982\u4e0b\u6240\u793a\uff1a 1.4 \u8bc4\u4ef7\u6307\u6807 \u00b6 \u56fe\u50cf\u5206\u5272\u4e2d\u901a\u5e38\u4f7f\u7528\u8bb8\u591a\u6807\u51c6\u6765\u8861\u91cf\u7b97\u6cd5\u7684\u7cbe\u5ea6\u3002\u8fd9\u4e9b\u6807\u51c6\u901a\u5e38\u662f\u50cf\u7d20\u7cbe\u5ea6\u53caIoU\u7684\u53d8\u79cd\uff0c\u4ee5\u4e0b\u6211\u4eec\u5c06\u4f1a\u4ecb\u7ecd\u5e38\u7528\u7684\u51e0\u79cd\u9010\u50cf\u7d20\u6807\u8bb0\u7684\u7cbe\u5ea6\u6807\u51c6\u3002 \u4e3a\u4e86\u4fbf\u4e8e\u89e3\u91ca\uff0c\u5047\u8bbe\u5982\u4e0b\uff1a\u5171\u6709 k+1 k+1 \u4e2a\u7c7b\uff08\u4ece L_0 L_0 \u5230 L_k L_k \uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u80cc\u666f\u7c7b\uff09\uff0c p_{ij} p_{ij} \u8868\u793a\u672c\u5c5e\u4e8e\u7c7b i i \u4f46\u88ab\u9884\u6d4b\u4e3a\u7c7b j j \u7684\u50cf\u7d20\u3002\u5373 p_{ii} p_{ii} \u8868\u793a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u3002 1.4.1 \u50cf\u7d20\u7cbe\u5ea6 \u00b6 Pixel Accuracy(PA\uff0c\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u8fd9\u662f\u6700\u7b80\u5355\u7684\u5ea6\u91cf\uff0c\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u5360\u603b\u50cf\u7d20\u7684\u6bd4\u4f8b\u3002 \u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\uff0c\u4f8b\u5982\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\uff0c\u80cc\u666f\u4e0e\u6807\u8bb0\u6837\u672c\u4e4b\u95f4\u7684\u6bd4\u4f8b\u5f80\u5f80\u4e25\u91cd\u5931\u8861\u3002\u56e0\u6b64\u5e76\u4e0d\u9002\u5408\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u5ea6\u91cf\u3002 1.4.2 \u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6 \u00b6 Mean Pixel Accuracy(MPA\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u662fPA\u7684\u4e00\u79cd\u7b80\u5355\u63d0\u5347\uff0c\u8ba1\u7b97\u6bcf\u4e2a**\u7c7b\u5185**\u88ab\u6b63\u786e\u5206\u7c7b\u50cf\u7d20\u6570\u7684\u6bd4\u4f8b\uff0c\u4e4b\u540e\u6c42\u6240\u6709\u7c7b\u7684\u5e73\u5747\u3002 1.4.3 \u5e73\u5747\u4ea4\u5e76\u6bd4 \u00b6 Mean Intersection over Union(MIoU\uff0c\u5e73\u5747\u4ea4\u5e76\u6bd4)\uff1a\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u6807\u51c6\u5ea6\u91cf\uff0c\u5176\u8ba1\u7b97\u4e24\u4e2a\u96c6\u5408\u7684\u4ea4\u96c6\u548c\u5e76\u96c6\u4e4b\u6bd4\uff0c\u5728\u8bed\u4e49\u5206\u5272\u7684\u95ee\u9898\u4e2d\uff0c\u8fd9\u4e24\u4e2a\u96c6\u5408\u4e3a\u771f\u5b9e\u503c\uff08ground truth\uff09\u548c\u9884\u6d4b\u503c\uff08predicted segmentation\uff09\u3002\u4ea4\u96c6\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u6570\uff08intersection\uff09\uff0c\u5e76\u96c6\u4e3a\u9884\u6d4b\u6216\u771f\u5b9e\u503c\u4e3a i i \u7c7b\u7684\u548c\u51cf\u53bb\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\uff0c\u5728\u6bcf\u4e2a\u7c7b\u4e0a\u8ba1\u7b97IoU\uff0c\u4e4b\u540e\u6c42\u5e73\u5747\u5373\u53ef\u3002 \u90a3\u4e48\uff0c\u5982\u4f55\u7406\u89e3\u8fd9\u91cc\u7684\u516c\u5f0f\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7ea2\u8272\u5706\u4ee3\u8868\u771f\u5b9e\u503c\uff0c\u9ec4\u8272\u5706\u4ee3\u8868\u9884\u6d4b\u503c\u3002\u6a59\u8272\u90e8\u5206\u7ea2\u8272\u5706\u4e0e\u9ec4\u8272\u5706\u7684\u4ea4\u96c6\uff0c\u5373\u9884\u6d4b\u6b63\u786e\u7684\u90e8\u5206\uff0c\u7ea2\u8272\u90e8\u5206\u8868\u793a\u5047\u8d1f\uff08\u771f\u5b9e\u503c\u4e3a\u8be5\u7c7b\u9884\u6d4b\u9519\u8bef\uff09\u7684\u90e8\u5206\uff0c\u9ec4\u8272\u8868\u793a\u5047\u6b63\uff08\u9884\u6d4b\u503c\u4e3ai\u7c7b\uff0c\u771f\u5b9e\u503c\u4e3a\u5176\u4ed6\uff09\u7684\u90e8\u5206\u3002 MIoU\u8ba1\u7b97\u7684\u662f\u8ba1\u7b97A\u4e0eB\u7684\u4ea4\u96c6\uff08\u6a59\u8272\u90e8\u5206\uff09\u4e0eA\u4e0eB\u7684\u5e76\u96c6\uff08\u7ea2\u8272+\u6a59\u8272+\u9ec4\u8272\uff09\u4e4b\u95f4\u7684\u6bd4\u4f8b\uff0c\u5728\u7406\u60f3\u72b6\u6001\u4e0bA\u4e0eB\u91cd\u5408\uff0c\u4e24\u8005\u6bd4\u4f8b\u4e3a1 \u3002 \u5728\u4ee5\u4e0a\u6240\u6709\u7684\u5ea6\u91cf\u6807\u51c6\u4e2d\uff0cMIoU\u7531\u4e8e\u5176\u7b80\u6d01\u3001\u4ee3\u8868\u6027\u5f3a\u800c\u6210\u4e3a\u6700\u5e38\u7528\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5927\u591a\u6570\u7814\u7a76\u4eba\u5458\u90fd\u4f7f\u7528\u8be5\u6807\u51c6\u62a5\u544a\u5176\u7ed3\u679c\u3002PA\u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\u4e0d\u9002\u7528\u3002 \u603b\u7ed3 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49 \u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u5c31\u662f\u7ed9\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u8fdb\u884c\u5206\u7c7b \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 Voc \u6570\u636e\u96c6\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49 \u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u6307\u6807 \u50cf\u7d20\u7cbe\u5ea6\uff08PA\uff09\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6\uff08mPA\uff09\u548c \u5e73\u5747\u4ea4\u5e76\u6bd4\uff08mIOU\uff09 \u6700\u5e38\u7528\u7684\u662fMIOU","title":"\u76ee\u6807\u5206\u5272\u4ecb\u7ecd"},{"location":"imageSegmentation/section1/#51","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u76ee\u7684 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 \u77e5\u9053\u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u65b9\u6cd5 \u8ba1\u7b97\u673a\u89c6\u89c9\u65e8\u5728\u8bc6\u522b\u548c\u7406\u89e3\u56fe\u50cf\u4e2d\u7684\u5185\u5bb9\uff0c\u5305\u542b\u4e09\u5927\u57fa\u672c\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b(\u56fea)\u3001\u76ee\u6807\u68c0\u6d4b(\u56feb)\u548c\u56fe\u50cf\u5206\u5272,\u5176\u4e2d\u56fe\u50cf\u5206\u5272\u53c8\u53ef\u5206\u4e3a\uff1a\u8bed\u4e49\u5206\u5272(\u56fec)\u548c\u5b9e\u4f8b\u5206\u5272(\u56fed)\u3002 \u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u56fe\u50cf\u7684\u7406\u89e3\u9010\u6b65\u6df1\u5165\u3002\u5047\u8bbe\u7ed9\u5b9a\u4e00\u5f20\u8f93\u5165\u56fe\u50cf\uff0c \u56fe\u50cf\u5206\u7c7b\u65e8\u5728\u5224\u65ad\u8be5\u56fe\u50cf\u6240\u5c5e\u7c7b\u522b\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u5728\u56fe\u50cf\u5206\u7c7b\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u5177\u4f53\u5728\u56fe\u50cf\u7684\u4ec0\u4e48\u4f4d\u7f6e\uff0c\u901a\u5e38\u662f\u4ee5\u5916\u5305\u77e9\u5f62(bounding box)\u7684\u5f62\u5f0f\u8868\u793a\u3002 \u56fe\u50cf\u5206\u5272\u662f\u76ee\u6807\u68c0\u6d4b\u66f4\u8fdb\u9636\u7684\u4efb\u52a1\uff0c\u76ee\u6807\u68c0\u6d4b\u53ea\u9700\u8981\u6846\u51fa\u6bcf\u4e2a\u76ee\u6807\u7684\u5305\u56f4\u76d2\uff0c\u8bed\u4e49\u5206\u5272\u9700\u8981\u8fdb\u4e00\u6b65\u5224\u65ad\u56fe\u50cf\u4e2d\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u54ea\u4e2a\u76ee\u6807\u3002\u4f46\u662f\uff0c\u8bed\u4e49\u5206\u5272\u4e0d\u533a\u5206\u5c5e\u4e8e\u76f8\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u5b9e\u4f8b\u3002\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5f53\u56fe\u50cf\u4e2d\u6709\u591a\u4e2acube\u65f6\uff0c\u8bed\u4e49\u5206\u5272\u4f1a\u5c06\u6240\u6709\u7acb\u65b9\u4f53\u6574\u4f53\u7684\u6240\u6709\u50cf\u7d20\u9884\u6d4b\u4e3a\u201ccube\u201d\u8fd9\u4e2a\u7c7b\u522b\u3002\u4e0e\u6b64\u4e0d\u540c\u7684\u662f\uff0c**\u5b9e\u4f8b\u5206\u5272**\u9700\u8981\u533a\u5206\u51fa\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e00\u4e2acube\u3001\u54ea\u4e9b\u50cf\u7d20\u5c5e\u4e8e\u7b2c\u4e8c\u4e2acube\u2026\u2026\u3002","title":"5.1 \u56fe\u50cf\u5206\u5272"},{"location":"imageSegmentation/section1/#11","text":"\u5b9a\u4e49\uff1a\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u76ee\u6807\u5c31\u662f\u4e3a\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\u5206\u7c7b\u3002\u5e94\u7528\u9886\u57df\u975e\u5e38\u7684\u5e7f\u6cdb\uff1a\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u5f71\u50cf\uff0c\u56fe\u50cf\u7f8e\u5316\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\u7b49\u3002 \u81ea\u52a8\u9a7e\u9a76\uff08Autonomous vehicles\uff09\uff1a\u6c7d\u8f66\u9700\u8981\u5b89\u88c5\u5fc5\u8981\u7684\u611f\u77e5\u7cfb\u7edf\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u73af\u5883\uff0c\u8fd9\u6837\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u624d\u80fd\u591f\u5b89\u5168\u5730\u9a76\u5165\u73b0\u6709\u7684\u9053\u8def \u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff08Medical image diagnostics\uff09\uff1a\u673a\u5668\u5728\u5206\u6790\u80fd\u529b\u4e0a\u6bd4\u653e\u5c04\u79d1\u533b\u751f\u66f4\u5f3a\uff0c\u800c\u4e14\u53ef\u4ee5\u5927\u5927\u51cf\u5c11\u8bca\u65ad\u6240\u9700\u65f6\u95f4\u3002 \u56fe\u50cf\u5206\u5272\u662f\u4e00\u4e2a\u975e\u5e38\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u3002\u6df1\u5ea6\u5b66\u4e60\u4f7f\u5f97\u56fe\u50cf\u5206\u5272\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u5f88\u591a\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u56f4\u7ed5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u56fe\u50cf\u5206\u5272\u7684\u5185\u5bb9\u3002","title":"1.1 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49"},{"location":"imageSegmentation/section1/#12","text":"","title":"1.2 \u4efb\u52a1\u7c7b\u578b"},{"location":"imageSegmentation/section1/#121","text":"\u7b80\u5355\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u8f93\u5165\u4e00\u4e2aRGB\u5f69\u8272\u56fe\u7247 \uff08height\u00d7width\u00d73\uff09 \uff08height\u00d7width\u00d73\uff09 \u6216\u8005\u4e00\u4e2a\u7070\u5ea6\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \uff0c\u7136\u540e\u8f93\u51fa\u4e00\u4e2a\u5305\u542b\u5404\u4e2a\u50cf\u7d20\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u5272\u56fe \uff08height\u00d7width\u00d71\uff09 \uff08height\u00d7width\u00d71\uff09 \u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0e\u6211\u4eec\u5904\u7406\u5206\u7c7b\u503c\u7684\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u9884\u6d4b\u76ee\u6807\u53ef\u4ee5\u91c7\u7528one-hot\u7f16\u7801\uff0c\u5373\u4e3a\u6bcf\u4e00\u4e2a\u53ef\u80fd\u7684\u7c7b\u521b\u5efa\u4e00\u4e2a\u8f93\u51fa\u901a\u9053\u3002\u901a\u8fc7\u53d6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728\u5404\u4e2achannel\u7684argmax\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u5206\u5272\u56fe\uff0c\uff08\u5982\u4e0b\u56fe\u6240\u793a\uff09\uff1a \u6bd4\u5982\uff1aperson\u7684\u7f16\u7801\u4e3a\uff1a10000\uff0c\u800cGrass\u7684\u7f16\u7801\u4e3a\uff1a00100 \u5f53\u5c06\u9884\u6d4b\u7ed3\u679c\u53e0\u52a0\u5230\u5355\u4e2achannel\u65f6\uff0c\u79f0\u8fd9\u4e3a\u4e00\u4e2a\u63a9\u819cmask\uff0c\u5b83\u53ef\u4ee5\u7ed9\u51fa\u4e00\u5f20\u56fe\u50cf\u4e2d\u67d0\u4e2a\u7279\u5b9a\u7c7b\u7684\u6240\u5728\u533a\u57df\uff1a","title":"1.2.1 \u4efb\u52a1\u63cf\u8ff0"},{"location":"imageSegmentation/section1/#122","text":"\u76ee\u524d\u7684\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u4e3b\u8981\u6709\u4e24\u7c7b\uff1a \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u6211\u4eec\u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0c\u6765\u4ecb\u7ecd\u8fd9\u4e24\u79cd\u5206\u5272\u65b9\u5f0f\uff1a \u8bed\u4e49\u5206\u5272\u5c31\u662f\u628a\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u8d4b\u4e88\u4e00\u4e2a\u7c7b\u522b\u6807\u7b7e\uff0c\u5982\u4e0b\u56fe\u6211\u4eec\u5c06\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u5206\u7c7b\u4e3a\u4eba\uff0c\u7f8a\uff0c\u72d7\uff0c\u8349\u5730\u5373\u53ef\u3002 \u5b9e\u4f8b\u5206\u5272\uff0c\u76f8\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272\u6765\u8bb2\uff0c\u4e0d\u4ec5\u8981\u533a\u5206\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\uff0c\u8fd8\u9700\u8981\u9700\u8981\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u533a\u5206\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0d\u4ec5\u9700\u8981\u8fdb\u884c\u7c7b\u522b\u7684\u5212\u5206\uff0c\u8fd8\u8981\u5c06\u5404\u4e2a\u4e2a\u4f53\u5212\u5206\u51fa\u6765\uff1a\u7f8a1\uff0c\u7f8a2\uff0c\u7f8a3\uff0c\u7f8a4\uff0c\u7f8a5\u7b49\u3002 \u76ee\u524d\u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u4e49\u5206\u5272\uff0c\u800c\u76ee\u524d\u7684\u96be\u70b9\u4e5f\u5728\u4e8e\u201c\u8bed\u4e49\u201d\uff0c\u8868\u8fbe\u67d0\u4e00\u8bed\u4e49\u7684\u540c\u4e00\u7269\u4f53\u5e76\u4e0d\u603b\u662f\u4ee5\u76f8\u540c\u7684\u5f62\u8c61\u51fa\u73b0\uff0c\u5982\u5305\u542b\u4e0d\u540c\u7684\u989c\u8272\u3001\u7eb9\u7406\u7b49\uff0c\u8fd9\u5bf9\u7cbe\u786e\u5206\u5272\u5e26\u6765\u4e86\u5f88\u5927\u7684\u6311\u6218\u3002\u800c\u4e14\u4ee5\u76ee\u524d\u7684\u6a21\u578b\u8868\u73b0\u6765\u770b\uff0c\u5728\u51c6\u786e\u7387\u4e0a\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4\u3002\u800c\u5b9e\u4f8b\u5206\u5272\u7684\u601d\u8def\u4e3b\u8981\u662f\u76ee\u6807\u68c0\u6d4b+\u8bed\u4e49\u5206\u5272\uff0c\u5373\u7528\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5c06\u56fe\u50cf\u4e2d\u7684\u4e0d\u540c\u5b9e\u4f8b\u6846\u51fa\uff0c\u518d\u7528\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\u5728\u4e0d\u540c\u68c0\u6d4b\u7ed3\u679c\u5185\u8fdb\u884c\u9010\u50cf\u7d20\u6807\u8bb0\u3002","title":"1.2.2 \u4efb\u52a1\u7c7b\u578b"},{"location":"imageSegmentation/section1/#13","text":"\u56fe\u50cf\u5206\u5272\u5e38\u7528\u7684\u6570\u636e\u96c6\u662fPASCAL VOC\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49\u3002","title":"1.3 \u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6"},{"location":"imageSegmentation/section1/#131-voc","text":"VOC\u6570\u636e\u96c6\u5171\u670920\u7c7b\u6570\u636e\uff0c\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u4e2a\u5728\u76ee\u6807\u68c0\u6d4b\u6982\u8ff0\u4e00\u8282\u4e2d\u5df2\u7ecf\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u8fc7\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u76ee\u6807\u5206\u5272\u76f8\u5173\u7684\u5185\u5bb9\uff1a JPEGImages\u4e2d\u5b58\u653e\u56fe\u7247\u6587\u4ef6 \u0015\u0015imagesets\u4e2d\u7684segmentation\u4e2d\u8bb0\u5f55\u4e86\u7528\u4e8e\u5206\u5272\u7684\u56fe\u50cf\u4fe1\u606f SegmentationClass\u4e2d\u662f\u8bed\u4e49\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f SegmentationObject\u4e2d\u662f\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u4fe1\u606f VOC\u4e2d\u7684\u56fe\u7247\u5e76\u4e0d\u662f\u6240\u6709\u90fd\u7528\u4e8e\u5206\u5272\uff0c\u7528\u4e8e\u5206\u5272\u6bd4\u8d5b\u7684\u56fe\u7247\u5b9e\u4f8b\u90fd\u8bb0\u5f55\u5728txt\u6587\u4ef6\u4e2d\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u76f8\u5173\u7684\u56fe\u50cf\u8bb0\u5f55\u5728\u76f8\u5e94\u7684\u6587\u672c\u6587\u4ef6\u4e2d\uff0c\u5982\u8bad\u7ec3\u96c6\u6570\u636e\u8bb0\u5f55\u5728train.txt\u6587\u4ef6\u4e2d\uff0c\u5176\u4e2d\u5185\u5bb9\u5982\u4e0b\uff1a \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u56fe\u50cf\u5206\u5272\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u56fe\u50cf\u7684\u6807\u6ce8\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a: \u539f\u56fe\u50cf002378.jpg\u7684\u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272\u7684\u6807\u6ce8\u7ed3\u679c\u5982\u4e0a\u6240\u793a\uff0c\u80cc\u666f\u662f\u9ed1\u8272\u7684\uff0c\u4e0d\u540c\u7c7b\u522b\u7684\u50cf\u7d20\u6807\u6ce8\u4e3a\u4e0d\u540c\u7684\u989c\u8272\u3002\u53ef\u4ee5\u770b\u51fa\uff0c\u8bed\u4e49\u5206\u5272\u53ea\u6807\u6ce8\u4e86\u50cf\u7d20\u7684\u7c7b\u522b\uff0c\u800c\u5b9e\u4f8b\u5206\u5272\u4e0d\u4ec5\u6807\u6ce8\u4e86\u7c7b\u522b\uff0c\u8fd8\u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u4e2a\u4f53\u8fdb\u884c\u4e86\u533a\u5206\u3002 \u5728\u5199\u7a0b\u5e8f\u7684\u65f6\u5019\u5c31\u5229\u7528 train.txt \u5bf9\u56fe\u7247\u8fdb\u884c\u6311\u9009\uff0c\u56e0\u4e3a\u4e0d\u662f\u6240\u6709\u7684\u56fe\u7247\u90fd\u6709\u5206\u5272\u771f\u5b9e\u503c\uff0c\u83b7\u53d6\u56fe\u7247\u53ca\u5176\u5bf9\u5e94\u7684\u771f\u5b9e\u503c\uff0c\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u5373\u53ef\u3002","title":"1.3.1 VOC\u6570\u636e\u96c6"},{"location":"imageSegmentation/section1/#132cityscapes","text":"Cityscapes\u662f\u7531\u5954\u9a70\u4e8e2015\u5e74\u63a8\u51fa\u7684\uff0c\u63d0\u4f9b\u65e0\u4eba\u9a7e\u9a76\u73af\u5883\u4e0b\u7684\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\u3002\u5b83\u5305\u542b50\u4e2a\u57ce\u5e02\u4e0d\u540c\u573a\u666f\u3001\u4e0d\u540c\u80cc\u666f\u3001\u4e0d\u540c\u5b63\u8282\u7684\u8857\u666f\uff0c\u63d0\u4f9b\u4e865000\u5f20\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u9a7e\u9a76\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u50cf\u7d20\u7ea7\u6ce8\u91ca\u56fe\u50cf\uff08\u5176\u4e2d 2975 for train\uff0c500 for val\uff0c1525 for test\uff09\u3002 Cityscapes\u662f\u76ee\u524d\u516c\u8ba4\u7684\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u5185\u6700\u5177\u6743\u5a01\u6027\u548c\u4e13\u4e1a\u6027\u7684\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u8bc4\u6d4b\u96c6\u4e4b\u4e00\uff0c\u5176\u5173\u6ce8\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u57ce\u533a\u9053\u8def\u73af\u5883\u7406\u89e3\uff0c\u4efb\u52a1\u96be\u5ea6\u66f4\u9ad8\u4e14\u66f4\u8d34\u8fd1\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7b49\u70ed\u95e8\u9700\u6c42\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u770b\u4e0b\u6570\u636e\u7684\u5185\u5bb9\uff0c\u6570\u636e\u96c6\u7684\u6587\u4ef6\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5176\u4e2dtxt\u6587\u4ef6\u4e2d\u4fdd\u5b58\u4e86\u76f8\u5173\u6837\u672c\u56fe\u7247\u7684\u8def\u5f84\u548c\u6587\u4ef6\u540d\uff0c\u4fbf\u4e8e\u67e5\u627e\u76f8\u5e94\u7684\u6570\u636e\uff0c\u6211\u4eec\u4e3b\u8981\u4f7f\u7528\u6570\u636e\u662fleftImg8bit\u548cgtFine\u4e2d\u7684\u5185\u5bb9\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u0015leftImg8bit\u6587\u4ef6\u5939\u6709\u4e09\u4e2a\u5b50\u76ee\u5f55\uff1atest\uff0c train\u4ee5\u53caval\uff0c\u5206\u522b\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u8bad\u7ec3\u96c6\u4ee5\u53ca\u9a8c\u8bc1\u96c6\u56fe\u7247\u3002\u8fd9\u4e09\u4e2a\u5b50\u76ee\u5f55\u7684\u56fe\u7247\u53c8\u4ee5\u57ce\u5e02\u4e3a\u5355\u5143\u6765\u5b58\u653e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8fd9\u91cc\u89e3\u91ca\u4e0bleftImg8bit\u7684\u542b\u4e49\uff0c\u56e0\u4e3acityscapes\u5b9e\u9645\u4e0a\u6765\u6e90\u4e8e\u53cc\u6444\u50cf\u5934\u62cd\u6444\u7684\u7acb\u4f53\u89c6\u9891\u5e8f\u5217\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684leftImg\u5c31\u662f\u6765\u81ea\u4e8e\u5de6\u6444\u50cf\u5934\u7684\u56fe\u7247\uff0c\u800c8bit\u610f\u5473\u7740\u8be5\u56fe\u7247\u96c6\u90fd\u4e3aRGB\u6bcf\u4e2a\u5206\u91cf\u4e3a8bit\u7684\u56fe\u7247\u3002 gtFine\u662f\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u7684\u6807\u6ce8\u4fe1\u606f\uff0cgtFine\u4e0b\u9762\u4e5f\u662f\u5206\u4e3atrain\uff0c test\u4ee5\u53caval\uff0c\u7136\u540e\u5b83\u4eec\u7684\u5b50\u76ee\u5f55\u4e5f\u662f\u4ee5\u57ce\u5e02\u4e3a\u5355\u4f4d\u6765\u653e\u7f6e\u56fe\u7247\u3002\u8fd9\u4e9b\u90fd\u662f\u548cleftImg8bit\u7684\u4e00\u4e00\u5bf9\u5e94\u3002 \u4e0d\u540c\u7684\u662f\uff0c\u5728\u57ce\u5e02\u5b50\u76ee\u5f55\u4e0b\u9762\uff0c\u6bcf\u5f20\u6837\u672c\u56fe\u7247\u5bf9\u5e94\u67096\u4e2a\u6807\u6ce8\u6587\u4ef6\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7cbe\u7ec6\u6807\u6ce8\u6570\u636e\u96c6\u91cc\u9762\u6bcf\u5f20\u56fe\u7247\u53ea\u5bf9\u5e94\u56db\u5f20\u6807\u6ce8\u6587\u4ef6\uff1axxx_gtFine_color.png, xxx_gtFine_instanceIds.png, xxx_gtFine_labelsIds.png\u4ee5\u53caxxx_gtFine_polygons.json\u3002 xxx_color.png\u662f\u6807\u6ce8\u7684\u53ef\u89c6\u5316\u56fe\u7247\uff0c\u771f\u6b63\u5bf9\u8bad\u7ec3\u6709\u7528\u7684\u662f\u540e\u9762\u4e09\u4e2a\u6587\u4ef6\u3002xxx_instanceIds.png\u662f\u7528\u6765\u505a\u5b9e\u4f8b\u5206\u5272\u8bad\u7ec3\u7528\u7684\uff0c\u800cxxx_labelsIds.png\u662f\u8bed\u4e49\u5206\u5272\u8bad\u7ec3\u9700\u8981\u7684\u3002\u800c\u6700\u540e\u4e00\u4e2a\u6587\u4ef6xxx_polygons.json\u4e3b\u8981\u8bb0\u5f55\u4e86\u6bcf\u4e2a\u591a\u8fb9\u5f62\u6807\u6ce8\u6846\u4e0a\u7684\u70b9\u96c6\u5750\u6807\u3002 \u8be5\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6548\u679c\u53ef\u89c6\u5316\u5982\u4e0b\u6240\u793a\uff1a","title":"1.3.2\u57ce\u5e02\u98ce\u5149Cityscapes\u6570\u636e\u96c6"},{"location":"imageSegmentation/section1/#14","text":"\u56fe\u50cf\u5206\u5272\u4e2d\u901a\u5e38\u4f7f\u7528\u8bb8\u591a\u6807\u51c6\u6765\u8861\u91cf\u7b97\u6cd5\u7684\u7cbe\u5ea6\u3002\u8fd9\u4e9b\u6807\u51c6\u901a\u5e38\u662f\u50cf\u7d20\u7cbe\u5ea6\u53caIoU\u7684\u53d8\u79cd\uff0c\u4ee5\u4e0b\u6211\u4eec\u5c06\u4f1a\u4ecb\u7ecd\u5e38\u7528\u7684\u51e0\u79cd\u9010\u50cf\u7d20\u6807\u8bb0\u7684\u7cbe\u5ea6\u6807\u51c6\u3002 \u4e3a\u4e86\u4fbf\u4e8e\u89e3\u91ca\uff0c\u5047\u8bbe\u5982\u4e0b\uff1a\u5171\u6709 k+1 k+1 \u4e2a\u7c7b\uff08\u4ece L_0 L_0 \u5230 L_k L_k \uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u80cc\u666f\u7c7b\uff09\uff0c p_{ij} p_{ij} \u8868\u793a\u672c\u5c5e\u4e8e\u7c7b i i \u4f46\u88ab\u9884\u6d4b\u4e3a\u7c7b j j \u7684\u50cf\u7d20\u3002\u5373 p_{ii} p_{ii} \u8868\u793a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u3002","title":"1.4 \u8bc4\u4ef7\u6307\u6807"},{"location":"imageSegmentation/section1/#141","text":"Pixel Accuracy(PA\uff0c\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u8fd9\u662f\u6700\u7b80\u5355\u7684\u5ea6\u91cf\uff0c\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u5360\u603b\u50cf\u7d20\u7684\u6bd4\u4f8b\u3002 \u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\uff0c\u4f8b\u5982\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\uff0c\u80cc\u666f\u4e0e\u6807\u8bb0\u6837\u672c\u4e4b\u95f4\u7684\u6bd4\u4f8b\u5f80\u5f80\u4e25\u91cd\u5931\u8861\u3002\u56e0\u6b64\u5e76\u4e0d\u9002\u5408\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u5ea6\u91cf\u3002","title":"1.4.1 \u50cf\u7d20\u7cbe\u5ea6"},{"location":"imageSegmentation/section1/#142","text":"Mean Pixel Accuracy(MPA\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6)\uff1a\u662fPA\u7684\u4e00\u79cd\u7b80\u5355\u63d0\u5347\uff0c\u8ba1\u7b97\u6bcf\u4e2a**\u7c7b\u5185**\u88ab\u6b63\u786e\u5206\u7c7b\u50cf\u7d20\u6570\u7684\u6bd4\u4f8b\uff0c\u4e4b\u540e\u6c42\u6240\u6709\u7c7b\u7684\u5e73\u5747\u3002","title":"1.4.2 \u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6"},{"location":"imageSegmentation/section1/#143","text":"Mean Intersection over Union(MIoU\uff0c\u5e73\u5747\u4ea4\u5e76\u6bd4)\uff1a\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u6807\u51c6\u5ea6\u91cf\uff0c\u5176\u8ba1\u7b97\u4e24\u4e2a\u96c6\u5408\u7684\u4ea4\u96c6\u548c\u5e76\u96c6\u4e4b\u6bd4\uff0c\u5728\u8bed\u4e49\u5206\u5272\u7684\u95ee\u9898\u4e2d\uff0c\u8fd9\u4e24\u4e2a\u96c6\u5408\u4e3a\u771f\u5b9e\u503c\uff08ground truth\uff09\u548c\u9884\u6d4b\u503c\uff08predicted segmentation\uff09\u3002\u4ea4\u96c6\u4e3a\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\u6570\uff08intersection\uff09\uff0c\u5e76\u96c6\u4e3a\u9884\u6d4b\u6216\u771f\u5b9e\u503c\u4e3a i i \u7c7b\u7684\u548c\u51cf\u53bb\u9884\u6d4b\u6b63\u786e\u7684\u50cf\u7d20\uff0c\u5728\u6bcf\u4e2a\u7c7b\u4e0a\u8ba1\u7b97IoU\uff0c\u4e4b\u540e\u6c42\u5e73\u5747\u5373\u53ef\u3002 \u90a3\u4e48\uff0c\u5982\u4f55\u7406\u89e3\u8fd9\u91cc\u7684\u516c\u5f0f\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7ea2\u8272\u5706\u4ee3\u8868\u771f\u5b9e\u503c\uff0c\u9ec4\u8272\u5706\u4ee3\u8868\u9884\u6d4b\u503c\u3002\u6a59\u8272\u90e8\u5206\u7ea2\u8272\u5706\u4e0e\u9ec4\u8272\u5706\u7684\u4ea4\u96c6\uff0c\u5373\u9884\u6d4b\u6b63\u786e\u7684\u90e8\u5206\uff0c\u7ea2\u8272\u90e8\u5206\u8868\u793a\u5047\u8d1f\uff08\u771f\u5b9e\u503c\u4e3a\u8be5\u7c7b\u9884\u6d4b\u9519\u8bef\uff09\u7684\u90e8\u5206\uff0c\u9ec4\u8272\u8868\u793a\u5047\u6b63\uff08\u9884\u6d4b\u503c\u4e3ai\u7c7b\uff0c\u771f\u5b9e\u503c\u4e3a\u5176\u4ed6\uff09\u7684\u90e8\u5206\u3002 MIoU\u8ba1\u7b97\u7684\u662f\u8ba1\u7b97A\u4e0eB\u7684\u4ea4\u96c6\uff08\u6a59\u8272\u90e8\u5206\uff09\u4e0eA\u4e0eB\u7684\u5e76\u96c6\uff08\u7ea2\u8272+\u6a59\u8272+\u9ec4\u8272\uff09\u4e4b\u95f4\u7684\u6bd4\u4f8b\uff0c\u5728\u7406\u60f3\u72b6\u6001\u4e0bA\u4e0eB\u91cd\u5408\uff0c\u4e24\u8005\u6bd4\u4f8b\u4e3a1 \u3002 \u5728\u4ee5\u4e0a\u6240\u6709\u7684\u5ea6\u91cf\u6807\u51c6\u4e2d\uff0cMIoU\u7531\u4e8e\u5176\u7b80\u6d01\u3001\u4ee3\u8868\u6027\u5f3a\u800c\u6210\u4e3a\u6700\u5e38\u7528\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5927\u591a\u6570\u7814\u7a76\u4eba\u5458\u90fd\u4f7f\u7528\u8be5\u6807\u51c6\u62a5\u544a\u5176\u7ed3\u679c\u3002PA\u5bf9\u4e8e\u6837\u672c\u4e0d\u5747\u8861\u7684\u60c5\u51b5\u4e0d\u9002\u7528\u3002 \u603b\u7ed3 \u56fe\u50cf\u5206\u5272\u7684\u5b9a\u4e49 \u56fe\u50cf\u5206\u5272\uff08Object Segmentation\uff09\u6307\u7684\u662f\u5c06\u6570\u5b57\u56fe\u50cf\u7ec6\u5206\u4e3a\u591a\u4e2a\u56fe\u50cf\u5b50\u533a\u57df\uff08\u50cf\u7d20\u7684\u96c6\u5408\uff09\u7684\u8fc7\u7a0b\uff0c\u5e76\u4e14\u540c\u4e00\u4e2a\u5b50\u533a\u57df\u5185\u7684\u7279\u5f81\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\uff0c\u4e0d\u540c\u5b50\u533a\u57df\u7684\u7279\u5f81\u5448\u73b0\u8f83\u4e3a\u660e\u663e\u7684\u5dee\u5f02\u3002 \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u7c7b\u578b \u56fe\u50cf\u5206\u5272\u7684\u4efb\u52a1\u5c31\u662f\u7ed9\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u8fdb\u884c\u5206\u7c7b \u8bed\u4e49\u5206\u5272\u548c\u5b9e\u4f8b\u5206\u5272 \u56fe\u50cf\u5206\u5272\u7684\u5e38\u89c1\u6570\u636e\u96c6 Voc \u6570\u636e\u96c6\uff0c\u57ce\u5e02\u98ce\u5149\u6570\u636e\u96c6\uff0ccoco\u6570\u636e\u96c6\u7b49 \u56fe\u50cf\u5206\u5272\u7684\u8bc4\u4f30\u6307\u6807 \u50cf\u7d20\u7cbe\u5ea6\uff08PA\uff09\uff0c\u5e73\u5747\u50cf\u7d20\u7cbe\u5ea6\uff08mPA\uff09\u548c \u5e73\u5747\u4ea4\u5e76\u6bd4\uff08mIOU\uff09 \u6700\u5e38\u7528\u7684\u662fMIOU","title":"1.4.3 \u5e73\u5747\u4ea4\u5e76\u6bd4"},{"location":"imageSegmentation/section2/","text":"5.2 \u8bed\u4e49\u5206\u5272\uff1aFCN\u548cUNet \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3FCN\u7684\u7ed3\u6784 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784 1.FCN\u7f51\u7edc \u00b6 FCN\uff08Fully Convolutional Networks\uff09 \u7528\u4e8e\u56fe\u50cf\u8bed\u4e49\u5206\u5272\uff0c\u81ea\u4ece\u8be5\u7f51\u7edc\u63d0\u51fa\u540e\uff0c\u5c31\u6210\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u57fa\u672c\u6846\u67b6\uff0c\u540e\u7eed\u7b97\u6cd5\u57fa\u672c\u90fd\u662f\u5728\u8be5\u7f51\u7edc\u6846\u67b6\u4e2d\u6539\u8fdb\u800c\u6765\u3002 \u5bf9\u4e8e\u4e00\u822c\u7684\u5206\u7c7bCNN\u7f51\u7edc\uff0c\u5982VGG\u548cResnet\uff0c\u90fd\u4f1a\u5728\u7f51\u7edc\u7684\u6700\u540e\u52a0\u5165\u4e00\u4e9b\u5168\u8fde\u63a5\u5c42\uff0c\u7ecf\u8fc7softmax\u540e\u5c31\u53ef\u4ee5\u83b7\u5f97\u7c7b\u522b\u6982\u7387\u4fe1\u606f\u3002 \u4f46\u662f\u8fd9\u4e2a\u6982\u7387\u53ea\u80fd\u6807\u8bc6\u6574\u4e2a\u56fe\u7247\u7684\u7c7b\u522b\uff0c\u4e0d\u80fd\u6807\u8bc6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u7c7b\u522b\uff0c\u6240\u4ee5\u8fd9\u79cd\u5168\u8fde\u63a5\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u5272\u3002 \u800cFCN\u63d0\u51fa\u53ef\u4ee5\u628a\u540e\u9762\u51e0\u4e2a\u5168\u8fde\u63a5\u90fd\u6362\u6210\u5377\u79ef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u83b7\u5f97\u4e00\u5f202\u7ef4\u7684feature map\uff0c\u540e\u63a5softmax\u83b7\u5f97\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u5206\u7c7b\u4fe1\u606f\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u5206\u5272\u95ee\u9898\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7b80\u800c\u8a00\u4e4b\uff0cFCN\u548cCNN\u7684\u533a\u522b\u5c31\u662f\uff1aCNN\u5377\u79ef\u5c42\u4e4b\u540e\u8fde\u63a5\u7684\u662f\u5168\u8fde\u63a5\u5c42\uff1bFCN\u5377\u79ef\u5c42\u4e4b\u540e\u4ecd\u8fde\u63a5\u5377\u79ef\u5c42\uff0c\u8f93\u51fa\u7684\u662f\u4e0e\u8f93\u5165\u5927\u5c0f\u76f8\u540c\u7684\u7279\u5f81\u56fe\u3002 1.1 \u7f51\u7edc\u7ed3\u6784 \u00b6 FCN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\uff0c\u50cf\u7d20\u5bf9\u50cf\u7d20\u7684\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u8fdb\u884c\u56fe\u50cf\u7684\u8bed\u4e49\u5206\u5272\u3002\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u90e8\u5206\u3002 1.1.1 \u5168\u5377\u79ef\u90e8\u5206 \u00b6 \u5168\u5377\u79ef\u90e8\u5206\u4f7f\u7528\u7ecf\u5178\u7684CNN\u7f51\u7edc\uff08\u4ee5AlexNet\u7f51\u7edc\u4e3a\u4f8b\uff09\uff0c\u5e76\u628a\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u6362\u6210 \u5377\u79ef\uff0c\u7528\u4e8e\u63d0\u53d6\u7279\u5f81\u3002 \u5728\u4f20\u7edf\u7684Alex\u7ed3\u6784\u4e2d\uff0c\u524d5\u5c42\u662f\u5377\u79ef\u5c42\uff0c\u7b2c6\u5c42\u548c\u7b2c7\u5c42\u5206\u522b\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a4096\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u7b2c8\u5c42\u662f\u957f\u5ea6\u4e3a1000\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u5206\u522b\u5bf9\u5e941000\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684\u6982\u7387\u3002 FCN\u5c06\u6700\u540e\u76843\u5c42\u8f6c\u6362\u4e3a\u5377\u79ef\u5c42\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f (\u901a\u9053\u6570\uff0c\u5bbd\uff0c\u9ad8) \u5206\u522b\u4e3a (4096,1,1)\u3001(4096,1,1)\u3001(1000,1,1)\uff0c\u867d\u7136\u53c2\u6570\u6570\u76ee\u76f8\u540c\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u5c31\u4e0d\u4e00\u6837\u4e86\uff0c\u8fd9\u65f6\u8fd8\u53ef\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u3002 CNN\u4e2d\u8f93\u5165\u7684\u56fe\u50cf\u56fa\u5b9a\u6210227x227\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u4e3a55x55\uff0c\u7b2c\u4e8c\u5c42pooling\u540e\u56fe\u50cf\u5927\u5c0f\u4e3a27x27\uff0c\u7b2c\u4e94\u5c42pooling\u540e\u7684\u56fe\u50cf\u5927\u5c0f\u4e3a13x13, \u800cFCN\u8f93\u5165\u7684\u56fe\u50cf\u662fH*W\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bd\uff0c\u7b2c\u4e8c\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bc\uff0c\u7b2c\u4e94\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u215b\uff0c\u7b2c\u516b\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u76841/16\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7ecf\u8fc7\u591a\u6b21\u5377\u79ef\u548cpooling\u4ee5\u540e\uff0c\u5f97\u5230\u7684\u56fe\u50cf\u8d8a\u6765\u8d8a\u5c0f\uff0c\u5206\u8fa8\u7387\u8d8a\u6765\u8d8a\u4f4e\u3002\u5bf9\u6700\u7ec8\u7684\u7279\u5f81\u56fe\u8fdb\u884cupsampling\uff0c\u628a\u56fe\u50cf\u8fdb\u884c\u653e\u5927\u5230\u539f\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u5c31\u5f97\u5230\u539f\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\u3002 1.1.2 \u4e0a\u91c7\u6837\u90e8\u5206 \u00b6 \u4e0a\u91c7\u6837\u90e8\u5206\u5c06\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e0a\u91c7\u6837\u5f97\u5230\u539f\u56fe\u50cf\u5927\u5c0f\u7684\u8bed\u4e49\u5206\u5272\u7ed3\u679c\u3002 \u5728\u8fd9\u91cc\u91c7\u7528\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u662f\u53cd\u5377\u79ef\uff08Deconvolution\uff09\uff0c\u4e5f\u53eb\u505a\u8f6c\u7f6e\u5377\u79ef\uff08Transposed Convolution\uff09\uff1a \u53cd\u5377\u79ef\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6b63\u5411\u5377\u79ef \u901a\u4fd7\u7684\u8bb2\uff0c\u5c31\u662f\u8f93\u5165\u88650+\u5377\u79ef\u3002\u5148\u6309\u7167\u4e00\u5b9a\u7684\u6bd4\u4f8b\u901a\u8fc7\u88650\u6765\u6269\u5927\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u518d\u8fdb\u884c\u6b63\u5411\u5377\u79ef\u5373\u53ef\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\u4e3a3x3\uff0c\u5377\u79ef\u6838kernel\u4e3a3x3\uff0c\u6b65\u957fstrides=2\uff0c\u586b\u5145padding=1 \u5047\u8bbe\u53cd\u5377\u79ef\u7684\u8f93\u5165\u662fn x n \uff0c\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u4e3amxm \uff0cpadding=p\uff0cstride=s\uff0ckernel_size = k\u3002 \u90a3\u4e48\u6b64\u65f6\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u5c31\u4e3a\uff1a m = s(n-1) + k -2p m = s(n-1) + k -2p \u4e0e\u6b63\u5411\u5377\u79ef\u4e0d\u540c\u7684\u662f\uff0c\u8981\u5148\u6839\u636e\u6b65\u957fstrides\u5bf9\u8f93\u5165\u7684\u5185\u90e8\u8fdb\u884c\u586b\u5145\uff0c\u8fd9\u91ccstrides\u53ef\u4ee5\u7406\u89e3\u6210\u8f93\u5165\u653e\u5927\u7684\u500d\u6570\uff0c\u800c\u4e0d\u80fd\u7406\u89e3\u6210\u5377\u79ef\u79fb\u52a8\u7684\u6b65\u957f\u3002 \u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u53cd\u5377\u79ef\u5b9e\u73b0\u4e0a\u91c7\u6837\u3002 1.2 \u8df3\u5c42\u8fde\u63a5 \u00b6 \u5982\u679c\u53ea\u5229\u7528\u53cd\u5377\u79ef\u5bf9\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\u7684\u5230\u539f\u56fe\u5927\u5c0f\u7684\u5206\u5272\uff0c\u7531\u4e8e\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u592a\u5c0f\uff0c\u4f1a\u635f\u5931\u5f88\u591a\u7ec6\u8282\u3002\u56e0\u800c\u63d0\u51fa\u589e\u52a0Skips\u7ed3\u6784\u5c06\u6700\u540e\u4e00\u5c42\u7684\u9884\u6d4b\uff08\u6709\u66f4\u5bcc\u7684\u5168\u5c40\u4fe1\u606f\uff09\u548c\u66f4\u6d45\u5c42\uff08\u6709\u66f4\u591a\u7684\u5c40\u90e8\u7ec6\u8282\uff09\u7684\u9884\u6d4b\u7ed3\u5408\u8d77\u6765\u3002 \u90a3\u4e48\uff1a \u5bf9\u4e8eFCN-32s\uff0c\u76f4\u63a5\u5bf9pool5 feature\u8fdb\u884c32\u500d\u4e0a\u91c7\u6837\u83b7\u5f9732x upsampled feature\uff0c\u518d\u5bf932x upsampled feature\u6bcf\u4e2a\u70b9\u505asoftmax prediction\u83b7\u5f9732x upsampled feature prediction\uff08\u5373\u5206\u5272\u56fe\uff09\u3002 \u5bf9\u4e8eFCN-16s\uff0c\u9996\u5148\u5bf9pool5 feature\u8fdb\u884c2\u500d\u4e0a\u91c7\u6837\u83b7\u5f972x upsampled feature\uff0c\u518d\u628apool4 feature\u548c2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u5bf9\u76f8\u52a0\u7684feature\u8fdb\u884c16\u500d\u4e0a\u91c7\u6837\uff0c\u5e76softmax prediction\uff0c\u83b7\u5f9716x upsampled feature prediction\u3002 \u5bf9\u4e8eFCN-8s\uff0c\u9996\u5148\u8fdb\u884cpool4+2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u53c8\u8fdb\u884cpool3+2x upsampled\u9010\u70b9\u76f8\u52a0\uff0c\u5373\u8fdb\u884c\u66f4\u591a\u6b21\u7279\u5f81\u878d\u5408\u3002\u5177\u4f53\u8fc7\u7a0b\u4e0e16s\u7c7b\u4f3c\uff0c\u4e0d\u518d\u8d58\u8ff0\u3002 \u4e0b\u9762\u6709\u4e00\u5f2032\u500d\uff0c16\u500d\u548c8\u500d\u4e0a\u91c7\u6837\u5f97\u5230\u7684\u7ed3\u679c\u56fe\u5bf9\u6bd4\uff1a \u53ef\u4ee5\u770b\u5230\u968f\u7740\u4e0a\u91c7\u6837\u505a\u5f97\u8d8a\u591a\uff0c\u5206\u5272\u7ed3\u679c\u8d8a\u6765\u8d8a\u7cbe\u7ec6\u3002 1.3 \u603b\u7ed3 \u00b6 \u4f18\u70b9 \u7aef\u5230\u7aef\u7684\uff0c\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u5927\u5c0f\u7684\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\uff0c\u6bd4\u8f83\u9ad8\u6548\u3002 \u5c40\u9650\u6027 \u5f97\u5230\u7684\u7ed3\u679c\u8fd8\u662f\u4e0d\u591f\u7cbe\u7ec6\u3002\u8fdb\u884c8\u500d\u4e0a\u91c7\u6837\u867d\u7136\u6bd432\u500d\u7684\u6548\u679c\u597d\u4e86\u5f88\u591a\uff0c\u4f46\u662f\u4e0a\u91c7\u6837\u7684\u7ed3\u679c\u8fd8\u662f\u6bd4\u8f83\u6a21\u7cca\u7684\uff0c\u5bf9\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u4e0d\u654f\u611f\u3002\u800c\u4e14\u5728\u5bf9\u5404\u4e2a\u50cf\u7d20\u8fdb\u884c\u5206\u7c7b\u65f6\uff0c\u6ca1\u6709\u8003\u8651\u50cf\u7d20\u4e0e\u50cf\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 2.Unet\u7f51\u7edc \u00b6 Unet\u7f51\u7edc\u662f\u5efa\u7acb\u5728FCN\u7f51\u7edc\u57fa\u7840\u4e0a\u7684\uff0c\u5b83\u7684\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u603b\u4f53\u6765\u8bf4\u4e0eFCN\u601d\u8def\u975e\u5e38\u7c7b\u4f3c\u3002 \u6574\u4e2a\u7f51\u7edc\u7531\u7f16\u7801\u90e8\u5206\uff08\u5de6\uff09 \u548c \u89e3\u7801\u90e8\u5206\uff08\u53f3\uff09\u7ec4\u6210\uff0c\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff0c\u5177\u4f53\u4ecb\u7ecd\u5982\u4e0b\uff1a 1\u3001\u7f16\u7801\u90e8\u5206\u662f\u5178\u578b\u7684\u5377\u79ef\u7f51\u7edc\u67b6\u6784\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002\uff08\u56fe\u4e2d\u7684\u84dd\u7bad\u5934\u3001\u7ea2\u7bad\u5934\uff0c\u6ca1\u753bReLu\uff09 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d 2\u3001\u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u6a21\u5f0f\uff1a \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u6700\u540e\u4e00\u5c42\u7684\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1 x 1\uff0c\u5c0664\u901a\u9053\u7684\u7279\u5f81\u56fe\u8f6c\u5316\u4e3a\u7279\u5b9a\u7c7b\u522b\u6570\u91cf\uff08\u5206\u7c7b\u6570\u91cf\uff09\u7684\u7ed3\u679c\u3002\uff08\u56fe\u4e2d\u9752\u8272\u7bad\u5934\uff09 \u603b\u7ed3 \u4e86\u89e3FCN\u7684\u7ed3\u6784 FCN\u7f51\u7edc\u4e0eCNN\u7684\u4e0d\u540c\u662f\u5c06\u5168\u8fde\u63a5\u5c42\u66ff\u6362\u4e3a\u5377\u79ef\u5c42\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u4e8c\u7ef4\u7684\u7279\u5f81\u56fe\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\uff0c\u6574\u4e2a\u7f51\u7edc\u53ef\u5206\u4e3a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u4e24\u90e8\u5206 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u4e0a\u91c7\u6837\uff1a\u4f7f\u7528\u53cd\u5377\u79ef\u5b8c\u6210 \u8df3\u5c42\u8fde\u63a5\uff1a\u5c06\u7f51\u7edc\u63d0\u53d6\u7684\u6df1\u5c42\u7279\u5f81\u548c\u6d45\u5c42\u7279\u5f81\u7ed3\u5408\u8d77\u6765 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784 \u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff1a\u9996\u5148\u8fdb\u884c\u5377\u79ef\u548c\u6c60\u5316\u6765\u5b8c\u6210\u4e0b\u91c7\u6837\uff1b\u7136\u540e\u901a\u8fc7\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\uff0ccrop\u4e4b\u524d\u7684\u4f4e\u5c42feature map\uff0c\u8fdb\u884c\u878d\u5408\uff1b\u7136\u540e\u518d\u6b21\u4e0a\u91c7\u6837\u3002\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u76f4\u5230\u83b7\u5f97\u8f93\u51fa\u7684feature map\uff0c\u6700\u540e\u7ecf\u8fc7softmax\u83b7\u5f97\u8f93\u51fa\u5206\u5272\u7ed3\u679c","title":"\u8bed\u4e49\u5206\u5272\uff1aFCN\u548cUNet"},{"location":"imageSegmentation/section2/#52-fcnunet","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3FCN\u7684\u7ed3\u6784 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784","title":"5.2 \u8bed\u4e49\u5206\u5272\uff1aFCN\u548cUNet"},{"location":"imageSegmentation/section2/#1fcn","text":"FCN\uff08Fully Convolutional Networks\uff09 \u7528\u4e8e\u56fe\u50cf\u8bed\u4e49\u5206\u5272\uff0c\u81ea\u4ece\u8be5\u7f51\u7edc\u63d0\u51fa\u540e\uff0c\u5c31\u6210\u4e3a\u8bed\u4e49\u5206\u5272\u7684\u57fa\u672c\u6846\u67b6\uff0c\u540e\u7eed\u7b97\u6cd5\u57fa\u672c\u90fd\u662f\u5728\u8be5\u7f51\u7edc\u6846\u67b6\u4e2d\u6539\u8fdb\u800c\u6765\u3002 \u5bf9\u4e8e\u4e00\u822c\u7684\u5206\u7c7bCNN\u7f51\u7edc\uff0c\u5982VGG\u548cResnet\uff0c\u90fd\u4f1a\u5728\u7f51\u7edc\u7684\u6700\u540e\u52a0\u5165\u4e00\u4e9b\u5168\u8fde\u63a5\u5c42\uff0c\u7ecf\u8fc7softmax\u540e\u5c31\u53ef\u4ee5\u83b7\u5f97\u7c7b\u522b\u6982\u7387\u4fe1\u606f\u3002 \u4f46\u662f\u8fd9\u4e2a\u6982\u7387\u53ea\u80fd\u6807\u8bc6\u6574\u4e2a\u56fe\u7247\u7684\u7c7b\u522b\uff0c\u4e0d\u80fd\u6807\u8bc6\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u7c7b\u522b\uff0c\u6240\u4ee5\u8fd9\u79cd\u5168\u8fde\u63a5\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u5272\u3002 \u800cFCN\u63d0\u51fa\u53ef\u4ee5\u628a\u540e\u9762\u51e0\u4e2a\u5168\u8fde\u63a5\u90fd\u6362\u6210\u5377\u79ef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u83b7\u5f97\u4e00\u5f202\u7ef4\u7684feature map\uff0c\u540e\u63a5softmax\u83b7\u5f97\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u5206\u7c7b\u4fe1\u606f\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u5206\u5272\u95ee\u9898\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7b80\u800c\u8a00\u4e4b\uff0cFCN\u548cCNN\u7684\u533a\u522b\u5c31\u662f\uff1aCNN\u5377\u79ef\u5c42\u4e4b\u540e\u8fde\u63a5\u7684\u662f\u5168\u8fde\u63a5\u5c42\uff1bFCN\u5377\u79ef\u5c42\u4e4b\u540e\u4ecd\u8fde\u63a5\u5377\u79ef\u5c42\uff0c\u8f93\u51fa\u7684\u662f\u4e0e\u8f93\u5165\u5927\u5c0f\u76f8\u540c\u7684\u7279\u5f81\u56fe\u3002","title":"1.FCN\u7f51\u7edc"},{"location":"imageSegmentation/section2/#11","text":"FCN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\uff0c\u50cf\u7d20\u5bf9\u50cf\u7d20\u7684\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u8fdb\u884c\u56fe\u50cf\u7684\u8bed\u4e49\u5206\u5272\u3002\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u90e8\u5206\u3002","title":"1.1 \u7f51\u7edc\u7ed3\u6784"},{"location":"imageSegmentation/section2/#111","text":"\u5168\u5377\u79ef\u90e8\u5206\u4f7f\u7528\u7ecf\u5178\u7684CNN\u7f51\u7edc\uff08\u4ee5AlexNet\u7f51\u7edc\u4e3a\u4f8b\uff09\uff0c\u5e76\u628a\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u6362\u6210 \u5377\u79ef\uff0c\u7528\u4e8e\u63d0\u53d6\u7279\u5f81\u3002 \u5728\u4f20\u7edf\u7684Alex\u7ed3\u6784\u4e2d\uff0c\u524d5\u5c42\u662f\u5377\u79ef\u5c42\uff0c\u7b2c6\u5c42\u548c\u7b2c7\u5c42\u5206\u522b\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a4096\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u7b2c8\u5c42\u662f\u957f\u5ea6\u4e3a1000\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u5206\u522b\u5bf9\u5e941000\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684\u6982\u7387\u3002 FCN\u5c06\u6700\u540e\u76843\u5c42\u8f6c\u6362\u4e3a\u5377\u79ef\u5c42\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f (\u901a\u9053\u6570\uff0c\u5bbd\uff0c\u9ad8) \u5206\u522b\u4e3a (4096,1,1)\u3001(4096,1,1)\u3001(1000,1,1)\uff0c\u867d\u7136\u53c2\u6570\u6570\u76ee\u76f8\u540c\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u5c31\u4e0d\u4e00\u6837\u4e86\uff0c\u8fd9\u65f6\u8fd8\u53ef\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u3002 CNN\u4e2d\u8f93\u5165\u7684\u56fe\u50cf\u56fa\u5b9a\u6210227x227\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u4e3a55x55\uff0c\u7b2c\u4e8c\u5c42pooling\u540e\u56fe\u50cf\u5927\u5c0f\u4e3a27x27\uff0c\u7b2c\u4e94\u5c42pooling\u540e\u7684\u56fe\u50cf\u5927\u5c0f\u4e3a13x13, \u800cFCN\u8f93\u5165\u7684\u56fe\u50cf\u662fH*W\u5927\u5c0f\uff0c\u7b2c\u4e00\u5c42pooling\u540e\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bd\uff0c\u7b2c\u4e8c\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u00bc\uff0c\u7b2c\u4e94\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u7684\u215b\uff0c\u7b2c\u516b\u5c42\u53d8\u4e3a\u539f\u56fe\u5927\u5c0f\u76841/16\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u7ecf\u8fc7\u591a\u6b21\u5377\u79ef\u548cpooling\u4ee5\u540e\uff0c\u5f97\u5230\u7684\u56fe\u50cf\u8d8a\u6765\u8d8a\u5c0f\uff0c\u5206\u8fa8\u7387\u8d8a\u6765\u8d8a\u4f4e\u3002\u5bf9\u6700\u7ec8\u7684\u7279\u5f81\u56fe\u8fdb\u884cupsampling\uff0c\u628a\u56fe\u50cf\u8fdb\u884c\u653e\u5927\u5230\u539f\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u5c31\u5f97\u5230\u539f\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\u3002","title":"1.1.1 \u5168\u5377\u79ef\u90e8\u5206"},{"location":"imageSegmentation/section2/#112","text":"\u4e0a\u91c7\u6837\u90e8\u5206\u5c06\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e0a\u91c7\u6837\u5f97\u5230\u539f\u56fe\u50cf\u5927\u5c0f\u7684\u8bed\u4e49\u5206\u5272\u7ed3\u679c\u3002 \u5728\u8fd9\u91cc\u91c7\u7528\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u662f\u53cd\u5377\u79ef\uff08Deconvolution\uff09\uff0c\u4e5f\u53eb\u505a\u8f6c\u7f6e\u5377\u79ef\uff08Transposed Convolution\uff09\uff1a \u53cd\u5377\u79ef\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6b63\u5411\u5377\u79ef \u901a\u4fd7\u7684\u8bb2\uff0c\u5c31\u662f\u8f93\u5165\u88650+\u5377\u79ef\u3002\u5148\u6309\u7167\u4e00\u5b9a\u7684\u6bd4\u4f8b\u901a\u8fc7\u88650\u6765\u6269\u5927\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u518d\u8fdb\u884c\u6b63\u5411\u5377\u79ef\u5373\u53ef\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\u4e3a3x3\uff0c\u5377\u79ef\u6838kernel\u4e3a3x3\uff0c\u6b65\u957fstrides=2\uff0c\u586b\u5145padding=1 \u5047\u8bbe\u53cd\u5377\u79ef\u7684\u8f93\u5165\u662fn x n \uff0c\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u4e3amxm \uff0cpadding=p\uff0cstride=s\uff0ckernel_size = k\u3002 \u90a3\u4e48\u6b64\u65f6\u53cd\u5377\u79ef\u7684\u8f93\u51fa\u5c31\u4e3a\uff1a m = s(n-1) + k -2p m = s(n-1) + k -2p \u4e0e\u6b63\u5411\u5377\u79ef\u4e0d\u540c\u7684\u662f\uff0c\u8981\u5148\u6839\u636e\u6b65\u957fstrides\u5bf9\u8f93\u5165\u7684\u5185\u90e8\u8fdb\u884c\u586b\u5145\uff0c\u8fd9\u91ccstrides\u53ef\u4ee5\u7406\u89e3\u6210\u8f93\u5165\u653e\u5927\u7684\u500d\u6570\uff0c\u800c\u4e0d\u80fd\u7406\u89e3\u6210\u5377\u79ef\u79fb\u52a8\u7684\u6b65\u957f\u3002 \u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u53cd\u5377\u79ef\u5b9e\u73b0\u4e0a\u91c7\u6837\u3002","title":"1.1.2 \u4e0a\u91c7\u6837\u90e8\u5206"},{"location":"imageSegmentation/section2/#12","text":"\u5982\u679c\u53ea\u5229\u7528\u53cd\u5377\u79ef\u5bf9\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\u7684\u5230\u539f\u56fe\u5927\u5c0f\u7684\u5206\u5272\uff0c\u7531\u4e8e\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u592a\u5c0f\uff0c\u4f1a\u635f\u5931\u5f88\u591a\u7ec6\u8282\u3002\u56e0\u800c\u63d0\u51fa\u589e\u52a0Skips\u7ed3\u6784\u5c06\u6700\u540e\u4e00\u5c42\u7684\u9884\u6d4b\uff08\u6709\u66f4\u5bcc\u7684\u5168\u5c40\u4fe1\u606f\uff09\u548c\u66f4\u6d45\u5c42\uff08\u6709\u66f4\u591a\u7684\u5c40\u90e8\u7ec6\u8282\uff09\u7684\u9884\u6d4b\u7ed3\u5408\u8d77\u6765\u3002 \u90a3\u4e48\uff1a \u5bf9\u4e8eFCN-32s\uff0c\u76f4\u63a5\u5bf9pool5 feature\u8fdb\u884c32\u500d\u4e0a\u91c7\u6837\u83b7\u5f9732x upsampled feature\uff0c\u518d\u5bf932x upsampled feature\u6bcf\u4e2a\u70b9\u505asoftmax prediction\u83b7\u5f9732x upsampled feature prediction\uff08\u5373\u5206\u5272\u56fe\uff09\u3002 \u5bf9\u4e8eFCN-16s\uff0c\u9996\u5148\u5bf9pool5 feature\u8fdb\u884c2\u500d\u4e0a\u91c7\u6837\u83b7\u5f972x upsampled feature\uff0c\u518d\u628apool4 feature\u548c2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u5bf9\u76f8\u52a0\u7684feature\u8fdb\u884c16\u500d\u4e0a\u91c7\u6837\uff0c\u5e76softmax prediction\uff0c\u83b7\u5f9716x upsampled feature prediction\u3002 \u5bf9\u4e8eFCN-8s\uff0c\u9996\u5148\u8fdb\u884cpool4+2x upsampled feature\u9010\u70b9\u76f8\u52a0\uff0c\u7136\u540e\u53c8\u8fdb\u884cpool3+2x upsampled\u9010\u70b9\u76f8\u52a0\uff0c\u5373\u8fdb\u884c\u66f4\u591a\u6b21\u7279\u5f81\u878d\u5408\u3002\u5177\u4f53\u8fc7\u7a0b\u4e0e16s\u7c7b\u4f3c\uff0c\u4e0d\u518d\u8d58\u8ff0\u3002 \u4e0b\u9762\u6709\u4e00\u5f2032\u500d\uff0c16\u500d\u548c8\u500d\u4e0a\u91c7\u6837\u5f97\u5230\u7684\u7ed3\u679c\u56fe\u5bf9\u6bd4\uff1a \u53ef\u4ee5\u770b\u5230\u968f\u7740\u4e0a\u91c7\u6837\u505a\u5f97\u8d8a\u591a\uff0c\u5206\u5272\u7ed3\u679c\u8d8a\u6765\u8d8a\u7cbe\u7ec6\u3002","title":"1.2 \u8df3\u5c42\u8fde\u63a5"},{"location":"imageSegmentation/section2/#13","text":"\u4f18\u70b9 \u7aef\u5230\u7aef\u7684\uff0c\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u5927\u5c0f\u7684\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\uff0c\u6bd4\u8f83\u9ad8\u6548\u3002 \u5c40\u9650\u6027 \u5f97\u5230\u7684\u7ed3\u679c\u8fd8\u662f\u4e0d\u591f\u7cbe\u7ec6\u3002\u8fdb\u884c8\u500d\u4e0a\u91c7\u6837\u867d\u7136\u6bd432\u500d\u7684\u6548\u679c\u597d\u4e86\u5f88\u591a\uff0c\u4f46\u662f\u4e0a\u91c7\u6837\u7684\u7ed3\u679c\u8fd8\u662f\u6bd4\u8f83\u6a21\u7cca\u7684\uff0c\u5bf9\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u4e0d\u654f\u611f\u3002\u800c\u4e14\u5728\u5bf9\u5404\u4e2a\u50cf\u7d20\u8fdb\u884c\u5206\u7c7b\u65f6\uff0c\u6ca1\u6709\u8003\u8651\u50cf\u7d20\u4e0e\u50cf\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\u3002","title":"1.3 \u603b\u7ed3"},{"location":"imageSegmentation/section2/#2unet","text":"Unet\u7f51\u7edc\u662f\u5efa\u7acb\u5728FCN\u7f51\u7edc\u57fa\u7840\u4e0a\u7684\uff0c\u5b83\u7684\u7f51\u7edc\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u603b\u4f53\u6765\u8bf4\u4e0eFCN\u601d\u8def\u975e\u5e38\u7c7b\u4f3c\u3002 \u6574\u4e2a\u7f51\u7edc\u7531\u7f16\u7801\u90e8\u5206\uff08\u5de6\uff09 \u548c \u89e3\u7801\u90e8\u5206\uff08\u53f3\uff09\u7ec4\u6210\uff0c\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff0c\u5177\u4f53\u4ecb\u7ecd\u5982\u4e0b\uff1a 1\u3001\u7f16\u7801\u90e8\u5206\u662f\u5178\u578b\u7684\u5377\u79ef\u7f51\u7edc\u67b6\u6784\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002\uff08\u56fe\u4e2d\u7684\u84dd\u7bad\u5934\u3001\u7ea2\u7bad\u5934\uff0c\u6ca1\u753bReLu\uff09 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d 2\u3001\u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u6a21\u5f0f\uff1a \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u6700\u540e\u4e00\u5c42\u7684\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1 x 1\uff0c\u5c0664\u901a\u9053\u7684\u7279\u5f81\u56fe\u8f6c\u5316\u4e3a\u7279\u5b9a\u7c7b\u522b\u6570\u91cf\uff08\u5206\u7c7b\u6570\u91cf\uff09\u7684\u7ed3\u679c\u3002\uff08\u56fe\u4e2d\u9752\u8272\u7bad\u5934\uff09 \u603b\u7ed3 \u4e86\u89e3FCN\u7684\u7ed3\u6784 FCN\u7f51\u7edc\u4e0eCNN\u7684\u4e0d\u540c\u662f\u5c06\u5168\u8fde\u63a5\u5c42\u66ff\u6362\u4e3a\u5377\u79ef\u5c42\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u4e8c\u7ef4\u7684\u7279\u5f81\u56fe\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u5206\u5272\u7ed3\u679c\uff0c\u6574\u4e2a\u7f51\u7edc\u53ef\u5206\u4e3a\u5168\u5377\u79ef\u90e8\u5206\u548c\u4e0a\u91c7\u6837\u4e24\u90e8\u5206 \u4e86\u89e3FCN\u7684\u4e0a\u91c7\u6837\u65b9\u6cd5\u53ca\u8df3\u5c42\u8fde\u63a5 \u4e0a\u91c7\u6837\uff1a\u4f7f\u7528\u53cd\u5377\u79ef\u5b8c\u6210 \u8df3\u5c42\u8fde\u63a5\uff1a\u5c06\u7f51\u7edc\u63d0\u53d6\u7684\u6df1\u5c42\u7279\u5f81\u548c\u6d45\u5c42\u7279\u5f81\u7ed3\u5408\u8d77\u6765 \u638c\u63e1Unet\u7f51\u7edc\u7ed3\u6784 \u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u5927\u5927\u7684U\u5b57\u6bcd\uff1a\u9996\u5148\u8fdb\u884c\u5377\u79ef\u548c\u6c60\u5316\u6765\u5b8c\u6210\u4e0b\u91c7\u6837\uff1b\u7136\u540e\u901a\u8fc7\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\uff0ccrop\u4e4b\u524d\u7684\u4f4e\u5c42feature map\uff0c\u8fdb\u884c\u878d\u5408\uff1b\u7136\u540e\u518d\u6b21\u4e0a\u91c7\u6837\u3002\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u76f4\u5230\u83b7\u5f97\u8f93\u51fa\u7684feature map\uff0c\u6700\u540e\u7ecf\u8fc7softmax\u83b7\u5f97\u8f93\u51fa\u5206\u5272\u7ed3\u679c","title":"2.Unet\u7f51\u7edc"},{"location":"imageSegmentation/section3/","text":"5.3 UNet\u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b 1.1 \u4efb\u52a1\u53ca\u6570\u636e\u96c6\u7b80\u4ecb \u00b6 \u4f7fOxford-IIIT Pet Dataset\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\uff0c\u5305\u542b37\u79cd\u5ba0\u7269\u7c7b\u522b\uff0c\u5176\u4e2d\u670912\u79cd\u732b\u7684\u7c7b\u522b\u548c25\u79cd\u72d7\u7684\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u5927\u7ea6\u6709200\u5f20\u56fe\u7247\uff0c\u6240\u6709\u56fe\u50cf\u90fd\u5177\u6709\u54c1\u79cd\uff0c\u5934\u90e8ROI\u548c\u50cf\u7d20\u7ea7\u5206\u5272\u7684\u6807\u6ce8\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u56fe\u50cf\u6570\u636e\u5305\u542b\u7684\u7c7b\u522b\u53ca\u5bf9\u5e94\u7684\u6570\u91cf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6570\u636e\u96c6\u7684\u76ee\u5f55\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a\\segdata 1\u3001Images\uff1a\u5b58\u50a8\u6570\u636e\u96c6\u7684\u56fe\u7247\u6570\u636e\uff0c\u5176\u4e2d\u56fe\u7247\u6587\u4ef6\u540d\u662f\u4ee5\u5927\u5199\u5f00\u5934\u4e3a\u201ccat\u201d\uff0c\u5c0f\u5199\u5f00\u5934\u4e3a\u201cdog\u201d\u3002 2\u3001Annotations\uff1a\u6807\u6ce8\u4fe1\u606f\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a list.txt\u4e2d\u7684\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b\u6240\u793a\uff0c\u5176\u4e2dClass ID\u5bf9\u5e94\u774037\u7c7b\u4e2d\u7684\u67d0\u4e00\u7c7b\uff0cSPECIES\u662f\u603b\u5206\u7c7b\uff0c1\u662f\u732b\uff0c2\u662f\u72d7\uff1bBreedID\u662f\u732b\u72d7\u5206\u7c7b\u4e2d\u7684\u5b50\u5206\u7c7b\uff0c\u732b\u7684\u5b50\u5206\u7c7b\u4e3a12\u7c7b\uff0c\u800c\u72d7\u7684\u5b50\u5206\u7c7b\u4e3a25\u7c7b\u3002 trimaps\u662f\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u6807\u6ce8\u4fe1\u606f\uff0c\u662f\u6211\u4eec\u7684\u76ee\u6807\u503c \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528UNET\u7f51\u7edc\u8fdb\u884c\u5ba0\u7269\u6570\u636e\u96c6\u5206\u5272\u3002 1.2 \u6570\u636e\u96c6\u83b7\u53d6 \u00b6 \u5728\u8fdb\u884c\u6a21\u578b\u6784\u5efa\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u8bfb\u53d6\u6570\u636e\u96c6\uff0c\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import os from IPython.display import Image , display from tensorflow.keras.preprocessing.image import load_img import PIL from PIL import ImageOps 1.2.1 \u8def\u5f84\u53ca\u76f8\u5173\u53c2\u6570\u8bbe\u7f6e \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u8bbe\u7f6e\u6570\u636e\u7684\u8def\u5f84\uff0c\u56fe\u50cf\u7684\u5927\u5c0f\uff0cbatch_size\u548c\u7c7b\u522b\u6570\u91cf\uff0c\u5728\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2a\u6280\u5de7\uff0c\u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u5bf9\u7c7b\u522b\u8fdb\u884c\u70ed\u7f16\u7801\u65f6\uff0c\u6211\u4eec\u7f16\u7801\u4e3a\uff1a1\uff1a0010\uff1b2\uff1a0100\uff1b3\uff1a1000\uff0c\u8fd9\u6837\u5728\u8bbe\u7f6e\u7c7b\u522b\u4e2a\u6570\u65f6\u8bbe\u4e3a4\u5373\u53ef\u3002 # \u56fe\u7247\u4f4d\u7f6e input_dir = \"segdata/images/\" # \u6807\u6ce8\u4fe1\u606f\u4f4d\u7f6e target_dir = \"segdata/annotations/trimaps/\" # \u56fe\u50cf\u5927\u5c0f\u8bbe\u7f6e\u53ca\u7c7b\u522b\u4fe1\u606f img_size = ( 160 , 160 ) batch_size = 32 num_classes = 4 # \u56fe\u50cf\u7684\u8def\u5f84 input_img_paths = sorted ( [ os . path . join ( input_dir , fname ) for fname in os . listdir ( input_dir ) if fname . endswith ( \".jpg\" ) ] ) # \u76ee\u6807\u503c\u8def\u5f84 target_img_paths = sorted ( [ os . path . join ( target_dir , fname ) for fname in os . listdir ( target_dir ) if fname . endswith ( \".png\" ) and not fname . startswith ( \".\" ) ] ) 1.2.2 \u6570\u636e\u5c55\u793a \u00b6 \u5c06\u56fe\u50cf\u53ca\u5bf9\u5e94\u7684\u7ed3\u679c\u8fdb\u884c\u5c55\u793a\uff1a # \u663e\u793a\u4e00\u4e2a\u56fe\u50cf display ( Image ( filename = input_img_paths [ 10 ])) \u6807\u6ce8\u4fe1\u606f\u4e2d\u53ea\u67093\u4e2a\u503c\uff0c\u6211\u4eec\u4f7f\u7528PIL.ImageOps.autocontrast\u8fdb\u884c\u5c55\u793a\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u8f93\u5165\u56fe\u50cf\u7684\u76f4\u65b9\u56fe\uff0c\u7136\u540e\u91cd\u65b0\u6620\u5c04\u56fe\u50cf\uff0c\u6700\u6697\u50cf\u7d20\u53d8\u4e3a\u9ed1\u8272\uff0c\u53730\uff0c\u6700\u4eae\u7684\u53d8\u4e3a\u767d\u8272\uff0c\u5373255\uff0c\u5176\u4ed6\u7684\u503c\u4ee5\u5176\u4ed6\u7684\u7070\u5ea6\u503c\u8fdb\u884c\u663e\u793a\uff0c\u5728\u8fd9\u91cc\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u6240\u4ee5\u524d\u666f\u6700\u5c0f\u663e\u793a\u4e3a\u9ed1\u8272\uff0c\u4e0d\u786e\u5b9a\u7684\u533a\u57df\u6700\u5927\u663e\u793a\u4e3a\u767d\u8272\u3002 # \u663e\u793a\u6807\u6ce8\u56fe\u50cf img = PIL . ImageOps . autocontrast ( load_img ( target_img_paths [ 10 ])) display ( img ) 1.2.3 \u6784\u5efa\u6570\u636e\u96c6\u751f\u6210\u5668 \u00b6 \u5229\u7528keras.utils.Sequence\u6784\u5efa\u56fe\u50cf\u751f\u6210\u5668\u6765\u8bfb\u53d6\u6570\u636e\uff0c\u6bcf\u4e2aSequence\u5fc5\u987b\u5b9e\u73b0 getitem \u548c len \u65b9\u6cd5\uff0c\u901a\u8fc7 getitem \u5e94\u8fd4\u56de\u5b8c\u6574\u7684\u6279\u6b21\uff0c Sequence\u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002\u4e3b\u8981\u5b9e\u73b03\u4e2a\u65b9\u6cd5\uff1binit,len\u548cgetitem\u5373\u53ef\u3002 from tensorflow import keras import numpy as np from tensorflow.keras.preprocessing.image import load_img # \u6570\u636e\u96c6\u83b7\u53d6\uff1a class OxfordPets ( keras . utils . Sequence ): # \u5728__init__\u65b9\u6cd5\u4e2d\u6307\u5b9abatch_size,img_size,input_img_paths,target_img_paths def __init__ ( self , batch_size , img_size , input_img_paths , target_img_paths ): self . batch_size = batch_size # \u6279\u91cf\u5927\u5c0f self . img_size = img_size # \u56fe\u50cf\u5927\u5c0f self . input_img_paths = input_img_paths # \u8f93\u5165\u56fe\u50cf\u8def\u5f84 self . target_img_paths = target_img_paths # \u6807\u6ce8\u56fe\u50cf\u8def\u5f84 def __len__ ( self ): # \u8ba1\u7b97\u8fed\u4ee3\u6b21\u6570 return len ( self . target_img_paths ) // self . batch_size def __getitem__ ( self , idx ): \"\"\" \u83b7\u53d6\u6bcf\u4e00\u4e2abatch\u6570\u636e \"\"\" i = idx * self . batch_size # \u83b7\u53d6\u8f93\u5165\u7684\u56fe\u50cf\u6570\u636e batch_input_img_paths = self . input_img_paths [ i : i + self . batch_size ] # \u83b7\u53d6\u6807\u7b7e\u6570\u636e batch_target_img_paths = self . target_img_paths [ i : i + self . batch_size ] # \u6784\u5efa\u7279\u5f81\u503c\u6570\u636e\uff1a\u83b7\u53d6\u56fe\u50cf\u6570\u636e\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u7684\u6570\u636e\u5b58\u50a8\u5728x\u4e2d x = np . zeros (( batch_size ,) + self . img_size + ( 3 ,), dtype = \"float32\" ) for j , path in enumerate ( batch_input_img_paths ): img = load_img ( path , target_size = self . img_size ) x [ j ] = img # \u6784\u5efa\u76ee\u6807\u503c\u6570\u636e\uff1a\u83b7\u53d6\u6807\u6ce8\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u4e2d\u7684\u6570\u636e\u5b58\u5728y\u4e2d y = np . zeros (( batch_size ,) + self . img_size + ( 1 ,), dtype = \"uint8\" ) for j , path in enumerate ( batch_target_img_paths ): img = load_img ( path , target_size = self . img_size , color_mode = \"grayscale\" ) y [ j ] = np . expand_dims ( img , 2 ) return x , y \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8be5\u65b9\u6cd5\u6765\u83b7\u53d6\u6570\u636e\u3002 1.3 \u6a21\u578b\u6784\u5efa \u00b6 Unet\u7684\u7f51\u7edc\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\uff0c\u6211\u4eec\u5206\u522b\u8fdb\u884c\u6784\u5efa \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import tensorflow.keras as keras from tensorflow.keras.layers import Input , Conv2D , Conv2DTranspose from tensorflow.keras.layers import MaxPooling2D , Cropping2D , Concatenate from tensorflow.keras.layers import Lambda , Activation , BatchNormalization , Dropout from tensorflow.keras.models import Model 1.3.1 \u7f16\u7801\u90e8\u5206 \u00b6 \u7f16\u7801\u90e8\u5206\u7684\u7279\u70b9\u662f\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d \u6bcf\u6b21\u91cd\u590d\u90fd\u6709\u4e24\u4e2a\u8f93\u51fa\uff1a\u4e00\u4e2a\u7528\u4e8e\u7f16\u7801\u90e8\u5206\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e00\u4e2a\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u878d\u5408 \u6784\u5efa\u7684\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def downsampling_block ( input_tensor , filters ): # \u8f93\u5165\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = 'same' )( input_tensor ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u51fd\u6570 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u8fd4\u56de\u7684\u662f\u6c60\u5316\u540e\u7684\u503c\u548c\u6fc0\u6d3b\u672a\u6c60\u5316\u7684\u503c\uff0c\u6fc0\u6d3b\u540e\u672a\u6c60\u5316\u7684\u503c\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7279\u5f81\u7ea7\u8054 return MaxPooling2D ( pool_size = ( 2 , 2 ))( x ), x 1.3.2 \u89e3\u7801\u90e8\u5206 \u00b6 \u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u91cd\u590d\u6a21\u5757\uff1a \u6bcf\u4e00\u4e2a\u6a21\u5757\u6709\u4e24\u4e2a\u8f93\u5165\uff1a\u4e00\u4e2a\u662f\u7f16\u7801\u9636\u6bb5\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u4e2a\u662f\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u56fe \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u7f16\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u7279\u5f81\u878d\u5408\u7684\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def upsampling_block ( input_tensor , skip_tensor , filters ): # \u53cd\u5377\u79ef x = Conv2DTranspose ( filters , kernel_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = \"same\" )( input_tensor ) # \u83b7\u53d6\u5f53\u524d\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , x_height , x_width , _ = x . shape # \u83b7\u53d6\u8981\u878d\u5408\u7684\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , s_height , s_width , _ = skip_tensor . shape # \u83b7\u53d6\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5dee\u5f02 h_crop = s_height - x_height w_crop = s_width - x_width # \u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u76f8\u540c\u4e0d\u8fdb\u884c\u88c1\u526a if h_crop == 0 and w_crop == 0 : y = skip_tensor #\u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u540c\uff0c\u4f7f\u7ea7\u8054\u65f6\u50cf\u7d20\u5927\u5c0f\u4e00\u81f4 else : # \u83b7\u53d6\u7279\u5f81\u56fe\u88c1\u526a\u540e\u7684\u7279\u5f81\u56fe\u7684\u5927\u5c0f cropping = (( h_crop // 2 , h_crop - h_crop // 2 ), ( w_crop // 2 , w_crop - w_crop // 2 )) # \u7279\u5f81\u56fe\u88c1\u526a y = Cropping2D ( cropping = cropping )( skip_tensor ) # \u7279\u5f81\u878d\u5408 x = Concatenate ()([ x , y ]) # \u5377\u79ef x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) return x 1.3.3 \u6a21\u578b\u6784\u5efa \u00b6 \u5c06\u7f16\u7801\u90e8\u5206\u548c\u89e3\u7801\u90e8\u5206\u7ec4\u5408\u4e00\u8d77\uff0c\u5c31\u53ef\u6784\u5efaunet\u7f51\u7edc\uff0c\u5728\u8fd9\u91ccunet\u7f51\u7edc\u7684\u6df1\u5ea6\u901a\u8fc7depth\u8fdb\u884c\u8bbe\u7f6e\uff0c\u5e76\u8bbe\u7f6e\u7b2c\u4e00\u4e2a\u7f16\u7801\u6a21\u5757\u7684\u5377\u79ef\u6838\u4e2a\u6570\u901a\u8fc7filter\u8fdb\u884c\u8bbe\u7f6e\uff0c\u901a\u8fc7\u4ee5\u4e0b\u6a21\u5757\u5c06\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\u8fdb\u884c\u7ec4\u5408\uff1a # \u4f7f\u75283\u4e2a\u6df1\u5ea6\u6784\u5efaunet\u7f51\u7edc def unet ( imagesize , classes , features = 64 , depth = 3 ): # \u5b9a\u4e49\u8f93\u5165\u6570\u636e inputs = keras . Input ( shape = img_size + ( 3 ,)) x = inputs # \u7528\u6765\u5b58\u653e\u8fdb\u884c\u7279\u5f81\u878d\u5408\u7684\u7279\u5f81\u56fe skips = [] # \u6784\u5efa\u7f16\u7801\u90e8\u5206 for i in range ( depth ): x , x0 = downsampling_block ( x , features ) skips . append ( x0 ) # \u4e0b\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u7ffb\u500d\uff0c\u5373\u6bcf\u6b21\u4f7f\u7528\u7ffb\u500d\u6570\u76ee\u7684\u6ee4\u6ce2\u5668 features *= 2 # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u89e3\u7801\u8fc7\u7a0b for i in reversed ( range ( depth )): # \u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u56fe\u901a\u9053\u51cf\u534a features //= 2 # \u4e0a\u91c7\u6837 x = upsampling_block ( x , skips [ i ], features ) # \u5377\u79ef x = Conv2D ( filters = classes , kernel_size = ( 1 , 1 ), padding = \"same\" )( x ) # \u6fc0\u6d3b outputs = Activation ( 'softmax' )( x ) # \u6a21\u578b\u5b9a\u4e49 model = keras . Model ( inputs , outputs ) return model \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\uff1a model = unet ( img_size , 4 ) model . summary () \u67e5\u770b\u6a21\u578b\u7ed3\u6784\uff0c\u4e5f\u53ef\u4f7f\u7528\uff1a keras . utils . plot_model ( model ) \u8fdb\u884c\u53ef\u89c6\u5316\u3002 1.4 \u6a21\u578b\u8bad\u7ec3 \u00b6 1.4.1 \u6570\u636e\u96c6\u5212\u5206 \u00b6 \u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u662f\u6309\u987a\u5e8f\u8fdb\u884c\u5b58\u50a8\u7684\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u6570\u636e\u96c6\u6253\u4e71\u540e\uff0c\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf1000\uff0c\u5269\u4f59\u7684\u4e3a\u8bad\u7ec3\u96c6\uff0c\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff1a import random # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u5176\u4e2d\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf\u8bbe\u4e3a1000 val_samples = 1000 # \u5c06\u6570\u636e\u96c6\u6253\u4e71(\u56fe\u50cf\u4e0e\u6807\u6ce8\u4fe1\u606f\u7684\u968f\u673a\u6570\u79cd\u5b50\u662f\u4e00\u6837\u7684\uff0c\u624d\u80fd\u4fdd\u8bc1\u6570\u636e\u7684\u6b63\u786e\u6027) random . Random ( 1337 ) . shuffle ( input_img_paths ) random . Random ( 1337 ) . shuffle ( target_img_paths ) # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84 train_input_img_paths = input_img_paths [: - val_samples ] train_target_img_paths = target_img_paths [: - val_samples ] # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84 val_input_img_paths = input_img_paths [ - val_samples :] val_target_img_paths = target_img_paths [ - val_samples :] 1.4.2 \u6570\u636e\u83b7\u53d6 \u00b6 \u8bfb\u53d6\u5212\u5206\u597d\u7684\u6570\u636e\u96c6\u5f97\u5230\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u83b7\u53d6\u8bad\u7ec3\u96c6 train_gen = OxfordPets ( batch_size , img_size , train_input_img_paths , train_target_img_paths ) # \u6a21\u578b\u9a8c\u8bc1\u96c6 val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths ) 1.4.3 \u6a21\u578b\u7f16\u8bd1 \u00b6 \u8fdb\u884c\u6a21\u578b\u7f16\u8bd1\uff0c\u8bbe\u7f6e\uff1a \u4f18\u5316\u65b9\u6cd5\uff1a\u4f7f\u7528rmsprop\u4f18\u5316\u65b9\u6cd5 \u635f\u5931\u51fd\u6570\uff1a\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u56e0\u4e3a\u6ca1\u6709\u5bf9\u76ee\u6807\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u6240\u4ee5\u4f7f\u7528sparse_categorical_crossentropy # \u6a21\u578b\u7f16\u8bd1 model . compile ( optimizer = \"rmsprop\" , loss = \"sparse_categorical_crossentropy\" ) 1.4.4 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u8bbe\u7f6eepoch\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u6307\u660e\u9a8c\u8bc1\u96c6\u6570\u636e\uff1a # \u6a21\u578b\u8bad\u7ec3\uff0cepoch\u8bbe\u4e3a5 epochs = 15 model . fit ( train_gen , epochs = epochs , validation_data = val_gen ) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff1a Epoch 1 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.9539 - val_loss : 13.5056 Epoch 2 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.5145 - val_loss : 2.2228 Epoch 3 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.4318 - val_loss : 0.4182 Epoch 4 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.4027 - val_loss : 0.4100 Epoch 5 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.3551 - val_loss : 0.3894 Epoch 6 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.3226 - val_loss : 0.4020 Epoch 7 / 15 199 / 199 [ ============================== ] - 44 s 219 ms / step - loss : 0.3195 - val_loss : 0.4273 Epoch 8 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.2789 - val_loss : 0.3707 Epoch 9 / 15 199 / 199 [ ============================== ] - 43 s 219 ms / step - loss : 0.2599 - val_loss : 0.4059 Epoch 10 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.2440 - val_loss : 0.3799 Epoch 11 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2297 - val_loss : 0.4244 Epoch 12 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2179 - val_loss : 0.4320 Epoch 13 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2081 - val_loss : 0.4034 Epoch 14 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.1977 - val_loss : 0.4034 Epoch 15 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.1901 - val_loss : 0.4150 < tensorflow . python . keras . callbacks . History at 0x110063898 > \u968f\u7740\u8fed\u4ee3\u6b21\u6570\u7684\u589e\u52a0\uff0c\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\u51fd\u6570\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.5 \u6a21\u578b\u9884\u6d4b \u00b6 \u83b7\u53d6\u9a8c\u8bc1\u6570\u636e\u5e76\u8fdb\u884c\u9884\u6d4b # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u9884\u6d4b val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths ) val_preds = model . predict ( val_gen ) \u5b9a\u4e49\u9884\u6d4b\u7ed3\u679c\u663e\u793a\u7684\u65b9\u6cd5 # \u56fe\u50cf\u663e\u793a def display_mask ( i ): # \u83b7\u53d6\u5230\u7b2ci\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c mask = np . argmax ( val_preds [ i ], axis =- 1 ) # \u7ef4\u5ea6\u8c03\u6574 mask = np . expand_dims ( mask , axis =- 1 ) # \u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5e76\u8fdb\u884c\u663e\u793a img = PIL . ImageOps . autocontrast ( keras . preprocessing . image . array_to_img ( mask )) display ( img ) \u9009\u62e9\u67d0\u4e00\u4e2a\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b # \u9009\u4e2d\u9a8c\u8bc1\u96c6\u7684\u7b2c10\u4e2a\u56fe\u50cf i = 10 \u539f\u56fe\u50cf\u5c55\u793a # \u8f93\u5165\u56fe\u50cf\u663e\u793a display ( Image ( filename = val_input_img_paths [ i ])) \u76ee\u6807\u503c\u5c55\u793a # \u771f\u5b9e\u503c\u663e\u793a img = PIL . ImageOps . autocontrast ( load_img ( val_target_img_paths [ i ])) display ( img ) \u6a21\u578b\u9884\u6d4b\u7ed3\u679c # \u663e\u793a\u9884\u6d4b\u7ed3\u679c display_mask ( i ) \u603b\u7ed3 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u5ba0\u7269\u6570\u636e\u96c6\u8fdb\u884c\u5206\u5272\u65f6\u53ea\u6709\u524d\u666f\u3001\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u7684\u50cf\u7d20\u4e09\u79cd \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u642d\u5efa\u7f16\u7801\uff0c\u89e3\u7801\u90e8\u5206\u7684\u7f51\u7edc\uff0c\u5e76\u5c06\u4e24\u8005\u7ed3\u5408\u5728\u4e00\u8d77\u6784\u5efaUnet\u7f51\u7edc \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b","title":"UNet\u6848\u4f8b"},{"location":"imageSegmentation/section3/#53-unet","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b","title":"5.3 UNet\u6848\u4f8b"},{"location":"imageSegmentation/section3/#11","text":"\u4f7fOxford-IIIT Pet Dataset\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6\uff0c\u5305\u542b37\u79cd\u5ba0\u7269\u7c7b\u522b\uff0c\u5176\u4e2d\u670912\u79cd\u732b\u7684\u7c7b\u522b\u548c25\u79cd\u72d7\u7684\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u5927\u7ea6\u6709200\u5f20\u56fe\u7247\uff0c\u6240\u6709\u56fe\u50cf\u90fd\u5177\u6709\u54c1\u79cd\uff0c\u5934\u90e8ROI\u548c\u50cf\u7d20\u7ea7\u5206\u5272\u7684\u6807\u6ce8\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u56fe\u50cf\u6570\u636e\u5305\u542b\u7684\u7c7b\u522b\u53ca\u5bf9\u5e94\u7684\u6570\u91cf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6570\u636e\u96c6\u7684\u76ee\u5f55\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a\\segdata 1\u3001Images\uff1a\u5b58\u50a8\u6570\u636e\u96c6\u7684\u56fe\u7247\u6570\u636e\uff0c\u5176\u4e2d\u56fe\u7247\u6587\u4ef6\u540d\u662f\u4ee5\u5927\u5199\u5f00\u5934\u4e3a\u201ccat\u201d\uff0c\u5c0f\u5199\u5f00\u5934\u4e3a\u201cdog\u201d\u3002 2\u3001Annotations\uff1a\u6807\u6ce8\u4fe1\u606f\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a list.txt\u4e2d\u7684\u5185\u5bb9\u683c\u5f0f\u5982\u4e0b\u6240\u793a\uff0c\u5176\u4e2dClass ID\u5bf9\u5e94\u774037\u7c7b\u4e2d\u7684\u67d0\u4e00\u7c7b\uff0cSPECIES\u662f\u603b\u5206\u7c7b\uff0c1\u662f\u732b\uff0c2\u662f\u72d7\uff1bBreedID\u662f\u732b\u72d7\u5206\u7c7b\u4e2d\u7684\u5b50\u5206\u7c7b\uff0c\u732b\u7684\u5b50\u5206\u7c7b\u4e3a12\u7c7b\uff0c\u800c\u72d7\u7684\u5b50\u5206\u7c7b\u4e3a25\u7c7b\u3002 trimaps\u662f\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u6807\u6ce8\u4fe1\u606f\uff0c\u662f\u6211\u4eec\u7684\u76ee\u6807\u503c \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528UNET\u7f51\u7edc\u8fdb\u884c\u5ba0\u7269\u6570\u636e\u96c6\u5206\u5272\u3002","title":"1.1 \u4efb\u52a1\u53ca\u6570\u636e\u96c6\u7b80\u4ecb"},{"location":"imageSegmentation/section3/#12","text":"\u5728\u8fdb\u884c\u6a21\u578b\u6784\u5efa\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u8bfb\u53d6\u6570\u636e\u96c6\uff0c\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import os from IPython.display import Image , display from tensorflow.keras.preprocessing.image import load_img import PIL from PIL import ImageOps","title":"1.2 \u6570\u636e\u96c6\u83b7\u53d6"},{"location":"imageSegmentation/section3/#121","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u8bbe\u7f6e\u6570\u636e\u7684\u8def\u5f84\uff0c\u56fe\u50cf\u7684\u5927\u5c0f\uff0cbatch_size\u548c\u7c7b\u522b\u6570\u91cf\uff0c\u5728\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2a\u6280\u5de7\uff0c\u56fe\u50cf\u5206\u5272\u65f6\u5171\u5206\u4e3a\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a3\u79cd\uff0c\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u5bf9\u7c7b\u522b\u8fdb\u884c\u70ed\u7f16\u7801\u65f6\uff0c\u6211\u4eec\u7f16\u7801\u4e3a\uff1a1\uff1a0010\uff1b2\uff1a0100\uff1b3\uff1a1000\uff0c\u8fd9\u6837\u5728\u8bbe\u7f6e\u7c7b\u522b\u4e2a\u6570\u65f6\u8bbe\u4e3a4\u5373\u53ef\u3002 # \u56fe\u7247\u4f4d\u7f6e input_dir = \"segdata/images/\" # \u6807\u6ce8\u4fe1\u606f\u4f4d\u7f6e target_dir = \"segdata/annotations/trimaps/\" # \u56fe\u50cf\u5927\u5c0f\u8bbe\u7f6e\u53ca\u7c7b\u522b\u4fe1\u606f img_size = ( 160 , 160 ) batch_size = 32 num_classes = 4 # \u56fe\u50cf\u7684\u8def\u5f84 input_img_paths = sorted ( [ os . path . join ( input_dir , fname ) for fname in os . listdir ( input_dir ) if fname . endswith ( \".jpg\" ) ] ) # \u76ee\u6807\u503c\u8def\u5f84 target_img_paths = sorted ( [ os . path . join ( target_dir , fname ) for fname in os . listdir ( target_dir ) if fname . endswith ( \".png\" ) and not fname . startswith ( \".\" ) ] )","title":"1.2.1 \u8def\u5f84\u53ca\u76f8\u5173\u53c2\u6570\u8bbe\u7f6e"},{"location":"imageSegmentation/section3/#122","text":"\u5c06\u56fe\u50cf\u53ca\u5bf9\u5e94\u7684\u7ed3\u679c\u8fdb\u884c\u5c55\u793a\uff1a # \u663e\u793a\u4e00\u4e2a\u56fe\u50cf display ( Image ( filename = input_img_paths [ 10 ])) \u6807\u6ce8\u4fe1\u606f\u4e2d\u53ea\u67093\u4e2a\u503c\uff0c\u6211\u4eec\u4f7f\u7528PIL.ImageOps.autocontrast\u8fdb\u884c\u5c55\u793a\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u8f93\u5165\u56fe\u50cf\u7684\u76f4\u65b9\u56fe\uff0c\u7136\u540e\u91cd\u65b0\u6620\u5c04\u56fe\u50cf\uff0c\u6700\u6697\u50cf\u7d20\u53d8\u4e3a\u9ed1\u8272\uff0c\u53730\uff0c\u6700\u4eae\u7684\u53d8\u4e3a\u767d\u8272\uff0c\u5373255\uff0c\u5176\u4ed6\u7684\u503c\u4ee5\u5176\u4ed6\u7684\u7070\u5ea6\u503c\u8fdb\u884c\u663e\u793a\uff0c\u5728\u8fd9\u91cc\u524d\u666f\uff0c\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u5206\u522b\u6807\u6ce8\u4e3a\uff1a1\uff0c2\uff0c3\uff0c\u6240\u4ee5\u524d\u666f\u6700\u5c0f\u663e\u793a\u4e3a\u9ed1\u8272\uff0c\u4e0d\u786e\u5b9a\u7684\u533a\u57df\u6700\u5927\u663e\u793a\u4e3a\u767d\u8272\u3002 # \u663e\u793a\u6807\u6ce8\u56fe\u50cf img = PIL . ImageOps . autocontrast ( load_img ( target_img_paths [ 10 ])) display ( img )","title":"1.2.2 \u6570\u636e\u5c55\u793a"},{"location":"imageSegmentation/section3/#123","text":"\u5229\u7528keras.utils.Sequence\u6784\u5efa\u56fe\u50cf\u751f\u6210\u5668\u6765\u8bfb\u53d6\u6570\u636e\uff0c\u6bcf\u4e2aSequence\u5fc5\u987b\u5b9e\u73b0 getitem \u548c len \u65b9\u6cd5\uff0c\u901a\u8fc7 getitem \u5e94\u8fd4\u56de\u5b8c\u6574\u7684\u6279\u6b21\uff0c Sequence\u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002\u4e3b\u8981\u5b9e\u73b03\u4e2a\u65b9\u6cd5\uff1binit,len\u548cgetitem\u5373\u53ef\u3002 from tensorflow import keras import numpy as np from tensorflow.keras.preprocessing.image import load_img # \u6570\u636e\u96c6\u83b7\u53d6\uff1a class OxfordPets ( keras . utils . Sequence ): # \u5728__init__\u65b9\u6cd5\u4e2d\u6307\u5b9abatch_size,img_size,input_img_paths,target_img_paths def __init__ ( self , batch_size , img_size , input_img_paths , target_img_paths ): self . batch_size = batch_size # \u6279\u91cf\u5927\u5c0f self . img_size = img_size # \u56fe\u50cf\u5927\u5c0f self . input_img_paths = input_img_paths # \u8f93\u5165\u56fe\u50cf\u8def\u5f84 self . target_img_paths = target_img_paths # \u6807\u6ce8\u56fe\u50cf\u8def\u5f84 def __len__ ( self ): # \u8ba1\u7b97\u8fed\u4ee3\u6b21\u6570 return len ( self . target_img_paths ) // self . batch_size def __getitem__ ( self , idx ): \"\"\" \u83b7\u53d6\u6bcf\u4e00\u4e2abatch\u6570\u636e \"\"\" i = idx * self . batch_size # \u83b7\u53d6\u8f93\u5165\u7684\u56fe\u50cf\u6570\u636e batch_input_img_paths = self . input_img_paths [ i : i + self . batch_size ] # \u83b7\u53d6\u6807\u7b7e\u6570\u636e batch_target_img_paths = self . target_img_paths [ i : i + self . batch_size ] # \u6784\u5efa\u7279\u5f81\u503c\u6570\u636e\uff1a\u83b7\u53d6\u56fe\u50cf\u6570\u636e\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u7684\u6570\u636e\u5b58\u50a8\u5728x\u4e2d x = np . zeros (( batch_size ,) + self . img_size + ( 3 ,), dtype = \"float32\" ) for j , path in enumerate ( batch_input_img_paths ): img = load_img ( path , target_size = self . img_size ) x [ j ] = img # \u6784\u5efa\u76ee\u6807\u503c\u6570\u636e\uff1a\u83b7\u53d6\u6807\u6ce8\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u4e2d\u7684\u6570\u636e\u5b58\u5728y\u4e2d y = np . zeros (( batch_size ,) + self . img_size + ( 1 ,), dtype = \"uint8\" ) for j , path in enumerate ( batch_target_img_paths ): img = load_img ( path , target_size = self . img_size , color_mode = \"grayscale\" ) y [ j ] = np . expand_dims ( img , 2 ) return x , y \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u8be5\u65b9\u6cd5\u6765\u83b7\u53d6\u6570\u636e\u3002","title":"1.2.3 \u6784\u5efa\u6570\u636e\u96c6\u751f\u6210\u5668"},{"location":"imageSegmentation/section3/#13","text":"Unet\u7684\u7f51\u7edc\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\uff0c\u6211\u4eec\u5206\u522b\u8fdb\u884c\u6784\u5efa \u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import tensorflow.keras as keras from tensorflow.keras.layers import Input , Conv2D , Conv2DTranspose from tensorflow.keras.layers import MaxPooling2D , Cropping2D , Concatenate from tensorflow.keras.layers import Lambda , Activation , BatchNormalization , Dropout from tensorflow.keras.models import Model","title":"1.3 \u6a21\u578b\u6784\u5efa"},{"location":"imageSegmentation/section3/#131","text":"\u7f16\u7801\u90e8\u5206\u7684\u7279\u70b9\u662f\uff1a \u67b6\u6784\u4e2d\u542b\u6709\u7740\u4e00\u79cd\u91cd\u590d\u7ed3\u6784\uff0c\u6bcf\u6b21\u91cd\u590d\u4e2d\u90fd\u67092\u4e2a 3 x 3\u5377\u79ef\u5c42\u3001\u975e\u7ebf\u6027ReLU\u5c42\u548c\u4e00\u4e2a 2 x 2 max pooling\u5c42\uff08stride\u4e3a2\uff09\u3002 \u6bcf\u4e00\u6b21\u4e0b\u91c7\u6837\u540e\u6211\u4eec\u90fd\u628a\u7279\u5f81\u901a\u9053\u7684\u6570\u91cf\u52a0\u500d \u6bcf\u6b21\u91cd\u590d\u90fd\u6709\u4e24\u4e2a\u8f93\u51fa\uff1a\u4e00\u4e2a\u7528\u4e8e\u7f16\u7801\u90e8\u5206\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e00\u4e2a\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u878d\u5408 \u6784\u5efa\u7684\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def downsampling_block ( input_tensor , filters ): # \u8f93\u5165\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = 'same' )( input_tensor ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u51fd\u6570 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u8fd4\u56de\u7684\u662f\u6c60\u5316\u540e\u7684\u503c\u548c\u6fc0\u6d3b\u672a\u6c60\u5316\u7684\u503c\uff0c\u6fc0\u6d3b\u540e\u672a\u6c60\u5316\u7684\u503c\u7528\u4e8e\u89e3\u7801\u90e8\u5206\u7279\u5f81\u7ea7\u8054 return MaxPooling2D ( pool_size = ( 2 , 2 ))( x ), x","title":"1.3.1 \u7f16\u7801\u90e8\u5206"},{"location":"imageSegmentation/section3/#132","text":"\u89e3\u7801\u90e8\u5206\u4e5f\u4f7f\u7528\u4e86\u91cd\u590d\u6a21\u5757\uff1a \u6bcf\u4e00\u4e2a\u6a21\u5757\u6709\u4e24\u4e2a\u8f93\u5165\uff1a\u4e00\u4e2a\u662f\u7f16\u7801\u9636\u6bb5\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u4e2a\u662f\u89e3\u7801\u90e8\u5206\u7684\u7279\u5f81\u56fe \u6bcf\u4e00\u6b65\u90fd\u9996\u5148\u4f7f\u7528\u53cd\u5377\u79ef(up-convolution)\uff0c\u6bcf\u6b21\u4f7f\u7528\u53cd\u5377\u79ef\u90fd\u5c06\u7279\u5f81\u901a\u9053\u6570\u91cf\u51cf\u534a\uff0c\u7279\u5f81\u56fe\u5927\u5c0f\u52a0\u500d\u3002\uff08\u56fe\u4e2d\u7eff\u7bad\u5934\uff09 \u53cd\u5377\u79ef\u8fc7\u540e\uff0c\u5c06\u53cd\u5377\u79ef\u7684\u7ed3\u679c\u4e0e\u7f16\u7801\u90e8\u5206\u4e2d\u5bf9\u5e94\u6b65\u9aa4\u7684\u7279\u5f81\u56fe\u62fc\u63a5\u8d77\u6765\u3002\uff08\u767d/\u84dd\u5757\uff09 \u7f16\u7801\u90e8\u5206\u4e2d\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u7a0d\u5927\uff0c\u5c06\u5176\u4fee\u526a\u8fc7\u540e\u8fdb\u884c\u62fc\u63a5\u3002\uff08\u5de6\u8fb9\u6df1\u84dd\u865a\u7ebf\uff09 \u5bf9\u62fc\u63a5\u540e\u7684map\u518d\u8fdb\u884c2\u6b213 x 3\u7684\u5377\u79ef\u3002\uff08\u53f3\u4fa7\u84dd\u7bad\u5934\uff09 \u7f16\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a # \u8f93\u5165\uff1a\u8f93\u5165\u5f20\u91cf\uff0c\u7279\u5f81\u878d\u5408\u7684\u5f20\u91cf\uff0c\u5377\u79ef\u6838\u4e2a\u6570 def upsampling_block ( input_tensor , skip_tensor , filters ): # \u53cd\u5377\u79ef x = Conv2DTranspose ( filters , kernel_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = \"same\" )( input_tensor ) # \u83b7\u53d6\u5f53\u524d\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , x_height , x_width , _ = x . shape # \u83b7\u53d6\u8981\u878d\u5408\u7684\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8 _ , s_height , s_width , _ = skip_tensor . shape # \u83b7\u53d6\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5dee\u5f02 h_crop = s_height - x_height w_crop = s_width - x_width # \u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u76f8\u540c\u4e0d\u8fdb\u884c\u88c1\u526a if h_crop == 0 and w_crop == 0 : y = skip_tensor #\u82e5\u7279\u5f81\u56fe\u5927\u5c0f\u4e0d\u540c\uff0c\u4f7f\u7ea7\u8054\u65f6\u50cf\u7d20\u5927\u5c0f\u4e00\u81f4 else : # \u83b7\u53d6\u7279\u5f81\u56fe\u88c1\u526a\u540e\u7684\u7279\u5f81\u56fe\u7684\u5927\u5c0f cropping = (( h_crop // 2 , h_crop - h_crop // 2 ), ( w_crop // 2 , w_crop - w_crop // 2 )) # \u7279\u5f81\u56fe\u88c1\u526a y = Cropping2D ( cropping = cropping )( skip_tensor ) # \u7279\u5f81\u878d\u5408 x = Concatenate ()([ x , y ]) # \u5377\u79ef x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) # \u5377\u79ef\u5c42 x = Conv2D ( filters , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b\u5c42 x = Activation ( 'relu' )( x ) return x","title":"1.3.2 \u89e3\u7801\u90e8\u5206"},{"location":"imageSegmentation/section3/#133","text":"\u5c06\u7f16\u7801\u90e8\u5206\u548c\u89e3\u7801\u90e8\u5206\u7ec4\u5408\u4e00\u8d77\uff0c\u5c31\u53ef\u6784\u5efaunet\u7f51\u7edc\uff0c\u5728\u8fd9\u91ccunet\u7f51\u7edc\u7684\u6df1\u5ea6\u901a\u8fc7depth\u8fdb\u884c\u8bbe\u7f6e\uff0c\u5e76\u8bbe\u7f6e\u7b2c\u4e00\u4e2a\u7f16\u7801\u6a21\u5757\u7684\u5377\u79ef\u6838\u4e2a\u6570\u901a\u8fc7filter\u8fdb\u884c\u8bbe\u7f6e\uff0c\u901a\u8fc7\u4ee5\u4e0b\u6a21\u5757\u5c06\u7f16\u7801\u548c\u89e3\u7801\u90e8\u5206\u8fdb\u884c\u7ec4\u5408\uff1a # \u4f7f\u75283\u4e2a\u6df1\u5ea6\u6784\u5efaunet\u7f51\u7edc def unet ( imagesize , classes , features = 64 , depth = 3 ): # \u5b9a\u4e49\u8f93\u5165\u6570\u636e inputs = keras . Input ( shape = img_size + ( 3 ,)) x = inputs # \u7528\u6765\u5b58\u653e\u8fdb\u884c\u7279\u5f81\u878d\u5408\u7684\u7279\u5f81\u56fe skips = [] # \u6784\u5efa\u7f16\u7801\u90e8\u5206 for i in range ( depth ): x , x0 = downsampling_block ( x , features ) skips . append ( x0 ) # \u4e0b\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u7ffb\u500d\uff0c\u5373\u6bcf\u6b21\u4f7f\u7528\u7ffb\u500d\u6570\u76ee\u7684\u6ee4\u6ce2\u5668 features *= 2 # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u5377\u79ef x = Conv2D ( filters = features , kernel_size = ( 3 , 3 ), padding = \"same\" )( x ) # BN\u5c42 x = BatchNormalization ()( x ) # \u6fc0\u6d3b x = Activation ( 'relu' )( x ) # \u89e3\u7801\u8fc7\u7a0b for i in reversed ( range ( depth )): # \u6df1\u5ea6\u589e\u52a0\uff0c\u7279\u5f81\u56fe\u901a\u9053\u51cf\u534a features //= 2 # \u4e0a\u91c7\u6837 x = upsampling_block ( x , skips [ i ], features ) # \u5377\u79ef x = Conv2D ( filters = classes , kernel_size = ( 1 , 1 ), padding = \"same\" )( x ) # \u6fc0\u6d3b outputs = Activation ( 'softmax' )( x ) # \u6a21\u578b\u5b9a\u4e49 model = keras . Model ( inputs , outputs ) return model \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\uff1a model = unet ( img_size , 4 ) model . summary () \u67e5\u770b\u6a21\u578b\u7ed3\u6784\uff0c\u4e5f\u53ef\u4f7f\u7528\uff1a keras . utils . plot_model ( model ) \u8fdb\u884c\u53ef\u89c6\u5316\u3002","title":"1.3.3 \u6a21\u578b\u6784\u5efa"},{"location":"imageSegmentation/section3/#14","text":"","title":"1.4 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageSegmentation/section3/#141","text":"\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u662f\u6309\u987a\u5e8f\u8fdb\u884c\u5b58\u50a8\u7684\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u6570\u636e\u96c6\u6253\u4e71\u540e\uff0c\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf1000\uff0c\u5269\u4f59\u7684\u4e3a\u8bad\u7ec3\u96c6\uff0c\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff1a import random # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u5176\u4e2d\u9a8c\u8bc1\u96c6\u7684\u6570\u91cf\u8bbe\u4e3a1000 val_samples = 1000 # \u5c06\u6570\u636e\u96c6\u6253\u4e71(\u56fe\u50cf\u4e0e\u6807\u6ce8\u4fe1\u606f\u7684\u968f\u673a\u6570\u79cd\u5b50\u662f\u4e00\u6837\u7684\uff0c\u624d\u80fd\u4fdd\u8bc1\u6570\u636e\u7684\u6b63\u786e\u6027) random . Random ( 1337 ) . shuffle ( input_img_paths ) random . Random ( 1337 ) . shuffle ( target_img_paths ) # \u83b7\u53d6\u8bad\u7ec3\u96c6\u6570\u636e\u8def\u5f84 train_input_img_paths = input_img_paths [: - val_samples ] train_target_img_paths = target_img_paths [: - val_samples ] # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\u8def\u5f84 val_input_img_paths = input_img_paths [ - val_samples :] val_target_img_paths = target_img_paths [ - val_samples :]","title":"1.4.1 \u6570\u636e\u96c6\u5212\u5206"},{"location":"imageSegmentation/section3/#142","text":"\u8bfb\u53d6\u5212\u5206\u597d\u7684\u6570\u636e\u96c6\u5f97\u5230\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a # \u83b7\u53d6\u8bad\u7ec3\u96c6 train_gen = OxfordPets ( batch_size , img_size , train_input_img_paths , train_target_img_paths ) # \u6a21\u578b\u9a8c\u8bc1\u96c6 val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths )","title":"1.4.2 \u6570\u636e\u83b7\u53d6"},{"location":"imageSegmentation/section3/#143","text":"\u8fdb\u884c\u6a21\u578b\u7f16\u8bd1\uff0c\u8bbe\u7f6e\uff1a \u4f18\u5316\u65b9\u6cd5\uff1a\u4f7f\u7528rmsprop\u4f18\u5316\u65b9\u6cd5 \u635f\u5931\u51fd\u6570\uff1a\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u56e0\u4e3a\u6ca1\u6709\u5bf9\u76ee\u6807\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u6240\u4ee5\u4f7f\u7528sparse_categorical_crossentropy # \u6a21\u578b\u7f16\u8bd1 model . compile ( optimizer = \"rmsprop\" , loss = \"sparse_categorical_crossentropy\" )","title":"1.4.3 \u6a21\u578b\u7f16\u8bd1"},{"location":"imageSegmentation/section3/#144","text":"\u8bbe\u7f6eepoch\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u6307\u660e\u9a8c\u8bc1\u96c6\u6570\u636e\uff1a # \u6a21\u578b\u8bad\u7ec3\uff0cepoch\u8bbe\u4e3a5 epochs = 15 model . fit ( train_gen , epochs = epochs , validation_data = val_gen ) \u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff1a Epoch 1 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.9539 - val_loss : 13.5056 Epoch 2 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.5145 - val_loss : 2.2228 Epoch 3 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.4318 - val_loss : 0.4182 Epoch 4 / 15 199 / 199 [ ============================== ] - 44 s 221 ms / step - loss : 0.4027 - val_loss : 0.4100 Epoch 5 / 15 199 / 199 [ ============================== ] - 44 s 223 ms / step - loss : 0.3551 - val_loss : 0.3894 Epoch 6 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.3226 - val_loss : 0.4020 Epoch 7 / 15 199 / 199 [ ============================== ] - 44 s 219 ms / step - loss : 0.3195 - val_loss : 0.4273 Epoch 8 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.2789 - val_loss : 0.3707 Epoch 9 / 15 199 / 199 [ ============================== ] - 43 s 219 ms / step - loss : 0.2599 - val_loss : 0.4059 Epoch 10 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.2440 - val_loss : 0.3799 Epoch 11 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2297 - val_loss : 0.4244 Epoch 12 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2179 - val_loss : 0.4320 Epoch 13 / 15 199 / 199 [ ============================== ] - 43 s 218 ms / step - loss : 0.2081 - val_loss : 0.4034 Epoch 14 / 15 199 / 199 [ ============================== ] - 44 s 220 ms / step - loss : 0.1977 - val_loss : 0.4034 Epoch 15 / 15 199 / 199 [ ============================== ] - 44 s 222 ms / step - loss : 0.1901 - val_loss : 0.4150 < tensorflow . python . keras . callbacks . History at 0x110063898 > \u968f\u7740\u8fed\u4ee3\u6b21\u6570\u7684\u589e\u52a0\uff0c\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\u51fd\u6570\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.4.4 \u6a21\u578b\u8bad\u7ec3"},{"location":"imageSegmentation/section3/#15","text":"\u83b7\u53d6\u9a8c\u8bc1\u6570\u636e\u5e76\u8fdb\u884c\u9884\u6d4b # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u9884\u6d4b val_gen = OxfordPets ( batch_size , img_size , val_input_img_paths , val_target_img_paths ) val_preds = model . predict ( val_gen ) \u5b9a\u4e49\u9884\u6d4b\u7ed3\u679c\u663e\u793a\u7684\u65b9\u6cd5 # \u56fe\u50cf\u663e\u793a def display_mask ( i ): # \u83b7\u53d6\u5230\u7b2ci\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c mask = np . argmax ( val_preds [ i ], axis =- 1 ) # \u7ef4\u5ea6\u8c03\u6574 mask = np . expand_dims ( mask , axis =- 1 ) # \u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5e76\u8fdb\u884c\u663e\u793a img = PIL . ImageOps . autocontrast ( keras . preprocessing . image . array_to_img ( mask )) display ( img ) \u9009\u62e9\u67d0\u4e00\u4e2a\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b # \u9009\u4e2d\u9a8c\u8bc1\u96c6\u7684\u7b2c10\u4e2a\u56fe\u50cf i = 10 \u539f\u56fe\u50cf\u5c55\u793a # \u8f93\u5165\u56fe\u50cf\u663e\u793a display ( Image ( filename = val_input_img_paths [ i ])) \u76ee\u6807\u503c\u5c55\u793a # \u771f\u5b9e\u503c\u663e\u793a img = PIL . ImageOps . autocontrast ( load_img ( val_target_img_paths [ i ])) display ( img ) \u6a21\u578b\u9884\u6d4b\u7ed3\u679c # \u663e\u793a\u9884\u6d4b\u7ed3\u679c display_mask ( i ) \u603b\u7ed3 \u4e86\u89e3\u5ba0\u7269\u56fe\u50cf\u5206\u5272\u6570\u636e\u96c6 \u5ba0\u7269\u6570\u636e\u96c6\u8fdb\u884c\u5206\u5272\u65f6\u53ea\u6709\u524d\u666f\u3001\u80cc\u666f\u548c\u4e0d\u786e\u5b9a\u7684\u50cf\u7d20\u4e09\u79cd \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u642d\u5efa \u642d\u5efa\u7f16\u7801\uff0c\u89e3\u7801\u90e8\u5206\u7684\u7f51\u7edc\uff0c\u5e76\u5c06\u4e24\u8005\u7ed3\u5408\u5728\u4e00\u8d77\u6784\u5efaUnet\u7f51\u7edc \u80fd\u591f\u5b8c\u6210UNet\u7f51\u7edc\u7684\u8bad\u7ec3\u4e0e\u9884\u6d4b","title":"1.5 \u6a21\u578b\u9884\u6d4b"},{"location":"imageSegmentation/section4/","text":"5.4 Mask RCNN \u00b6 \u5b66\u4e60\u76ee\u6807 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u4e0a\u56fe\u662fMaskRCNN\u9884\u6d4b\u7684\u7ed3\u679c 1.1 Mask RCNN\u6d41\u7a0b \u00b6 Mask-RCNN\u662f\u4e00\u4e2a\u5b9e\u4f8b\u5206\u5272\uff08Instance segmentation\uff09\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u4e0d\u540c\u7684\u5206\u652f\u53ef\u4ee5\u5b8c\u6210\u76ee\u6807\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u5b9e\u4f8b\u5206\u5272\u7b49\u591a\u79cd\u4efb\u52a1\u3002\u5177\u4f53\u6765\u8bb2\uff0c\u5c31\u662f\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20\uff0c\u5176\u5206\u652f\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u63a9\u7801\u5206\u652f\u662f\u4f5c\u7528\u4e8e\u6bcf\u4e2aRoI\u533a\u57df\uff08\u5019\u9009\u533a\u57df\uff09\uff0c\u4ee5\u50cf\u7d20\u5230\u50cf\u7d20\u7684\u65b9\u5f0f\u9884\u6d4b\u5206\u5272\u63a9\u7801\uff0c\u5f97\u5230\u5b9e\u4f8b\u5206\u5272\u7684\u7ed3\u679c\u3002 Mask RCNN\u7684\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4f53\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u8981\u5904\u7406\u7684\u56fe\u7247\u3002 \u5c06\u56fe\u7247\u9001\u5165\u5230CNN\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5f97\u5230\u7279\u5f81\u56fe\u3002 \u7136\u540e\u5bf9\u7279\u5f81\u56fe\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f4d\u7f6e\u8bbe\u5b9a\u56fa\u5b9a\u4e2a\u6570\u7684ROI\uff08\u5bf9\u5e94\u4e8e\u5728FasterRCNN\u4e2d\u7684Anchor\uff09\uff0c\u7136\u540e\u5c06ROI\u533a\u57df\u9001\u5165RPN\u7f51\u7edc\u8fdb\u884c\u4e8c\u5206\u7c7b(\u524d\u666f\u548c\u80cc\u666f)\u4ee5\u53ca\u5750\u6807\u56de\u5f52\uff0c\u4ee5\u83b7\u5f97\u7cbe\u70bc\u540e\u7684ROI\u533a\u57df\uff08\u5bf9\u5e94\u4e8eFasterRCNN\u4e2d\u7684\u5019\u9009\u533a\u57df\uff09\u3002 \u5bf9\u4e0a\u4e2a\u6b65\u9aa4\u4e2d\u83b7\u5f97\u7684ROI\u533a\u57df\u6267\u884cROIAlign\u64cd\u4f5c\uff08\u662f\u5bf9ROIPooling\u7684\u6539\u8fdb\uff09\uff0c\u5373\u5148\u5c06\u539f\u56fe\u548cfeature map\u7684pixel\u5bf9\u5e94\u8d77\u6765\uff0c\u7136\u540e\u5c06feature map\u548c\u56fa\u5b9a\u5927\u5c0f\u7684feature\u5bf9\u5e94\u8d77\u6765\u3002 \u6700\u540e\u5bf9\u8fd9\u4e9bROI\u533a\u57df\u8fdb\u884c\u591a\u7c7b\u522b\u5206\u7c7b\uff0c\u5019\u9009\u6846\u56de\u5f52\u548c\u5f15\u5165FCN\u751f\u6210Mask\uff0c\u5b8c\u6210\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u3002 \u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4e0eFasterRCNN\u4e2d\u4e0d\u540c\u7684\u662fROIAlign\u548c\u5206\u5272\u5206\u652f\uff0c\u5176\u4ed6\u90fd\u662f\u76f8\u540c\u7684\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u4e24\u4e2a\u5185\u5bb9\u3002 1.2 ROIAlign \u00b6 1.2.1 \u539f\u7406\u4ecb\u7ecd \u00b6 FasterRCNN\u4e2d\u7684ROIPooling\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u5b83\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78=20x20\uff0c\u56e0\u4e3a\u5750\u6807\u8981\u4fdd\u7559\u6574\u6570\u6240\u4ee5\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e00\u4e2a\u91cf\u5316\u8bef\u5dee\u5373\u820d\u5f03\u4e86\u76ee\u6807\u6846\u5728\u7279\u5f81\u56fe\u4e0a\u5bf9\u5e94\u957f\u5bbd\u7684\u6d6e\u70b9\u6570\u90e8\u5206\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20x20\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u6839\u636eROI Pooling\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u5176\u7ed3\u679c\u5c31\u662f20/7x20/7=2.86x2.86\uff0c\u540c\u6837\u6267\u884c\u53d6\u6574\u64cd\u4f5c\u64cd\u4f5c\u540eROI\u7279\u5f81\u533a\u57df\u7684\u5c3a\u5bf8\u4e3a2x2\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e8c\u6b21\u91cf\u5316\u8bef\u5dee\u3002 \u4ece\u4e0a\u9762\u7684\u5206\u6790\u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u4e24\u6b21\u91cf\u5316\u8bef\u5dee\u4f1a\u5bfc\u81f4\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u548c\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u8fdb\u884c\u5bf9\u5e94\u65f6\u51fa\u73b0\u504f\u5dee\uff0c\u4f8b\u5982\u4e0a\u9762\u5c062.86\u91cf\u5316\u4e3a2\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e860.86\u7684\u504f\u5dee\uff0c\u8fd9\u4e2a\u504f\u5dee\u6620\u5c04\u56de\u539f\u56fe\u5c31\u662f0.86x32=27.52\uff0c\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u50cf\u7d20\u504f\u5dee\u662f\u5f88\u5927\u7684\uff0c\u800c\u4e14\u8fd9\u4ec5\u4ec5\u8003\u8651\u4e86\u7b2c\u4e8c\u6b21\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u6240\u4ee5\u8fd9\u4f1a\u5f71\u54cd\u6574\u4e2a\u7b97\u6cd5\u7684\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3ROI Pooling\u91cf\u5316\u8bef\u5dee\u8fc7\u5927\u7684\u95ee\u9898\uff0cMaskRCNN\u63d0\u51fa\u4e86ROIAlign\uff0cROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c\u3002\u8fd9\u4e00\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9488\u5bf9\u4e0a\u56fe\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78\uff0c\u6b64\u65f6\uff0c\u6ca1\u6709\u50cfRoiPooling\u90a3\u6837\u5c31\u884c\u53d6\u6574\u64cd\u4f5c\uff0c\u800c\u662f\u4fdd\u7559\u6d6e\u70b9\u6570\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20.78x20.78\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u7ed3\u679c\u5c31\u662f20.78/7x20.78/7=2.97x2.97\uff0c\u5373\u6bcf\u4e2a\u5c0f\u533a\u57df\u7684\u5927\u5c0f\u4e3a2.97x2.97\u3002 \u5047\u5b9a\u6bcf\u4e2a\u5c0f\u533a\u57df\u91c7\u6837\u70b9\u6570\u4e3a4\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u6bcf\u4e2a2.97*2.97\u7684\u5c0f\u533a\u57df\uff0c\u5e73\u5206\u56db\u4efd\uff0c\u6bcf\u4e00\u4efd\u53d6\u5176\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\uff0c\u800c\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\u7684\u50cf\u7d20\uff0c\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u6cd5\u8fdb\u884c\u8ba1\u7b97\uff0c\u8fd9\u6837\uff0c\u5c31\u4f1a\u5f97\u5230\u56db\u4e2a\u70b9\u7684\u50cf\u7d20\u503c\uff0c\u5982\u4e0b\u56fe\uff1a \u4e0a\u56fe\u4e2d\uff0c\u56db\u4e2a\u7ea2\u8272\u53c9\u53c9\u2018\u00d7\u2019\u7684\u50cf\u7d20\u503c\u662f\u901a\u8fc7\u53cc\u7ebf\u6027\u63d2\u503c\u7b97\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684\u3002 \u6700\u540e\uff0c\u53d6\u56db\u4e2a\u50cf\u7d20\u503c\u4e2d\u6700\u5927\u503c\uff08\u6700\u5927\u6c60\u5316\uff09\u4f5c\u4e3a\u8fd9\u4e2a\u5c0f\u533a\u57df(\u5373\uff1a2.97x2.97\u5927\u5c0f\u7684\u533a\u57df)\u7684\u50cf\u7d20\u503c\uff0c\u5982\u6b64\u7c7b\u63a8\uff0c\u540c\u6837\u662f49\u4e2a\u5c0f\u533a\u57df\u5f97\u523049\u4e2a\u50cf\u7d20\u503c\uff0c\u7ec4\u62107x7\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002 \u53cc\u7ebf\u6027\u63d2\u503c\u662f\u4e00\u79cd\u56fe\u50cf\u7f29\u653e\u586b\u5145\u7b97\u6cd5\uff0c\u5b83\u5145\u5206\u7684\u5229\u7528\u4e86\u539f\u56fe\u4e2d\u865a\u62df\u70b9\uff08\u6bd4\u598220.56\u8fd9\u4e2a\u6d6e\u70b9\u6570\uff0c\u50cf\u7d20\u4f4d\u7f6e\u4e0d\u662f\u6574\u6570\u503c\uff0c\u800c\u662f\u6d6e\u70b9\u503c\uff09\u56db\u5468\u7684\u771f\u5b9e\u5b58\u5728\u7684\u50cf\u7d20\u503c\u6765\u5171\u540c\u51b3\u5b9a\u76ee\u6807\u56fe\u4e2d\u7684\u4e00\u4e2a\u50cf\u7d20\u503c\uff0c\u5373\u53ef\u4ee5\u5c0620.56\u8fd9\u4e2a\u865a\u62df\u7684\u4f4d\u7f6e\u70b9\u5bf9\u5e94\u7684\u50cf\u7d20\u503c\u4f30\u8ba1\u51fa\u6765\u3002 1.2.2 \u5b9e\u73b0\u6548\u679c \u00b6 \u5728tensorFlow\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528\uff1a tf . image . crop_and_resize ( image , boxes , box_indices , crop_size , method = 'bilinear' , extrapolation_value = 0 , name = None ) \u53c2\u6570\u4ecb\u7ecd\uff1a image: \u8868\u793a\u7279\u5f81\u56fe boxes\uff1a\u6307\u9700\u8981\u5212\u5206\u7684ROI\u533a\u57df\uff0c\u8f93\u5165\u683c\u5f0f\u4e3a[ymin\uff0cxmin\uff0cymax\uff0cxmax]\uff0c\u6ce8\u610f\u662f\u5f52\u4e00\u5316\u7684\u7ed3\u679c\u3002 \u5047\u8bbe\u5019\u9009\u533a\u57df\u5750\u6807\u662f[y1,x1,y2,x2]\uff0c\u90a3\u4e48\u60f3\u8981\u5f97\u5230\u76f8\u5e94\u6b63\u786e\u7684crop\u56fe\u5f62\u5c31\u4e00\u5b9a\u8981\u5f52\u4e00\u5316,\u5373\u56fe\u7247\u7684\u957f\u5ea6\u662f[w,h],\u5219\u5b9e\u9645\u8f93\u5165\u7684boxes\u4e3a[y1/h,x1/w,y2/h,x2/w]\uff0c\u8d85\u51fa1\u7684\u90e8\u5206\u4f7f\u7528\u9ed1\u82720\u8fdb\u884c\u586b\u5145\u3002 box_indice: \u662fboxes\u548cimage\u4e4b\u95f4\u7684\u7d22\u5f15\uff0c\u5373box\u5bf9\u5e94\u7684\u56fe\u50cf\u7d22\u5f15 crop_size: \u8868\u793aRoiAlign\u4e4b\u540e\u7684\u5019\u9009\u533a\u57df\u7684\u5927\u5c0f\u3002 method\uff1a\u63d2\u503c\u65b9\u6cd5\uff0c\u9ed8\u8ba4\u662f\u53cc\u7ebf\u6027\u63d2\u503c \u4e0b\u9762\u6211\u4eec\u5229\u7528\u4e24\u5f20\u56fe\u7247\u770b\u4e0bROIAlign\u7684\u6548\u679c\uff1a \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt \u539f\u56fe\u50cf\u8bfb\u53d6\u548c\u5c55\u793a # \u56fe\u50cf\u8bfb\u53d6 img = plt . imread ( 'Trump.jpg' ) / 255. img2 = plt . imread ( 'Trump2.jpg' ) / 255. # \u56fe\u50cf\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) plt . subplot ( 1 , 2 , 1 ) plt . imshow ( img ) plt . subplot ( 1 , 2 , 2 ) plt . imshow ( img2 ) \u6784\u5efabatch_size\u6570\u636e\uff08batch_size=2\uff09 # \u5bf9\u56fe\u50cf\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u5e76\u6dfb\u52a0batch\u7ef4 img = tf . convert_to_tensor ( img , dtype = tf . float32 ) img = tf . expand_dims ( img , axis = 0 ) img = tf . image . resize ( img , ( 500 , 500 )) img2 = tf . convert_to_tensor ( img2 , dtype = tf . float32 ) img2 = tf . expand_dims ( img2 , axis = 0 ) img2 = tf . image . resize ( img2 , ( 500 , 500 )) # \u5c06\u4e24\u4e2a\u56fe\u50cf\u62fc\u63a5\u5728\u4e00\u8d77 img = tf . concat ([ img , img2 ], axis = 0 ) print ( 'img:' , img . shape ) \u8f93\u51fa\u4e3a\uff1a img : ( 2 , 500 , 500 , 3 ) \u4e00\u4e2abatch\u4e2d\u5305\u542b2\u4e2a\u56fe\u50cf\uff0c\u6bcf\u4e2a\u56fe\u50cf\u7684\u5927\u5c0f\u4e3a500x500x3\uff0c\u7406\u89e3\u4e3a\u4e24\u4e2a\u7279\u5f81\u56fe ROIAlign # \u8fdb\u884cROIAlign\u5904\u7406\uff1a\u7279\u5f81\u56fe\uff0c2\u4e2aboxes\uff0c\u5206\u522b\u5bf9\u5e94\u56fe\u50cf\u7d22\u5f150\u548c1\uff0cROIAlign\u540e\u7684\u5927\u5c0f\u4e3a50x50 out = tf . image . crop_and_resize ( img , [[ 0.5 , 0.5 , 1.0 , 1.0 ], [ 0.5 , 0.5 , 1.5 , 1.5 ]], [ 0 , 1 ], crop_size = ( 50 , 50 )) print ( 'out:' , a . shape ) \u8f93\u51fa\u4e3a\uff1a out : ( 2 , 50 , 50 , 3 ) \u6548\u679c\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) # \u5c3a\u5bf8\u8c03\u6574\u540e\u7684\u56fe\u50cf plt . subplot ( 2 , 2 , 1 ) plt . imshow ( img [ 0 ]) plt . subplot ( 2 , 2 , 2 ) plt . imshow ( img [ 1 ]) # ROIAlign\u7684\u7ed3\u679c plt . subplot ( 2 , 2 , 3 ) plt . imshow ( a [ 0 ]) plt . subplot ( 2 , 2 , 4 ) plt . imshow ( a [ 1 ]) plt . show () 1.3 \u7f51\u7edc\u7ed3\u6784 \u00b6 \u4e0a\u8ff0\u5df2\u7ecf\u4ecb\u7ecd\u4e86Mask-RCNN \u7684\u7ed3\u6784\u4e0eFasterRCNN\u662f\u76f8\u540c\u7684\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u5272\u7684\u5934\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9aa8\u5e72\u7f51\u7edcResNet-FPN\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\uff0cRPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u63d0\u53d6\uff0cROIAlign\u83b7\u53d6\u56fa\u5b9a\u5927\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u5934\u90e8\u7f51\u7edc\u5305\u62ec\u8fb9\u754c\u6846\u8bc6\u522b\uff08\u5206\u7c7b\u548c\u56de\u5f52\uff09+mask\u9884\u6d4b\uff0c\u5177\u4f53\u5982\u4e0b\u6240\u793a\uff1a mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u5b9e\u9645\u5de5\u4f5c\u4e2d\u6211\u4eec\u4f7f\u7528\u53f3\u56fe\u8f83\u591a\u4e00\u4e9b\uff0c\u5176\u4e2d\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\u3002\u9884\u6d4b\u65f6 mask \u5206\u652f\u8f93\u51fa\u7ed3\u679c resize \u5230 RoI \u7684\u5927\u5c0f, \u7136\u540e\u5e94\u7528 0.5 \u7684\u9608\u503c\u8fdb\u884c\u4e8c\u503c\u5316\u5f97\u5230\u6700\u7ec8\u7684\u5206\u5272\u7ed3\u679c\u3002 1.4 \u635f\u5931\u51fd\u6570 \u00b6 Mask-RCNN\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u591a\u4e86\u4e00\u4e2aROIAligin\u548cMask\u9884\u6d4b\u5206\u652f\uff0c\u56e0\u6b64Mask R-CNN\u7684\u635f\u5931\u4e5f\u662f\u591a\u4efb\u52a1\u635f\u5931\uff1a L_{cls} L_{cls} \u548c L_{box} L_{box} \u4e0efaster rcnn\u7684\u5b9a\u4e49\u6ca1\u6709\u533a\u522b\u3002\u5177\u4f53\u6765\u770b\u4e0b L_{mask} L_{mask} \u3002 Mask\u5206\u652f\u5bf9\u6bcf\u4e2aROI\u533a\u57df\u4ea7\u751f\u4e00\u4e2amxmxK\u7684\u8f93\u51fa\u7279\u5f81\u56fe\uff0c\u5373K\u4e2a\u7684\u4e8c\u503c\u63a9\u819c\u56fe\u50cf\uff0c\u5176\u4e2dK\u4ee3\u8868\u76ee\u6807\u79cd\u7c7b\u6570\u3002\u5bf9\u4e8e\u9884\u6d4b\u7684\u4e8c\u503c\u63a9\u819c\u8f93\u51fa\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u5e94\u7528 sigmoid \u51fd\u6570\uff0c\u6574\u4f53\u635f\u5931\u5b9a\u4e49\u4e3a\u5e73\u5747\u4e8c\u503c\u4ea4\u53c9\u635f\u5931\u71b5\u3002\u5bf9\u4e8e\u771f\u5b9e\u7c7b\u522b\u4e3a\ud835\udc58\u7684\ud835\udc45\ud835\udc5c\ud835\udc3c\uff0c\u4ec5\u5728\u7b2ck\u4e2a\u63a9\u7801\u4e0a\u8ba1\u7b97\u635f\u5931\uff08\u5176\u4ed6\u63a9\u7801\u8f93\u51fa\u4e0d\u8ba1\u5165\uff09\u3002\u8fd9\u6837\u505a\u89e3\u8026\u4e86\u63a9\u819c\u548c\u79cd\u7c7b\u9884\u6d4b\u3002 \u4e0d\u50cfFCN\u7684\u505a\u6cd5\uff0c\u5728\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e0a\u5e94\u7528 softmax \u51fd\u6570\uff0c\u6574\u4f53\u91c7\u7528\u7684\u591a\u4efb\u52a1\u4ea4\u53c9\u71b5\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u7c7b\u95f4\u7ade\u4e89\uff0c\u6700\u7ec8\u5bfc\u81f4\u5206\u5272\u6548\u679c\u5dee\u3002 \u603b\u7ed3 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 ROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u591a\u4efb\u52a1\u635f\u5931\u51fd\u6570\uff1a\u6709\u5206\u7c7b\uff0c\u56de\u5f52\u548c\u5206\u5272\u4e09\u90e8\u5206\u7ec4\u6210","title":"\u5b9e\u4f8b\u5206\u5272\uff1aMask RCNN"},{"location":"imageSegmentation/section4/#54-mask-rcnn","text":"\u5b66\u4e60\u76ee\u6807 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u4e0a\u56fe\u662fMaskRCNN\u9884\u6d4b\u7684\u7ed3\u679c","title":"5.4 Mask RCNN"},{"location":"imageSegmentation/section4/#11-mask-rcnn","text":"Mask-RCNN\u662f\u4e00\u4e2a\u5b9e\u4f8b\u5206\u5272\uff08Instance segmentation\uff09\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u4e0d\u540c\u7684\u5206\u652f\u53ef\u4ee5\u5b8c\u6210\u76ee\u6807\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u5b9e\u4f8b\u5206\u5272\u7b49\u591a\u79cd\u4efb\u52a1\u3002\u5177\u4f53\u6765\u8bb2\uff0c\u5c31\u662f\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20\uff0c\u5176\u5206\u652f\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u63a9\u7801\u5206\u652f\u662f\u4f5c\u7528\u4e8e\u6bcf\u4e2aRoI\u533a\u57df\uff08\u5019\u9009\u533a\u57df\uff09\uff0c\u4ee5\u50cf\u7d20\u5230\u50cf\u7d20\u7684\u65b9\u5f0f\u9884\u6d4b\u5206\u5272\u63a9\u7801\uff0c\u5f97\u5230\u5b9e\u4f8b\u5206\u5272\u7684\u7ed3\u679c\u3002 Mask RCNN\u7684\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4f53\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u8981\u5904\u7406\u7684\u56fe\u7247\u3002 \u5c06\u56fe\u7247\u9001\u5165\u5230CNN\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5f97\u5230\u7279\u5f81\u56fe\u3002 \u7136\u540e\u5bf9\u7279\u5f81\u56fe\u7684\u6bcf\u4e00\u4e2a\u50cf\u7d20\u4f4d\u7f6e\u8bbe\u5b9a\u56fa\u5b9a\u4e2a\u6570\u7684ROI\uff08\u5bf9\u5e94\u4e8e\u5728FasterRCNN\u4e2d\u7684Anchor\uff09\uff0c\u7136\u540e\u5c06ROI\u533a\u57df\u9001\u5165RPN\u7f51\u7edc\u8fdb\u884c\u4e8c\u5206\u7c7b(\u524d\u666f\u548c\u80cc\u666f)\u4ee5\u53ca\u5750\u6807\u56de\u5f52\uff0c\u4ee5\u83b7\u5f97\u7cbe\u70bc\u540e\u7684ROI\u533a\u57df\uff08\u5bf9\u5e94\u4e8eFasterRCNN\u4e2d\u7684\u5019\u9009\u533a\u57df\uff09\u3002 \u5bf9\u4e0a\u4e2a\u6b65\u9aa4\u4e2d\u83b7\u5f97\u7684ROI\u533a\u57df\u6267\u884cROIAlign\u64cd\u4f5c\uff08\u662f\u5bf9ROIPooling\u7684\u6539\u8fdb\uff09\uff0c\u5373\u5148\u5c06\u539f\u56fe\u548cfeature map\u7684pixel\u5bf9\u5e94\u8d77\u6765\uff0c\u7136\u540e\u5c06feature map\u548c\u56fa\u5b9a\u5927\u5c0f\u7684feature\u5bf9\u5e94\u8d77\u6765\u3002 \u6700\u540e\u5bf9\u8fd9\u4e9bROI\u533a\u57df\u8fdb\u884c\u591a\u7c7b\u522b\u5206\u7c7b\uff0c\u5019\u9009\u6846\u56de\u5f52\u548c\u5f15\u5165FCN\u751f\u6210Mask\uff0c\u5b8c\u6210\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u3002 \u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4e0eFasterRCNN\u4e2d\u4e0d\u540c\u7684\u662fROIAlign\u548c\u5206\u5272\u5206\u652f\uff0c\u5176\u4ed6\u90fd\u662f\u76f8\u540c\u7684\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u7740\u91cd\u4ecb\u7ecd\u8fd9\u4e24\u4e2a\u5185\u5bb9\u3002","title":"1.1 Mask RCNN\u6d41\u7a0b"},{"location":"imageSegmentation/section4/#12-roialign","text":"","title":"1.2 ROIAlign"},{"location":"imageSegmentation/section4/#121","text":"FasterRCNN\u4e2d\u7684ROIPooling\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a \u5b83\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78=20x20\uff0c\u56e0\u4e3a\u5750\u6807\u8981\u4fdd\u7559\u6574\u6570\u6240\u4ee5\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e00\u4e2a\u91cf\u5316\u8bef\u5dee\u5373\u820d\u5f03\u4e86\u76ee\u6807\u6846\u5728\u7279\u5f81\u56fe\u4e0a\u5bf9\u5e94\u957f\u5bbd\u7684\u6d6e\u70b9\u6570\u90e8\u5206\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20x20\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u6839\u636eROI Pooling\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u5176\u7ed3\u679c\u5c31\u662f20/7x20/7=2.86x2.86\uff0c\u540c\u6837\u6267\u884c\u53d6\u6574\u64cd\u4f5c\u64cd\u4f5c\u540eROI\u7279\u5f81\u533a\u57df\u7684\u5c3a\u5bf8\u4e3a2x2\uff0c\u8fd9\u91cc\u5f15\u5165\u4e86\u7b2c\u4e8c\u6b21\u91cf\u5316\u8bef\u5dee\u3002 \u4ece\u4e0a\u9762\u7684\u5206\u6790\u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u4e24\u6b21\u91cf\u5316\u8bef\u5dee\u4f1a\u5bfc\u81f4\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u548c\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u8fdb\u884c\u5bf9\u5e94\u65f6\u51fa\u73b0\u504f\u5dee\uff0c\u4f8b\u5982\u4e0a\u9762\u5c062.86\u91cf\u5316\u4e3a2\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e860.86\u7684\u504f\u5dee\uff0c\u8fd9\u4e2a\u504f\u5dee\u6620\u5c04\u56de\u539f\u56fe\u5c31\u662f0.86x32=27.52\uff0c\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u50cf\u7d20\u504f\u5dee\u662f\u5f88\u5927\u7684\uff0c\u800c\u4e14\u8fd9\u4ec5\u4ec5\u8003\u8651\u4e86\u7b2c\u4e8c\u6b21\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u6240\u4ee5\u8fd9\u4f1a\u5f71\u54cd\u6574\u4e2a\u7b97\u6cd5\u7684\u6027\u80fd\u3002 \u4e3a\u4e86\u7f13\u89e3ROI Pooling\u91cf\u5316\u8bef\u5dee\u8fc7\u5927\u7684\u95ee\u9898\uff0cMaskRCNN\u63d0\u51fa\u4e86ROIAlign\uff0cROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c\u3002\u8fd9\u4e00\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9488\u5bf9\u4e0a\u56fe\u7684\u6d41\u7a0b\u662f\uff1a \u8f93\u5165\u56fe\u7247\u7684\u5927\u5c0f\u4e3a800x800\uff0c\u5176\u4e2d\u72d7\u8fd9\u4e2a\u76ee\u6807\u6846\u7684\u5927\u5c0f\u4e3a665x665\uff0c\u7ecf\u8fc7VGG16\u7f51\u7edc\u4e4b\u540e\u83b7\u5f97\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a800/32x800/32=25x25\uff0c\u5176\u4e2d32\u4ee3\u8868VGG16\u4e2d\u76845\u6b21\u4e0b\u91c7\u6837\uff08\u6b65\u957f\u4e3a2\uff09\u64cd\u4f5c\u3002\u90a3\u4e48\uff0c\u5bf9\u4e8e\u72d7\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u5c06\u5176\u5bf9\u5e94\u5230\u7279\u5f81\u56fe\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u662f665/32x665/32=20.78x20.78\uff0c\u6b64\u65f6\uff0c\u6ca1\u6709\u50cfRoiPooling\u90a3\u6837\u5c31\u884c\u53d6\u6574\u64cd\u4f5c\uff0c\u800c\u662f\u4fdd\u7559\u6d6e\u70b9\u6570\u3002 \u63a5\u4e0b\u6765\u9700\u8981\u5c06\u8fd9\u4e2a20.78x20.78\u7684ROI\u533a\u57df\u6620\u5c04\u4e3a7x7\u7684ROI\u7279\u5f81\u56fe\uff0c\u7ed3\u679c\u5c31\u662f20.78/7x20.78/7=2.97x2.97\uff0c\u5373\u6bcf\u4e2a\u5c0f\u533a\u57df\u7684\u5927\u5c0f\u4e3a2.97x2.97\u3002 \u5047\u5b9a\u6bcf\u4e2a\u5c0f\u533a\u57df\u91c7\u6837\u70b9\u6570\u4e3a4\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u6bcf\u4e2a2.97*2.97\u7684\u5c0f\u533a\u57df\uff0c\u5e73\u5206\u56db\u4efd\uff0c\u6bcf\u4e00\u4efd\u53d6\u5176\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\uff0c\u800c\u4e2d\u5fc3\u70b9\u4f4d\u7f6e\u7684\u50cf\u7d20\uff0c\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u6cd5\u8fdb\u884c\u8ba1\u7b97\uff0c\u8fd9\u6837\uff0c\u5c31\u4f1a\u5f97\u5230\u56db\u4e2a\u70b9\u7684\u50cf\u7d20\u503c\uff0c\u5982\u4e0b\u56fe\uff1a \u4e0a\u56fe\u4e2d\uff0c\u56db\u4e2a\u7ea2\u8272\u53c9\u53c9\u2018\u00d7\u2019\u7684\u50cf\u7d20\u503c\u662f\u901a\u8fc7\u53cc\u7ebf\u6027\u63d2\u503c\u7b97\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684\u3002 \u6700\u540e\uff0c\u53d6\u56db\u4e2a\u50cf\u7d20\u503c\u4e2d\u6700\u5927\u503c\uff08\u6700\u5927\u6c60\u5316\uff09\u4f5c\u4e3a\u8fd9\u4e2a\u5c0f\u533a\u57df(\u5373\uff1a2.97x2.97\u5927\u5c0f\u7684\u533a\u57df)\u7684\u50cf\u7d20\u503c\uff0c\u5982\u6b64\u7c7b\u63a8\uff0c\u540c\u6837\u662f49\u4e2a\u5c0f\u533a\u57df\u5f97\u523049\u4e2a\u50cf\u7d20\u503c\uff0c\u7ec4\u62107x7\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002 \u53cc\u7ebf\u6027\u63d2\u503c\u662f\u4e00\u79cd\u56fe\u50cf\u7f29\u653e\u586b\u5145\u7b97\u6cd5\uff0c\u5b83\u5145\u5206\u7684\u5229\u7528\u4e86\u539f\u56fe\u4e2d\u865a\u62df\u70b9\uff08\u6bd4\u598220.56\u8fd9\u4e2a\u6d6e\u70b9\u6570\uff0c\u50cf\u7d20\u4f4d\u7f6e\u4e0d\u662f\u6574\u6570\u503c\uff0c\u800c\u662f\u6d6e\u70b9\u503c\uff09\u56db\u5468\u7684\u771f\u5b9e\u5b58\u5728\u7684\u50cf\u7d20\u503c\u6765\u5171\u540c\u51b3\u5b9a\u76ee\u6807\u56fe\u4e2d\u7684\u4e00\u4e2a\u50cf\u7d20\u503c\uff0c\u5373\u53ef\u4ee5\u5c0620.56\u8fd9\u4e2a\u865a\u62df\u7684\u4f4d\u7f6e\u70b9\u5bf9\u5e94\u7684\u50cf\u7d20\u503c\u4f30\u8ba1\u51fa\u6765\u3002","title":"1.2.1 \u539f\u7406\u4ecb\u7ecd"},{"location":"imageSegmentation/section4/#122","text":"\u5728tensorFlow\u4e2d\u5b9e\u73b0\u65f6\u4f7f\u7528\uff1a tf . image . crop_and_resize ( image , boxes , box_indices , crop_size , method = 'bilinear' , extrapolation_value = 0 , name = None ) \u53c2\u6570\u4ecb\u7ecd\uff1a image: \u8868\u793a\u7279\u5f81\u56fe boxes\uff1a\u6307\u9700\u8981\u5212\u5206\u7684ROI\u533a\u57df\uff0c\u8f93\u5165\u683c\u5f0f\u4e3a[ymin\uff0cxmin\uff0cymax\uff0cxmax]\uff0c\u6ce8\u610f\u662f\u5f52\u4e00\u5316\u7684\u7ed3\u679c\u3002 \u5047\u8bbe\u5019\u9009\u533a\u57df\u5750\u6807\u662f[y1,x1,y2,x2]\uff0c\u90a3\u4e48\u60f3\u8981\u5f97\u5230\u76f8\u5e94\u6b63\u786e\u7684crop\u56fe\u5f62\u5c31\u4e00\u5b9a\u8981\u5f52\u4e00\u5316,\u5373\u56fe\u7247\u7684\u957f\u5ea6\u662f[w,h],\u5219\u5b9e\u9645\u8f93\u5165\u7684boxes\u4e3a[y1/h,x1/w,y2/h,x2/w]\uff0c\u8d85\u51fa1\u7684\u90e8\u5206\u4f7f\u7528\u9ed1\u82720\u8fdb\u884c\u586b\u5145\u3002 box_indice: \u662fboxes\u548cimage\u4e4b\u95f4\u7684\u7d22\u5f15\uff0c\u5373box\u5bf9\u5e94\u7684\u56fe\u50cf\u7d22\u5f15 crop_size: \u8868\u793aRoiAlign\u4e4b\u540e\u7684\u5019\u9009\u533a\u57df\u7684\u5927\u5c0f\u3002 method\uff1a\u63d2\u503c\u65b9\u6cd5\uff0c\u9ed8\u8ba4\u662f\u53cc\u7ebf\u6027\u63d2\u503c \u4e0b\u9762\u6211\u4eec\u5229\u7528\u4e24\u5f20\u56fe\u7247\u770b\u4e0bROIAlign\u7684\u6548\u679c\uff1a \u5bfc\u5165\u5de5\u5177\u5305 import tensorflow as tf import matplotlib.pyplot as plt \u539f\u56fe\u50cf\u8bfb\u53d6\u548c\u5c55\u793a # \u56fe\u50cf\u8bfb\u53d6 img = plt . imread ( 'Trump.jpg' ) / 255. img2 = plt . imread ( 'Trump2.jpg' ) / 255. # \u56fe\u50cf\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) plt . subplot ( 1 , 2 , 1 ) plt . imshow ( img ) plt . subplot ( 1 , 2 , 2 ) plt . imshow ( img2 ) \u6784\u5efabatch_size\u6570\u636e\uff08batch_size=2\uff09 # \u5bf9\u56fe\u50cf\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u5e76\u6dfb\u52a0batch\u7ef4 img = tf . convert_to_tensor ( img , dtype = tf . float32 ) img = tf . expand_dims ( img , axis = 0 ) img = tf . image . resize ( img , ( 500 , 500 )) img2 = tf . convert_to_tensor ( img2 , dtype = tf . float32 ) img2 = tf . expand_dims ( img2 , axis = 0 ) img2 = tf . image . resize ( img2 , ( 500 , 500 )) # \u5c06\u4e24\u4e2a\u56fe\u50cf\u62fc\u63a5\u5728\u4e00\u8d77 img = tf . concat ([ img , img2 ], axis = 0 ) print ( 'img:' , img . shape ) \u8f93\u51fa\u4e3a\uff1a img : ( 2 , 500 , 500 , 3 ) \u4e00\u4e2abatch\u4e2d\u5305\u542b2\u4e2a\u56fe\u50cf\uff0c\u6bcf\u4e2a\u56fe\u50cf\u7684\u5927\u5c0f\u4e3a500x500x3\uff0c\u7406\u89e3\u4e3a\u4e24\u4e2a\u7279\u5f81\u56fe ROIAlign # \u8fdb\u884cROIAlign\u5904\u7406\uff1a\u7279\u5f81\u56fe\uff0c2\u4e2aboxes\uff0c\u5206\u522b\u5bf9\u5e94\u56fe\u50cf\u7d22\u5f150\u548c1\uff0cROIAlign\u540e\u7684\u5927\u5c0f\u4e3a50x50 out = tf . image . crop_and_resize ( img , [[ 0.5 , 0.5 , 1.0 , 1.0 ], [ 0.5 , 0.5 , 1.5 , 1.5 ]], [ 0 , 1 ], crop_size = ( 50 , 50 )) print ( 'out:' , a . shape ) \u8f93\u51fa\u4e3a\uff1a out : ( 2 , 50 , 50 , 3 ) \u6548\u679c\u5c55\u793a plt . figure ( figsize = ( 10 , 8 )) # \u5c3a\u5bf8\u8c03\u6574\u540e\u7684\u56fe\u50cf plt . subplot ( 2 , 2 , 1 ) plt . imshow ( img [ 0 ]) plt . subplot ( 2 , 2 , 2 ) plt . imshow ( img [ 1 ]) # ROIAlign\u7684\u7ed3\u679c plt . subplot ( 2 , 2 , 3 ) plt . imshow ( a [ 0 ]) plt . subplot ( 2 , 2 , 4 ) plt . imshow ( a [ 1 ]) plt . show ()","title":"1.2.2 \u5b9e\u73b0\u6548\u679c"},{"location":"imageSegmentation/section4/#13","text":"\u4e0a\u8ff0\u5df2\u7ecf\u4ecb\u7ecd\u4e86Mask-RCNN \u7684\u7ed3\u6784\u4e0eFasterRCNN\u662f\u76f8\u540c\u7684\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u5272\u7684\u5934\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9aa8\u5e72\u7f51\u7edcResNet-FPN\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\uff0cRPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u63d0\u53d6\uff0cROIAlign\u83b7\u53d6\u56fa\u5b9a\u5927\u5c0f\u7684\u7279\u5f81\u56fe\uff0c\u5934\u90e8\u7f51\u7edc\u5305\u62ec\u8fb9\u754c\u6846\u8bc6\u522b\uff08\u5206\u7c7b\u548c\u56de\u5f52\uff09+mask\u9884\u6d4b\uff0c\u5177\u4f53\u5982\u4e0b\u6240\u793a\uff1a mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u5b9e\u9645\u5de5\u4f5c\u4e2d\u6211\u4eec\u4f7f\u7528\u53f3\u56fe\u8f83\u591a\u4e00\u4e9b\uff0c\u5176\u4e2d\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837\u3002\u9884\u6d4b\u65f6 mask \u5206\u652f\u8f93\u51fa\u7ed3\u679c resize \u5230 RoI \u7684\u5927\u5c0f, \u7136\u540e\u5e94\u7528 0.5 \u7684\u9608\u503c\u8fdb\u884c\u4e8c\u503c\u5316\u5f97\u5230\u6700\u7ec8\u7684\u5206\u5272\u7ed3\u679c\u3002","title":"1.3 \u7f51\u7edc\u7ed3\u6784"},{"location":"imageSegmentation/section4/#14","text":"Mask-RCNN\u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u591a\u4e86\u4e00\u4e2aROIAligin\u548cMask\u9884\u6d4b\u5206\u652f\uff0c\u56e0\u6b64Mask R-CNN\u7684\u635f\u5931\u4e5f\u662f\u591a\u4efb\u52a1\u635f\u5931\uff1a L_{cls} L_{cls} \u548c L_{box} L_{box} \u4e0efaster rcnn\u7684\u5b9a\u4e49\u6ca1\u6709\u533a\u522b\u3002\u5177\u4f53\u6765\u770b\u4e0b L_{mask} L_{mask} \u3002 Mask\u5206\u652f\u5bf9\u6bcf\u4e2aROI\u533a\u57df\u4ea7\u751f\u4e00\u4e2amxmxK\u7684\u8f93\u51fa\u7279\u5f81\u56fe\uff0c\u5373K\u4e2a\u7684\u4e8c\u503c\u63a9\u819c\u56fe\u50cf\uff0c\u5176\u4e2dK\u4ee3\u8868\u76ee\u6807\u79cd\u7c7b\u6570\u3002\u5bf9\u4e8e\u9884\u6d4b\u7684\u4e8c\u503c\u63a9\u819c\u8f93\u51fa\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\u70b9\u5e94\u7528 sigmoid \u51fd\u6570\uff0c\u6574\u4f53\u635f\u5931\u5b9a\u4e49\u4e3a\u5e73\u5747\u4e8c\u503c\u4ea4\u53c9\u635f\u5931\u71b5\u3002\u5bf9\u4e8e\u771f\u5b9e\u7c7b\u522b\u4e3a\ud835\udc58\u7684\ud835\udc45\ud835\udc5c\ud835\udc3c\uff0c\u4ec5\u5728\u7b2ck\u4e2a\u63a9\u7801\u4e0a\u8ba1\u7b97\u635f\u5931\uff08\u5176\u4ed6\u63a9\u7801\u8f93\u51fa\u4e0d\u8ba1\u5165\uff09\u3002\u8fd9\u6837\u505a\u89e3\u8026\u4e86\u63a9\u819c\u548c\u79cd\u7c7b\u9884\u6d4b\u3002 \u4e0d\u50cfFCN\u7684\u505a\u6cd5\uff0c\u5728\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e0a\u5e94\u7528 softmax \u51fd\u6570\uff0c\u6574\u4f53\u91c7\u7528\u7684\u591a\u4efb\u52a1\u4ea4\u53c9\u71b5\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u7c7b\u95f4\u7ade\u4e89\uff0c\u6700\u7ec8\u5bfc\u81f4\u5206\u5272\u6548\u679c\u5dee\u3002 \u603b\u7ed3 \u8bf4\u660eMask RCNN\u7684\u7ed3\u6784\u7279\u70b9 \u5728Faster-RCNN\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u5206\u652f\uff0c\u5728\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u7684\u540c\u65f6\u5206\u5272\u76ee\u6807\u50cf\u7d20 \u638c\u63e1Mask RCNN\u7684RoIAlign\u65b9\u6cd5 ROIAlign\u6ca1\u6709\u4f7f\u7528\u91cf\u5316\u64cd\u4f5c\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u4f30\u8ba1\u975e\u6574\u6570\u70b9\u7684\u50cf\u7d20\u503c \u638c\u63e1Mask RCNN\u7684mask\u539f\u7406 mask\u5206\u652f\u662f\u4e00\u4e2a\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u4f7f\u75282x2\u7684\u53cd\u5377\u79ef\u8fdb\u884c\u4e0a\u91c7\u6837 \u77e5\u9053Mask RCNN\u7684\u635f\u5931\u51fd\u6570 \u591a\u4efb\u52a1\u635f\u5931\u51fd\u6570\uff1a\u6709\u5206\u7c7b\uff0c\u56de\u5f52\u548c\u5206\u5272\u4e09\u90e8\u5206\u7ec4\u6210","title":"1.4 \u635f\u5931\u51fd\u6570"},{"location":"introduction/","text":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb \u00b6","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb"},{"location":"introduction/#_1","text":"","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb"},{"location":"introduction/section1/","text":"\u6df1\u5ea6\u5b66\u4e60 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u573a\u666f 1.\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 \u00b6 \u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u4eba\u5de5\u667a\u80fd\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a \u673a\u5668\u5b66\u4e60\u662f\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u79cd\u9014\u5f84\uff0c\u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u4eff\u4eba\u7c7b\u5927\u8111\u7684\u8fd0\u884c\u65b9\u5f0f\uff0c\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u83b7\u53d6\u77e5\u8bc6\u3002\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6df1\u5ea6\u5b66\u4e60\u7684\u4e3b\u8981\u5e94\u7528\u9886\u57df\u6709\uff1a \u667a\u80fd\u624b\u673a \u8bed\u97f3\u8bc6\u522b \u6bd4\u5982\u82f9\u679c\u7684\u667a\u80fd\u8bed\u97f3\u52a9\u624bsiri \u673a\u5668\u7ffb\u8bd1 \u8c37\u6b4c\u5c06\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5d4c\u5165\u5230\u8c37\u6b4c\u7ffb\u8bd1\u4e2d\uff0c\u80fd\u591f\u652f\u6301100\u591a\u79cd\u8bed\u8a00\u7684\u5373\u65f6\u7ffb\u8bd1\u3002 \u62cd\u7167\u7ffb\u8bd1 \u81ea\u52a8\u9a7e\u9a76 \u5f53\u7136\u5728\u5176\u4ed6\u9886\u57df\u4e5f\u80fd\u89c1\u5230\u6df1\u5ea6\u5b66\u4e60\u7684\u8eab\u5f71\uff0c\u6bd4\u5982\u98ce\u63a7\uff0c\u5b89\u9632\uff0c\u667a\u80fd\u96f6\u552e\uff0c\u533b\u7597\u9886\u57df\uff0c\u63a8\u8350\u7cfb\u7edf\u7b49\u3002 \u5728\u8be5\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\uff1a \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u7684\u5e94\u7528 \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4e24\u90e8\u5206\u5185\u5bb9\u3002 2 \u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u5176\u5b9e\u5e76\u4e0d\u662f\u65b0\u7684\u4e8b\u7269\uff0c\u6df1\u5ea6\u5b66\u4e60\u6240\u9700\u8981\u7684\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u8d77\u6e90\u4e8e20\u4e16\u7eaa50\u5e74\u4ee3\uff0c\u53eb\u505a\u611f\u77e5\u673a\u3002\u5f53\u65f6\u4e5f\u901a\u5e38\u4f7f\u7528\u5355\u5c42\u611f\u77e5\u673a\uff0c\u5c3d\u7ba1\u7ed3\u6784\u7b80\u5355\uff0c\u4f46\u662f\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u95ee\u9898\u3002\u540e\u6765\u611f\u77e5\u673a\u88ab\u8bc1\u660e\u5b58\u5728\u4e25\u91cd\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u53ea\u80fd\u5b66\u4e60\u7ebf\u6027\u53ef\u5206\u51fd\u6570\uff0c\u8fde\u7b80\u5355\u7684\u5f02\u6216(XOR)\u7b49\u7ebf\u6027\u4e0d\u53ef\u5206\u95ee\u9898\u90fd\u65e0\u80fd\u4e3a\u529b\uff0c1969\u5e74Marvin Minsky\u5199\u4e86\u4e00\u672c\u53eb\u505a\u300aPerceptrons\u300b\u7684\u4e66\uff0c\u4ed6\u63d0\u51fa\u4e86\u8457\u540d\u7684\u4e24\u4e2a\u89c2\u70b9\uff1a1.\u5355\u5c42\u611f\u77e5\u673a\u6ca1\u7528\uff0c\u6211\u4eec\u9700\u8981\u591a\u5c42\u611f\u77e5\u673a\u6765\u89e3\u51b3\u590d\u6742\u95ee\u9898 2.\u6ca1\u6709\u6709\u6548\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002 20\u4e16\u7eaa80\u5e74\u4ee3\u672b\u671f\uff0c\u7528\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08\u4e5f\u53ebBack Propagation\u7b97\u6cd5\u6216\u8005BP\u7b97\u6cd5\uff09\u7684\u53d1\u660e\uff0c\u7ed9\u673a\u5668\u5b66\u4e60\u5e26\u6765\u4e86\u5e0c\u671b\uff0c\u6380\u8d77\u4e86\u57fa\u4e8e\u7edf\u8ba1\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u70ed\u6f6e\u3002\u8fd9\u4e2a\u70ed\u6f6e\u4e00\u76f4\u6301\u7eed\u5230\u4eca\u5929\u3002\u4eba\u4eec\u53d1\u73b0\uff0c\u5229\u7528BP\u7b97\u6cd5\u53ef\u4ee5\u8ba9\u4e00\u4e2a\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4ece\u5927\u91cf\u8bad\u7ec3\u6837\u672c\u4e2d\u5b66\u4e60\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4ece\u800c\u5bf9\u672a\u77e5\u4e8b\u4ef6\u505a\u9884\u6d4b\u3002\u8fd9\u79cd\u57fa\u4e8e\u7edf\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8d77\u8fc7\u53bb\u57fa\u4e8e\u4eba\u5de5\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u5728\u5f88\u591a\u65b9\u9762\u663e\u51fa\u4f18\u8d8a\u6027\u3002\u8fd9\u4e2a\u65f6\u5019\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u867d\u4e5f\u88ab\u79f0\u4f5c\u591a\u5c42\u611f\u77e5\u673a\uff08Multi-layer Perceptron\uff09\uff0c\u4f46\u5b9e\u9645\u662f\u79cd\u53ea\u542b\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\u7684\u6d45\u5c42\u6a21\u578b\u3002 20\u4e16\u7eaa90\u5e74\u4ee3\uff0c\u5404\u79cd\u5404\u6837\u7684\u6d45\u5c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76f8\u7ee7\u88ab\u63d0\u51fa\uff0c\u4f8b\u5982\u652f\u6491\u5411\u91cf\u673a\uff08SVM\uff0cSupport Vector Machines\uff09\u3001 Boosting\u3001\u6700\u5927\u71b5\u65b9\u6cd5\uff08\u5982LR\uff0cLogistic Regression\uff09\u7b49\u3002\u8fd9\u4e9b\u6a21\u578b\u7684\u7ed3\u6784\u57fa\u672c\u4e0a\u53ef\u4ee5\u770b\u6210\u5e26\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\uff08\u5982SVM\u3001Boosting\uff09\uff0c\u6216\u6ca1\u6709\u9690\u5c42\u8282\u70b9\uff08\u5982LR\uff09\u3002\u8fd9\u4e9b\u6a21\u578b\u65e0\u8bba\u662f\u5728\u7406\u8bba\u5206\u6790\u8fd8\u662f\u5e94\u7528\u4e2d\u90fd\u83b7\u5f97\u4e86\u5de8\u5927\u7684\u6210\u529f\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u7531\u4e8e\u7406\u8bba\u5206\u6790\u7684\u96be\u5ea6\u5927\uff0c\u8bad\u7ec3\u65b9\u6cd5\u53c8\u9700\u8981\u5f88\u591a\u7ecf\u9a8c\u548c\u6280\u5de7\uff0c\u8fd9\u4e2a\u65f6\u671f\u6d45\u5c42\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53cd\u800c\u76f8\u5bf9\u6c89\u5bc2. 2006\u5e74\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u4ee5\u53ca\u4ed6\u7684\u5b66\u751f\u9c81\u65af\u5170\u00b7\u8428\u62c9\u8d6b\u4e01\u8bfa\u592b\u6b63\u5f0f\u63d0\u51fa\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u5ff5\u3002\u4ed6\u4eec\u5728\u4e16\u754c\u9876\u7ea7\u5b66\u672f\u671f\u520a\u300a\u79d1\u5b66\u300b\u53d1\u8868\u7684\u4e00\u7bc7\u6587\u7ae0\u4e2d\u8be6\u7ec6\u7684\u7ed9\u51fa\u4e86\u201c\u68af\u5ea6\u6d88\u5931\u201d\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u2014\u2014\u901a\u8fc7\u65e0\u76d1\u7763\u7684\u5b66\u4e60\u65b9\u6cd5\u9010\u5c42\u8bad\u7ec3\u7b97\u6cd5\uff0c\u518d\u4f7f\u7528\u6709\u76d1\u7763\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u8fdb\u884c\u8c03\u4f18\u3002\u8be5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u63d0\u51fa\uff0c\u7acb\u5373\u5728\u5b66\u672f\u5708\u5f15\u8d77\u4e86\u5de8\u5927\u7684\u53cd\u54cd\uff0c\u4ee5\u65af\u5766\u798f\u5927\u5b66\u3001\u591a\u4f26\u591a\u5927\u5b66\u4e3a\u4ee3\u8868\u7684\u4f17\u591a\u4e16\u754c\u77e5\u540d\u9ad8\u6821\u7eb7\u7eb7\u6295\u5165\u5de8\u5927\u7684\u4eba\u529b\u3001\u8d22\u529b\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u76f8\u5173\u7814\u7a76\u3002\u800c\u540e\u53c8\u8fc5\u901f\u8513\u5ef6\u5230\u5de5\u4e1a\u754c\u4e2d\u3002 2012\u5e74\uff0c\u5728\u8457\u540d\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u5927\u8d5b\u4e2d\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u9886\u5bfc\u7684\u5c0f\u7ec4\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bAlexNet\u4e00\u4e3e\u593a\u51a0\u3002AlexNet\u91c7\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5e76\u91c7\u7528GPU\u6781\u5927\u7684\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8fd0\u7b97\u901f\u5ea6\u3002\u540c\u5e74\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u8457\u540d\u7684\u5434\u6069\u8fbe\u6559\u6388\u548c\u4e16\u754c\u9876\u5c16\u8ba1\u7b97\u673a\u4e13\u5bb6Jeff Dean\u5171\u540c\u4e3b\u5bfc\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u2014\u2014DNN\u6280\u672f\u5728\u56fe\u50cf\u8bc6\u522b\u9886\u57df\u53d6\u5f97\u4e86\u60ca\u4eba\u7684\u6210\u7ee9\uff0c\u5728ImageNet\u8bc4\u6d4b\u4e2d\u6210\u529f\u7684\u628a\u9519\u8bef\u7387\u4ece26\uff05\u964d\u4f4e\u5230\u4e8615\uff05\u3002\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u4e16\u754c\u5927\u8d5b\u7684\u8131\u9896\u800c\u51fa\uff0c\u4e5f\u518d\u4e00\u6b21\u5438\u5f15\u4e86\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u5173\u6ce8\u3002 2016\u5e74\uff0c\u968f\u7740\u8c37\u6b4c\u516c\u53f8\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u7684AlphaGo\u4ee54:1\u7684\u6bd4\u5206\u6218\u80dc\u4e86\u56fd\u9645\u9876\u5c16\u56f4\u68cb\u9ad8\u624b\u674e\u4e16\u77f3\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u70ed\u5ea6\u4e00\u65f6\u65e0\u4e24\u3002\u540e\u6765\uff0cAlphaGo\u53c8\u63a5\u8fde\u548c\u4f17\u591a\u4e16\u754c\u7ea7\u56f4\u68cb\u9ad8\u624b\u8fc7\u62db\uff0c\u5747\u53d6\u5f97\u4e86\u5b8c\u80dc\u3002\u8fd9\u4e5f\u8bc1\u660e\u4e86\u5728\u56f4\u68cb\u754c\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u673a\u5668\u4eba\u5df2\u7ecf\u8d85\u8d8a\u4e86\u4eba\u7c7b\u3002 2017\u5e74\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684AlphaGo\u5347\u7ea7\u7248AlphaGo Zero\u6a2a\u7a7a\u51fa\u4e16\u3002\u5176\u91c7\u7528\u201c\u4ece\u96f6\u5f00\u59cb\u201d\u3001\u201c\u65e0\u5e08\u81ea\u901a\u201d\u7684\u5b66\u4e60\u6a21\u5f0f\uff0c\u4ee5100:0\u7684\u6bd4\u5206\u8f7b\u800c\u6613\u4e3e\u6253\u8d25\u4e86\u4e4b\u524d\u7684AlphaGo\u3002\u9664\u4e86\u56f4\u68cb\uff0c\u5b83\u8fd8\u7cbe\u901a\u56fd\u9645\u8c61\u68cb\u7b49\u5176\u5b83\u68cb\u7c7b\u6e38\u620f\uff0c\u53ef\u4ee5\u8bf4\u662f\u771f\u6b63\u7684\u68cb\u7c7b\u201c\u5929\u624d\u201d\u3002\u6b64\u5916\u5728\u8fd9\u4e00\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u76f8\u5173\u7b97\u6cd5\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u827a\u672f\u3001\u65e0\u4eba\u9a7e\u9a76\u7b49\u591a\u4e2a\u9886\u57df\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002\u6240\u4ee5\uff0c\u4e5f\u6709\u4e13\u5bb6\u628a2017\u5e74\u770b\u4f5c\u662f\u6df1\u5ea6\u5b66\u4e60\u751a\u81f3\u662f\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u6700\u4e3a\u7a81\u98de\u731b\u8fdb\u7684\u4e00\u5e74\u3002 2019\u5e74\uff0c\u57fa\u4e8eTransformer \u7684\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u589e\u957f\u548c\u6269\u6563\uff0c\u8fd9\u662f\u4e00\u79cd\u8bed\u8a00\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u4e0a\u63d0\u9ad8NLP\u7684\u8d28\u91cf\u3002Google\u751a\u81f3\u5c06\u5176\u7528\u4f5c\u76f8\u5173\u6027\u7684\u4e3b\u8981\u4fe1\u53f7\u4e4b\u4e00\uff0c\u8fd9\u662f\u591a\u5e74\u6765\u6700\u91cd\u8981\u7684\u66f4\u65b0 2020\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u6269\u5c55\u5230\u66f4\u591a\u7684\u5e94\u7528\u573a\u666f\uff0c\u6bd4\u5982\u79ef\u6c34\u8bc6\u522b\uff0c\u8def\u9762\u584c\u9677\u7b49\uff0c\u800c\u4e14\u75ab\u60c5\u671f\u95f4\uff0c\u5728\u667a\u80fd\u5916\u547c\u7cfb\u7edf\uff0c\u4eba\u7fa4\u6d4b\u6e29\u7cfb\u7edf\uff0c\u53e3\u7f69\u4eba\u8138\u8bc6\u522b\u7b49\u90fd\u6709\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u3002 \u603b\u7ed3 \u6df1\u5ea6\u5b66\u4e60\u662f\u4ec0\u4e48 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e00\u79cd\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u8111\u5b9e\u73b0\u76f8\u5e94\u7684\u529f\u80fd \u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u573a\u666f \u624b\u673a\uff0c\u673a\u5668\u7ffb\u8bd1\uff0c\u81ea\u52a8\u9a7e\u9a76\uff0c\u8bed\u97f3\u8bc6\u522b\uff0c\u533b\u7597\uff0c\u5b89\u9632\u7b49\u3002","title":"\u6df1\u5ea6\u5b66\u4e60"},{"location":"introduction/section1/#_1","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 \u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u573a\u666f","title":"\u6df1\u5ea6\u5b66\u4e60"},{"location":"introduction/section1/#1","text":"\u5728\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u4e0b\u4eba\u5de5\u667a\u80fd\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a \u673a\u5668\u5b66\u4e60\u662f\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u79cd\u9014\u5f84\uff0c\u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u5b50\u96c6\uff0c\u4e5f\u5c31\u662f\u8bf4\u6df1\u5ea6\u5b66\u4e60\u662f\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u672f\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9700\u8981\u4eba\u5de5\uff0c\u800c\u662f\u4f9d\u8d56\u7b97\u6cd5\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u4eff\u4eba\u7c7b\u5927\u8111\u7684\u8fd0\u884c\u65b9\u5f0f\uff0c\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u83b7\u53d6\u77e5\u8bc6\u3002\u8fd9\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u88ab\u770b\u505a\u9ed1\u76d2\u5b50\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u539f\u56e0\u3002 \u968f\u7740\u8ba1\u7b97\u673a\u8f6f\u786c\u4ef6\u7684\u98de\u901f\u53d1\u5c55\uff0c\u73b0\u9636\u6bb5\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6765\u6a21\u62df\u4eba\u8111\u6765\u89e3\u91ca\u6570\u636e\uff0c\u5305\u62ec\u56fe\u50cf\uff0c\u6587\u672c\uff0c\u97f3\u9891\u7b49\u5185\u5bb9\u3002\u76ee\u524d\u6df1\u5ea6\u5b66\u4e60\u7684\u4e3b\u8981\u5e94\u7528\u9886\u57df\u6709\uff1a \u667a\u80fd\u624b\u673a \u8bed\u97f3\u8bc6\u522b \u6bd4\u5982\u82f9\u679c\u7684\u667a\u80fd\u8bed\u97f3\u52a9\u624bsiri \u673a\u5668\u7ffb\u8bd1 \u8c37\u6b4c\u5c06\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5d4c\u5165\u5230\u8c37\u6b4c\u7ffb\u8bd1\u4e2d\uff0c\u80fd\u591f\u652f\u6301100\u591a\u79cd\u8bed\u8a00\u7684\u5373\u65f6\u7ffb\u8bd1\u3002 \u62cd\u7167\u7ffb\u8bd1 \u81ea\u52a8\u9a7e\u9a76 \u5f53\u7136\u5728\u5176\u4ed6\u9886\u57df\u4e5f\u80fd\u89c1\u5230\u6df1\u5ea6\u5b66\u4e60\u7684\u8eab\u5f71\uff0c\u6bd4\u5982\u98ce\u63a7\uff0c\u5b89\u9632\uff0c\u667a\u80fd\u96f6\u552e\uff0c\u533b\u7597\u9886\u57df\uff0c\u63a8\u8350\u7cfb\u7edf\u7b49\u3002 \u5728\u8be5\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\uff1a \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u7684\u5e94\u7528 \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4e24\u90e8\u5206\u5185\u5bb9\u3002","title":"1.\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60"},{"location":"introduction/section1/#2","text":"\u6df1\u5ea6\u5b66\u4e60\u5176\u5b9e\u5e76\u4e0d\u662f\u65b0\u7684\u4e8b\u7269\uff0c\u6df1\u5ea6\u5b66\u4e60\u6240\u9700\u8981\u7684\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u8d77\u6e90\u4e8e20\u4e16\u7eaa50\u5e74\u4ee3\uff0c\u53eb\u505a\u611f\u77e5\u673a\u3002\u5f53\u65f6\u4e5f\u901a\u5e38\u4f7f\u7528\u5355\u5c42\u611f\u77e5\u673a\uff0c\u5c3d\u7ba1\u7ed3\u6784\u7b80\u5355\uff0c\u4f46\u662f\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u95ee\u9898\u3002\u540e\u6765\u611f\u77e5\u673a\u88ab\u8bc1\u660e\u5b58\u5728\u4e25\u91cd\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u53ea\u80fd\u5b66\u4e60\u7ebf\u6027\u53ef\u5206\u51fd\u6570\uff0c\u8fde\u7b80\u5355\u7684\u5f02\u6216(XOR)\u7b49\u7ebf\u6027\u4e0d\u53ef\u5206\u95ee\u9898\u90fd\u65e0\u80fd\u4e3a\u529b\uff0c1969\u5e74Marvin Minsky\u5199\u4e86\u4e00\u672c\u53eb\u505a\u300aPerceptrons\u300b\u7684\u4e66\uff0c\u4ed6\u63d0\u51fa\u4e86\u8457\u540d\u7684\u4e24\u4e2a\u89c2\u70b9\uff1a1.\u5355\u5c42\u611f\u77e5\u673a\u6ca1\u7528\uff0c\u6211\u4eec\u9700\u8981\u591a\u5c42\u611f\u77e5\u673a\u6765\u89e3\u51b3\u590d\u6742\u95ee\u9898 2.\u6ca1\u6709\u6709\u6548\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002 20\u4e16\u7eaa80\u5e74\u4ee3\u672b\u671f\uff0c\u7528\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff08\u4e5f\u53ebBack Propagation\u7b97\u6cd5\u6216\u8005BP\u7b97\u6cd5\uff09\u7684\u53d1\u660e\uff0c\u7ed9\u673a\u5668\u5b66\u4e60\u5e26\u6765\u4e86\u5e0c\u671b\uff0c\u6380\u8d77\u4e86\u57fa\u4e8e\u7edf\u8ba1\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u70ed\u6f6e\u3002\u8fd9\u4e2a\u70ed\u6f6e\u4e00\u76f4\u6301\u7eed\u5230\u4eca\u5929\u3002\u4eba\u4eec\u53d1\u73b0\uff0c\u5229\u7528BP\u7b97\u6cd5\u53ef\u4ee5\u8ba9\u4e00\u4e2a\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4ece\u5927\u91cf\u8bad\u7ec3\u6837\u672c\u4e2d\u5b66\u4e60\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4ece\u800c\u5bf9\u672a\u77e5\u4e8b\u4ef6\u505a\u9884\u6d4b\u3002\u8fd9\u79cd\u57fa\u4e8e\u7edf\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8d77\u8fc7\u53bb\u57fa\u4e8e\u4eba\u5de5\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u5728\u5f88\u591a\u65b9\u9762\u663e\u51fa\u4f18\u8d8a\u6027\u3002\u8fd9\u4e2a\u65f6\u5019\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u867d\u4e5f\u88ab\u79f0\u4f5c\u591a\u5c42\u611f\u77e5\u673a\uff08Multi-layer Perceptron\uff09\uff0c\u4f46\u5b9e\u9645\u662f\u79cd\u53ea\u542b\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\u7684\u6d45\u5c42\u6a21\u578b\u3002 20\u4e16\u7eaa90\u5e74\u4ee3\uff0c\u5404\u79cd\u5404\u6837\u7684\u6d45\u5c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76f8\u7ee7\u88ab\u63d0\u51fa\uff0c\u4f8b\u5982\u652f\u6491\u5411\u91cf\u673a\uff08SVM\uff0cSupport Vector Machines\uff09\u3001 Boosting\u3001\u6700\u5927\u71b5\u65b9\u6cd5\uff08\u5982LR\uff0cLogistic Regression\uff09\u7b49\u3002\u8fd9\u4e9b\u6a21\u578b\u7684\u7ed3\u6784\u57fa\u672c\u4e0a\u53ef\u4ee5\u770b\u6210\u5e26\u6709\u4e00\u5c42\u9690\u5c42\u8282\u70b9\uff08\u5982SVM\u3001Boosting\uff09\uff0c\u6216\u6ca1\u6709\u9690\u5c42\u8282\u70b9\uff08\u5982LR\uff09\u3002\u8fd9\u4e9b\u6a21\u578b\u65e0\u8bba\u662f\u5728\u7406\u8bba\u5206\u6790\u8fd8\u662f\u5e94\u7528\u4e2d\u90fd\u83b7\u5f97\u4e86\u5de8\u5927\u7684\u6210\u529f\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u7531\u4e8e\u7406\u8bba\u5206\u6790\u7684\u96be\u5ea6\u5927\uff0c\u8bad\u7ec3\u65b9\u6cd5\u53c8\u9700\u8981\u5f88\u591a\u7ecf\u9a8c\u548c\u6280\u5de7\uff0c\u8fd9\u4e2a\u65f6\u671f\u6d45\u5c42\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53cd\u800c\u76f8\u5bf9\u6c89\u5bc2. 2006\u5e74\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u4ee5\u53ca\u4ed6\u7684\u5b66\u751f\u9c81\u65af\u5170\u00b7\u8428\u62c9\u8d6b\u4e01\u8bfa\u592b\u6b63\u5f0f\u63d0\u51fa\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u6982\u5ff5\u3002\u4ed6\u4eec\u5728\u4e16\u754c\u9876\u7ea7\u5b66\u672f\u671f\u520a\u300a\u79d1\u5b66\u300b\u53d1\u8868\u7684\u4e00\u7bc7\u6587\u7ae0\u4e2d\u8be6\u7ec6\u7684\u7ed9\u51fa\u4e86\u201c\u68af\u5ea6\u6d88\u5931\u201d\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u2014\u2014\u901a\u8fc7\u65e0\u76d1\u7763\u7684\u5b66\u4e60\u65b9\u6cd5\u9010\u5c42\u8bad\u7ec3\u7b97\u6cd5\uff0c\u518d\u4f7f\u7528\u6709\u76d1\u7763\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u8fdb\u884c\u8c03\u4f18\u3002\u8be5\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u63d0\u51fa\uff0c\u7acb\u5373\u5728\u5b66\u672f\u5708\u5f15\u8d77\u4e86\u5de8\u5927\u7684\u53cd\u54cd\uff0c\u4ee5\u65af\u5766\u798f\u5927\u5b66\u3001\u591a\u4f26\u591a\u5927\u5b66\u4e3a\u4ee3\u8868\u7684\u4f17\u591a\u4e16\u754c\u77e5\u540d\u9ad8\u6821\u7eb7\u7eb7\u6295\u5165\u5de8\u5927\u7684\u4eba\u529b\u3001\u8d22\u529b\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u76f8\u5173\u7814\u7a76\u3002\u800c\u540e\u53c8\u8fc5\u901f\u8513\u5ef6\u5230\u5de5\u4e1a\u754c\u4e2d\u3002 2012\u5e74\uff0c\u5728\u8457\u540d\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u5927\u8d5b\u4e2d\uff0c\u6770\u5f17\u91cc\u00b7\u8f9b\u987f\u9886\u5bfc\u7684\u5c0f\u7ec4\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bAlexNet\u4e00\u4e3e\u593a\u51a0\u3002AlexNet\u91c7\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5e76\u91c7\u7528GPU\u6781\u5927\u7684\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8fd0\u7b97\u901f\u5ea6\u3002\u540c\u5e74\uff0c\u7531\u65af\u5766\u798f\u5927\u5b66\u8457\u540d\u7684\u5434\u6069\u8fbe\u6559\u6388\u548c\u4e16\u754c\u9876\u5c16\u8ba1\u7b97\u673a\u4e13\u5bb6Jeff Dean\u5171\u540c\u4e3b\u5bfc\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u2014\u2014DNN\u6280\u672f\u5728\u56fe\u50cf\u8bc6\u522b\u9886\u57df\u53d6\u5f97\u4e86\u60ca\u4eba\u7684\u6210\u7ee9\uff0c\u5728ImageNet\u8bc4\u6d4b\u4e2d\u6210\u529f\u7684\u628a\u9519\u8bef\u7387\u4ece26\uff05\u964d\u4f4e\u5230\u4e8615\uff05\u3002\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u4e16\u754c\u5927\u8d5b\u7684\u8131\u9896\u800c\u51fa\uff0c\u4e5f\u518d\u4e00\u6b21\u5438\u5f15\u4e86\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u7684\u5173\u6ce8\u3002 2016\u5e74\uff0c\u968f\u7740\u8c37\u6b4c\u516c\u53f8\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u7684AlphaGo\u4ee54:1\u7684\u6bd4\u5206\u6218\u80dc\u4e86\u56fd\u9645\u9876\u5c16\u56f4\u68cb\u9ad8\u624b\u674e\u4e16\u77f3\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u70ed\u5ea6\u4e00\u65f6\u65e0\u4e24\u3002\u540e\u6765\uff0cAlphaGo\u53c8\u63a5\u8fde\u548c\u4f17\u591a\u4e16\u754c\u7ea7\u56f4\u68cb\u9ad8\u624b\u8fc7\u62db\uff0c\u5747\u53d6\u5f97\u4e86\u5b8c\u80dc\u3002\u8fd9\u4e5f\u8bc1\u660e\u4e86\u5728\u56f4\u68cb\u754c\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u673a\u5668\u4eba\u5df2\u7ecf\u8d85\u8d8a\u4e86\u4eba\u7c7b\u3002 2017\u5e74\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684AlphaGo\u5347\u7ea7\u7248AlphaGo Zero\u6a2a\u7a7a\u51fa\u4e16\u3002\u5176\u91c7\u7528\u201c\u4ece\u96f6\u5f00\u59cb\u201d\u3001\u201c\u65e0\u5e08\u81ea\u901a\u201d\u7684\u5b66\u4e60\u6a21\u5f0f\uff0c\u4ee5100:0\u7684\u6bd4\u5206\u8f7b\u800c\u6613\u4e3e\u6253\u8d25\u4e86\u4e4b\u524d\u7684AlphaGo\u3002\u9664\u4e86\u56f4\u68cb\uff0c\u5b83\u8fd8\u7cbe\u901a\u56fd\u9645\u8c61\u68cb\u7b49\u5176\u5b83\u68cb\u7c7b\u6e38\u620f\uff0c\u53ef\u4ee5\u8bf4\u662f\u771f\u6b63\u7684\u68cb\u7c7b\u201c\u5929\u624d\u201d\u3002\u6b64\u5916\u5728\u8fd9\u4e00\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u76f8\u5173\u7b97\u6cd5\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u827a\u672f\u3001\u65e0\u4eba\u9a7e\u9a76\u7b49\u591a\u4e2a\u9886\u57df\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002\u6240\u4ee5\uff0c\u4e5f\u6709\u4e13\u5bb6\u628a2017\u5e74\u770b\u4f5c\u662f\u6df1\u5ea6\u5b66\u4e60\u751a\u81f3\u662f\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u6700\u4e3a\u7a81\u98de\u731b\u8fdb\u7684\u4e00\u5e74\u3002 2019\u5e74\uff0c\u57fa\u4e8eTransformer \u7684\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u589e\u957f\u548c\u6269\u6563\uff0c\u8fd9\u662f\u4e00\u79cd\u8bed\u8a00\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u4e0a\u63d0\u9ad8NLP\u7684\u8d28\u91cf\u3002Google\u751a\u81f3\u5c06\u5176\u7528\u4f5c\u76f8\u5173\u6027\u7684\u4e3b\u8981\u4fe1\u53f7\u4e4b\u4e00\uff0c\u8fd9\u662f\u591a\u5e74\u6765\u6700\u91cd\u8981\u7684\u66f4\u65b0 2020\u5e74\uff0c\u6df1\u5ea6\u5b66\u4e60\u6269\u5c55\u5230\u66f4\u591a\u7684\u5e94\u7528\u573a\u666f\uff0c\u6bd4\u5982\u79ef\u6c34\u8bc6\u522b\uff0c\u8def\u9762\u584c\u9677\u7b49\uff0c\u800c\u4e14\u75ab\u60c5\u671f\u95f4\uff0c\u5728\u667a\u80fd\u5916\u547c\u7cfb\u7edf\uff0c\u4eba\u7fa4\u6d4b\u6e29\u7cfb\u7edf\uff0c\u53e3\u7f69\u4eba\u8138\u8bc6\u522b\u7b49\u90fd\u6709\u6df1\u5ea6\u5b66\u4e60\u7684\u5e94\u7528\u3002 \u603b\u7ed3 \u6df1\u5ea6\u5b66\u4e60\u662f\u4ec0\u4e48 \u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e00\u79cd\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u8111\u5b9e\u73b0\u76f8\u5e94\u7684\u529f\u80fd \u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u573a\u666f \u624b\u673a\uff0c\u673a\u5668\u7ffb\u8bd1\uff0c\u81ea\u52a8\u9a7e\u9a76\uff0c\u8bed\u97f3\u8bc6\u522b\uff0c\u533b\u7597\uff0c\u5b89\u9632\u7b49\u3002","title":"2 \u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09"},{"location":"introduction/section2/","text":"\u8ba1\u7b97\u673a\u89c6\u89c9 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u5e38\u89c1\u4efb\u52a1 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f 1.\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9a\u4e49 \u00b6 \u8ba1\u7b97\u673a\u89c6\u89c9\u662f\u6307\u7528\u6444\u50cf\u673a\u548c\u7535\u8111\u53ca\u5176\u4ed6\u76f8\u5173\u8bbe\u5907\uff0c\u5bf9\u751f\u7269\u89c6\u89c9\u7684\u4e00\u79cd\u6a21\u62df\u3002\u5b83\u7684\u4e3b\u8981\u4efb\u52a1\u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9\uff0c\u5c31\u50cf\u4eba\u7c7b\u548c\u8bb8\u591a\u5176\u4ed6\u751f\u7269\u6bcf\u5929\u6240\u505a\u7684\u90a3\u6837\u3002 \u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4efb\u52a1\u76ee\u6807\u62c6\u5206\u4e3a\uff1a \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u4e2d\u7684\u573a\u666f\uff08\u529e\u516c\u5ba4\uff0c\u5ba2\u5385\uff0c\u5496\u5561\u5385\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u8bc6\u522b\u573a\u666f\u4e2d\u5305\u542b\u7684\u7269\u4f53\uff08\u5ba0\u7269\uff0c\u4ea4\u901a\u5de5\u5177\uff0c\u4eba\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u5b9a\u4f4d\u7269\u4f53\u5728\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff08\u7269\u4f53\u7684\u5927\u5c0f\uff0c\u8fb9\u754c\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u7269\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u6216\u884c\u4e3a\uff08\u662f\u5728\u5bf9\u8bdd\uff0c\u6bd4\u8d5b\u6216\u5435\u67b6\u7b49\uff09\uff0c\u4ee5\u53ca\u56fe\u50cf\u8868\u8fbe\u7684\u610f\u4e49\uff08\u559c\u5e86\u7684\uff0c\u60b2\u4f24\u7684\u7b49\uff09 \u90a3\u6211\u4eec\u5728OpenCV\u9636\u6bb5\uff0c\u4e3b\u8981\u5b66\u4e60\u56fe\u50cf\u5904\u7406\uff0c\u800c\u56fe\u50cf\u5904\u7406\u4e3b\u8981\u76ee\u7684\u662f\u5bf9\u56fe\u50cf\u7684\u5904\u7406\uff0c\u6bd4\u5982\u5e73\u6ed1\uff0c\u7f29\u653e\u7b49\uff0c\u60f3\u3001\u4ece\u800c\u4e3a\u5176\u4ed6\u4efb\u52a1\uff08\u6bd4\u5982\u201c\u8ba1\u7b97\u673a\u89c6\u89c9\u201d\uff09\u505a\u597d\u524d\u671f\u5de5\u4f5c\u3002 2.\u5e38\u89c1\u4efb\u52a1 \u00b6 \u6839\u636e\u4e0a\u8ff0\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u76ee\u6807\u4efb\u52a1\u7684\u5206\u89e3\uff0c\u53ef\u5c06\u5176\u5206\u4e3a\u4e09\u5927\u7ecf\u5178\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u3001\u56fe\u50cf\u5206\u5272 \u56fe\u50cf\u5206\u7c7b\uff08Classification\uff09\uff1a\u5373\u662f\u5c06\u56fe\u50cf\u7ed3\u6784\u5316\u4e3a\u67d0\u4e00\u7c7b\u522b\u7684\u4fe1\u606f\uff0c\u7528\u4e8b\u5148\u786e\u5b9a\u597d\u7684\u7c7b\u522b(category)\u6765\u63cf\u8ff0\u56fe\u7247\u3002 \u76ee\u6807\u68c0\u6d4b\uff08Detection\uff09\uff1a\u5206\u7c7b\u4efb\u52a1\u5173\u5fc3\u6574\u4f53\uff0c\u7ed9\u51fa\u7684\u662f\u6574\u5f20\u56fe\u7247\u7684\u5185\u5bb9\u63cf\u8ff0\uff0c\u800c\u68c0\u6d4b\u5219\u5173\u6ce8\u7279\u5b9a\u7684\u7269\u4f53\u76ee\u6807\uff0c\u8981\u6c42\u540c\u65f6\u83b7\u5f97\u8fd9\u4e00\u76ee\u6807\u7684\u7c7b\u522b\u4fe1\u606f\u548c\u4f4d\u7f6e\u4fe1\u606f\uff08classification + localization\uff09\u3002 \u56fe\u50cf\u5206\u5272\uff08Segmentation\uff09\uff1a\u5206\u5272\u662f\u5bf9\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u63cf\u8ff0\uff0c\u5b83\u8d4b\u4e88\u6bcf\u4e2a\u50cf\u7d20\u7c7b\u522b\uff08\u5b9e\u4f8b\uff09\u610f\u4e49\uff0c\u9002\u7528\u4e8e\u7406\u89e3\u8981\u6c42\u8f83\u9ad8\u7684\u573a\u666f\uff0c\u5982\u65e0\u4eba\u9a7e\u9a76\u4e2d\u5bf9\u9053\u8def\u548c\u975e\u9053\u8def\u7684\u5206\u5272\u3002 \u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5c06\u56f4\u7ed5\u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u8fdb\u884c\u4ecb\u7ecd\u3002 3.\u5e94\u7528\u573a\u666f \u00b6 \u8ba1\u7b97\u673a\u89c6\u89c9\u6d89\u53ca\u7684\u9886\u57df\u590d\u6742\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\u3002\u603b\u4f53\u800c\u8a00\uff0c\u4f9d\u8d56\u4e8e\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\uff0c\u5c24\u5176\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u521b\u65b0\u7684\u597d\u5904\u662f\uff0c\u4ece\u7535\u5b50\u5546\u52a1\u884c\u4e1a\u5230\u66f4\u7ecf\u5178\u7684\u5404\u79cd\u7c7b\u578b\u548c\u89c4\u6a21\u7684\u516c\u53f8\u90fd\u53ef\u4ee5\u5229\u7528\u5176\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u4e0b\u56fe\u5c55\u793a\u4e86\u76f8\u5173\u7684\u5e94\u7528\u573a\u666f\u53ca\u76f8\u5173\u7684\u4f01\u4e1a\uff1a 3.1 \u4eba\u8138\u8bc6\u522b \u00b6 \u4eba\u8138\u8bc6\u522b\u6280\u672f\u76ee\u524d\u5df2\u7ecf\u5e7f\u6cdb\u5e94\u7528\u4e8e\u91d1\u878d\u3001\u53f8\u6cd5\u3001\u519b\u961f\u3001\u516c\u5b89\u3001\u8fb9\u68c0\u3001\u653f\u5e9c\u3001\u822a\u5929\u3001\u7535\u529b\u3001\u5de5\u5382\u3001\u6559\u80b2\u3001\u533b\u7597\u7b49\u884c\u4e1a\u3002\u636e\u4e1a\u5185\u4eba\u58eb\u5206\u6790\uff0c\u6211\u56fd\u7684\u4eba\u8138\u8bc6\u522b\u4ea7\u4e1a\u7684\u9700\u6c42\u65fa\u76db\uff0c\u9700\u6c42\u63a8\u52a8\u5bfc\u81f4\u4f01\u4e1a\u6562\u4e8e\u6295\u5165\u8d44\u91d1\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u5546\u6c64\u79d1\u6280\u3001\u6df1\u9192\u79d1\u6280\u3001\u4e91\u4ece\u79d1\u6280\u7b49\u3002 3.2 \u89c6\u9891\u76d1\u63a7 \u00b6 \u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u4ee5\u5bf9\u7ed3\u6784\u5316\u7684\u4eba\u3001\u8f66\u3001\u7269\u7b49\u89c6\u9891\u5185\u5bb9\u4fe1\u606f\u8fdb\u884c\u5feb\u901f\u68c0\u7d22\u3001\u67e5\u8be2\u3002\u8fd9\u9879\u5e94\u7528\u4f7f\u5f97\u8ba9\u516c\u5b89\u7cfb\u7edf\u5728\u7e41\u6742\u7684\u76d1\u63a7\u89c6\u9891\u4e2d\u641c\u5bfb\u5230\u7f6a\u72af\u7684\u6709\u4e86\u53ef\u80fd\u3002\u5728\u5927\u91cf\u4eba\u7fa4\u6d41\u52a8\u7684\u4ea4\u901a\u67a2\u7ebd\uff0c\u8be5\u6280\u672f\u4e5f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4eba\u7fa4\u5206\u6790\u3001\u9632\u63a7\u9884\u8b66\u7b49\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aSenseTime \u5546\u6c64\u79d1\u6280\u3001DeepGlint \u683c\u7075\u6df1\u77b3\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u4e91\u5929\u52b1\u98de\u3001\u6df1\u7f51\u89c6\u754c\u7b49\u3002 3.3 \u56fe\u7247\u8bc6\u522b\u5206\u6790 \u00b6 \u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u56fe\u666e\u79d1\u6280\u3001\u7801\u9686\u79d1\u6280\u3001\u9152\u5494\u5693\u3001YI+\u964c\u4e0a\u82b1\u79d1\u6280\u7b49\u3002 3.4 \u8f85\u52a9\u9a7e\u9a76 \u00b6 \u968f\u7740\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u6c7d\u8f66\u5df2\u7ecf\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u6280\u672f\u975e\u5e38\u5927\u7684\u5e94\u7528\u6295\u653e\u65b9\u5411\uff0c\u4f46\u5c31\u76ee\u524d\u6765\u8bf4\uff0c\u60f3\u8981\u5b8c\u5168\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76/\u65e0\u4eba\u9a7e\u9a76\uff0c\u8ddd\u79bb\u6280\u672f\u6210\u719f\u8fd8\u6709\u4e00\u6bb5\u8def\u8981\u8d70\u3002\u4e0d\u8fc7\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u6c7d\u8f66\u7684\u9a7e\u9a76\u8f85\u52a9\u7684\u529f\u80fd\u53ca\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u8fd9\u4e9b\u5e94\u7528\u591a\u534a\u662f\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u56fe\u50cf\u5904\u7406\u6280\u672f\u6765\u5b9e\u73b0\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1a\u7eb5\u76ee\u79d1\u6280\u3001TuSimple \u56fe\u68ee\u79d1\u6280\u3001\u9a6d\u52bf\u79d1\u6280\u3001MINIEYE \u4f51\u9a7e\u521b\u65b0\u3001\u4e2d\u5929\u5b89\u9a70\u7b49\u3002 \u9664\u4e86\u4e0a\u8ff0\u8fd9\u4e9b\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u4e09\u7ef4\u89c6\u89c9\uff0c\u4e09\u7ef4\u91cd\u5efa\uff0c\u5de5\u4e1a\u4eff\u771f\uff0c\u5730\u7406\u4fe1\u606f\u7cfb\u7edf\uff0c\u5de5\u4e1a\u89c6\u89c9\uff0c\u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff0c\u6587\u5b57\u8bc6\u522b\uff08OCR\uff09\uff0c\u56fe\u50cf\u53ca\u89c6\u9891\u7f16\u8f91\u7b49\u9886\u57df\u4e5f\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u3002 5.\u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09 \u00b6 1963\u5e74\uff0cLarry Roberts\u53d1\u8868\u4e86CV\u9886\u57df\u7684\u7b2c\u4e00\u7bc7\u4e13\u4e1a\u8bba\u6587\uff0c\u7528\u4ee5\u5bf9\u7b80\u5355\u51e0\u4f55\u4f53\u8fdb\u884c\u8fb9\u7f18\u63d0\u53d6\u548c\u4e09\u7ef4\u91cd\u5efa\u3002 1966\u5e74\uff0c\u9ebb\u7701\u7406\u5de5\u5b66\u9662(MIT)\u53d1\u8d77\u4e86\u4e00\u4e2a\u590f\u5b63\u9879\u76ee\uff0c\u76ee\u6807\u662f\u642d\u5efa\u4e00\u4e2a\u673a\u5668\u89c6\u89c9\u7cfb\u7edf\uff0c\u5b8c\u6210\u6a21\u5f0f\u8bc6\u522b(pattern recognition)\u7b49\u5de5\u4f5c\u3002\u867d\u7136\u672a\u6210\u529f\uff0c\u4f46\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4f5c\u4e3a\u4e00\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u6b63\u5f0f\u8bde\u751f\u7684\u6807\u5fd7\u3002 1982\u5e74\uff0c\u5b66\u8005David Marr\u53d1\u8868\u7684\u8457\u4f5c\u300aVision\u300b\u4ece\u4e25\u8c28\u53c8\u957f\u8fdc\u7684\u89d2\u5ea6\u7ed9\u51fa\u4e86CV\u7684\u53d1\u5c55\u65b9\u5411\u548c\u4e00\u4e9b\u57fa\u672c\u7b97\u6cd5\uff0c\u5176\u4e2d\u4e0d\u4e4f\u73b0\u5728\u4e3a\u4eba\u719f\u77e5\u7684\u201c\u56fe\u5c42\u201d\u7684\u6982\u5ff5\u3001\u8fb9\u7f18\u63d0\u53d6\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\uff0c\u6807\u5fd7\u7740\u8ba1\u7b97\u673a\u89c6\u89c9\u6210\u4e3a\u4e86\u4e00\u95e8\u72ec\u7acb\u5b66\u79d1\u3002 1999\u5e74David Lowe\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4e0d\u53d8\u7279\u5f81\u53d8\u6362\uff08SIFT, Scale-invariant feature transform\uff09\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7528\u4e8e\u5339\u914d\u4e0d\u540c\u62cd\u6444\u65b9\u5411\u3001\u7eb5\u6df1\u3001\u5149\u7ebf\u7b49\u56fe\u7247\u4e2d\u7684\u76f8\u540c\u5143\u7d20\u3002 2009\u5e74\uff0c\u7531Felzenszwalb\u6559\u6388\u5728\u63d0\u51fa\u57fa\u4e8eHOG\u7684deformable parts model\uff0c\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\u5f00\u53d1\uff0c\u5b83\u662f\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u6700\u597d\u7684\u6700\u6210\u529f\u7684objectdetection & recognition\u7b97\u6cd5\u3002 Everingham\u7b49\u4eba\u57282006\u5e74\u81f32012\u5e74\u95f4\u642d\u5efa\u4e86\u4e00\u4e2a\u5927\u578b\u56fe\u7247\u6570\u636e\u5e93\uff0c\u4f9b\u673a\u5668\u8bc6\u522b\u548c\u8bad\u7ec3\uff0c\u79f0\u4e3aPASCAL Visual Object Challenge\uff0c\u8be5\u6570\u636e\u5e93\u4e2d\u670920\u79cd\u7c7b\u522b\u7684\u56fe\u7247\uff0c\u6bcf\u79cd\u56fe\u7247\u6570\u91cf\u5728\u4e00\u5343\u81f3\u4e00\u4e07\u5f20\u4e0d\u7b49\u3002 2009\u5e74\uff0c\u674e\u98de\u98de\u6559\u6388\u7b49\u5728CVPR2009\u4e0a\u53d1\u8868\u4e86\u4e00\u7bc7\u540d\u4e3a\u300aImageNet: A Large-Scale Hierarchical Image Database\u300b\u7684\u8bba\u6587\uff0c\u53d1\u5e03\u4e86ImageNet\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e3a\u4e86\u68c0\u6d4b\u8ba1\u7b97\u673a\u89c6\u89c9\u80fd\u5426\u8bc6\u522b\u81ea\u7136\u4e07\u7269\uff0c\u56de\u5f52\u673a\u5668\u5b66\u4e60\uff0c\u514b\u670d\u8fc7\u62df\u5408\u95ee\u9898\u3002 2012 \u5e74\uff0cAlex Krizhevsky\u3001Ilya Sutskever \u548c Geoffrey Hinton \u521b\u9020\u4e86\u4e00\u4e2a\u201c\u5927\u578b\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u201d\uff0c\u4e5f\u5373\u73b0\u5728\u4f17\u6240\u5468\u77e5\u7684 AlexNet\uff0c\u8d62\u5f97\u4e86\u5f53\u5e74\u7684 ILSVRC\u3002\u8fd9\u662f\u53f2\u4e0a\u7b2c\u4e00\u6b21\u6709\u6a21\u578b\u5728 ImageNet \u6570\u636e\u96c6\u8868\u73b0\u5982\u6b64\u51fa\u8272\u3002\u81ea\u90a3\u65f6\u8d77\uff0cCNN \u624d\u6210\u4e86\u5bb6\u55bb\u6237\u6653\u7684\u540d\u5b57\u3002 2014\u5e74\uff0c\u8499\u7279\u5229\u5c14\u5927\u5b66\u63d0\u51fa\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\uff1a\u62e5\u6709\u4e24\u4e2a\u76f8\u4e92\u7ade\u4e89\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4f7f\u673a\u5668\u5b66\u4e60\u5f97\u66f4\u5feb\u3002\u4e00\u4e2a\u7f51\u7edc\u5c1d\u8bd5\u6a21\u4eff\u771f\u5b9e\u6570\u636e\u751f\u6210\u5047\u7684\u6570\u636e\uff0c\u800c\u53e6\u4e00\u4e2a\u7f51\u7edc\u5219\u8bd5\u56fe\u5c06\u5047\u6570\u636e\u533a\u5206\u51fa\u6765\u3002\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u4e24\u4e2a\u7f51\u7edc\u90fd\u4f1a\u5f97\u5230\u8bad\u7ec3\uff0c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u88ab\u8ba4\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\u3002 2018\u5e74\u672b\uff0c\u82f1\u4f1f\u8fbe\u53d1\u5e03\u7684\u89c6\u9891\u5230\u89c6\u9891\u751f\u6210\uff08Video-to-Video synthesis\uff09\uff0c\u5b83\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u53d1\u751f\u5668\u3001\u9274\u522b\u5668\u7f51\u7edc\u4ee5\u53ca\u65f6\u7a7a\u5bf9\u6297\u7269\u955c\uff0c\u5408\u6210\u9ad8\u5206\u8fa8\u7387\u3001\u7167\u7247\u7ea7\u771f\u5b9e\u3001\u65f6\u95f4\u4e00\u81f4\u7684\u89c6\u9891\uff0c\u5b9e\u73b0\u4e86\u8ba9AI\u66f4\u5177\u7269\u7406\u610f\u8bc6\uff0c\u66f4\u5f3a\u5927\uff0c\u5e76\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u7684\u548c\u770b\u4e0d\u89c1\u7684\u66f4\u591a\u573a\u666f\u3002 2019\uff0c\u66f4\u5f3a\u5927\u7684GAN\uff0cBigGAN\uff0c\u662f\u62e5\u6709\u4e86\u66f4\u806a\u660e\u7684\u5b66\u4e60\u6280\u5de7\u7684GAN\uff0c\u7531\u5b83\u8bad\u7ec3\u751f\u6210\u7684\u56fe\u50cf\u8fde\u5b83\u81ea\u5df1\u90fd\u5206\u8fa8\u4e0d\u51fa\u771f\u5047\uff0c\u56e0\u4e3a\u9664\u975e\u62ff\u663e\u5fae\u955c\u770b\uff0c\u5426\u5219\u5c06\u65e0\u6cd5\u5224\u65ad\u8be5\u56fe\u50cf\u662f\u5426\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u56e0\u800c\uff0c\u5b83\u66f4\u88ab\u8a89\u4e3a\u53f2\u4e0a\u6700\u5f3a\u7684\u56fe\u50cf\u751f\u6210\u5668. \u603b\u7ed3 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4efb\u52a1 \u56fe\u50cf\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u56fe\u50cf\u5206\u5272 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f \u4eba\u8138\u8bc6\u522b\uff0c\u89c6\u9891\u76d1\u63a7\uff0c\u56fe\u7247\u8bc6\u522b\u5206\u6790\uff0c\u8f85\u52a9\u9a7e\u9a76","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09"},{"location":"introduction/section2/#_1","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u5e38\u89c1\u4efb\u52a1 \u77e5\u9053\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f","title":"\u8ba1\u7b97\u673a\u89c6\u89c9"},{"location":"introduction/section2/#1","text":"\u8ba1\u7b97\u673a\u89c6\u89c9\u662f\u6307\u7528\u6444\u50cf\u673a\u548c\u7535\u8111\u53ca\u5176\u4ed6\u76f8\u5173\u8bbe\u5907\uff0c\u5bf9\u751f\u7269\u89c6\u89c9\u7684\u4e00\u79cd\u6a21\u62df\u3002\u5b83\u7684\u4e3b\u8981\u4efb\u52a1\u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9\uff0c\u5c31\u50cf\u4eba\u7c7b\u548c\u8bb8\u591a\u5176\u4ed6\u751f\u7269\u6bcf\u5929\u6240\u505a\u7684\u90a3\u6837\u3002 \u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4efb\u52a1\u76ee\u6807\u62c6\u5206\u4e3a\uff1a \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u4e2d\u7684\u573a\u666f\uff08\u529e\u516c\u5ba4\uff0c\u5ba2\u5385\uff0c\u5496\u5561\u5385\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u8bc6\u522b\u573a\u666f\u4e2d\u5305\u542b\u7684\u7269\u4f53\uff08\u5ba0\u7269\uff0c\u4ea4\u901a\u5de5\u5177\uff0c\u4eba\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u5b9a\u4f4d\u7269\u4f53\u5728\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff08\u7269\u4f53\u7684\u5927\u5c0f\uff0c\u8fb9\u754c\u7b49\uff09 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u7269\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u6216\u884c\u4e3a\uff08\u662f\u5728\u5bf9\u8bdd\uff0c\u6bd4\u8d5b\u6216\u5435\u67b6\u7b49\uff09\uff0c\u4ee5\u53ca\u56fe\u50cf\u8868\u8fbe\u7684\u610f\u4e49\uff08\u559c\u5e86\u7684\uff0c\u60b2\u4f24\u7684\u7b49\uff09 \u90a3\u6211\u4eec\u5728OpenCV\u9636\u6bb5\uff0c\u4e3b\u8981\u5b66\u4e60\u56fe\u50cf\u5904\u7406\uff0c\u800c\u56fe\u50cf\u5904\u7406\u4e3b\u8981\u76ee\u7684\u662f\u5bf9\u56fe\u50cf\u7684\u5904\u7406\uff0c\u6bd4\u5982\u5e73\u6ed1\uff0c\u7f29\u653e\u7b49\uff0c\u60f3\u3001\u4ece\u800c\u4e3a\u5176\u4ed6\u4efb\u52a1\uff08\u6bd4\u5982\u201c\u8ba1\u7b97\u673a\u89c6\u89c9\u201d\uff09\u505a\u597d\u524d\u671f\u5de5\u4f5c\u3002","title":"1.\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9a\u4e49"},{"location":"introduction/section2/#2","text":"\u6839\u636e\u4e0a\u8ff0\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u76ee\u6807\u4efb\u52a1\u7684\u5206\u89e3\uff0c\u53ef\u5c06\u5176\u5206\u4e3a\u4e09\u5927\u7ecf\u5178\u4efb\u52a1\uff1a\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u3001\u56fe\u50cf\u5206\u5272 \u56fe\u50cf\u5206\u7c7b\uff08Classification\uff09\uff1a\u5373\u662f\u5c06\u56fe\u50cf\u7ed3\u6784\u5316\u4e3a\u67d0\u4e00\u7c7b\u522b\u7684\u4fe1\u606f\uff0c\u7528\u4e8b\u5148\u786e\u5b9a\u597d\u7684\u7c7b\u522b(category)\u6765\u63cf\u8ff0\u56fe\u7247\u3002 \u76ee\u6807\u68c0\u6d4b\uff08Detection\uff09\uff1a\u5206\u7c7b\u4efb\u52a1\u5173\u5fc3\u6574\u4f53\uff0c\u7ed9\u51fa\u7684\u662f\u6574\u5f20\u56fe\u7247\u7684\u5185\u5bb9\u63cf\u8ff0\uff0c\u800c\u68c0\u6d4b\u5219\u5173\u6ce8\u7279\u5b9a\u7684\u7269\u4f53\u76ee\u6807\uff0c\u8981\u6c42\u540c\u65f6\u83b7\u5f97\u8fd9\u4e00\u76ee\u6807\u7684\u7c7b\u522b\u4fe1\u606f\u548c\u4f4d\u7f6e\u4fe1\u606f\uff08classification + localization\uff09\u3002 \u56fe\u50cf\u5206\u5272\uff08Segmentation\uff09\uff1a\u5206\u5272\u662f\u5bf9\u56fe\u50cf\u7684\u50cf\u7d20\u7ea7\u63cf\u8ff0\uff0c\u5b83\u8d4b\u4e88\u6bcf\u4e2a\u50cf\u7d20\u7c7b\u522b\uff08\u5b9e\u4f8b\uff09\u610f\u4e49\uff0c\u9002\u7528\u4e8e\u7406\u89e3\u8981\u6c42\u8f83\u9ad8\u7684\u573a\u666f\uff0c\u5982\u65e0\u4eba\u9a7e\u9a76\u4e2d\u5bf9\u9053\u8def\u548c\u975e\u9053\u8def\u7684\u5206\u5272\u3002 \u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u6211\u4eec\u5c06\u56f4\u7ed5\u8fd9\u4e09\u4e2a\u4efb\u52a1\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u8fdb\u884c\u4ecb\u7ecd\u3002","title":"2.\u5e38\u89c1\u4efb\u52a1"},{"location":"introduction/section2/#3","text":"\u8ba1\u7b97\u673a\u89c6\u89c9\u6d89\u53ca\u7684\u9886\u57df\u590d\u6742\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\u3002\u603b\u4f53\u800c\u8a00\uff0c\u4f9d\u8d56\u4e8e\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\uff0c\u5c24\u5176\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u521b\u65b0\u7684\u597d\u5904\u662f\uff0c\u4ece\u7535\u5b50\u5546\u52a1\u884c\u4e1a\u5230\u66f4\u7ecf\u5178\u7684\u5404\u79cd\u7c7b\u578b\u548c\u89c4\u6a21\u7684\u516c\u53f8\u90fd\u53ef\u4ee5\u5229\u7528\u5176\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u4e0b\u56fe\u5c55\u793a\u4e86\u76f8\u5173\u7684\u5e94\u7528\u573a\u666f\u53ca\u76f8\u5173\u7684\u4f01\u4e1a\uff1a","title":"3.\u5e94\u7528\u573a\u666f"},{"location":"introduction/section2/#31","text":"\u4eba\u8138\u8bc6\u522b\u6280\u672f\u76ee\u524d\u5df2\u7ecf\u5e7f\u6cdb\u5e94\u7528\u4e8e\u91d1\u878d\u3001\u53f8\u6cd5\u3001\u519b\u961f\u3001\u516c\u5b89\u3001\u8fb9\u68c0\u3001\u653f\u5e9c\u3001\u822a\u5929\u3001\u7535\u529b\u3001\u5de5\u5382\u3001\u6559\u80b2\u3001\u533b\u7597\u7b49\u884c\u4e1a\u3002\u636e\u4e1a\u5185\u4eba\u58eb\u5206\u6790\uff0c\u6211\u56fd\u7684\u4eba\u8138\u8bc6\u522b\u4ea7\u4e1a\u7684\u9700\u6c42\u65fa\u76db\uff0c\u9700\u6c42\u63a8\u52a8\u5bfc\u81f4\u4f01\u4e1a\u6562\u4e8e\u6295\u5165\u8d44\u91d1\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u5546\u6c64\u79d1\u6280\u3001\u6df1\u9192\u79d1\u6280\u3001\u4e91\u4ece\u79d1\u6280\u7b49\u3002","title":"3.1 \u4eba\u8138\u8bc6\u522b"},{"location":"introduction/section2/#32","text":"\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u4ee5\u5bf9\u7ed3\u6784\u5316\u7684\u4eba\u3001\u8f66\u3001\u7269\u7b49\u89c6\u9891\u5185\u5bb9\u4fe1\u606f\u8fdb\u884c\u5feb\u901f\u68c0\u7d22\u3001\u67e5\u8be2\u3002\u8fd9\u9879\u5e94\u7528\u4f7f\u5f97\u8ba9\u516c\u5b89\u7cfb\u7edf\u5728\u7e41\u6742\u7684\u76d1\u63a7\u89c6\u9891\u4e2d\u641c\u5bfb\u5230\u7f6a\u72af\u7684\u6709\u4e86\u53ef\u80fd\u3002\u5728\u5927\u91cf\u4eba\u7fa4\u6d41\u52a8\u7684\u4ea4\u901a\u67a2\u7ebd\uff0c\u8be5\u6280\u672f\u4e5f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4eba\u7fa4\u5206\u6790\u3001\u9632\u63a7\u9884\u8b66\u7b49\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1aSenseTime \u5546\u6c64\u79d1\u6280\u3001DeepGlint \u683c\u7075\u6df1\u77b3\u3001\u4f9d\u56fe\u79d1\u6280\u3001\u4e91\u5929\u52b1\u98de\u3001\u6df1\u7f51\u89c6\u754c\u7b49\u3002","title":"3.2 \u89c6\u9891\u76d1\u63a7"},{"location":"introduction/section2/#33","text":"\u4ee3\u8868\u4f01\u4e1a\uff1aFace++\u65f7\u89c6\u79d1\u6280\u3001\u56fe\u666e\u79d1\u6280\u3001\u7801\u9686\u79d1\u6280\u3001\u9152\u5494\u5693\u3001YI+\u964c\u4e0a\u82b1\u79d1\u6280\u7b49\u3002","title":"3.3 \u56fe\u7247\u8bc6\u522b\u5206\u6790"},{"location":"introduction/section2/#34","text":"\u968f\u7740\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u6c7d\u8f66\u5df2\u7ecf\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u6280\u672f\u975e\u5e38\u5927\u7684\u5e94\u7528\u6295\u653e\u65b9\u5411\uff0c\u4f46\u5c31\u76ee\u524d\u6765\u8bf4\uff0c\u60f3\u8981\u5b8c\u5168\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76/\u65e0\u4eba\u9a7e\u9a76\uff0c\u8ddd\u79bb\u6280\u672f\u6210\u719f\u8fd8\u6709\u4e00\u6bb5\u8def\u8981\u8d70\u3002\u4e0d\u8fc7\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u6c7d\u8f66\u7684\u9a7e\u9a76\u8f85\u52a9\u7684\u529f\u80fd\u53ca\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u8fd9\u4e9b\u5e94\u7528\u591a\u534a\u662f\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u56fe\u50cf\u5904\u7406\u6280\u672f\u6765\u5b9e\u73b0\u3002 \u4ee3\u8868\u4f01\u4e1a\uff1a\u7eb5\u76ee\u79d1\u6280\u3001TuSimple \u56fe\u68ee\u79d1\u6280\u3001\u9a6d\u52bf\u79d1\u6280\u3001MINIEYE \u4f51\u9a7e\u521b\u65b0\u3001\u4e2d\u5929\u5b89\u9a70\u7b49\u3002 \u9664\u4e86\u4e0a\u8ff0\u8fd9\u4e9b\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u4e09\u7ef4\u89c6\u89c9\uff0c\u4e09\u7ef4\u91cd\u5efa\uff0c\u5de5\u4e1a\u4eff\u771f\uff0c\u5730\u7406\u4fe1\u606f\u7cfb\u7edf\uff0c\u5de5\u4e1a\u89c6\u89c9\uff0c\u533b\u7597\u5f71\u50cf\u8bca\u65ad\uff0c\u6587\u5b57\u8bc6\u522b\uff08OCR\uff09\uff0c\u56fe\u50cf\u53ca\u89c6\u9891\u7f16\u8f91\u7b49\u9886\u57df\u4e5f\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u3002","title":"3.4 \u8f85\u52a9\u9a7e\u9a76"},{"location":"introduction/section2/#5","text":"1963\u5e74\uff0cLarry Roberts\u53d1\u8868\u4e86CV\u9886\u57df\u7684\u7b2c\u4e00\u7bc7\u4e13\u4e1a\u8bba\u6587\uff0c\u7528\u4ee5\u5bf9\u7b80\u5355\u51e0\u4f55\u4f53\u8fdb\u884c\u8fb9\u7f18\u63d0\u53d6\u548c\u4e09\u7ef4\u91cd\u5efa\u3002 1966\u5e74\uff0c\u9ebb\u7701\u7406\u5de5\u5b66\u9662(MIT)\u53d1\u8d77\u4e86\u4e00\u4e2a\u590f\u5b63\u9879\u76ee\uff0c\u76ee\u6807\u662f\u642d\u5efa\u4e00\u4e2a\u673a\u5668\u89c6\u89c9\u7cfb\u7edf\uff0c\u5b8c\u6210\u6a21\u5f0f\u8bc6\u522b(pattern recognition)\u7b49\u5de5\u4f5c\u3002\u867d\u7136\u672a\u6210\u529f\uff0c\u4f46\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4f5c\u4e3a\u4e00\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u6b63\u5f0f\u8bde\u751f\u7684\u6807\u5fd7\u3002 1982\u5e74\uff0c\u5b66\u8005David Marr\u53d1\u8868\u7684\u8457\u4f5c\u300aVision\u300b\u4ece\u4e25\u8c28\u53c8\u957f\u8fdc\u7684\u89d2\u5ea6\u7ed9\u51fa\u4e86CV\u7684\u53d1\u5c55\u65b9\u5411\u548c\u4e00\u4e9b\u57fa\u672c\u7b97\u6cd5\uff0c\u5176\u4e2d\u4e0d\u4e4f\u73b0\u5728\u4e3a\u4eba\u719f\u77e5\u7684\u201c\u56fe\u5c42\u201d\u7684\u6982\u5ff5\u3001\u8fb9\u7f18\u63d0\u53d6\u3001\u4e09\u7ef4\u91cd\u5efa\u7b49\uff0c\u6807\u5fd7\u7740\u8ba1\u7b97\u673a\u89c6\u89c9\u6210\u4e3a\u4e86\u4e00\u95e8\u72ec\u7acb\u5b66\u79d1\u3002 1999\u5e74David Lowe\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4e0d\u53d8\u7279\u5f81\u53d8\u6362\uff08SIFT, Scale-invariant feature transform\uff09\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7528\u4e8e\u5339\u914d\u4e0d\u540c\u62cd\u6444\u65b9\u5411\u3001\u7eb5\u6df1\u3001\u5149\u7ebf\u7b49\u56fe\u7247\u4e2d\u7684\u76f8\u540c\u5143\u7d20\u3002 2009\u5e74\uff0c\u7531Felzenszwalb\u6559\u6388\u5728\u63d0\u51fa\u57fa\u4e8eHOG\u7684deformable parts model\uff0c\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\u5f00\u53d1\uff0c\u5b83\u662f\u6df1\u5ea6\u5b66\u4e60\u4e4b\u524d\u6700\u597d\u7684\u6700\u6210\u529f\u7684objectdetection & recognition\u7b97\u6cd5\u3002 Everingham\u7b49\u4eba\u57282006\u5e74\u81f32012\u5e74\u95f4\u642d\u5efa\u4e86\u4e00\u4e2a\u5927\u578b\u56fe\u7247\u6570\u636e\u5e93\uff0c\u4f9b\u673a\u5668\u8bc6\u522b\u548c\u8bad\u7ec3\uff0c\u79f0\u4e3aPASCAL Visual Object Challenge\uff0c\u8be5\u6570\u636e\u5e93\u4e2d\u670920\u79cd\u7c7b\u522b\u7684\u56fe\u7247\uff0c\u6bcf\u79cd\u56fe\u7247\u6570\u91cf\u5728\u4e00\u5343\u81f3\u4e00\u4e07\u5f20\u4e0d\u7b49\u3002 2009\u5e74\uff0c\u674e\u98de\u98de\u6559\u6388\u7b49\u5728CVPR2009\u4e0a\u53d1\u8868\u4e86\u4e00\u7bc7\u540d\u4e3a\u300aImageNet: A Large-Scale Hierarchical Image Database\u300b\u7684\u8bba\u6587\uff0c\u53d1\u5e03\u4e86ImageNet\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e3a\u4e86\u68c0\u6d4b\u8ba1\u7b97\u673a\u89c6\u89c9\u80fd\u5426\u8bc6\u522b\u81ea\u7136\u4e07\u7269\uff0c\u56de\u5f52\u673a\u5668\u5b66\u4e60\uff0c\u514b\u670d\u8fc7\u62df\u5408\u95ee\u9898\u3002 2012 \u5e74\uff0cAlex Krizhevsky\u3001Ilya Sutskever \u548c Geoffrey Hinton \u521b\u9020\u4e86\u4e00\u4e2a\u201c\u5927\u578b\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u201d\uff0c\u4e5f\u5373\u73b0\u5728\u4f17\u6240\u5468\u77e5\u7684 AlexNet\uff0c\u8d62\u5f97\u4e86\u5f53\u5e74\u7684 ILSVRC\u3002\u8fd9\u662f\u53f2\u4e0a\u7b2c\u4e00\u6b21\u6709\u6a21\u578b\u5728 ImageNet \u6570\u636e\u96c6\u8868\u73b0\u5982\u6b64\u51fa\u8272\u3002\u81ea\u90a3\u65f6\u8d77\uff0cCNN \u624d\u6210\u4e86\u5bb6\u55bb\u6237\u6653\u7684\u540d\u5b57\u3002 2014\u5e74\uff0c\u8499\u7279\u5229\u5c14\u5927\u5b66\u63d0\u51fa\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\uff1a\u62e5\u6709\u4e24\u4e2a\u76f8\u4e92\u7ade\u4e89\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4f7f\u673a\u5668\u5b66\u4e60\u5f97\u66f4\u5feb\u3002\u4e00\u4e2a\u7f51\u7edc\u5c1d\u8bd5\u6a21\u4eff\u771f\u5b9e\u6570\u636e\u751f\u6210\u5047\u7684\u6570\u636e\uff0c\u800c\u53e6\u4e00\u4e2a\u7f51\u7edc\u5219\u8bd5\u56fe\u5c06\u5047\u6570\u636e\u533a\u5206\u51fa\u6765\u3002\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u4e24\u4e2a\u7f51\u7edc\u90fd\u4f1a\u5f97\u5230\u8bad\u7ec3\uff0c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u88ab\u8ba4\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\u3002 2018\u5e74\u672b\uff0c\u82f1\u4f1f\u8fbe\u53d1\u5e03\u7684\u89c6\u9891\u5230\u89c6\u9891\u751f\u6210\uff08Video-to-Video synthesis\uff09\uff0c\u5b83\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u53d1\u751f\u5668\u3001\u9274\u522b\u5668\u7f51\u7edc\u4ee5\u53ca\u65f6\u7a7a\u5bf9\u6297\u7269\u955c\uff0c\u5408\u6210\u9ad8\u5206\u8fa8\u7387\u3001\u7167\u7247\u7ea7\u771f\u5b9e\u3001\u65f6\u95f4\u4e00\u81f4\u7684\u89c6\u9891\uff0c\u5b9e\u73b0\u4e86\u8ba9AI\u66f4\u5177\u7269\u7406\u610f\u8bc6\uff0c\u66f4\u5f3a\u5927\uff0c\u5e76\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u7684\u548c\u770b\u4e0d\u89c1\u7684\u66f4\u591a\u573a\u666f\u3002 2019\uff0c\u66f4\u5f3a\u5927\u7684GAN\uff0cBigGAN\uff0c\u662f\u62e5\u6709\u4e86\u66f4\u806a\u660e\u7684\u5b66\u4e60\u6280\u5de7\u7684GAN\uff0c\u7531\u5b83\u8bad\u7ec3\u751f\u6210\u7684\u56fe\u50cf\u8fde\u5b83\u81ea\u5df1\u90fd\u5206\u8fa8\u4e0d\u51fa\u771f\u5047\uff0c\u56e0\u4e3a\u9664\u975e\u62ff\u663e\u5fae\u955c\u770b\uff0c\u5426\u5219\u5c06\u65e0\u6cd5\u5224\u65ad\u8be5\u56fe\u50cf\u662f\u5426\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u56e0\u800c\uff0c\u5b83\u66f4\u88ab\u8a89\u4e3a\u53f2\u4e0a\u6700\u5f3a\u7684\u56fe\u50cf\u751f\u6210\u5668. \u603b\u7ed3 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5b9a\u4e49 \u8ba9\u8ba1\u7b97\u673a\u7406\u89e3\u56fe\u7247\u6216\u8005\u89c6\u9891\u4e2d\u7684\u5185\u5bb9 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4efb\u52a1 \u56fe\u50cf\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\uff0c\u56fe\u50cf\u5206\u5272 \u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e94\u7528\u573a\u666f \u4eba\u8138\u8bc6\u522b\uff0c\u89c6\u9891\u76d1\u63a7\uff0c\u56fe\u7247\u8bc6\u522b\u5206\u6790\uff0c\u8f85\u52a9\u9a7e\u9a76","title":"5.\u53d1\u5c55\u5386\u53f2\uff08\u4e86\u89e3\uff09"},{"location":"objectdection/","text":"\u76ee\u6807\u68c0\u6d4b(Object Detection) \u00b6","title":"\u76ee\u6807\u68c0\u6d4b(Object Detection)"},{"location":"objectdection/#object-detection","text":"","title":"\u76ee\u6807\u68c0\u6d4b(Object Detection)"},{"location":"objectdection/01.overview/","text":"4.1 \u76ee\u6807\u68c0\u6d4b\u6982\u8ff0 \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b 1. \u76ee\u6807\u68c0\u6d4b \u00b6 \u76ee\u6807\u68c0\u6d4b\uff08Object Detection\uff09\u7684\u4efb\u52a1\u662f\u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u3002 \u76ee\u6807\u68c0\u6d4b\u4e2d\u80fd\u68c0\u6d4b\u51fa\u6765\u7684\u7269\u4f53\u53d6\u51b3\u4e8e\u5f53\u524d\u4efb\u52a1\uff08\u6570\u636e\u96c6\uff09\u9700\u8981\u68c0\u6d4b\u7684\u7269\u4f53\u6709\u54ea\u4e9b\u3002\u5047\u8bbe\u6211\u4eec\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5b9a\u4f4d\u662f\u68c0\u6d4b\u52a8\u7269\uff08\u725b\u3001\u7f8a\u3001\u732a\u3001\u72d7\u3001\u732b\u4e94\u79cd\u7ed3\u679c\uff09\uff0c\u90a3\u4e48\u6a21\u578b\u5bf9\u4efb\u4f55\u4e00\u5f20\u56fe\u7247\u8f93\u51fa\u7ed3\u679c\u4e0d\u4f1a\u8f93\u51fa\u9e2d\u5b50\u3001\u4e66\u7c4d\u7b49\u5176\u5b83\u7c7b\u578b\u7ed3\u679c\u3002 \u76ee\u6807\u68c0\u6d4b\u7684\u4f4d\u7f6e\u4fe1\u606f\u4e00\u822c\u7531\u4e24\u79cd\u683c\u5f0f\uff08\u4ee5\u56fe\u7247\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9(0,0)\uff09\uff1a 1\u3001\u6781\u5750\u6807\u8868\u793a\uff1a(xmin, ymin, xmax, ymax) xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5c0f\u503c xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5927\u503c 2\u3001\u4e2d\u5fc3\u70b9\u5750\u6807\uff1a(x_center, y_center, w, h) x_center, y_center:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 w,h:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u5bbd\u3001\u9ad8 \u5047\u8bbe\u5728\u4e0b\u9762\u7684\u56fe\u50cf\u4e2d\u8fdb\u884c\u68c0\u6d4b\uff0c\uff1a \u90a3\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u7684\u4e2d\u5fc3\u70b9\u8868\u793a\u5f62\u5f0f\u5982\u4e0b\u6240\u793a\uff1a 2.\u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6 \u00b6 \u7ecf\u5178\u7684\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u6709\u4e24\u79cd\uff0c PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u3002 2.1 PASCAL VOC\u6570\u636e\u96c6 \u00b6 PASCAL VOC\u662f\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u7684\u7ecf\u5178\u6570\u636e\u96c6\u3002PASCAL VOC\u5305\u542b\u7ea610,000\u5f20\u5e26\u6709\u8fb9\u754c\u6846\u7684\u56fe\u7247\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002PASCAL VOC\u6570\u636e\u96c6\u662f\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u7684\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f88\u591a\u6a21\u578b\u90fd\u662f\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u7684\uff0c\u5e38\u7528\u7684\u662fVOC2007\u548cVOC2012\u4e24\u4e2a\u7248\u672c\u6570\u636e\uff0c\u517120\u4e2a\u7c7b\u522b\uff0c\u5206\u522b\u662f\uff1a \u4e5f\u5c31\u662f\uff1a 1.\u4eba: \u4eba 2.\u52a8\u7269: \u9e1f\uff0c\u732b\uff0c\u725b\uff0c\u72d7\uff0c\u9a6c\uff0c\u7f8a 3.\u4ea4\u901a\u5de5\u5177: \u98de\u673a\uff0c\u81ea\u884c\u8f66\uff0c\u8239\uff0c\u516c\u5171\u6c7d\u8f66\uff0c\u6c7d\u8f66\uff0c\u6469\u6258\u8f66\uff0c\u706b\u8f66 4.\u5ba4\u5185: \u74f6\u5b50\uff0c\u6905\u5b50\uff0c\u9910\u684c\uff0c\u76c6\u683d\uff0c\u6c99\u53d1\uff0c\u7535\u89c6/\u663e\u793a\u5668 \u4e0b\u8f7d\u5730\u5740 \uff1a https://pjreddie.com/projects/pascal-voc-dataset-mirror/ \u6574\u4e2a\u6570\u636e\u7684\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2d\uff1a JPEGImages\u5b58\u653e\u56fe\u7247\u6587\u4ef6 Annotations\u4e0b\u5b58\u653e\u7684\u662fxml\u6587\u4ef6,\u63cf\u8ff0\u4e86\u56fe\u7247\u4fe1\u606f\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u9700\u8981\u5173\u6ce8\u7684\u5c31\u662f\u8282\u70b9\u4e0b\u7684\u6570\u636e,\u5c24\u5176\u662fbndbox\u4e0b\u7684\u6570\u636e.xmin,ymin\u6784\u6210\u4e86boundingbox\u7684\u5de6\u4e0a\u89d2,xmax,ymax\u6784\u6210\u4e86boundingbox\u7684\u53f3\u4e0b\u89d2\uff0c\u4e5f\u5c31\u662f\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u4f4d\u7f6e\u4fe1\u606f ImageSets\u5305\u542b\u4ee5\u4e0b4\u4e2a\u6587\u4ef6\u5939\uff1a Action\u4e0b\u5b58\u653e\u7684\u662f\u4eba\u7684\u52a8\u4f5c\uff08\u4f8b\u5982running\u3001jumping\u7b49\u7b49\uff09 Layout\u4e0b\u5b58\u653e\u7684\u662f\u5177\u6709\u4eba\u4f53\u90e8\u4f4d\u7684\u6570\u636e\uff08\u4eba\u7684head\u3001hand\u3001feet\u7b49\u7b49\uff09 Segmentation\u4e0b\u5b58\u653e\u7684\u662f\u53ef\u7528\u4e8e\u5206\u5272\u7684\u6570\u636e\u3002 Main\u4e0b\u5b58\u653e\u7684\u662f\u56fe\u50cf\u7269\u4f53\u8bc6\u522b\u7684\u6570\u636e\uff0c\u603b\u5171\u5206\u4e3a20\u7c7b\uff0c\u8fd9\u662f\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u91cd\u70b9\u3002\u8be5\u6587\u4ef6\u5939\u4e2d\u7684\u6570\u636e\u5bf9\u8d1f\u6837\u672c\u6587\u4ef6\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 2.2 MS COCO\u6570\u636e\u96c6 \u00b6 MS COCO\u7684\u5168\u79f0\u662fMicrosoft Common Objects in Context\uff0c\u5fae\u8f6f\u4e8e2014\u5e74\u51fa\u8d44\u6807\u6ce8\u7684Microsoft COCO\u6570\u636e\u96c6\uff0c\u4e0eImageNet\u7ade\u8d5b\u4e00\u6837\uff0c\u88ab\u89c6\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6700\u53d7\u5173\u6ce8\u548c\u6700\u6743\u5a01\u7684\u6bd4\u8d5b\u4e4b\u4e00\u3002 COCO\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u5927\u578b\u7684\u3001\u4e30\u5bcc\u7684\u7269\u4f53\u68c0\u6d4b\uff0c\u5206\u5272\u548c\u5b57\u5e55\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4ee5\u573a\u666f\u7406\u89e3\u4e3a\u76ee\u6807\uff0c\u4e3b\u8981\u4ece\u590d\u6742\u7684\u65e5\u5e38\u573a\u666f\u4e2d\u622a\u53d6\uff0c\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u901a\u8fc7\u7cbe\u786e\u7684\u5206\u5272\u8fdb\u884c\u4f4d\u7f6e\u7684\u6807\u5b9a\u3002\u56fe\u50cf\u5305\u62ec91\u7c7b\u76ee\u6807\uff0c328,000\u5f71\u50cf\u548c2,500,000\u4e2alabel\u3002\u76ee\u524d\u4e3a\u6b62\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u5927\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u7684\u7c7b\u522b\u670980 \u7c7b\uff0c\u6709\u8d85\u8fc733 \u4e07\u5f20\u56fe\u7247\uff0c\u5176\u4e2d20 \u4e07\u5f20\u6709\u6807\u6ce8\uff0c\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u4e2a\u4f53\u7684\u6570\u76ee\u8d85\u8fc7150 \u4e07\u4e2a\u3002 \u56fe\u50cf\u793a\u4f8b\uff1a coco\u6570\u636e\u96c6\u7684\u6807\u7b7e\u6587\u4ef6\u6807\u8bb0\u4e86\u6bcf\u4e2asegmentation+bounding box\u7684\u7cbe\u786e\u5750\u6807\uff0c\u5176\u7cbe\u5ea6\u5747\u4e3a\u5c0f\u6570\u70b9\u540e\u4e24\u4f4d\u4e00\u4e2a\u76ee\u6807\u7684\u6807\u7b7e\u793a\u610f\u5982\u4e0b\uff1a {\"segmentation\":[[392.87, 275.77, 402.24, 284.2, 382.54, 342.36, 375.99, 356.43, 372.23, 357.37, 372.23, 397.7, 383.48, 419.27,407.87, 439.91, 427.57, 389.25, 447.26, 346.11, 447.26, 328.29, 468.84, 290.77,472.59, 266.38], [429.44,465.23, 453.83, 473.67, 636.73, 474.61, 636.73, 392.07, 571.07, 364.88, 546.69,363.0]], \"area\": 28458.996150000003, \"iscrowd\": 0,\"image_id\": 503837, \"bbox\": [372.23, 266.38, 264.5,208.23] , \"category_id\": 4, \"id\": 151109}, 3.\u5e38\u7528\u7684\u8bc4\u4ef7\u6307\u6807 \u00b6 3.1 IOU \u00b6 \u5728\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0cIoU\uff08intersection over union\uff0c\u4ea4\u5e76\u6bd4\uff09\u662f\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7528\u6765\u8bc4\u4ef72\u4e2a\u77e9\u5f62\u6846\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\uff1a IoU = \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u4ea4\u7684\u9762\u79ef / \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u5e76\u7684\u9762\u79ef \uff0c \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e0b\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff1a \u5176\u4e2d\u4e0a\u56fe\u84dd\u8272\u6846\u6846\u4e3a\u68c0\u6d4b\u7ed3\u679c\uff0c\u7ea2\u8272\u6846\u6846\u4e3a\u771f\u5b9e\u6807\u6ce8\u3002 \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u7ed3\u679c\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4\u6765\u8861\u91cf\u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u5bf9\u4e8e\u68c0\u6d4b\u6846\u7684\u5224\u5b9a\u90fd\u4f1a\u5b58\u5728\u4e00\u4e2a\u9608\u503c\uff0c\u4e5f\u5c31\u662f IoU \u7684\u9608\u503c\uff0c\u4e00\u822c\u53ef\u4ee5\u8bbe\u7f6e\u5f53 IoU \u7684\u503c\u5927\u4e8e 0.5 \u7684\u65f6\u5019\uff0c\u5219\u53ef\u8ba4\u4e3a\u68c0\u6d4b\u5230\u76ee\u6807\u7269\u4f53\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a import numpy as np # \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97IOU def Iou ( box1 , box2 , wh = False ): # \u5224\u65adbbox\u7684\u8868\u793a\u5f62\u5f0f if wh == False : # \u4f7f\u7528\u6781\u5750\u6807\u5f62\u5f0f\u8868\u793a\uff1a\u76f4\u63a5\u83b7\u53d6\u4e24\u4e2abbox\u7684\u5750\u6807 xmin1 , ymin1 , xmax1 , ymax1 = box1 xmin2 , ymin2 , xmax2 , ymax2 = box2 else : # \u4f7f\u7528\u4e2d\u5fc3\u70b9\u5f62\u5f0f\u8868\u793a\uff1a \u83b7\u53d6\u4e24\u4e2a\u4e24\u4e2abbox\u7684\u6781\u5750\u6807\u8868\u793a\u5f62\u5f0f # \u7b2c\u4e00\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin1 , ymin1 = int ( box1 [ 0 ] - box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] - box1 [ 3 ] / 2.0 ) # \u7b2c\u4e00\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax1 , ymax1 = int ( box1 [ 0 ] + box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] + box1 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin2 , ymin2 = int ( box2 [ 0 ] - box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] - box2 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax2 , ymax2 = int ( box2 [ 0 ] + box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] + box2 [ 3 ] / 2.0 ) # \u83b7\u53d6\u77e9\u5f62\u6846\u4ea4\u96c6\u5bf9\u5e94\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u7684\u5750\u6807\uff08intersection\uff09 xx1 = np . max ([ xmin1 , xmin2 ]) yy1 = np . max ([ ymin1 , ymin2 ]) xx2 = np . min ([ xmax1 , xmax2 ]) yy2 = np . min ([ ymax1 , ymax2 ]) # \u8ba1\u7b97\u4e24\u4e2a\u77e9\u5f62\u6846\u9762\u79ef area1 = ( xmax1 - xmin1 ) * ( ymax1 - ymin1 ) area2 = ( xmax2 - xmin2 ) * ( ymax2 - ymin2 ) #\u8ba1\u7b97\u4ea4\u96c6\u9762\u79ef inter_area = ( np . max ([ 0 , xx2 - xx1 ])) * ( np . max ([ 0 , yy2 - yy1 ])) #\u8ba1\u7b97\u4ea4\u5e76\u6bd4 iou = inter_area / ( area1 + area2 - inter_area + 1e-6 ) return iou \u5047\u8bbe\u6211\u4eec\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff0c\u5e76\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a import matplotlib.pyplot as plt import matplotlib.patches as patches # \u771f\u5b9e\u6846\u4e0e\u9884\u6d4b\u6846 True_bbox , predict_bbox = [ 100 , 35 , 398 , 400 ], [ 40 , 150 , 355 , 398 ] # bbox\u662fbounding box\u7684\u7f29\u5199 img = plt . imread ( 'dog.jpeg' ) fig = plt . imshow ( img ) # \u5c06\u8fb9\u754c\u6846(\u5de6\u4e0ax, \u5de6\u4e0ay, \u53f3\u4e0bx, \u53f3\u4e0by)\u683c\u5f0f\u8f6c\u6362\u6210matplotlib\u683c\u5f0f\uff1a((\u5de6\u4e0ax, \u5de6\u4e0ay), \u5bbd, \u9ad8) # \u771f\u5b9e\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( True_bbox [ 0 ], True_bbox [ 1 ]), width = True_bbox [ 2 ] - True_bbox [ 0 ], height = True_bbox [ 3 ] - True_bbox [ 1 ], fill = False , edgecolor = \"blue\" , linewidth = 2 )) # \u9884\u6d4b\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( predict_bbox [ 0 ], predict_bbox [ 1 ]), width = predict_bbox [ 2 ] - predict_bbox [ 0 ], height = predict_bbox [ 3 ] - predict_bbox [ 1 ], fill = False , edgecolor = \"red\" , linewidth = 2 )) \u8ba1\u7b97IoU\uff1a Iou ( True_bbox , predict_bbox ) \u7ed3\u679c\u4e3a\uff1a 0.5114435907762924 3.2 mAP\uff08 Mean Average Precision \uff09 \u00b6 \u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u4e2d\u7684\u6bcf\u4e2a\u56fe\u7247\u90fd\u53ef\u80fd\u5305\u542b\u4e00\u4e9b\u4e0d\u540c\u7c7b\u522b\u7684\u7269\u4f53\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u7684\u7269\u4f53\u5206\u7c7b\u548c\u5b9a\u4f4d\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u6807\u51c6\u6307\u6807precision\u4e0d\u80fd\u76f4\u63a5\u5e94\u7528\u4e8e\u6b64\u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cmAP\u662f\u4e3b\u8981\u7684\u8861\u91cf\u6307\u6807\u3002 mAP\u662f\u591a\u4e2a\u5206\u7c7b\u4efb\u52a1\u7684AP\u7684\u5e73\u5747\u503c\uff0c\u800cAP\uff08average precision\uff09\u662fPR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0c\u6240\u4ee5\u5728\u4ecb\u7ecdmAP\u4e4b\u524d\u6211\u4eec\u8981\u5148\u5f97\u5230PR\u66f2\u7ebf\u3002 TP\u3001FP\u3001FN\u3001TN True Positive (TP): IoU> ( \u4e00\u822c\u53d6 0.5 ) \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff08\u540c\u4e00 Ground Truth \u53ea\u8ba1\u7b97\u4e00\u6b21\uff09 False Positive (FP): IoU<= \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff0c\u6216\u8005\u662f\u68c0\u6d4b\u5230\u540c\u4e00\u4e2a GT \u7684\u591a\u4f59\u68c0\u6d4b\u6846\u7684\u6570\u91cf False Negative (FN): \u6ca1\u6709\u68c0\u6d4b\u5230\u7684 GT \u7684\u6570\u91cf True Negative (TN): \u5728 mAP \u8bc4\u4ef7\u6307\u6807\u4e2d\u4e0d\u4f1a\u4f7f\u7528\u5230 \u67e5\u51c6\u7387\u3001\u67e5\u5168\u7387 \u67e5\u51c6\u7387\uff08Precision\uff09: TP/(TP + FP) \u67e5\u5168\u7387\uff08Recall\uff09: TP/(TP + FN) \u4e8c\u8005\u7ed8\u5236\u7684\u66f2\u7ebf\u79f0\u4e3a P-R \u66f2\u7ebf \u5148\u5b9a\u4e49\u4e24\u4e2a\u516c\u5f0f\uff0c\u4e00\u4e2a\u662f Precision\uff0c\u4e00\u4e2a\u662f Recall\uff0c\u4e0e\u4e0a\u9762\u7684\u516c\u5f0f\u76f8\u540c\uff0c\u6269\u5c55\u5f00\u6765\uff0c\u7528\u53e6\u5916\u4e00\u79cd\u5f62\u5f0f\u8fdb\u884c\u5c55\u793a\uff0c\u5176\u4e2d all detctions \u4ee3\u8868\u6240\u6709\u9884\u6d4b\u6846\u7684\u6570\u91cf\uff0c all ground truths \u4ee3\u8868\u6240\u6709 GT \u7684\u6570\u91cf\u3002 AP \u662f\u8ba1\u7b97\u67d0\u4e00\u7c7b P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0cmAP \u5219\u662f\u8ba1\u7b97\u6240\u6709\u7c7b\u522b P-R \u66f2\u7ebf\u4e0b\u9762\u79ef\u7684\u5e73\u5747\u503c\u3002 \u5047\u8bbe\u6211\u4eec\u6709 7 \u5f20\u56fe\u7247\uff08Images1-Image7\uff09\uff0c\u8fd9\u4e9b\u56fe\u7247\u6709 15 \u4e2a\u76ee\u6807\uff08\u7eff\u8272\u7684\u6846\uff0cGT \u7684\u6570\u91cf\uff0c\u4e0a\u6587\u63d0\u53ca\u7684 all ground truths \uff09\u4ee5\u53ca 24 \u4e2a\u9884\u6d4b\u8fb9\u6846\uff08\u7ea2\u8272\u7684\u6846\uff0cA-Y \u7f16\u53f7\u8868\u793a\uff0c\u5e76\u4e14\u6709\u4e00\u4e2a\u7f6e\u4fe1\u5ea6\u503c\uff09\uff1a \u6839\u636e\u4e0a\u56fe\u4ee5\u53ca\u8bf4\u660e\uff0c\u6211\u4eec\u53ef\u4ee5\u5217\u51fa\u4ee5\u4e0b\u8868\u683c\uff0c\u5176\u4e2d Images \u4ee3\u8868\u56fe\u7247\u7684\u7f16\u53f7\uff0cDetections \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f16\u53f7\uff0cConfidences \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cTP or FP \u4ee3\u8868\u9884\u6d4b\u7684\u8fb9\u6846\u662f\u6807\u8bb0\u4e3a TP \u8fd8\u662f FP\uff08\u8ba4\u4e3a\u9884\u6d4b\u8fb9\u6846\u4e0e GT \u7684 IOU \u503c\u5927\u4e8e\u7b49\u4e8e 0.3 \u5c31\u6807\u8bb0\u4e3a TP\uff1b\u82e5\u4e00\u4e2a GT \u6709\u591a\u4e2a\u9884\u6d4b\u8fb9\u6846\uff0c\u5219\u8ba4\u4e3a IOU \u6700\u5927\u4e14\u5927\u4e8e\u7b49\u4e8e 0.3 \u7684\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff0c\u5176\u4ed6\u7684\u6807\u8bb0\u4e3a FP\uff0c\u5373\u4e00\u4e2a GT \u53ea\u80fd\u6709\u4e00\u4e2a\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff09\uff0c\u8fd9\u91cc\u7684 0.3 \u662f\u968f\u673a\u53d6\u7684\u4e00\u4e2a\u503c\u3002 \u901a\u8fc7\u4e0a\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf\uff08\u56e0\u4e3a AP \u5c31\u662f P-R \u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\uff09\uff0c\u4f46\u662f\u5728\u6b64\u4e4b\u524d\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u51fa P-R \u66f2\u7ebf\u4e0a\u5404\u4e2a\u70b9\u7684\u5750\u6807\uff0c\u6839\u636e\u7f6e\u4fe1\u5ea6\u4ece\u5927\u5230\u5c0f\u6392\u5e8f\u6240\u6709\u7684\u9884\u6d4b\u6846\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u8ba1\u7b97 Precision \u548c Recall \u7684\u503c\uff0c\u89c1\u4e0b\u8868\u3002\uff08\u9700\u8981\u8bb0\u4f4f\u4e00\u4e2a\u53eb\u7d2f\u52a0\u7684\u6982\u5ff5\uff0c\u5c31\u662f\u4e0b\u56fe\u7684 ACC TP \u548c ACC FP\uff09 \u6807\u53f7\u4e3a 1 \u7684 Precision \u548c Recall \u7684\u8ba1\u7b97\u65b9\u5f0f\uff1aPrecision=TP/(TP+FP)=1/(1+0)=1\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \uff08 all ground truths \u4e0a\u9762\u6709\u5b9a\u4e49\u8fc7\u4e86 \uff09 \u6807\u53f7 2\uff1aPrecision=TP/(TP+FP)=1/(1+1)=0.5\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \u6807\u53f7 3\uff1aPrecision=TP/(TP+FP)=2/(2+1)=0.6666\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=2/15=0.1333 \u5176\u4ed6\u7684\u4f9d\u6b21\u7c7b\u63a8 \u7136\u540e\u5c31\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf \u5f97\u5230 P-R \u66f2\u7ebf\u5c31\u53ef\u4ee5\u8ba1\u7b97 AP\uff08P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff09\uff0c\u8981\u8ba1\u7b97 P-R \u4e0b\u65b9\u7684\u9762\u79ef\uff0c\u6709\u4e24\u79cd\u65b9\u6cd5\uff1a \u5728VOC2010\u4ee5\u524d\uff0c\u53ea\u9700\u8981\u9009\u53d6\u5f53Recall >= 0, 0.1, 0.2, ..., 1\u517111\u4e2a\u70b9\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u7136\u540eAP\u5c31\u662f\u8fd911\u4e2aPrecision\u7684\u5e73\u5747\u503c\uff0c\u53d6 11 \u4e2a\u70b9 [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] \u7684\u63d2\u503c\u6240\u5f97 \u5f97\u5230\u4e00\u4e2a\u7c7b\u522b\u7684 AP \u7ed3\u679c\u5982\u4e0b\uff1a \u8981\u8ba1\u7b97 mAP\uff0c\u5c31\u628a\u6240\u6709\u7c7b\u522b\u7684 AP \u8ba1\u7b97\u51fa\u6765\uff0c\u7136\u540e\u6c42\u53d6\u5e73\u5747\u5373\u53ef\u3002 \u5728VOC2010\u53ca\u4ee5\u540e\uff0c\u9700\u8981\u9488\u5bf9\u6bcf\u4e00\u4e2a\u4e0d\u540c\u7684Recall\u503c\uff08\u5305\u62ec0\u548c1\uff09\uff0c\u9009\u53d6\u5176\u5927\u4e8e\u7b49\u4e8e\u8fd9\u4e9bRecall\u503c\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7136\u540e\u8ba1\u7b97PR\u66f2\u7ebf\u4e0b\u9762\u79ef\u4f5c\u4e3aAP\u503c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a 4.NMS\uff08\u975e\u6781\u5927\u503c\u6291\u5236\uff09 \u00b6 \u975e\u6781\u5927\u503c\u6291\u5236\uff08Non-Maximum Suppression\uff0cNMS\uff09\uff0c\u987e\u540d\u601d\u4e49\u5c31\u662f\u6291\u5236\u4e0d\u662f\u6781\u5927\u503c\u7684\u5143\u7d20\u3002\u4f8b\u5982\u5728\u884c\u4eba\u68c0\u6d4b\u4e2d\uff0c\u6ed1\u52a8\u7a97\u53e3\u7ecf\u63d0\u53d6\u7279\u5f81\uff0c\u7ecf\u5206\u7c7b\u5668\u5206\u7c7b\u8bc6\u522b\u540e\uff0c\u6bcf\u4e2a\u7a97\u53e3\u90fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5206\u6570\u3002\u4f46\u662f\u6ed1\u52a8\u7a97\u53e3\u4f1a\u5bfc\u81f4\u5f88\u591a\u7a97\u53e3\u4e0e\u5176\u4ed6\u7a97\u53e3\u5b58\u5728\u5305\u542b\u6216\u8005\u5927\u90e8\u5206\u4ea4\u53c9\u7684\u60c5\u51b5\u3002\u8fd9\u65f6\u5c31\u9700\u8981\u7528\u5230NMS\u6765\u9009\u53d6\u90a3\u4e9b\u90bb\u57df\u91cc\u5206\u6570\u6700\u9ad8\uff08\u662f\u884c\u4eba\u7684\u6982\u7387\u6700\u5927\uff09\uff0c\u5e76\u4e14\u6291\u5236\u90a3\u4e9b\u5206\u6570\u4f4e\u7684\u7a97\u53e3\u3002 NMS\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6709\u7740\u975e\u5e38\u91cd\u8981\u7684\u5e94\u7528\uff0c\u5982\u89c6\u9891\u76ee\u6807\u8ddf\u8e2a\u3001\u6570\u636e\u6316\u6398\u30013D\u91cd\u5efa\u3001\u76ee\u6807\u8bc6\u522b\u4ee5\u53ca\u7eb9\u7406\u5206\u6790\u7b49 \u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cNMS\u7684\u76ee\u7684\u5c31\u662f\u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a NMS\u7684\u539f\u7406\u662f\u5bf9\u4e8e\u9884\u6d4b\u6846\u7684\u5217\u8868B\u53ca\u5176\u5bf9\u5e94\u7684\u7f6e\u4fe1\u5ea6S,\u9009\u62e9\u5177\u6709\u6700\u5927score\u7684\u68c0\u6d4b\u6846M,\u5c06\u5176\u4eceB\u96c6\u5408\u4e2d\u79fb\u9664\u5e76\u52a0\u5165\u5230\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679cD\u4e2d.\u901a\u5e38\u5c06B\u4e2d\u5269\u4f59\u68c0\u6d4b\u6846\u4e2d\u4e0eM\u7684IoU\u5927\u4e8e\u9608\u503cNt\u7684\u6846\u4eceB\u4e2d\u79fb\u9664.\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b,\u76f4\u5230B\u4e3a\u7a7a\u3002 \u4f7f\u7528\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u662f\u68c0\u6d4b\u51fa\u4e00\u7cfb\u5217\u7684\u68c0\u6d4b\u6846 \u5c06\u68c0\u6d4b\u6846\u6309\u7167\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b \u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u68c0\u6d4b\u6846\u5e94\u7528NMS\u83b7\u53d6\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e9bNMS\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u5047\u8bbe\u5b9a\u4f4d\u8f66\u8f86\uff0c\u7b97\u6cd5\u5c31\u627e\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u77e9\u5f62\u6846\uff0c\u6211\u4eec\u9700\u8981\u5224\u522b\u54ea\u4e9b\u77e9\u5f62\u6846\u662f\u6ca1\u7528\u7684\uff0c\u9700\u8981\u4f7f\u7528NMS\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u3002 \u5047\u8bbe\u73b0\u5728\u68c0\u6d4b\u7a97\u53e3\u6709\uff1aA\u3001B\u3001C\u3001D\u3001E 5\u4e2a\u5019\u9009\u6846\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u8fed\u4ee3\u8ba1\u7b97\uff1a \u7b2c\u4e00\u8f6e\uff1a\u56e0\u4e3aB\u662f\u5f97\u5206\u6700\u9ad8\u7684\uff0c\u4e0eB\u7684IoU\uff1e0.5\u5220\u9664\u3002A\uff0cCDE\u4e2d\u73b0\u5728\u4e0eB\u8ba1\u7b97IoU\uff0cDE\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664DE\uff0cB\u4f5c\u4e3a\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u6709\u4e2a\u68c0\u6d4b\u6846\u7559\u4e0bB\uff0c\u653e\u5165\u96c6\u5408 \u7b2c\u4e8c\u8f6e\uff1aA\u7684\u5f97\u5206\u6700\u9ad8\uff0c\u4e0eA\u8ba1\u7b97IoU\uff0cC\u7684\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664C\uff0cA\u4f5c\u4e3a\u4e00\u4e2a\u7ed3\u679c \u6700\u7ec8\u7ed3\u679c\u4e3a\u5728\u8fd9\u4e2a5\u4e2a\u4e2d\u68c0\u6d4b\u51fa\u4e86\u4e24\u4e2a\u76ee\u6807\u4e3aA\u548cB\u3002 \u5355\u7c7b\u522b\u7684NMS\u7684\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a import numpy as np def nms ( bboxes , confidence_score , threshold ): \"\"\"\u975e\u6781\u5927\u6291\u5236\u8fc7\u7a0b :param bboxes: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5750\u6807 :param confidence: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5206\u6570 :param threshold: iou\u9608\u503c :return: \"\"\" # 1\u3001\u4f20\u5165\u65e0\u5019\u9009\u6846\u8fd4\u56de\u7a7a if len ( bboxes ) == 0 : return [], [] # \u5f3a\u8f6c\u6570\u7ec4 bboxes = np . array ( bboxes ) score = np . array ( confidence_score ) # \u53d6\u51fan\u4e2a\u7684\u6781\u5750\u6807\u70b9 x1 = bboxes [:, 0 ] y1 = bboxes [:, 1 ] x2 = bboxes [:, 2 ] y2 = bboxes [:, 3 ] # 2\u3001\u5bf9\u5019\u9009\u6846\u8fdb\u884cNMS\u7b5b\u9009 # \u8fd4\u56de\u7684\u6846\u5750\u6807\u548c\u5206\u6570 picked_boxes = [] picked_score = [] # \u5bf9\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u6392\u5e8f, \u83b7\u53d6\u6392\u5e8f\u540e\u7684\u4e0b\u6807\u5e8f\u53f7, argsort\u9ed8\u8ba4\u4ece\u5c0f\u5230\u5927\u6392\u5e8f order = np . argsort ( score ) areas = ( x2 - x1 ) * ( y2 - y1 ) while order . size > 0 : # \u5c06\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u6846\u52a0\u5165\u8fd4\u56de\u503c\u5217\u8868\u4e2d index = order [ - 1 ] #\u4fdd\u7559\u8be5\u7c7b\u5269\u4f59box\u4e2d\u5f97\u5206\u6700\u9ad8\u7684\u4e00\u4e2a picked_boxes . append ( bboxes [ index ]) picked_score . append ( confidence_score [ index ]) # \u83b7\u53d6\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u5019\u9009\u6846\u4e0e\u5176\u4ed6\u4efb\u610f\u5019\u9009\u6846\u7684\u76f8\u4ea4\u9762\u79ef x11 = np . maximum ( x1 [ index ], x1 [ order [: - 1 ]]) y11 = np . maximum ( y1 [ index ], y1 [ order [: - 1 ]]) x22 = np . minimum ( x2 [ index ], x2 [ order [: - 1 ]]) y22 = np . minimum ( y2 [ index ], y2 [ order [: - 1 ]]) # \u8ba1\u7b97\u76f8\u4ea4\u7684\u9762\u79ef,\u4e0d\u91cd\u53e0\u65f6\u9762\u79ef\u4e3a0 w = np . maximum ( 0.0 , x22 - x11 ) h = np . maximum ( 0.0 , y22 - y11 ) intersection = w * h # \u5229\u7528\u76f8\u4ea4\u7684\u9762\u79ef\u548c\u4e24\u4e2a\u6846\u81ea\u8eab\u7684\u9762\u79ef\u8ba1\u7b97\u6846\u7684\u4ea4\u5e76\u6bd4 ratio = intersection / ( areas [ index ] + areas [ order [: - 1 ]] - intersection ) # \u4fdd\u7559IoU\u5c0f\u4e8e\u9608\u503c\u7684box keep_boxes_indics = np . where ( ratio < threshold ) # \u4fdd\u7559\u5269\u4f59\u7684\u6846 order = order [ keep_boxes_indics ] # \u8fd4\u56deNMS\u540e\u7684\u6846\u53ca\u5206\u7c7b\u7ed3\u679c return picked_boxes , picked_score \u5047\u8bbe\u6709\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\uff1a bounding = [( 187 , 82 , 337 , 317 ), ( 150 , 67 , 305 , 282 ), ( 246 , 121 , 368 , 304 )] confidence_score = [ 0.9 , 0.65 , 0.8 ] threshold = 0.3 picked_boxes , picked_score = nms ( bounding , confidence_score , threshold ) print ( '\u9608\u503cthreshold\u4e3a:' , threshold ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u662f\uff1a' , picked_boxes ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f\uff1a' , picked_score ) \u8fd4\u56de\u7ed3\u679c\uff1a \u9608\u503c threshold\u4e3a : 0.3 NMS\u540e\u5f97\u5230\u7684bbox\u662f \uff1a [ array ([ 187 , 82 , 337 , 317 ])] NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f \uff1a [ 0.9 ] 5.\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5206\u7c7b \u00b6 \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3atwo-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09\u4e24\u7c7b\uff1a two-stage\u7684\u7b97\u6cd5 \u5148\u7531\u7b97\u6cd5\u751f\u6210\u4e00\u7cfb\u5217\u4f5c\u4e3a\u6837\u672c\u7684\u5019\u9009\u6846\uff0c\u518d\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6837\u672c\u5206\u7c7b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u8fc7\u7a0b\uff0c\u5176\u63d0\u53d6\u7684\u662fCNN\u5377\u79ef\u7279\u5f81\uff0c\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u548c\u76ee\u6807\u68c0\u6d4b\u4e24\u90e8\u5206\u3002\u7f51\u7edc\u7684\u51c6\u786e\u5ea6\u9ad8\u3001\u901f\u5ea6\u76f8\u5bf9\u8f83\u6162\u3002 two-stages\u7b97\u6cd5\u7684\u4ee3\u8868\u662fRCNN\u7cfb\u5217\uff1aR-CNN\u5230Faster R-CNN\u7f51\u7edc One-stage\u7684\u7b97\u6cd5 \u76f4\u63a5\u901a\u8fc7\u4e3b\u5e72\u7f51\u7edc\u7ed9\u51fa\u76ee\u6807\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6ca1\u6709\u4f7f\u7528\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u7f51\u8def\uff0c\u8fd9\u79cd\u7b97\u6cd5\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u7cbe\u5ea6\u76f8\u5bf9Two-stage\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u964d\u4f4e\u4e86\u5f88\u591a\u3002 one-stage\u7b97\u6cd5\u7684\u4ee3\u8868\u662f\uff1a YOLO\u7cfb\u5217\uff1aYOLOv1\u3001YOLOv2\u3001YOLOv3\u3001 SSD\u7b49 \u603b\u7ed3 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 IOU\u548cmAP \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b two-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09","title":"\u76ee\u6807\u68c0\u6d4b\u6982\u8ff0"},{"location":"objectdection/01.overview/#41","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b","title":"4.1 \u76ee\u6807\u68c0\u6d4b\u6982\u8ff0"},{"location":"objectdection/01.overview/#1","text":"\u76ee\u6807\u68c0\u6d4b\uff08Object Detection\uff09\u7684\u4efb\u52a1\u662f\u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u3002 \u76ee\u6807\u68c0\u6d4b\u4e2d\u80fd\u68c0\u6d4b\u51fa\u6765\u7684\u7269\u4f53\u53d6\u51b3\u4e8e\u5f53\u524d\u4efb\u52a1\uff08\u6570\u636e\u96c6\uff09\u9700\u8981\u68c0\u6d4b\u7684\u7269\u4f53\u6709\u54ea\u4e9b\u3002\u5047\u8bbe\u6211\u4eec\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5b9a\u4f4d\u662f\u68c0\u6d4b\u52a8\u7269\uff08\u725b\u3001\u7f8a\u3001\u732a\u3001\u72d7\u3001\u732b\u4e94\u79cd\u7ed3\u679c\uff09\uff0c\u90a3\u4e48\u6a21\u578b\u5bf9\u4efb\u4f55\u4e00\u5f20\u56fe\u7247\u8f93\u51fa\u7ed3\u679c\u4e0d\u4f1a\u8f93\u51fa\u9e2d\u5b50\u3001\u4e66\u7c4d\u7b49\u5176\u5b83\u7c7b\u578b\u7ed3\u679c\u3002 \u76ee\u6807\u68c0\u6d4b\u7684\u4f4d\u7f6e\u4fe1\u606f\u4e00\u822c\u7531\u4e24\u79cd\u683c\u5f0f\uff08\u4ee5\u56fe\u7247\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9(0,0)\uff09\uff1a 1\u3001\u6781\u5750\u6807\u8868\u793a\uff1a(xmin, ymin, xmax, ymax) xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5c0f\u503c xmin,ymin:x,y\u5750\u6807\u7684\u6700\u5927\u503c 2\u3001\u4e2d\u5fc3\u70b9\u5750\u6807\uff1a(x_center, y_center, w, h) x_center, y_center:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 w,h:\u76ee\u6807\u68c0\u6d4b\u6846\u7684\u5bbd\u3001\u9ad8 \u5047\u8bbe\u5728\u4e0b\u9762\u7684\u56fe\u50cf\u4e2d\u8fdb\u884c\u68c0\u6d4b\uff0c\uff1a \u90a3\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u7684\u4e2d\u5fc3\u70b9\u8868\u793a\u5f62\u5f0f\u5982\u4e0b\u6240\u793a\uff1a","title":"1. \u76ee\u6807\u68c0\u6d4b"},{"location":"objectdection/01.overview/#2","text":"\u7ecf\u5178\u7684\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u6709\u4e24\u79cd\uff0c PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u3002","title":"2.\u5e38\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6"},{"location":"objectdection/01.overview/#21-pascal-voc","text":"PASCAL VOC\u662f\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u7684\u7ecf\u5178\u6570\u636e\u96c6\u3002PASCAL VOC\u5305\u542b\u7ea610,000\u5f20\u5e26\u6709\u8fb9\u754c\u6846\u7684\u56fe\u7247\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002PASCAL VOC\u6570\u636e\u96c6\u662f\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u7684\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f88\u591a\u6a21\u578b\u90fd\u662f\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u7684\uff0c\u5e38\u7528\u7684\u662fVOC2007\u548cVOC2012\u4e24\u4e2a\u7248\u672c\u6570\u636e\uff0c\u517120\u4e2a\u7c7b\u522b\uff0c\u5206\u522b\u662f\uff1a \u4e5f\u5c31\u662f\uff1a 1.\u4eba: \u4eba 2.\u52a8\u7269: \u9e1f\uff0c\u732b\uff0c\u725b\uff0c\u72d7\uff0c\u9a6c\uff0c\u7f8a 3.\u4ea4\u901a\u5de5\u5177: \u98de\u673a\uff0c\u81ea\u884c\u8f66\uff0c\u8239\uff0c\u516c\u5171\u6c7d\u8f66\uff0c\u6c7d\u8f66\uff0c\u6469\u6258\u8f66\uff0c\u706b\u8f66 4.\u5ba4\u5185: \u74f6\u5b50\uff0c\u6905\u5b50\uff0c\u9910\u684c\uff0c\u76c6\u683d\uff0c\u6c99\u53d1\uff0c\u7535\u89c6/\u663e\u793a\u5668 \u4e0b\u8f7d\u5730\u5740 \uff1a https://pjreddie.com/projects/pascal-voc-dataset-mirror/ \u6574\u4e2a\u6570\u636e\u7684\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u5176\u4e2d\uff1a JPEGImages\u5b58\u653e\u56fe\u7247\u6587\u4ef6 Annotations\u4e0b\u5b58\u653e\u7684\u662fxml\u6587\u4ef6,\u63cf\u8ff0\u4e86\u56fe\u7247\u4fe1\u606f\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u9700\u8981\u5173\u6ce8\u7684\u5c31\u662f\u8282\u70b9\u4e0b\u7684\u6570\u636e,\u5c24\u5176\u662fbndbox\u4e0b\u7684\u6570\u636e.xmin,ymin\u6784\u6210\u4e86boundingbox\u7684\u5de6\u4e0a\u89d2,xmax,ymax\u6784\u6210\u4e86boundingbox\u7684\u53f3\u4e0b\u89d2\uff0c\u4e5f\u5c31\u662f\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u4f4d\u7f6e\u4fe1\u606f ImageSets\u5305\u542b\u4ee5\u4e0b4\u4e2a\u6587\u4ef6\u5939\uff1a Action\u4e0b\u5b58\u653e\u7684\u662f\u4eba\u7684\u52a8\u4f5c\uff08\u4f8b\u5982running\u3001jumping\u7b49\u7b49\uff09 Layout\u4e0b\u5b58\u653e\u7684\u662f\u5177\u6709\u4eba\u4f53\u90e8\u4f4d\u7684\u6570\u636e\uff08\u4eba\u7684head\u3001hand\u3001feet\u7b49\u7b49\uff09 Segmentation\u4e0b\u5b58\u653e\u7684\u662f\u53ef\u7528\u4e8e\u5206\u5272\u7684\u6570\u636e\u3002 Main\u4e0b\u5b58\u653e\u7684\u662f\u56fe\u50cf\u7269\u4f53\u8bc6\u522b\u7684\u6570\u636e\uff0c\u603b\u5171\u5206\u4e3a20\u7c7b\uff0c\u8fd9\u662f\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u7684\u91cd\u70b9\u3002\u8be5\u6587\u4ef6\u5939\u4e2d\u7684\u6570\u636e\u5bf9\u8d1f\u6837\u672c\u6587\u4ef6\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002","title":"2.1 PASCAL VOC\u6570\u636e\u96c6"},{"location":"objectdection/01.overview/#22-ms-coco","text":"MS COCO\u7684\u5168\u79f0\u662fMicrosoft Common Objects in Context\uff0c\u5fae\u8f6f\u4e8e2014\u5e74\u51fa\u8d44\u6807\u6ce8\u7684Microsoft COCO\u6570\u636e\u96c6\uff0c\u4e0eImageNet\u7ade\u8d5b\u4e00\u6837\uff0c\u88ab\u89c6\u4e3a\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6700\u53d7\u5173\u6ce8\u548c\u6700\u6743\u5a01\u7684\u6bd4\u8d5b\u4e4b\u4e00\u3002 COCO\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u5927\u578b\u7684\u3001\u4e30\u5bcc\u7684\u7269\u4f53\u68c0\u6d4b\uff0c\u5206\u5272\u548c\u5b57\u5e55\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4ee5\u573a\u666f\u7406\u89e3\u4e3a\u76ee\u6807\uff0c\u4e3b\u8981\u4ece\u590d\u6742\u7684\u65e5\u5e38\u573a\u666f\u4e2d\u622a\u53d6\uff0c\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u901a\u8fc7\u7cbe\u786e\u7684\u5206\u5272\u8fdb\u884c\u4f4d\u7f6e\u7684\u6807\u5b9a\u3002\u56fe\u50cf\u5305\u62ec91\u7c7b\u76ee\u6807\uff0c328,000\u5f71\u50cf\u548c2,500,000\u4e2alabel\u3002\u76ee\u524d\u4e3a\u6b62\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u5927\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u7684\u7c7b\u522b\u670980 \u7c7b\uff0c\u6709\u8d85\u8fc733 \u4e07\u5f20\u56fe\u7247\uff0c\u5176\u4e2d20 \u4e07\u5f20\u6709\u6807\u6ce8\uff0c\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u4e2a\u4f53\u7684\u6570\u76ee\u8d85\u8fc7150 \u4e07\u4e2a\u3002 \u56fe\u50cf\u793a\u4f8b\uff1a coco\u6570\u636e\u96c6\u7684\u6807\u7b7e\u6587\u4ef6\u6807\u8bb0\u4e86\u6bcf\u4e2asegmentation+bounding box\u7684\u7cbe\u786e\u5750\u6807\uff0c\u5176\u7cbe\u5ea6\u5747\u4e3a\u5c0f\u6570\u70b9\u540e\u4e24\u4f4d\u4e00\u4e2a\u76ee\u6807\u7684\u6807\u7b7e\u793a\u610f\u5982\u4e0b\uff1a {\"segmentation\":[[392.87, 275.77, 402.24, 284.2, 382.54, 342.36, 375.99, 356.43, 372.23, 357.37, 372.23, 397.7, 383.48, 419.27,407.87, 439.91, 427.57, 389.25, 447.26, 346.11, 447.26, 328.29, 468.84, 290.77,472.59, 266.38], [429.44,465.23, 453.83, 473.67, 636.73, 474.61, 636.73, 392.07, 571.07, 364.88, 546.69,363.0]], \"area\": 28458.996150000003, \"iscrowd\": 0,\"image_id\": 503837, \"bbox\": [372.23, 266.38, 264.5,208.23] , \"category_id\": 4, \"id\": 151109},","title":"2.2 MS COCO\u6570\u636e\u96c6"},{"location":"objectdection/01.overview/#3","text":"","title":"3.\u5e38\u7528\u7684\u8bc4\u4ef7\u6307\u6807"},{"location":"objectdection/01.overview/#31-iou","text":"\u5728\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0cIoU\uff08intersection over union\uff0c\u4ea4\u5e76\u6bd4\uff09\u662f\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7528\u6765\u8bc4\u4ef72\u4e2a\u77e9\u5f62\u6846\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\uff1a IoU = \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u4ea4\u7684\u9762\u79ef / \u4e24\u4e2a\u77e9\u5f62\u6846\u76f8\u5e76\u7684\u9762\u79ef \uff0c \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e0b\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff1a \u5176\u4e2d\u4e0a\u56fe\u84dd\u8272\u6846\u6846\u4e3a\u68c0\u6d4b\u7ed3\u679c\uff0c\u7ea2\u8272\u6846\u6846\u4e3a\u771f\u5b9e\u6807\u6ce8\u3002 \u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u7ed3\u679c\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4\u6765\u8861\u91cf\u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u5bf9\u4e8e\u68c0\u6d4b\u6846\u7684\u5224\u5b9a\u90fd\u4f1a\u5b58\u5728\u4e00\u4e2a\u9608\u503c\uff0c\u4e5f\u5c31\u662f IoU \u7684\u9608\u503c\uff0c\u4e00\u822c\u53ef\u4ee5\u8bbe\u7f6e\u5f53 IoU \u7684\u503c\u5927\u4e8e 0.5 \u7684\u65f6\u5019\uff0c\u5219\u53ef\u8ba4\u4e3a\u68c0\u6d4b\u5230\u76ee\u6807\u7269\u4f53\u3002 \u5b9e\u73b0\u65b9\u6cd5\uff1a import numpy as np # \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97IOU def Iou ( box1 , box2 , wh = False ): # \u5224\u65adbbox\u7684\u8868\u793a\u5f62\u5f0f if wh == False : # \u4f7f\u7528\u6781\u5750\u6807\u5f62\u5f0f\u8868\u793a\uff1a\u76f4\u63a5\u83b7\u53d6\u4e24\u4e2abbox\u7684\u5750\u6807 xmin1 , ymin1 , xmax1 , ymax1 = box1 xmin2 , ymin2 , xmax2 , ymax2 = box2 else : # \u4f7f\u7528\u4e2d\u5fc3\u70b9\u5f62\u5f0f\u8868\u793a\uff1a \u83b7\u53d6\u4e24\u4e2a\u4e24\u4e2abbox\u7684\u6781\u5750\u6807\u8868\u793a\u5f62\u5f0f # \u7b2c\u4e00\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin1 , ymin1 = int ( box1 [ 0 ] - box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] - box1 [ 3 ] / 2.0 ) # \u7b2c\u4e00\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax1 , ymax1 = int ( box1 [ 0 ] + box1 [ 2 ] / 2.0 ), int ( box1 [ 1 ] + box1 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u5de6\u4e0a\u89d2\u5750\u6807 xmin2 , ymin2 = int ( box2 [ 0 ] - box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] - box2 [ 3 ] / 2.0 ) # \u7b2c\u4e8c\u4e2a\u6846\u53f3\u4e0b\u89d2\u5750\u6807 xmax2 , ymax2 = int ( box2 [ 0 ] + box2 [ 2 ] / 2.0 ), int ( box2 [ 1 ] + box2 [ 3 ] / 2.0 ) # \u83b7\u53d6\u77e9\u5f62\u6846\u4ea4\u96c6\u5bf9\u5e94\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u7684\u5750\u6807\uff08intersection\uff09 xx1 = np . max ([ xmin1 , xmin2 ]) yy1 = np . max ([ ymin1 , ymin2 ]) xx2 = np . min ([ xmax1 , xmax2 ]) yy2 = np . min ([ ymax1 , ymax2 ]) # \u8ba1\u7b97\u4e24\u4e2a\u77e9\u5f62\u6846\u9762\u79ef area1 = ( xmax1 - xmin1 ) * ( ymax1 - ymin1 ) area2 = ( xmax2 - xmin2 ) * ( ymax2 - ymin2 ) #\u8ba1\u7b97\u4ea4\u96c6\u9762\u79ef inter_area = ( np . max ([ 0 , xx2 - xx1 ])) * ( np . max ([ 0 , yy2 - yy1 ])) #\u8ba1\u7b97\u4ea4\u5e76\u6bd4 iou = inter_area / ( area1 + area2 - inter_area + 1e-6 ) return iou \u5047\u8bbe\u6211\u4eec\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff0c\u5e76\u5c55\u793a\u5728\u56fe\u50cf\u4e0a\uff1a import matplotlib.pyplot as plt import matplotlib.patches as patches # \u771f\u5b9e\u6846\u4e0e\u9884\u6d4b\u6846 True_bbox , predict_bbox = [ 100 , 35 , 398 , 400 ], [ 40 , 150 , 355 , 398 ] # bbox\u662fbounding box\u7684\u7f29\u5199 img = plt . imread ( 'dog.jpeg' ) fig = plt . imshow ( img ) # \u5c06\u8fb9\u754c\u6846(\u5de6\u4e0ax, \u5de6\u4e0ay, \u53f3\u4e0bx, \u53f3\u4e0by)\u683c\u5f0f\u8f6c\u6362\u6210matplotlib\u683c\u5f0f\uff1a((\u5de6\u4e0ax, \u5de6\u4e0ay), \u5bbd, \u9ad8) # \u771f\u5b9e\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( True_bbox [ 0 ], True_bbox [ 1 ]), width = True_bbox [ 2 ] - True_bbox [ 0 ], height = True_bbox [ 3 ] - True_bbox [ 1 ], fill = False , edgecolor = \"blue\" , linewidth = 2 )) # \u9884\u6d4b\u6846\u7ed8\u5236 fig . axes . add_patch ( plt . Rectangle ( xy = ( predict_bbox [ 0 ], predict_bbox [ 1 ]), width = predict_bbox [ 2 ] - predict_bbox [ 0 ], height = predict_bbox [ 3 ] - predict_bbox [ 1 ], fill = False , edgecolor = \"red\" , linewidth = 2 )) \u8ba1\u7b97IoU\uff1a Iou ( True_bbox , predict_bbox ) \u7ed3\u679c\u4e3a\uff1a 0.5114435907762924","title":"3.1 IOU"},{"location":"objectdection/01.overview/#32-mapmean-average-precision","text":"\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u4e2d\u7684\u6bcf\u4e2a\u56fe\u7247\u90fd\u53ef\u80fd\u5305\u542b\u4e00\u4e9b\u4e0d\u540c\u7c7b\u522b\u7684\u7269\u4f53\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u7684\u7269\u4f53\u5206\u7c7b\u548c\u5b9a\u4f4d\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u6807\u51c6\u6307\u6807precision\u4e0d\u80fd\u76f4\u63a5\u5e94\u7528\u4e8e\u6b64\u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cmAP\u662f\u4e3b\u8981\u7684\u8861\u91cf\u6307\u6807\u3002 mAP\u662f\u591a\u4e2a\u5206\u7c7b\u4efb\u52a1\u7684AP\u7684\u5e73\u5747\u503c\uff0c\u800cAP\uff08average precision\uff09\u662fPR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0c\u6240\u4ee5\u5728\u4ecb\u7ecdmAP\u4e4b\u524d\u6211\u4eec\u8981\u5148\u5f97\u5230PR\u66f2\u7ebf\u3002 TP\u3001FP\u3001FN\u3001TN True Positive (TP): IoU> ( \u4e00\u822c\u53d6 0.5 ) \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff08\u540c\u4e00 Ground Truth \u53ea\u8ba1\u7b97\u4e00\u6b21\uff09 False Positive (FP): IoU<= \u7684\u68c0\u6d4b\u6846\u6570\u91cf\uff0c\u6216\u8005\u662f\u68c0\u6d4b\u5230\u540c\u4e00\u4e2a GT \u7684\u591a\u4f59\u68c0\u6d4b\u6846\u7684\u6570\u91cf False Negative (FN): \u6ca1\u6709\u68c0\u6d4b\u5230\u7684 GT \u7684\u6570\u91cf True Negative (TN): \u5728 mAP \u8bc4\u4ef7\u6307\u6807\u4e2d\u4e0d\u4f1a\u4f7f\u7528\u5230 \u67e5\u51c6\u7387\u3001\u67e5\u5168\u7387 \u67e5\u51c6\u7387\uff08Precision\uff09: TP/(TP + FP) \u67e5\u5168\u7387\uff08Recall\uff09: TP/(TP + FN) \u4e8c\u8005\u7ed8\u5236\u7684\u66f2\u7ebf\u79f0\u4e3a P-R \u66f2\u7ebf \u5148\u5b9a\u4e49\u4e24\u4e2a\u516c\u5f0f\uff0c\u4e00\u4e2a\u662f Precision\uff0c\u4e00\u4e2a\u662f Recall\uff0c\u4e0e\u4e0a\u9762\u7684\u516c\u5f0f\u76f8\u540c\uff0c\u6269\u5c55\u5f00\u6765\uff0c\u7528\u53e6\u5916\u4e00\u79cd\u5f62\u5f0f\u8fdb\u884c\u5c55\u793a\uff0c\u5176\u4e2d all detctions \u4ee3\u8868\u6240\u6709\u9884\u6d4b\u6846\u7684\u6570\u91cf\uff0c all ground truths \u4ee3\u8868\u6240\u6709 GT \u7684\u6570\u91cf\u3002 AP \u662f\u8ba1\u7b97\u67d0\u4e00\u7c7b P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff0cmAP \u5219\u662f\u8ba1\u7b97\u6240\u6709\u7c7b\u522b P-R \u66f2\u7ebf\u4e0b\u9762\u79ef\u7684\u5e73\u5747\u503c\u3002 \u5047\u8bbe\u6211\u4eec\u6709 7 \u5f20\u56fe\u7247\uff08Images1-Image7\uff09\uff0c\u8fd9\u4e9b\u56fe\u7247\u6709 15 \u4e2a\u76ee\u6807\uff08\u7eff\u8272\u7684\u6846\uff0cGT \u7684\u6570\u91cf\uff0c\u4e0a\u6587\u63d0\u53ca\u7684 all ground truths \uff09\u4ee5\u53ca 24 \u4e2a\u9884\u6d4b\u8fb9\u6846\uff08\u7ea2\u8272\u7684\u6846\uff0cA-Y \u7f16\u53f7\u8868\u793a\uff0c\u5e76\u4e14\u6709\u4e00\u4e2a\u7f6e\u4fe1\u5ea6\u503c\uff09\uff1a \u6839\u636e\u4e0a\u56fe\u4ee5\u53ca\u8bf4\u660e\uff0c\u6211\u4eec\u53ef\u4ee5\u5217\u51fa\u4ee5\u4e0b\u8868\u683c\uff0c\u5176\u4e2d Images \u4ee3\u8868\u56fe\u7247\u7684\u7f16\u53f7\uff0cDetections \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f16\u53f7\uff0cConfidences \u4ee3\u8868\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cTP or FP \u4ee3\u8868\u9884\u6d4b\u7684\u8fb9\u6846\u662f\u6807\u8bb0\u4e3a TP \u8fd8\u662f FP\uff08\u8ba4\u4e3a\u9884\u6d4b\u8fb9\u6846\u4e0e GT \u7684 IOU \u503c\u5927\u4e8e\u7b49\u4e8e 0.3 \u5c31\u6807\u8bb0\u4e3a TP\uff1b\u82e5\u4e00\u4e2a GT \u6709\u591a\u4e2a\u9884\u6d4b\u8fb9\u6846\uff0c\u5219\u8ba4\u4e3a IOU \u6700\u5927\u4e14\u5927\u4e8e\u7b49\u4e8e 0.3 \u7684\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff0c\u5176\u4ed6\u7684\u6807\u8bb0\u4e3a FP\uff0c\u5373\u4e00\u4e2a GT \u53ea\u80fd\u6709\u4e00\u4e2a\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a TP\uff09\uff0c\u8fd9\u91cc\u7684 0.3 \u662f\u968f\u673a\u53d6\u7684\u4e00\u4e2a\u503c\u3002 \u901a\u8fc7\u4e0a\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf\uff08\u56e0\u4e3a AP \u5c31\u662f P-R \u66f2\u7ebf\u4e0b\u9762\u7684\u9762\u79ef\uff09\uff0c\u4f46\u662f\u5728\u6b64\u4e4b\u524d\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u51fa P-R \u66f2\u7ebf\u4e0a\u5404\u4e2a\u70b9\u7684\u5750\u6807\uff0c\u6839\u636e\u7f6e\u4fe1\u5ea6\u4ece\u5927\u5230\u5c0f\u6392\u5e8f\u6240\u6709\u7684\u9884\u6d4b\u6846\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u8ba1\u7b97 Precision \u548c Recall \u7684\u503c\uff0c\u89c1\u4e0b\u8868\u3002\uff08\u9700\u8981\u8bb0\u4f4f\u4e00\u4e2a\u53eb\u7d2f\u52a0\u7684\u6982\u5ff5\uff0c\u5c31\u662f\u4e0b\u56fe\u7684 ACC TP \u548c ACC FP\uff09 \u6807\u53f7\u4e3a 1 \u7684 Precision \u548c Recall \u7684\u8ba1\u7b97\u65b9\u5f0f\uff1aPrecision=TP/(TP+FP)=1/(1+0)=1\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \uff08 all ground truths \u4e0a\u9762\u6709\u5b9a\u4e49\u8fc7\u4e86 \uff09 \u6807\u53f7 2\uff1aPrecision=TP/(TP+FP)=1/(1+1)=0.5\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=1/15=0.0666 \u6807\u53f7 3\uff1aPrecision=TP/(TP+FP)=2/(2+1)=0.6666\uff0cRecall=TP/(TP+FN)=TP/( all ground truths )=2/15=0.1333 \u5176\u4ed6\u7684\u4f9d\u6b21\u7c7b\u63a8 \u7136\u540e\u5c31\u53ef\u4ee5\u7ed8\u5236\u51fa P-R \u66f2\u7ebf \u5f97\u5230 P-R \u66f2\u7ebf\u5c31\u53ef\u4ee5\u8ba1\u7b97 AP\uff08P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff09\uff0c\u8981\u8ba1\u7b97 P-R \u4e0b\u65b9\u7684\u9762\u79ef\uff0c\u6709\u4e24\u79cd\u65b9\u6cd5\uff1a \u5728VOC2010\u4ee5\u524d\uff0c\u53ea\u9700\u8981\u9009\u53d6\u5f53Recall >= 0, 0.1, 0.2, ..., 1\u517111\u4e2a\u70b9\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u7136\u540eAP\u5c31\u662f\u8fd911\u4e2aPrecision\u7684\u5e73\u5747\u503c\uff0c\u53d6 11 \u4e2a\u70b9 [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] \u7684\u63d2\u503c\u6240\u5f97 \u5f97\u5230\u4e00\u4e2a\u7c7b\u522b\u7684 AP \u7ed3\u679c\u5982\u4e0b\uff1a \u8981\u8ba1\u7b97 mAP\uff0c\u5c31\u628a\u6240\u6709\u7c7b\u522b\u7684 AP \u8ba1\u7b97\u51fa\u6765\uff0c\u7136\u540e\u6c42\u53d6\u5e73\u5747\u5373\u53ef\u3002 \u5728VOC2010\u53ca\u4ee5\u540e\uff0c\u9700\u8981\u9488\u5bf9\u6bcf\u4e00\u4e2a\u4e0d\u540c\u7684Recall\u503c\uff08\u5305\u62ec0\u548c1\uff09\uff0c\u9009\u53d6\u5176\u5927\u4e8e\u7b49\u4e8e\u8fd9\u4e9bRecall\u503c\u65f6\u7684Precision\u6700\u5927\u503c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7136\u540e\u8ba1\u7b97PR\u66f2\u7ebf\u4e0b\u9762\u79ef\u4f5c\u4e3aAP\u503c\uff1a \u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a","title":"3.2 mAP\uff08Mean Average Precision\uff09"},{"location":"objectdection/01.overview/#4nms","text":"\u975e\u6781\u5927\u503c\u6291\u5236\uff08Non-Maximum Suppression\uff0cNMS\uff09\uff0c\u987e\u540d\u601d\u4e49\u5c31\u662f\u6291\u5236\u4e0d\u662f\u6781\u5927\u503c\u7684\u5143\u7d20\u3002\u4f8b\u5982\u5728\u884c\u4eba\u68c0\u6d4b\u4e2d\uff0c\u6ed1\u52a8\u7a97\u53e3\u7ecf\u63d0\u53d6\u7279\u5f81\uff0c\u7ecf\u5206\u7c7b\u5668\u5206\u7c7b\u8bc6\u522b\u540e\uff0c\u6bcf\u4e2a\u7a97\u53e3\u90fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5206\u6570\u3002\u4f46\u662f\u6ed1\u52a8\u7a97\u53e3\u4f1a\u5bfc\u81f4\u5f88\u591a\u7a97\u53e3\u4e0e\u5176\u4ed6\u7a97\u53e3\u5b58\u5728\u5305\u542b\u6216\u8005\u5927\u90e8\u5206\u4ea4\u53c9\u7684\u60c5\u51b5\u3002\u8fd9\u65f6\u5c31\u9700\u8981\u7528\u5230NMS\u6765\u9009\u53d6\u90a3\u4e9b\u90bb\u57df\u91cc\u5206\u6570\u6700\u9ad8\uff08\u662f\u884c\u4eba\u7684\u6982\u7387\u6700\u5927\uff09\uff0c\u5e76\u4e14\u6291\u5236\u90a3\u4e9b\u5206\u6570\u4f4e\u7684\u7a97\u53e3\u3002 NMS\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6709\u7740\u975e\u5e38\u91cd\u8981\u7684\u5e94\u7528\uff0c\u5982\u89c6\u9891\u76ee\u6807\u8ddf\u8e2a\u3001\u6570\u636e\u6316\u6398\u30013D\u91cd\u5efa\u3001\u76ee\u6807\u8bc6\u522b\u4ee5\u53ca\u7eb9\u7406\u5206\u6790\u7b49 \u3002 \u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cNMS\u7684\u76ee\u7684\u5c31\u662f\u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a NMS\u7684\u539f\u7406\u662f\u5bf9\u4e8e\u9884\u6d4b\u6846\u7684\u5217\u8868B\u53ca\u5176\u5bf9\u5e94\u7684\u7f6e\u4fe1\u5ea6S,\u9009\u62e9\u5177\u6709\u6700\u5927score\u7684\u68c0\u6d4b\u6846M,\u5c06\u5176\u4eceB\u96c6\u5408\u4e2d\u79fb\u9664\u5e76\u52a0\u5165\u5230\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679cD\u4e2d.\u901a\u5e38\u5c06B\u4e2d\u5269\u4f59\u68c0\u6d4b\u6846\u4e2d\u4e0eM\u7684IoU\u5927\u4e8e\u9608\u503cNt\u7684\u6846\u4eceB\u4e2d\u79fb\u9664.\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b,\u76f4\u5230B\u4e3a\u7a7a\u3002 \u4f7f\u7528\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u662f\u68c0\u6d4b\u51fa\u4e00\u7cfb\u5217\u7684\u68c0\u6d4b\u6846 \u5c06\u68c0\u6d4b\u6846\u6309\u7167\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b \u5bf9\u540c\u4e00\u7c7b\u522b\u7684\u68c0\u6d4b\u6846\u5e94\u7528NMS\u83b7\u53d6\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c \u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u770b\u4e9bNMS\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u5047\u8bbe\u5b9a\u4f4d\u8f66\u8f86\uff0c\u7b97\u6cd5\u5c31\u627e\u51fa\u4e86\u4e00\u7cfb\u5217\u7684\u77e9\u5f62\u6846\uff0c\u6211\u4eec\u9700\u8981\u5224\u522b\u54ea\u4e9b\u77e9\u5f62\u6846\u662f\u6ca1\u7528\u7684\uff0c\u9700\u8981\u4f7f\u7528NMS\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u3002 \u5047\u8bbe\u73b0\u5728\u68c0\u6d4b\u7a97\u53e3\u6709\uff1aA\u3001B\u3001C\u3001D\u3001E 5\u4e2a\u5019\u9009\u6846\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u8fed\u4ee3\u8ba1\u7b97\uff1a \u7b2c\u4e00\u8f6e\uff1a\u56e0\u4e3aB\u662f\u5f97\u5206\u6700\u9ad8\u7684\uff0c\u4e0eB\u7684IoU\uff1e0.5\u5220\u9664\u3002A\uff0cCDE\u4e2d\u73b0\u5728\u4e0eB\u8ba1\u7b97IoU\uff0cDE\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664DE\uff0cB\u4f5c\u4e3a\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u6709\u4e2a\u68c0\u6d4b\u6846\u7559\u4e0bB\uff0c\u653e\u5165\u96c6\u5408 \u7b2c\u4e8c\u8f6e\uff1aA\u7684\u5f97\u5206\u6700\u9ad8\uff0c\u4e0eA\u8ba1\u7b97IoU\uff0cC\u7684\u7ed3\u679c\uff1e0.5\uff0c\u5254\u9664C\uff0cA\u4f5c\u4e3a\u4e00\u4e2a\u7ed3\u679c \u6700\u7ec8\u7ed3\u679c\u4e3a\u5728\u8fd9\u4e2a5\u4e2a\u4e2d\u68c0\u6d4b\u51fa\u4e86\u4e24\u4e2a\u76ee\u6807\u4e3aA\u548cB\u3002 \u5355\u7c7b\u522b\u7684NMS\u7684\u5b9e\u73b0\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a import numpy as np def nms ( bboxes , confidence_score , threshold ): \"\"\"\u975e\u6781\u5927\u6291\u5236\u8fc7\u7a0b :param bboxes: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5750\u6807 :param confidence: \u540c\u7c7b\u522b\u5019\u9009\u6846\u5206\u6570 :param threshold: iou\u9608\u503c :return: \"\"\" # 1\u3001\u4f20\u5165\u65e0\u5019\u9009\u6846\u8fd4\u56de\u7a7a if len ( bboxes ) == 0 : return [], [] # \u5f3a\u8f6c\u6570\u7ec4 bboxes = np . array ( bboxes ) score = np . array ( confidence_score ) # \u53d6\u51fan\u4e2a\u7684\u6781\u5750\u6807\u70b9 x1 = bboxes [:, 0 ] y1 = bboxes [:, 1 ] x2 = bboxes [:, 2 ] y2 = bboxes [:, 3 ] # 2\u3001\u5bf9\u5019\u9009\u6846\u8fdb\u884cNMS\u7b5b\u9009 # \u8fd4\u56de\u7684\u6846\u5750\u6807\u548c\u5206\u6570 picked_boxes = [] picked_score = [] # \u5bf9\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u6392\u5e8f, \u83b7\u53d6\u6392\u5e8f\u540e\u7684\u4e0b\u6807\u5e8f\u53f7, argsort\u9ed8\u8ba4\u4ece\u5c0f\u5230\u5927\u6392\u5e8f order = np . argsort ( score ) areas = ( x2 - x1 ) * ( y2 - y1 ) while order . size > 0 : # \u5c06\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u6846\u52a0\u5165\u8fd4\u56de\u503c\u5217\u8868\u4e2d index = order [ - 1 ] #\u4fdd\u7559\u8be5\u7c7b\u5269\u4f59box\u4e2d\u5f97\u5206\u6700\u9ad8\u7684\u4e00\u4e2a picked_boxes . append ( bboxes [ index ]) picked_score . append ( confidence_score [ index ]) # \u83b7\u53d6\u5f53\u524d\u7f6e\u4fe1\u5ea6\u6700\u5927\u7684\u5019\u9009\u6846\u4e0e\u5176\u4ed6\u4efb\u610f\u5019\u9009\u6846\u7684\u76f8\u4ea4\u9762\u79ef x11 = np . maximum ( x1 [ index ], x1 [ order [: - 1 ]]) y11 = np . maximum ( y1 [ index ], y1 [ order [: - 1 ]]) x22 = np . minimum ( x2 [ index ], x2 [ order [: - 1 ]]) y22 = np . minimum ( y2 [ index ], y2 [ order [: - 1 ]]) # \u8ba1\u7b97\u76f8\u4ea4\u7684\u9762\u79ef,\u4e0d\u91cd\u53e0\u65f6\u9762\u79ef\u4e3a0 w = np . maximum ( 0.0 , x22 - x11 ) h = np . maximum ( 0.0 , y22 - y11 ) intersection = w * h # \u5229\u7528\u76f8\u4ea4\u7684\u9762\u79ef\u548c\u4e24\u4e2a\u6846\u81ea\u8eab\u7684\u9762\u79ef\u8ba1\u7b97\u6846\u7684\u4ea4\u5e76\u6bd4 ratio = intersection / ( areas [ index ] + areas [ order [: - 1 ]] - intersection ) # \u4fdd\u7559IoU\u5c0f\u4e8e\u9608\u503c\u7684box keep_boxes_indics = np . where ( ratio < threshold ) # \u4fdd\u7559\u5269\u4f59\u7684\u6846 order = order [ keep_boxes_indics ] # \u8fd4\u56deNMS\u540e\u7684\u6846\u53ca\u5206\u7c7b\u7ed3\u679c return picked_boxes , picked_score \u5047\u8bbe\u6709\u68c0\u6d4b\u7ed3\u679c\u5982\u4e0b\uff1a bounding = [( 187 , 82 , 337 , 317 ), ( 150 , 67 , 305 , 282 ), ( 246 , 121 , 368 , 304 )] confidence_score = [ 0.9 , 0.65 , 0.8 ] threshold = 0.3 picked_boxes , picked_score = nms ( bounding , confidence_score , threshold ) print ( '\u9608\u503cthreshold\u4e3a:' , threshold ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u662f\uff1a' , picked_boxes ) print ( 'NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f\uff1a' , picked_score ) \u8fd4\u56de\u7ed3\u679c\uff1a \u9608\u503c threshold\u4e3a : 0.3 NMS\u540e\u5f97\u5230\u7684bbox\u662f \uff1a [ array ([ 187 , 82 , 337 , 317 ])] NMS\u540e\u5f97\u5230\u7684bbox\u7684confidences\u662f \uff1a [ 0.9 ]","title":"4.NMS\uff08\u975e\u6781\u5927\u503c\u6291\u5236\uff09"},{"location":"objectdection/01.overview/#5","text":"\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3atwo-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09\u4e24\u7c7b\uff1a two-stage\u7684\u7b97\u6cd5 \u5148\u7531\u7b97\u6cd5\u751f\u6210\u4e00\u7cfb\u5217\u4f5c\u4e3a\u6837\u672c\u7684\u5019\u9009\u6846\uff0c\u518d\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6837\u672c\u5206\u7c7b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u8fc7\u7a0b\uff0c\u5176\u63d0\u53d6\u7684\u662fCNN\u5377\u79ef\u7279\u5f81\uff0c\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u548c\u76ee\u6807\u68c0\u6d4b\u4e24\u90e8\u5206\u3002\u7f51\u7edc\u7684\u51c6\u786e\u5ea6\u9ad8\u3001\u901f\u5ea6\u76f8\u5bf9\u8f83\u6162\u3002 two-stages\u7b97\u6cd5\u7684\u4ee3\u8868\u662fRCNN\u7cfb\u5217\uff1aR-CNN\u5230Faster R-CNN\u7f51\u7edc One-stage\u7684\u7b97\u6cd5 \u76f4\u63a5\u901a\u8fc7\u4e3b\u5e72\u7f51\u7edc\u7ed9\u51fa\u76ee\u6807\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6ca1\u6709\u4f7f\u7528\u5019\u9009\u533a\u57df\u7684\u7b5b\u9009\u7f51\u8def\uff0c\u8fd9\u79cd\u7b97\u6cd5\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u7cbe\u5ea6\u76f8\u5bf9Two-stage\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u964d\u4f4e\u4e86\u5f88\u591a\u3002 one-stage\u7b97\u6cd5\u7684\u4ee3\u8868\u662f\uff1a YOLO\u7cfb\u5217\uff1aYOLOv1\u3001YOLOv2\u3001YOLOv3\u3001 SSD\u7b49 \u603b\u7ed3 \u4e86\u89e3\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1 \u627e\u51fa\u56fe\u50cf\u4e2d\u6240\u6709\u611f\u5174\u8da3\u7684\u76ee\u6807\uff0c\u5e76\u786e\u5b9a\u5b83\u4eec\u7684\u7c7b\u522b\u548c\u4f4d\u7f6e \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7684\u5e38\u7528\u6570\u636e\u96c6 PASCAL VOC\u6570\u636e\u96c6 \u548c MS COCO\u6570\u636e\u96c6 \u77e5\u9053\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4ef7\u6307\u6807 IOU\u548cmAP \u638c\u63e1\u975e\u6781\u5927\u503cNMS\u7b97\u6cd5\u7684\u5e94\u7528 \u8981\u53bb\u9664\u5197\u4f59\u7684\u68c0\u6d4b\u6846,\u4fdd\u7559\u6700\u597d\u7684\u4e00\u4e2a \u4e86\u89e3\u5e38\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5206\u7c7b two-stage\uff08\u4e24\u9636\u6bb5\uff09\u548cone-stage\uff08\u5355\u9636\u6bb5\uff09","title":"5.\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5206\u7c7b"},{"location":"objectdection/02.RCNN/","text":"4.2 R-CNN\u7cfb\u5217\u7f51\u7edc \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u77e5\u9053anchor\u7684\u601d\u60f3 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 1.Overfeat\u6a21\u578b \u00b6 Overfeat\u65b9\u6cd5\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u548c\u795e\u7ecf\u7f51\u7edc\u6765\u68c0\u6d4b\u76ee\u6807\u3002\u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u7ed3\u679c\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4f8b\u5982\u8981\u68c0\u6d4b\u6c7d\u8f66\uff0c\u5c31\u4f7f\u7528\u4e0b\u56fe\u4e2d\u7ea2\u8272\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u626b\u63cf\uff0c\u5c06\u6240\u6709\u7684\u626b\u63cf\u7ed3\u679c\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u6c7d\u8f66\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e00\u79cd\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u5f0f\uff0c\u4f1a\u6d88\u8017\u5927\u91cf\u7684\u8ba1\u7b97\u529b\uff0c\u5e76\u4e14\u7531\u4e8e\u7a97\u53e3\u5927\u5c0f\u95ee\u9898\u53ef\u80fd\u4f1a\u9020\u6210\u6548\u679c\u4e0d\u51c6\u786e\u3002 2.RCNN\u6a21\u578b \u00b6 \u5728CVPR 2014\u5e74\u4e2dRoss Girshick\u63d0\u51faR-CNN\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u4e0d\u5728\u4f7f\u7528\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u6cd5\uff0c\u800c\u662f\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\uff0c\u521b\u5efa\u76ee\u6807\u68c0\u6d4b\u7684\u533a\u57df\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1\uff0cR-CNN\u662f\u4ee5\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e3a\u57fa\u7840\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6a21\u578b \uff0c\u4ee5R-CNN\u4e3a\u57fa\u70b9\uff0c\u540e\u7eed\u7684Fast R-CNN\u3001Faster R-CNN\u6a21\u578b\u90fd\u5ef6\u7eed\u4e86\u8fd9\u79cd\u76ee\u6807\u68c0\u6d4b\u601d\u8def\u3002 2.1 \u7b97\u6cd5\u6d41\u7a0b \u00b6 RCNN\u7684\u68c0\u6d4b\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b65\u9aa4\u662f\uff1a \u5019\u9009\u533a\u57df \uff1a\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\u627e\u51fa\u56fe\u7247\u4e2d\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u7684\u4faf\u9009\u533a\u57dfregion proposal \u7f51\u7edc\u9009\u62e9 \uff1a\u9009\u53d6\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7f51\u7edc\uff08AlexNet\uff09\u7528\u4e8e\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 \u76ee\u6807\u5206\u7c7b \uff1a\u8bad\u7ec3\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u6765\u8fa8\u522b\u76ee\u6807\u7269\u4f53\u548c\u80cc\u666f\u3002\u5bf9\u6bcf\u4e2a\u7c7b\u522b\uff0c\u90fd\u8981\u8bad\u7ec3\u4e00\u4e2a\u4e8c\u5143SVM\u3002 \u76ee\u6807\u5b9a\u4f4d \uff1a\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u4e3a\u6bcf\u4e2a\u8fa8\u8bc6\u5230\u7684\u7269\u4f53\u751f\u6210\u66f4\u7cbe\u786e\u7684\u8fb9\u754c\u6846 \u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\u6765\u5c55\u793a\u8fd9\u4e2a\u6d41\u7a0b\uff1a \u9009\u62e9\u4e00\u4e2a\u56fe\u7247\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1a \u5229\u7528\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u5019\u9009\u533a\u57df \u5c06\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u8fdb\u884c\u53d8\u5f62\uff0c\u82e5\u662fAlexNet\u5c06\u56fe\u7247resize\u6210227*227\u540e\u9001\u5165\u5230CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 \u5c06CNN\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c\u9001\u5165\u5230SVM\u4e2d\u8fdb\u884c\u5206\u7c7b\uff1a \u7528\u7ebf\u6027\u56de\u5f52\u7684\u65b9\u6cd5\u9884\u6d4b\u6bcf\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u4f4d\u7f6e \u8fd9\u5c31\u662f\u6574\u4e2aRCNN\u7b97\u6cd5\u7684\u6d41\u7a0b\u3002 \u3010\u4e86\u89e3\u3011\u9009\u62e9\u6027\u641c\u7d22\uff08SelectiveSearch\uff0cSS\uff09\u4e2d \uff0c\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5728\u50cf\u7d20\u7ea7\u7684\u6807\u6ce8\uff0c\u628a\u989c\u8272\u3001\u8fb9\u754c\u3001\u7eb9\u7406\u7b49\u4fe1\u606f\u4f5c\u4e3a\u5408\u5e76\u6761\u4ef6\uff0c\u591a\u5c3a\u5ea6\u7684\u7efc\u5408\u91c7\u6837\u65b9\u6cd5\uff0c\u5212\u5206\u51fa\u4e00\u7cfb\u5217\u7684\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u8981\u8fdc\u8fdc\u5c11\u4e8e\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u7684\u7a77\u4e3e\u6cd5\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df\u3002 SelectiveSearch\u5728\u4e00\u5f20\u56fe\u7247\u4e0a\u63d0\u53d6\u51fa\u6765\u7ea62000\u4e2a\u4faf\u9009\u533a\u57df\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u7684\u957f\u5bbd\u4e0d\u56fa\u5b9a \u3002 \u800c\u4f7f\u7528CNN\u63d0\u53d6\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9700\u8981\u63a5\u53d7\u56fa\u5b9a\u957f\u5ea6\u7684\u8f93\u5165\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u5019\u9009\u533a\u57df\u505a\u4e00\u4e9b\u5c3a\u5bf8\u4e0a\u7684\u4fee\u6539\u3002 2.2 \u7b97\u6cd5\u603b\u7ed3 \u00b6 1\u3001\u8bad\u7ec3\u9636\u6bb5\u591a\uff1a\u6b65\u9aa4\u7e41\u7410: \u5fae\u8c03\u7f51\u7edc+\u8bad\u7ec3SVM+\u8bad\u7ec3\u8fb9\u6846\u56de\u5f52\u5668\u3002 2\u3001\u8bad\u7ec3\u8017\u65f6\uff1a\u5360\u7528\u78c1\u76d8\u7a7a\u95f4\u5927\uff1a5000\u5f20\u56fe\u50cf\u4ea7\u751f\u51e0\u767eG\u7684\u7279\u5f81\u6587\u4ef6\u3002 3\u3001\u5904\u7406\u901f\u5ea6\u6162: \u4f7f\u7528GPU, VGG16\u6a21\u578b\u5904\u7406\u4e00\u5f20\u56fe\u50cf\u9700\u898147s \u3002 4\u3001\u56fe\u7247\u5f62\u72b6\u53d8\u5316\uff1a\u5019\u9009\u533a\u57df\u8981\u7ecf\u8fc7crop/warp\u8fdb\u884c\u56fa\u5b9a\u5927\u5c0f\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u56fe\u7247\u4e0d\u53d8\u5f62 3. Fast RCNN\u6a21\u578b \u00b6 \u8003\u8651\u5230R-CNN\u901f\u5ea6\u5f88\u6162, \u63d0\u51fa\u4e86\u4e00\u4e2a\u6539\u5584\u6a21\u578b:Fast R-CNN\u3002 \u76f8\u6bd4R-CNN, Fast R-CNN\u7684\u4f18\u70b9\u5728\u4e8e\u52a0\u5feb\u4e86selective search\u7684\u6b65\u9aa4\u548c\u540c\u65f6\u8bad\u7ec3\u5206\u7c7b\u548c\u56de\u5f52\u8fc7\u7a0b, \u4ece\u6574\u4f53\u4e0a\u52a0\u5feb\u4e86\u901f\u5ea6\u3002 Fast R-CNN\u5bf9R-CNN\u7684\u6539\u8fdb\u90e8\u5206: \u5c06R-CNN\u4e2d\u4e09\u4e2a\u6a21\u5757(CNN, SVM, Regression)\u6574\u5408, \u6781\u5927\u4e86\u51cf\u5c11\u4e86\u8ba1\u7b97\u91cf\u548c\u52a0\u5feb\u4e86\u901f\u5ea6 \u4e0d\u5bf9\u539f\u59cb\u56fe\u50cf\u8fdb\u884cselective search\u63d0\u53d6, \u800c\u662f\u5148\u7ecf\u8fc7\u4e00\u6b21CNN, \u5728feature map\u4e0a\u4f7f\u7528selective search\u751f\u6210\u5019\u9009\u533a\u57df\u8fdb\u884c\u6620\u5c04, \u5e76\u8fdb\u884c\u5206\u7c7b\u56de\u5f52 \u4e3a\u4e86\u517c\u5bb9\u4e0d\u540c\u56fe\u7247\u5c3a\u5ea6, \u4f7f\u7528\u4e86ROI Pooling \u7b97\u6cd5, \u5c06\u7279\u5f81\u56fe\u6c60\u5316\u5230\u56fa\u5b9a\u7ef4\u5ea6\u7684\u7279\u5f81\u5411\u91cf\u3002 fastRCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u63cf\u8ff0\u5982\u4e0b\uff1a \u8f93\u5165\u56fe\u50cf\uff1a \u56fe\u50cf\u88ab\u9001\u5165\u5230\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u901a\u8fc7\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\uff1a \u5728\u7279\u5f81\u56fe\u4e0aRol\u4e2d\u5e94\u7528RoIPooling\uff0c\u83b7\u53d6\u5c3a\u5bf8\u76f8\u540c\u7684\u7279\u5f81\u5411\u91cf \u5c06\u8fd9\u4e9b\u533a\u57df\u4f20\u9012\u5230\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u7ed3\u679c\u3002 4.FasterRCNN\u6a21\u578b \u00b6 \u5728R-CNN\u548cFast RCNN\u7684\u57fa\u7840\u4e0a\uff0cRoss B. Girshick\u57282016\u5e74\u63d0\u51fa\u4e86Faster RCNN\uff0c\u5728\u7ed3\u6784\u4e0a\uff0cFaster RCNN\u5df2\u7ecf\u5c06\u7279\u5f81\u62bd\u53d6(feature extraction)\uff0cproposal\u63d0\u53d6\uff0cbounding box regression(rect refine)\uff0cclassification\u90fd\u6574\u5408\u5728\u4e86\u4e00\u4e2a\u7f51\u7edc\u4e2d\uff0c\u4f7f\u5f97\u7efc\u5408\u6027\u80fd\u6709\u8f83\u5927\u63d0\u9ad8\uff0c\u5728\u68c0\u6d4b\u901f\u5ea6\u65b9\u9762\u5c24\u4e3a\u660e\u663e\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u7ed9\u5927\u5bb6\u8be6\u7ec6\u4ecb\u7ecdfasterRCNN\u7f51\u7edc\u6a21\u578b\u3002\u7f51\u7edc\u57fa\u672c\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u7f51\u7edc\u4e3b\u8981\u53ef\u5206\u4e3a\u56db\u90e8\u5206\uff1a Backbone \uff1abackbone\u7531\u4e00\u7ec4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6784\u6210\uff0cFaster RCNN\u9996\u5148\u4f7f\u7528\u4e00\u7ec4\u57fa\u7840\u7684conv+relu+pooling\u5c42\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u56fe\u50cf\u7684\u7279\u5f81\u56fefeaturemaps\u3002\u8be5feature maps\u88ab\u5171\u4eab\u7528\u4e8e\u540e\u7eedRPN\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u3002 RPN\u7f51\u7edc \uff1aRPN\u7f51\u7edc\u7528\u4e8e\u751f\u6210\u5019\u9009\u533a\u57dfregion proposals\u3002\u8be5\u90e8\u5206\u901a\u8fc7softmax\u5224\u65adanchors\u5c5e\u4e8epositive\u6216\u8005negative\uff0c\u5373\u662f\u5426\u5305\u542b\u76ee\u6807\uff0c\u518d\u5229\u7528bounding box regression\u4fee\u6b63anchors\u83b7\u5f97\u7cbe\u786e\u7684proposals\u3002 Roi Pooling : \u8be5\u90e8\u5206\u6536\u96c6\u8f93\u5165\u56fe\u50cf\u7684feature maps\u548cproposals\uff0c\u7efc\u5408\u4fe1\u606f\u540e\u63d0\u53d6proposal\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9001\u5165\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u5224\u5b9a\u76ee\u6807\u7c7b\u522b\u548c\u786e\u5b9a\u76ee\u6807\u4f4d\u7f6e\u3002 Classifier : \u8be5\u90e8\u5206\u5229\u7528\u7279\u5f81\u5411\u91cf\u8ba1\u7b97proposal\u7684\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7bounding box regression\u83b7\u5f97\u68c0\u6d4b\u6846\u6700\u7ec8\u7684\u7cbe\u786e\u4f4d\u7f6e \u5c06\u4e0a\u8ff0\u7ed3\u6784\u5c55\u5f00\u540e\u5982\u4e0b\u6240\u793a\uff0c\u4e0b\u56fe\u4e2d\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u662fVGG16\uff1a \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u4e8e\u4e00\u526f\u4efb\u610f\u5927\u5c0fPxQ\u7684\u56fe\u50cf\uff1a \u9996\u5148\u5c06\u56fe\u50cf\u7f29\u653e\u81f3\u56fa\u5b9a\u5927\u5c0fMxN\uff0c\u7136\u540e\u5c06MxN\u56fe\u50cf\u9001\u5165\u7f51\u7edc\uff1b \u800cConv layers\u4e2d\u5305\u542b\u4e8613\u4e2aconv\u5c42+13\u4e2arelu\u5c42+4\u4e2apooling\u5c42\uff0c\u5728\u8fd9\u91cc\u4f7f\u7528VGG16\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u820d\u5f03\u3002\u5728\u6574\u4e2aConv layers\u4e2d\uff0cconv\u548crelu\u5c42\u4e0d\u6539\u53d8\u8f93\u5165\u8f93\u51fa\u5927\u5c0f\uff0c\u53ea\u6709pooling\u5c42\u4f7f\u8f93\u51fa\u957f\u5bbd\u90fd\u53d8\u4e3a\u8f93\u5165\u7684\u00bd\uff0c\u4e00\u5171\u67094\u4e2a\u6c60\u5316\u5c42\uff0c\u6240\u4ee5\uff1a \u4e00\u4e2aMxN\u5927\u5c0f\u7684\u77e9\u9635\u7ecf\u8fc7Conv layers\u56fa\u5b9a\u53d8\u4e3a(M/16)x(N/16\uff09\uff1b RPN\u7f51\u7edc\u9996\u5148\u7ecf\u8fc73x3\u5377\u79ef\uff0c\u518d\u5206\u522b\u751f\u6210positive anchors\u548c\u5bf9\u5e94bounding box regression\u504f\u79fb\u91cf\uff0c\u7136\u540e\u8ba1\u7b97\u51faproposals\uff1b \u800cRoi Pooling\u5c42\u5219\u5229\u7528proposals\u4ecefeature maps\u4e2d\u63d0\u53d6proposal feature\u9001\u5165\u540e\u7eed\u5168\u8fde\u63a5\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u4ece\u8fd9\u56db\u4e2a\u65b9\u9762\u6765\u8be6\u7ec6fasterRCNN\u7f51\u7edc\u5e76\u7ed3\u5408\u6e90\u7801\u5206\u6790\u5176\u5b9e\u73b0\u8fc7\u7a0b\u3002 4.1backbone \u00b6 backbone\u4e00\u822c\u4e3aVGG\uff0cResNet\u7b49\u7f51\u7edc\u6784\u6210\uff0c\u4e3b\u8981\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u820d\u5f03\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u8fdb\u884c\u540e\u7eed\u5904\u7406\u3002 \u5728\u6e90\u7801\u4e2d\u6211\u4eec\u4f7f\u7528ResNet + FPN \u7ed3\u6784\uff0c\u6765\u63d0\u53d6\u7279\u5f81\u3002\u666e\u901a\u7684 FasterRCNN \u53ea\u9700\u8981\u5c06 feature_map \u8f93\u5165\u5230 rpn \u7f51\u7edc\u751f\u6210 proposals \u5373\u53ef\u3002\u4f46\u662f\u7531\u4e8e\u52a0\u5165 FPN\uff0c\u9700\u8981\u5c06\u591a\u4e2a feature_map \u9010\u4e2a\u8f93\u5165\u5230 rpn \u7f51\u7edc\u548c\u68c0\u6d4b\u7f51\u7edc\u4e2d\uff1a \u5728\u8fd9\u91ccResNet\u548cFPN\u7684\u5b8c\u6574\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0cRPN\u8f93\u5165\u7684feature map\u662f[p2,p3,p4,p5,p6] \uff0c\u800c\u4f5c\u4e3a\u540e\u7eed\u76ee\u6807\u68c0\u6d4b\u7f51\u7edcFastRCNN\u7684\u8f93\u5165\u5219\u662f [p2,p3,p4,p5] \u3002 \u90a3\u7f51\u7edc\u7684\u6574\u4f53\u67b6\u6784\u8868\u793a\u6210\uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790\u4e0b\u76f8\u5173\u5185\u5bb9\u53ca\u6e90\u7801\uff1a 4.1.1 ResNet \u00b6 \u6e90\u7801\u4f4d\u7f6e\uff1afasterRCNN/detection/models/backbones/reset.py 1.\u74f6\u9888\u6a21\u5757 \u00b6 \u8981\u6784\u5efaresnet\u7f51\u7edc\u9996\u5148\u6784\u5efa\u74f6\u9888\u6a21\u5757\u5982\u4e0b\u6240\u793a\uff1a class _Bottleneck ( tf . keras . Model ): \"\"\" \u74f6\u9888\u6a21\u5757\u7684\u5b9e\u73b0 \"\"\" def __init__ ( self , filters , block , downsampling = False , stride = 1 , ** kwargs ): super ( _Bottleneck , self ) . __init__ ( ** kwargs ) # \u83b7\u53d6\u4e09\u4e2a\u5377\u79ef\u7684\u5377\u79ef\u6838\u6570\u91cf filters1 , filters2 , filters3 = filters # \u5377\u79ef\u5c42\u547d\u540d\u65b9\u5f0f conv_name_base = 'res' + block + '_branch' # BN\u5c42\u547d\u540d\u65b9\u5f0f bn_name_base = 'bn' + block + '_branch' # \u662f\u5426\u8fdb\u884c\u4e0b\u91c7\u6837 self . downsampling = downsampling # \u5377\u79ef\u6b65\u957f self . stride = stride # \u74f6\u9888\u6a21\u5757\u8f93\u51fa\u7684\u901a\u9053\u6570 self . out_channel = filters3 # 1*1 \u5377\u79ef self . conv2a = layers . Conv2D ( filters1 , ( 1 , 1 ), strides = ( stride , stride ), kernel_initializer = 'he_normal' , name = conv_name_base + '2a' ) # BN\u5c42 self . bn2a = layers . BatchNormalization ( name = bn_name_base + '2a' ) # 3*3 \u5377\u79ef self . conv2b = layers . Conv2D ( filters2 , ( 3 , 3 ), padding = 'same' , kernel_initializer = 'he_normal' , name = conv_name_base + '2b' ) # BN\u5c42 self . bn2b = layers . BatchNormalization ( name = bn_name_base + '2b' ) # 1*1\u5377\u79ef self . conv2c = layers . Conv2D ( filters3 , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = conv_name_base + '2c' ) # BN\u5c42 self . bn2c = layers . BatchNormalization ( name = bn_name_base + '2c' ) # \u4e0b\u91c7\u6837 if self . downsampling : # \u5728\u77ed\u8fde\u63a5\u5904\u8fdb\u884c\u4e0b\u91c7\u6837 self . conv_shortcut = layers . Conv2D ( filters3 , ( 1 , 1 ), strides = ( stride , stride ), kernel_initializer = 'he_normal' , name = conv_name_base + '1' ) # BN\u5c42 self . bn_shortcut = layers . BatchNormalization ( name = bn_name_base + '1' ) def call ( self , inputs , training = False ): \"\"\" \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b :param inputs: :param training: :return: \"\"\" # \u7b2c\u4e00\u7ec4\u5377\u79ef+BN+Relu x = self . conv2a ( inputs ) x = self . bn2a ( x , training = training ) x = tf . nn . relu ( x ) # \u7b2c\u4e8c\u7ec4\u5377\u79ef+BN+Relu x = self . conv2b ( x ) x = self . bn2b ( x , training = training ) x = tf . nn . relu ( x ) # \u7b2c\u4e09\u7ec4\u5377\u79ef+BN x = self . conv2c ( x ) x = self . bn2c ( x , training = training ) # \u77ed\u8fde\u63a5 if self . downsampling : shortcut = self . conv_shortcut ( inputs ) shortcut = self . bn_shortcut ( shortcut , training = training ) else : shortcut = inputs # \u76f8\u52a0\u6c42\u548c x += shortcut # \u6fc0\u6d3b x = tf . nn . relu ( x ) # \u6700\u7ec8\u8f93\u51fa return x 2. resnet \u00b6 \u5229\u7528\u74f6\u9888\u6a21\u5757\u6784\u5efabackbone\u4e2d\u7684resNet. class ResNet ( tf . keras . Model ): \"\u6784\u5efa50\u6216101\u5c42\u7684resnet\u7f51\u7edc\" def __init__ ( self , depth , ** kwargs ): super ( ResNet , self ) . __init__ ( ** kwargs ) # \u82e5\u6df1\u5ea6\u4e0d\u662f50\u6216101\u62a5\u9519 if depth not in [ 50 , 101 ]: raise AssertionError ( 'depth must be 50 or 101.' ) self . depth = depth # padding self . padding = layers . ZeroPadding2D (( 3 , 3 )) # \u8f93\u5165\u7684\u5377\u79ef self . conv1 = layers . Conv2D ( 64 , ( 7 , 7 ), strides = ( 2 , 2 ), kernel_initializer = 'he_normal' , name = 'conv1' ) # BN\u5c42 self . bn_conv1 = layers . BatchNormalization ( name = 'bn_conv1' ) # maxpooling self . max_pool = layers . MaxPooling2D (( 3 , 3 ), strides = ( 2 , 2 ), padding = 'same' ) # \u7b2c\u4e00\u7ec4\u74f6\u9888\u6a21\u5757 self . res2a = _Bottleneck ([ 64 , 64 , 256 ], block = '2a' , downsampling = True , stride = 1 ) self . res2b = _Bottleneck ([ 64 , 64 , 256 ], block = '2b' ) self . res2c = _Bottleneck ([ 64 , 64 , 256 ], block = '2c' ) # \u7b2c\u4e8c\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u9996\u4e2a\u8fdb\u884c\u4e0b\u91c7\u6837 self . res3a = _Bottleneck ([ 128 , 128 , 512 ], block = '3a' , downsampling = True , stride = 2 ) self . res3b = _Bottleneck ([ 128 , 128 , 512 ], block = '3b' ) self . res3c = _Bottleneck ([ 128 , 128 , 512 ], block = '3c' ) self . res3d = _Bottleneck ([ 128 , 128 , 512 ], block = '3d' ) # \u7b2c\u4e09\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u9996\u4e2a\u8fdb\u884c\u4e0b\u91c7\u6837 self . res4a = _Bottleneck ([ 256 , 256 , 1024 ], block = '4a' , downsampling = True , stride = 2 ) self . res4b = _Bottleneck ([ 256 , 256 , 1024 ], block = '4b' ) self . res4c = _Bottleneck ([ 256 , 256 , 1024 ], block = '4c' ) self . res4d = _Bottleneck ([ 256 , 256 , 1024 ], block = '4d' ) self . res4e = _Bottleneck ([ 256 , 256 , 1024 ], block = '4e' ) self . res4f = _Bottleneck ([ 256 , 256 , 1024 ], block = '4f' ) # \u82e5\u6df1\u5ea6\u4e3a101\u8fd8\u9700\u8fdb\u884c\u74f6\u9888\u6a21\u5757\u7684\u4e32\u8054 if self . depth == 101 : self . res4g = _Bottleneck ([ 256 , 256 , 1024 ], block = '4g' ) self . res4h = _Bottleneck ([ 256 , 256 , 1024 ], block = '4h' ) self . res4i = _Bottleneck ([ 256 , 256 , 1024 ], block = '4i' ) self . res4j = _Bottleneck ([ 256 , 256 , 1024 ], block = '4j' ) self . res4k = _Bottleneck ([ 256 , 256 , 1024 ], block = '4k' ) self . res4l = _Bottleneck ([ 256 , 256 , 1024 ], block = '4l' ) self . res4m = _Bottleneck ([ 256 , 256 , 1024 ], block = '4m' ) self . res4n = _Bottleneck ([ 256 , 256 , 1024 ], block = '4n' ) self . res4o = _Bottleneck ([ 256 , 256 , 1024 ], block = '4o' ) self . res4p = _Bottleneck ([ 256 , 256 , 1024 ], block = '4p' ) self . res4q = _Bottleneck ([ 256 , 256 , 1024 ], block = '4q' ) self . res4r = _Bottleneck ([ 256 , 256 , 1024 ], block = '4r' ) self . res4s = _Bottleneck ([ 256 , 256 , 1024 ], block = '4s' ) self . res4t = _Bottleneck ([ 256 , 256 , 1024 ], block = '4t' ) self . res4u = _Bottleneck ([ 256 , 256 , 1024 ], block = '4u' ) self . res4v = _Bottleneck ([ 256 , 256 , 1024 ], block = '4v' ) self . res4w = _Bottleneck ([ 256 , 256 , 1024 ], block = '4w' ) # \u7b2c\u56db\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u9996\u4e2a\u8fdb\u884c\u4e0b\u91c7\u6837 self . res5a = _Bottleneck ([ 512 , 512 , 2048 ], block = '5a' , downsampling = True , stride = 2 ) self . res5b = _Bottleneck ([ 512 , 512 , 2048 ], block = '5b' ) self . res5c = _Bottleneck ([ 512 , 512 , 2048 ], block = '5c' ) # \u8f93\u51fa\u901a\u9053\u6570\uff1aC2,C3,C4,C5\u7684\u8f93\u51fa\u901a\u9053\u6570 self . out_channel = ( 256 , 512 , 1024 , 2048 ) def call ( self , inputs , training = True ): \"\u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0c\u6bcf\u7ec4\u74f6\u9888\u6a21\u5757\u5747\u8f93\u51fa\u7ed3\u679c\" x = self . padding ( inputs ) x = self . conv1 ( x ) x = self . bn_conv1 ( x , training = training ) x = tf . nn . relu ( x ) x = self . max_pool ( x ) # \u7b2c1\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u8f93\u51fac2 x = self . res2a ( x , training = training ) x = self . res2b ( x , training = training ) C2 = x = self . res2c ( x , training = training ) # \u7b2c2\u7ec4\u74f6\u9888\u6a21\u5757:\u8f93\u51fac3 x = self . res3a ( x , training = training ) x = self . res3b ( x , training = training ) x = self . res3c ( x , training = training ) C3 = x = self . res3d ( x , training = training ) # \u7b2c3\u7ec4\u74f6\u9888\u6a21\u5757:\u8f93\u51fac4 x = self . res4a ( x , training = training ) x = self . res4b ( x , training = training ) x = self . res4c ( x , training = training ) x = self . res4d ( x , training = training ) x = self . res4e ( x , training = training ) x = self . res4f ( x , training = training ) if self . depth == 101 : x = self . res4g ( x , training = training ) x = self . res4h ( x , training = training ) x = self . res4i ( x , training = training ) x = self . res4j ( x , training = training ) x = self . res4k ( x , training = training ) x = self . res4l ( x , training = training ) x = self . res4m ( x , training = training ) x = self . res4n ( x , training = training ) x = self . res4o ( x , training = training ) x = self . res4p ( x , training = training ) x = self . res4q ( x , training = training ) x = self . res4r ( x , training = training ) x = self . res4s ( x , training = training ) x = self . res4t ( x , training = training ) x = self . res4u ( x , training = training ) x = self . res4v ( x , training = training ) x = self . res4w ( x , training = training ) C4 = x # \u7b2c4\u7ec4\u74f6\u9888\u6a21\u5757:\u8f93\u51fac5 x = self . res5a ( x , training = training ) x = self . res5b ( x , training = training ) C5 = x = self . res5c ( x , training = training ) # \u8fd4\u56de\u6240\u6709\u7684\u8f93\u51fa\u9001\u5165\u5230fpn\u4e2d return ( C2 , C3 , C4 , C5 ) 4.1.2 fpn \u00b6 FPN\u7684\u4f5c\u7528\u662f\u5f53\u524d\u5c42\u7684feature map\u4f1a\u5bf9\u672a\u6765\u5c42\u7684feature map\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684feature map\u5c31\u53ef\u4ee5\u83b7\u5f97\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u8fd9\u6837\u7684\u8bdd\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u67b6\u6784\u4e2d\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6e90\u7801\u4f4d\u7f6e\uff1afasterRCNN/detection/models/necks/fpn.py class FPN ( tf . keras . Model ): def __init__ ( self , out_channels = 256 , ** kwargs ): ''' \u6784\u5efaFPN\u6a21\u5757\uff1a out_channels:\u662f\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570 ''' super ( FPN , self ) . __init__ ( ** kwargs ) # \u8f93\u51fa\u901a\u9053\u6570 self . out_channels = out_channels # \u4f7f\u75281*1\u5377\u79ef\u5bf9\u6bcf\u4e2a\u8f93\u5165\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u901a\u9053\u6570\u8c03\u6574 self . fpn_c2p2 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c2p2' ) self . fpn_c3p3 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c3p3' ) self . fpn_c4p4 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c4p4' ) self . fpn_c5p5 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c5p5' ) # \u5bf9\u6df1\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u4f7f\u5176\u4e0e\u524d\u4e00\u5c42\u7684\u5927\u5c0f\u76f8\u540c self . fpn_p3upsampled = layers . UpSampling2D ( size = ( 2 , 2 ), name = 'fpn_p3upsampled' ) self . fpn_p4upsampled = layers . UpSampling2D ( size = ( 2 , 2 ), name = 'fpn_p4upsampled' ) self . fpn_p5upsampled = layers . UpSampling2D ( size = ( 2 , 2 ), name = 'fpn_p5upsampled' ) # 3*3\u5377\u79ef\uff0c\u4f5c\u7528\u4e8e\u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u4e2d\u5f97\u5230\u6700\u7ec8\u7684\u7ed3\u679c self . fpn_p2 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p2' ) self . fpn_p3 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p3' ) self . fpn_p4 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p4' ) self . fpn_p5 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p5' ) # \u5bf9\u4e0a\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0b\u91c7\u6837\u5f97\u5230\u7ed3\u679c self . fpn_p6 = layers . MaxPooling2D ( pool_size = ( 1 , 1 ), strides = 2 , name = 'fpn_p6' ) def call ( self , inputs , training = True ): # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b # \u83b7\u53d6\u4eceresnet\u4e2d\u5f97\u5230\u76844\u4e2a\u7279\u5f81\u56fe C2 , C3 , C4 , C5 = inputs # \u5bf9\u8fd9\u4e9b\u7279\u5f81\u56fe\u8fdb\u884c1*1\u5377\u79ef\u548c\u4e0a\u91c7\u6837\u540e\u8fdb\u884c\u878d\u5408 P5 = self . fpn_c5p5 ( C5 ) P4 = self . fpn_c4p4 ( C4 ) + self . fpn_p5upsampled ( P5 ) P3 = self . fpn_c3p3 ( C3 ) + self . fpn_p4upsampled ( P4 ) P2 = self . fpn_c2p2 ( C2 ) + self . fpn_p3upsampled ( P3 ) # \u5bf9\u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u8fdb\u884c3*3\u5377\u79ef\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ed3\u679c P2 = self . fpn_p2 ( P2 ) P3 = self . fpn_p3 ( P3 ) P4 = self . fpn_p4 ( P4 ) P5 = self . fpn_p5 ( P5 ) # \u5bf9p5\u8fdb\u884c\u4e0b\u91c7\u6837\u5f97\u5230p6\u7279\u5f81\u56fe P6 = self . fpn_p6 ( P5 ) # \u8fd4\u56de\u6700\u7ec8\u7684\u7ed3\u679c return [ P2 , P3 , P4 , P5 , P6 ] 4.2 RPN\u7f51\u7edc \u00b6 \u7ecf\u5178\u7684\u68c0\u6d4b\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u90fd\u975e\u5e38\u8017\u65f6\uff0c\u5982OpenCV adaboost\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3+\u56fe\u50cf\u91d1\u5b57\u5854\u751f\u6210\u68c0\u6d4b\u6846\uff1b\u6216\u5982R-CNN\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u3002\u800cFaster RCNN\u5219\u629b\u5f03\u4e86\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u548cSS\u65b9\u6cd5\uff0c\u76f4\u63a5\u4f7f\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u80fd\u6781\u5927\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u3002 RPN\u7f51\u7edc\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u662f\u901a\u8fc7softmax\u5206\u7c7b\u5224\u65adanchor\u4e2d\u662f\u5426\u5305\u542b\u76ee\u6807\uff0c\u53e6\u4e00\u90e8\u5206\u7528\u4e8e\u8ba1\u7b97\u5bf9\u4e8eanchors\u7684\u504f\u79fb\u91cf\uff0c\u4ee5\u83b7\u5f97\u7cbe\u786e\u7684\u5019\u9009\u533a\u57df\u3002\u800c\u6700\u540e\u7684Proposal\u5c42\u5219\u8d1f\u8d23\u7efc\u5408\u542b\u6709\u76ee\u6807\u7684anchors\u548c\u5bf9\u5e94bbox\u56de\u5f52\u504f\u79fb\u91cf\u83b7\u53d6\u5019\u9009\u533a\u57df\uff0c\u540c\u65f6\u5254\u9664\u592a\u5c0f\u548c\u8d85\u51fa\u8fb9\u754c\u7684\u5019\u9009\u533a\u57df\u3002 4.2.1 anchors \u00b6 anchor\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u8868\u793a \u56fa\u5b9a\u7684\u53c2\u8003\u6846 \uff0c\u9996\u5148\u9884\u8bbe\u4e00\u7ec4\u4e0d\u540c\u5c3a\u5ea6\u4e0d\u540c\u957f\u5bbd\u6bd4\u7684\u56fa\u5b9a\u53c2\u8003\u6846\uff0c\u8986\u76d6\u51e0\u4e4e\u6240\u6709\u4f4d\u7f6e\uff0c \u6bcf\u4e2a\u53c2\u8003\u6846\u8d1f\u8d23\u68c0\u6d4b\u4e0e\u5176\u4ea4\u5e76\u6bd4\u5927\u4e8e\u9608\u503c (\u8bad\u7ec3\u9884\u8bbe\u503c\uff0c\u5e38\u75280.5\u62160.7) \u7684\u76ee\u6807 \uff0canchor\u6280\u672f\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u6362\u4e3a \"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\" \uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97\uff0c\u771f\u6b63\u5b9e\u73b0\u4e86\u53c8\u597d\u53c8\u5feb\u3002 \u5728fasterRCNN\u4e2d\u6846\u51fa\u591a\u5c3a\u5ea6\u3001\u591a\u79cd\u957f\u5bbd\u6bd4\u7684anchors,\u591a\u79cd\u5c3a\u5ea6\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u70b9\u591a\u4e2a\u6846\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8e\u6709 FPN \u7f51\u7edc\uff0c\u6240\u4ee5\u4f1a\u5728\u591a\u4e2a\u7279\u5f81\u56fe\u4e2d\u751f\u6210anchor\uff0c\u5047\u8bbe\u67d0\u4e00\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u4e3ahxw\uff0c\u9996\u5148\u4f1a\u8ba1\u7b97\u8fd9\u4e2a\u7279\u5f81\u76f8\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u4e0b\u91c7\u6837\u500d\u6570 stride\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728\u8fd9\u91cc\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u5bf9\u5e94\u4e00\u4e2a\u5c3a\u5ea6\u7684anchor\u3002 \u6e90\u7801\u4e2danchor\u7684\u751f\u6210\u65b9\u6cd5\uff1afasterRCNN/detection/core/anchor/anchor_generator.py \u4e3b\u8981\u65b9\u6cd5\u662f\uff1a _generate_level_anchors\uff1a\u901a\u8fc7\u5e7f\u64ad\u7684\u65b9\u6cd5\u751f\u6210\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u7684anchorbox _generate_valid_flags\uff1a\u6807\u8bb0\u771f\u5b9e\u56fe\u50cf\u4e2d\u7684anchor generate_pyramid_anchors:\u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\u5b8c\u6210\u56fe\u50cf\u7684anchor\u7684\u751f\u6210 class AnchorGenerator : def __init__ ( self , scales = ( 32 , 64 , 128 , 256 , 512 ), ratios = ( 0.5 , 1 , 2 ), feature_strides = ( 4 , 8 , 16 , 32 , 64 )): ''' \u521d\u59cb\u5316anchor ''' # scales: \u751f\u6210\u7684anchor\u7684\u5c3a\u5ea6 self . scales = scales # ratios: anchor\u7684\u957f\u5bbd\u6bd4 self . ratios = ratios # feature_strides: \u56e0\u4e3afpn\u751f\u6210\u4e86\u4e94\u79cd\u7279\u5f81\u56fe\uff0c\u5728\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0a\u79fb\u52a8\u4e00\u4e2a\u4f4d\u7f6e\u76f8\u5f53\u4e8e\u539f\u56fe\u7684\u5927\u5c0f self . feature_strides = feature_strides def generate_pyramid_anchors ( self , img_metas ): ''' \u751f\u6210anchor \u53c2\u6570\uff1a img_metas: [batch_size, 11]\uff0c\u56fe\u50cf\u7684\u4fe1\u606f\uff0c\u5305\u62ec\u539f\u59cb\u56fe\u50cf\u7684\u5927\u5c0f\uff0cresize\u7684\u5927\u5c0f\u548c\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f \u8fd4\u56de\uff1a anchors: [num_anchors, (y1, x1, y2, x2)] anchor\u7684\u5750\u6807\uff0c\u5728\u539f\u56fe\u50cf\u4e2d\u7684\u5750\u6807 valid_flags: [batch_size, num_anchors] \u662f\u5426\u4e3a\u7a7a\u7684\u6807\u5fd7 ''' # \u83b7\u53d6\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f\uff1a[1216, 1216] pad_shape = calc_batch_padded_shape ( img_metas ) # \u83b7\u53d6\u56fe\u50cf\u7684\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff1a[(304, 304), (152, 152), (76, 76), (38, 38), (19, 19)] feature_shapes = [( pad_shape [ 0 ] // stride , pad_shape [ 1 ] // stride ) for stride in self . feature_strides ] # \u751f\u6210\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0aanchor\u7684\u4f4d\u7f6e\u4fe1\u606f\uff1a [277248, 4], [69312, 4], [17328, 4], [4332, 4], [1083, 4] anchors = [ self . _generate_level_anchors ( level , feature_shape ) for level , feature_shape in enumerate ( feature_shapes ) ] # \u5c06\u6240\u6709\u7684anchor\u4e32\u8054\u5728\u4e00\u4e2a\u5217\u8868\u4e2d\uff1a[369303, 4] anchors = tf . concat ( anchors , axis = 0 ) # \u83b7\u53d6\u56fe\u50cf\u975e0\u4f4d\u7f6e\u7684\u5927\u5c0f\uff1a(800, 1067) img_shapes = calc_img_shapes ( img_metas ) # \u83b7\u53d6anchor\u7684\u975e\u96f6\u6807\u8bc6 valid_flags = [ self . _generate_valid_flags ( anchors , img_shapes [ i ]) for i in range ( img_shapes . shape [ 0 ]) ] # \u5806\u53e0\u4e3a\u4e00\u4e2a\u4e00\u7ef4\u5411\u91cf valid_flags = tf . stack ( valid_flags , axis = 0 ) # \u505c\u6b62\u68af\u5ea6\u8ba1\u7b97 anchors = tf . stop_gradient ( anchors ) valid_flags = tf . stop_gradient ( valid_flags ) # \u8fd4\u56deanchor\u548c\u5bf9\u5e94\u975e\u96f6\u6807\u5fd7 return anchors , valid_flags def _generate_valid_flags ( self , anchors , img_shape ): ''' \u79fb\u9664padding\u4f4d\u7f6e\u7684anchor \u53c2\u6570\uff1a anchors: [num_anchors, (y1, x1, y2, x2)] \u6240\u6709\u7684anchor img_shape: Tuple. (height, width, channels) \u975e0\u50cf\u7d20\u70b9\u7684\u56fe\u50cf\u7684\u5927\u5c0f \u8fd4\u56de\uff1a valid_flags: [num_anchors] \u8fd4\u56de\u975e0\u4f4d\u7f6e\u7684anchor ''' # \u8ba1\u7b97\u6240\u6709anchor\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\uff1a[369300] y_center = ( anchors [:, 2 ] + anchors [:, 0 ]) / 2 x_center = ( anchors [:, 3 ] + anchors [:, 1 ]) / 2 # \u521d\u59cb\u5316flags\u4e3a\u51681\u6570\u7ec4\uff1a[369300] valid_flags = tf . ones ( anchors . shape [ 0 ], dtype = tf . int32 ) # \u521d\u59cb\u5316\u76f8\u540c\u5927\u5c0f\u7684\u51680\u6570\u7ec4 zeros = tf . zeros ( anchors . shape [ 0 ], dtype = tf . int32 ) # \u5c06anchor\u4e2d\u5fc3\u70b9\u5728\u975e0\u533a\u57df\u7684\u7f6e\u4e3a1\uff0c\u5176\u4ed6\u7f6e\u4e3a0 valid_flags = tf . where ( y_center <= img_shape [ 0 ], valid_flags , zeros ) valid_flags = tf . where ( x_center <= img_shape [ 1 ], valid_flags , zeros ) # \u8fd4\u56de\u6807\u5fd7\u7ed3\u679c return valid_flags def _generate_level_anchors ( self , level , feature_shape ): '''\u751f\u6210fpn\u8f93\u51fa\u7684\u67d0\u4e00\u4e2a\u7279\u5f81\u56fe\u7684anchor \u53c2\u6570\uff1a feature_shape: (height, width) \u7279\u5f81\u56fe\u5927\u5c0f \u8fd4\u56de\uff1a numpy.ndarray [anchors_num, (y1, x1, y2, x2)]\uff1a\u751f\u6210\u7684anchor\u7ed3\u679c ''' # \u83b7\u53d6\u5bf9\u5e94\u7684\u5c3a\u5ea6 scale = self . scales [ level ] # \u83b7\u53d6\u957f\u5bbd\u6bd4 ratios = self . ratios # \u83b7\u53d6\u5bf9\u5e94\u6b65\u957f feature_stride = self . feature_strides [ level ] # \u83b7\u53d6\u4e0d\u540c\u957f\u5bbd\u6bd4\u4e0b\u7684scale scales , ratios = tf . meshgrid ([ float ( scale )], ratios ) # \u5c3a\u5ea6 [32, 32, 32] scales = tf . reshape ( scales , [ - 1 ]) # \u957f\u5bbd\u6bd4 [0.5, 1, 2] ratios = tf . reshape ( ratios , [ - 1 ]) # \u83b7\u53d6\u4e0d\u540c\u5bbd\u9ad8\u6bd4\u60c5\u51b5\u4e0b\u7684H\u548cw # [45, 32, 22] heights = scales / tf . sqrt ( ratios ) # [22, 32, 45] widths = scales * tf . sqrt ( ratios ) # \u83b7\u53d6\u751f\u6210anchor\u5bf9\u5e94\u7684\u4f4d\u7f6e,\u5047\u8bbe\u6b65\u957f\u4e3a4\u65f6\u7684\u7ed3\u679c\uff1a [0, 4, ..., 1216-4] shifts_y = tf . multiply ( tf . range ( feature_shape [ 0 ]), feature_stride ) shifts_x = tf . multiply ( tf . range ( feature_shape [ 1 ]), feature_stride ) # \u7c7b\u578b\u8f6c\u6362 shifts_x , shifts_y = tf . cast ( shifts_x , tf . float32 ), tf . cast ( shifts_y , tf . float32 ) # \u83b7\u53d6\u5728\u56fe\u50cf\u4e2d\u751f\u6210anchor\u7684\u4f4d\u7f6e shifts_x , shifts_y = tf . meshgrid ( shifts_x , shifts_y ) # \u5c06\u5bbd\u9ad8\u5206\u522b\u76f8\u5bf9\u4e8ex,y\u8fdb\u884c\u5e7f\u64ad\uff0c \u5f97\u5230\u5bbd\u9ad8\u548c\u4e2d\u5fc3\u70b9\u5750\u6807 box_widths , box_centers_x = tf . meshgrid ( widths , shifts_x ) box_heights , box_centers_y = tf . meshgrid ( heights , shifts_y ) # \u8fdb\u884creshape\u5f97\u5230anchor\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8 box_centers = tf . reshape ( tf . stack ([ box_centers_y , box_centers_x ], axis = 2 ), ( - 1 , 2 )) box_sizes = tf . reshape ( tf . stack ([ box_heights , box_widths ], axis = 2 ), ( - 1 , 2 )) # \u62fc\u63a5\u6210\u4e00\u7ef4\u5411\u91cf\uff0c\u5e76\u4ee5\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u7684\u5f62\u5f0f\u8868\u793a [304x304, 3, 4] => [277448, 4] boxes = tf . concat ([ box_centers - 0.5 * box_sizes , box_centers + 0.5 * box_sizes ], axis = 1 ) # \u8fd4\u56de\u6700\u7ec8\u7684anchorbox return boxes \u90a3\u8fd9\u4e9banchors\u662f\u5982\u4f55\u4f7f\u7528\u7684\u5462\uff1f\u5bf9\u4e8eConv layers\u7279\u5f81\u63d0\u53d6\u5f97\u5230\u7684feature maps\uff0c\u4e3a\u6bcf\u4e00\u4e2a\u70b9\u90fd\u5206\u914d\u8fd9k\u4e2aanchors\u4f5c\u4e3a\u521d\u59cb\u7684\u53c2\u8003\u6846\uff0c\u9001\u5165\u5230softmax\u548c\u5168\u8fde\u63a5\u5c42\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u8fc7\u7a0b\uff0c\u5224\u65adanchor\u4e2d\u662f\u5426\u5305\u542b\u76ee\u6807\uff0c\u5e76\u5bf9anchors\u8fdb\u884c\u4fee\u6b63\u3002 4.2.2 RPN\u5206\u7c7b \u00b6 \u4e00\u526fMxN\u5927\u5c0f\u7684\u77e9\u9635\u9001\u5165Faster RCNN\u7f51\u7edc\u540e\uff0c\u7ecf\u8fc7backbone\u7279\u5f81\u63d0\u53d6\u5230RPN\u7f51\u7edc\u53d8\u4e3aHxW\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u662fRPN\u8fdb\u884c\u5206\u7c7b\u7684\u7f51\u7edc\u7ed3\u6784\uff1a(k=9) \u5148\u505a\u4e00\u4e2a1x1\u7684\u5377\u79ef\uff0c\u5f97\u5230[batchsize,H,W,18]\u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u8fdb\u884creshape,\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u4e3a[batchsize,9xH,W,2]\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165softmax\u4e2d\u8fdb\u884c\u5206\u7c7b\uff0c\u5f97\u5230\u5206\u7c7b\u7ed3\u679c\u540e\uff0c\u518d\u8fdb\u884creshape\u6700\u7ec8\u5f97\u5230[batchsize,H,W,18]\u5927\u5c0f\u7684\u7ed3\u679c,18\u8868\u793ak=9\u4e2aanchor\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\u503c\u3002 4.2.3 RPN\u56de\u5f52 \u00b6 RPN\u56de\u5f52\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a(k=9) \u7ecf\u8fc7\u8be5\u5377\u79ef\u8f93\u51fa\u7279\u5f81\u56fe\u4e3a\u4e3a[1, H, W,4x9]\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8efeature maps\u6bcf\u4e2a\u70b9\u90fd\u67099\u4e2aanchors\uff0c\u6bcf\u4e2aanchors\u53c8\u90fd\u67094\u4e2a\u7528\u4e8e\u56de\u5f52\u7684: \u53d8\u6362\u91cf\u3002 \u8be5\u53d8\u6362\u91cf\u9884\u6d4b\u7684\u662fanchor\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5e73\u79fb\u91cf\u548c\u5c3a\u5ea6\u56e0\u5b50\uff1a \u5750\u6807\u53d8\u6362\u7684\u6e90\u7801\u4e3a\uff1afasterRCNN/detection/core/bbox/transforms.py def bbox2delta ( box , gt_box , target_means , target_stds ): '''\u8ba1\u7b97box\u5230gtbox\u7684\u4fee\u6b63\u503c. \u53c2\u6570 box: [..., (y1, x1, y2, x2)] : \u8981\u4fee\u6b63\u7684box gt_box: [..., (y1, x1, y2, x2)] : GT\u503c target_means: [4] :\u5747\u503c target_stds: [4]:\u65b9\u5dee ''' # \u8f6c\u5316\u4e3atensor target_means = tf . constant ( target_means , dtype = tf . float32 ) target_stds = tf . constant ( target_stds , dtype = tf . float32 ) # \u7c7b\u578b\u8f6c\u6362 box = tf . cast ( box , tf . float32 ) gt_box = tf . cast ( gt_box , tf . float32 ) # \u83b7\u53d6box\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8 height = box [ ... , 2 ] - box [ ... , 0 ] width = box [ ... , 3 ] - box [ ... , 1 ] center_y = box [ ... , 0 ] + 0.5 * height center_x = box [ ... , 1 ] + 0.5 * width # \u83b7\u53d6Gtbox\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8 gt_height = gt_box [ ... , 2 ] - gt_box [ ... , 0 ] gt_width = gt_box [ ... , 3 ] - gt_box [ ... , 1 ] gt_center_y = gt_box [ ... , 0 ] + 0.5 * gt_height gt_center_x = gt_box [ ... , 1 ] + 0.5 * gt_width # \u8ba1\u7b97\u4e24\u8005\u4e4b\u95f4\u7684\u5e73\u79fb\u503c\u548c\u5c3a\u5ea6\u53d8\u6362 dy = ( gt_center_y - center_y ) / height dx = ( gt_center_x - center_x ) / width dh = tf . math . log ( gt_height / height ) dw = tf . math . log ( gt_width / width ) # \u7ec4\u6210\u4e00\u7ef4\u5411\u91cf delta = tf . stack ([ dy , dx , dh , dw ], axis =- 1 ) # \u6807\u51c6\u5316 delta = ( delta - target_means ) / target_stds # \u8fd4\u56de\u7ed3\u679c return delta RPN\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7684\u6e90\u7801\u5982\u4e0b\uff1afasterRCNN/detection/models/rpn_heads/rpn_head.py class RPNHead ( tf . keras . Model ): \"\"\" \u5b8c\u6210RPN\u7f51\u7edc\u4e2d\u7684\u76f8\u5173\u64cd\u4f5c \"\"\" def __init__ ( self , anchor_scales = ( 32 , 64 , 128 , 256 , 512 ), anchor_ratios = ( 0.5 , 1 , 2 ), anchor_feature_strides = ( 4 , 8 , 16 , 32 , 64 ), proposal_count = 2000 , nms_threshold = 0.7 , target_means = ( 0. , 0. , 0. , 0. ), target_stds = ( 0.1 , 0.1 , 0.2 , 0.2 ), num_rpn_deltas = 256 , positive_fraction = 0.5 , pos_iou_thr = 0.7 , neg_iou_thr = 0.3 , ** kwags ): ''' RPN\u7f51\u7edc\u7ed3\u6784\uff0c\u5982\u4e0b\u6240\u793a\uff1a / - rpn_cls \u5206\u7c7b(1x1 conv) \u8f93\u5165 - rpn_conv \u5377\u79ef(3x3 conv) - \\ - rpn_reg \u56de\u5f52(1x1 conv) \u53c2\u6570 anchor_scales: anchorbox\u7684\u9762\u79ef\uff0c\u76f8\u5bf9\u4e8e\u539f\u56fe\u50cf\u50cf\u7d20\u7684 anchor_ratios: anchorbox\u7684\u957f\u5bbd\u6bd4 anchor_feature_strides: \u751f\u6210anchor\u7684\u6b65\u957f\uff0c\u76f8\u5bf9\u4e8e\u539f\u56fe\u50cf\u7d20\u7684 proposal_count:RPN\u6700\u540e\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u7684\u4e2a\u6570\uff0c\u7ecf\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236 nms_threshold: \u5bf9RPN\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u8fdb\u884cNMS\u7684\u53c2\u6570\u9608\u503c target_means: [4] Bounding box refinement mean. target_stds: [4] Bounding box refinement standard deviation. num_rpn_deltas: int. positive_fraction: float. pos_iou_thr: \u4e0eGT\u7684IOU\u5927\u4e8e\u8be5\u503c\u7684anchor\u4e3a\u6b63\u4f8b neg_iou_thr: \u4e0eGT\u7684IOU\u5c0f\u4e8e\u8be5\u503c\u7684anchor\u4e3a\u8d1f\u4f8b ''' super ( RPNHead , self ) . __init__ ( ** kwags ) # \u53c2\u6570\u521d\u59cb\u5316 # RPN\u6700\u540e\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u7684\u4e2a\u6570\uff0c\u7ecf\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236 self . proposal_count = proposal_count # \u5bf9RPN\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u8fdb\u884cNMS\u7684\u53c2\u6570\u9608\u503c self . nms_threshold = nms_threshold self . target_means = target_means self . target_stds = target_stds # \u8c03\u7528anchor\u751f\u6210\u5668\u751f\u6210\u5bf9\u5e94\u7684anchor self . generator = anchor_generator . AnchorGenerator ( scales = anchor_scales , ratios = anchor_ratios , feature_strides = anchor_feature_strides ) # \u5c06anchor\u5212\u5206\u4e3a\u6b63\u8d1f\u6837\u672c self . anchor_target = anchor_target . AnchorTarget ( target_means = target_means , target_stds = target_stds , num_rpn_deltas = num_rpn_deltas , positive_fraction = positive_fraction , pos_iou_thr = pos_iou_thr , neg_iou_thr = neg_iou_thr ) # \u8bbe\u7f6eRPN\u7f51\u7edc\u7684\u5206\u7c7b\u548c\u56de\u5f52\u635f\u5931 self . rpn_class_loss = losses . rpn_class_loss self . rpn_bbox_loss = losses . rpn_bbox_loss # 3*3\u5377\u79ef self . rpn_conv_shared = layers . Conv2D ( 512 , ( 3 , 3 ), padding = 'same' , kernel_initializer = 'he_normal' , name = 'rpn_conv_shared' ) # 1*1\u5377\u79ef \u5206\u7c7b \u6bcf\u4e00\u4e2aanchor\u5206\u4e3a2\u7c7b self . rpn_class_raw = layers . Conv2D ( len ( anchor_ratios ) * 2 , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'rpn_class_raw' ) # 1*1\u5377\u79ef \u56de\u5f52 \u6bcf\u4e00\u4e2aanchor\u7684\u56de\u5f52\u7ed3\u679c self . rpn_delta_pred = layers . Conv2D ( len ( anchor_ratios ) * 4 , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'rpn_bbox_pred' ) def call ( self , inputs , training = True ): ''' \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b \u53c2\u6570\uff1a inputs: [batch_size, feat_map_height, feat_map_width, channels] FPN\u8f93\u51fa\u7684\u4e00\u4e2a\u7279\u5f81\u56fe \u8fd4\u56de\uff1a rpn_class_logits: [batch_size, num_anchors, 2] \u5206\u7c7b\u7ed3\u679c\uff0c\u4ee5logits\u8868\u793a rpn_probs: [batch_size, num_anchors, 2] \u5206\u7c7b\u7ed3\u679c\uff0c\u7ecfsoftmax\u4e4b\u540e\u7684\u6982\u7387\u8868\u793a\u5f62\u5f0f rpn_deltas: [batch_size, num_anchors, 4] \u56de\u5f52\u7ed3\u679c\uff0canchor\u7684\u4f4d\u7f6e\u4fe1\u606f ''' # \u8f93\u51fa\u7ed3\u679c layer_outputs = [] # \u904d\u5386\u8f93\u5165\u4e2d\u7684\u6bcf\u4e00\u7279\u5f81\u56fe for feat in inputs : # 3*3 \u5377\u79ef\uff0c\u5047\u8bbe\u7279\u5f81\u56fe\u5927\u5c0f\u4e3a\uff1a(1, 304, 304, 256) shared = self . rpn_conv_shared ( feat ) # \u6fc0\u6d3b\uff1a(1, 304, 304, 256) shared = tf . nn . relu ( shared ) # \u5206\u7c7b\u8fc7\u7a0b # 1*1\u5377\u79ef\uff1a\u8f93\u51fa\u5927\u5c0f\u4e3a(1, 304, 304, 6) x = self . rpn_class_raw ( shared ) # reshape:(1, 277248, 2) rpn_class_logits = tf . reshape ( x , [ tf . shape ( x )[ 0 ], - 1 , 2 ]) # softmax\u8fdb\u884c\u5206\u7c7b\uff1a(1, 277248, 2)\uff0c\u4e00\u5171\u6709277248\u4e2aanchor\uff0c\u6bcf\u4e2aanchor\u67092\u4e2a\u5206\u7c7b\u7ed3\u679c rpn_probs = tf . nn . softmax ( rpn_class_logits ) # \u56de\u5f52\u8fc7\u7a0b # 1*1 \u5377\u79ef\uff0c\u8f93\u51fa\u5927\u5c0f\u4e3a(1, 304, 304, 12) x = self . rpn_delta_pred ( shared ) # reshape:(1, 277248, 4),\u4e00\u5171\u6709277248\u4e2aanchor\uff0c\u6bcf\u4e2aanchor\u67094\u4e2a\u4f4d\u7f6e\u4fe1\u606f rpn_deltas = tf . reshape ( x , [ tf . shape ( x )[ 0 ], - 1 , 4 ]) # \u5c06\u7f51\u7edc\u7684\u5206\u7c7b\u548c\u8f93\u51fa\u7ed3\u679c\u5b58\u653e\u5728layer_outputs layer_outputs . append ([ rpn_class_logits , rpn_probs , rpn_deltas ]) # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u8f93\u51fa\u7ed3\u679c\u7684\u5927\u5c0f\u4e3a\uff1a \"\"\" (1, 277248, 2) (1, 277248, 2) (1, 277248, 4) (1, 69312, 2) (1, 69312, 2) (1, 69312, 4) (1, 17328, 2) (1, 17328, 2) (1, 17328, 4) (1, 4332, 2) (1, 4332, 2) (1, 4332, 4) (1, 1083, 2) (1, 1083, 2) (1, 1083, 4) \"\"\" # \u5c06\u8f93\u51fa\u7ed3\u679c\u8f6c\u6362\u4e3a\u5217\u8868 outputs = list ( zip ( * layer_outputs )) # \u904d\u5386\u8f93\u51fa\uff0c\u5c06\u4e0d\u540c\u7279\u5f81\u56fe\u4e2d\u540c\u4e00\u7c7b\u522b\u7684\u8f93\u51fa\u7ed3\u679c\u4e32\u8054\u5728\u4e00\u8d77 outputs = [ tf . concat ( list ( o ), axis = 1 ) for o in outputs ] # \u83b7\u53d6\u6bcf\u4e00\u79cd\u8f93\u51fa\uff1a5\u4e2a\u7279\u5f81\u56fe\u7684\u8f93\u51fa\u5927\u5c0f\u4e3a\uff1a(1, 369303, 2) (1, 369303, 2) (1, 369303, 4) rpn_class_logits , rpn_probs , rpn_deltas = outputs # \u8fd4\u56de\u8f93\u51fa\u7ed3\u679c return rpn_class_logits , rpn_probs , rpn_deltas 4.2.4 Proposal Layer \u00b6 Proposal Layer\u8d1f\u8d23\u7efc\u5408\u6240\u6709 \u53d8\u6362\u91cf\u548c\u5305\u542b\u76ee\u6807\u7684anchors\uff0c\u8ba1\u7b97\u51fa\u5019\u9009\u533a\u57dfproposal\uff0c\u9001\u5165\u540e\u7eedRoI Pooling Layer\u3002 Proposal Layer\u67093\u4e2a\u8f93\u5165\uff1aanchors\u5206\u7c7b\u5668\u7ed3\u679c\uff0c\u5bf9\u5e94\u7684bbox reg\u7684 \u53d8\u6362\u91cf\uff0c\u4ee5\u53caim_info\uff1b\u53e6\u5916\u8fd8\u6709\u53c2\u6570feat_stride\uff0c\u7528\u4e8e\u8ba1\u7b97anchor\u7684\u6b65\u957f\u3002 Proposal Layer \u5b8c\u6210\u4ee5\u4e0b\u5904\u7406\uff1a \u751f\u6210anchors\uff0c\u5229\u7528 \u5bf9\u6240\u6709\u7684anchors\u505abbox regression\u56de\u5f52 \u6309\u7167\u8f93\u5165\u7684positive softmax scores\u7531\u5927\u5230\u5c0f\u6392\u5e8fanchors\uff0c\u63d0\u53d6\u524dpre_nms_topN(e.g. 6000)\u4e2aanchors\uff0c\u5373\u63d0\u53d6\u4fee\u6b63\u4f4d\u7f6e\u540e\u7684positive anchors \u9650\u5b9a\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u7684positive anchors\u4e3a\u56fe\u50cf\u8fb9\u754c\uff0c\u9632\u6b62\u540e\u7eedroi pooling\u65f6proposal\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u3002 \u5254\u9664\u5c3a\u5bf8\u975e\u5e38\u5c0f\u7684positive anchors \u5bf9\u5269\u4f59\u7684positive anchors\u8fdb\u884cNMS\uff08nonmaximum suppression\uff09 Proposal Layer\u7684\u8f93\u51fa\u662f\u5bf9\u5e94MxN\u8f93\u5165\u56fe\u50cf\u5c3a\u5ea6\u7684\u5750\u6807\u503c[x1, y1, x2, y2]\u3002 \u5230\u6b64RPN\u7f51\u7edc\u7684\u5de5\u4f5c\u5c31\u7ed3\u675f\u4e86\u3002 \u8be5\u90e8\u5206\u7684\u6e90\u7801\u5728\uff1afasterRCNN/detection/models/rpn_heads/rpn_head.py def _get_proposals_single ( self , rpn_probs , rpn_deltas , anchors , valid_flags , img_shape , with_probs ): ''' \u8ba1\u7b97\u5019\u9009\u533a\u57df\u7ed3\u679c \u53c2\u6570\uff1a rpn_probs: [num_anchors] anchor\u662f\u76ee\u6807\u7684\u6982\u7387\u503c rpn_deltas: [num_anchors, (dy, dx, log(dh), log(dw))] \u56de\u5f52\u5f97\u5230\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5bf9anchor\u8fdb\u884c\u4fee\u6b63 anchors: [num_anchors, (y1, x1, y2, x2)] anchor\u7684\u4f4d\u7f6e valid_flags: [num_anchors] anchor\u5c5e\u4e8e\u56fe\u50cf\u4f4d\u7f6e\u7684\u6807\u8bb0\u4fe1\u606f img_shape: np.ndarray. [2]. (img_height, img_width) \u56fe\u50cf\u7684\u5927\u5c0f with_probs: bool. \u662f\u5426\u8f93\u51fa\u5206\u7c7b\u7ed3\u679c \u8fd4\u56de proposals: \u8fd4\u56de\u5019\u9009\u533a\u57df\u7684\u5217\u8868 \u82e5with_probs = False\uff0c\u5219\u8fd4\u56de\uff1a[num_proposals, (y1, x1, y2, x2)] \u82e5with_probs = True\uff0c\u5219\u8fd4\u56de\uff1a[num_proposals, (y1, x1, y2, x2, score)] \u5728\u8fd9\u91ccnum_proposals\u4e0d\u4f1a\u5927\u4e8eproposal_count ''' # \u56fe\u50cf\u7684\u9ad8\u5bbd H , W = img_shape # \u5c06anchor\u7684\u6807\u8bb0\u4fe1\u606f\u8f6c\u6362\u4e3a\u5e03\u5c14\u578b, int => bool valid_flags = tf . cast ( valid_flags , tf . bool ) # \u5c06\u65e0\u7528\u7684anchor\u8fc7\u6ee4 \uff0c\u5e76\u5bf9\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\u8fdb\u884c\u5904\u7406[369303] => [215169], respectively rpn_probs = tf . boolean_mask ( rpn_probs , valid_flags ) rpn_deltas = tf . boolean_mask ( rpn_deltas , valid_flags ) anchors = tf . boolean_mask ( anchors , valid_flags ) # \u81f3\u591a6000\u4e2a\u7ed3\u679c\u4f1a\u8fdb\u884c\u540e\u7eed\u64cd\u4f5c min(6000, 215169) => 6000 pre_nms_limit = min ( 6000 , anchors . shape [ 0 ]) # \u83b7\u53d6\u81f3\u591a6000\u4e2a\u5206\u7c7b\u6982\u7387\u6700\u9ad8\u7684anchor\u7684\u7d22\u5f15 ix = tf . nn . top_k ( rpn_probs , pre_nms_limit , sorted = True ) . indices # \u6839\u636e\u5f97\u5230\u7684\u7d22\u5f15\u503c\u83b7\u53d6\u5bf9\u5e94\u7684\u5206\u7c7b\uff0c\u56de\u5f52\u548canchor [215169] => [6000] rpn_probs = tf . gather ( rpn_probs , ix ) rpn_deltas = tf . gather ( rpn_deltas , ix ) anchors = tf . gather ( anchors , ix ) # \u5229\u7528\u56de\u5f52\u5f97\u5230\u7684\u7ed3\u679c\u5bf9anchor\u8fdb\u884c\u4fee\u6b63, [6000, 4] proposals = transforms . delta2bbox ( anchors , rpn_deltas , self . target_means , self . target_stds ) # \u82e5\u4fee\u6b63\u540e\u7684\u7ed3\u679c\u8d85\u51fa\u56fe\u50cf\u8303\u56f4\u5219\u8fdb\u884c\u88c1\u526a, [6000, 4] window = tf . constant ([ 0. , 0. , H , W ], dtype = tf . float32 ) proposals = transforms . bbox_clip ( proposals , window ) # \u5bf9\u5750\u6807\u503c\u8fdb\u884c\u5f52\u4e00\u5316, (y1, x1, y2, x2) proposals = proposals / tf . constant ([ H , W , H , W ], dtype = tf . float32 ) # \u8fdb\u884cNMS\uff0c\u83b7\u53d6\u6700\u7ec8\u5927\u69822000\u4e2a\u5019\u9009\u533a\u57df: [2000] indices = tf . image . non_max_suppression ( proposals , rpn_probs , self . proposal_count , self . nms_threshold ) proposals = tf . gather ( proposals , indices ) # [2000, 4] # \u82e5\u8981\u8fd4\u56de\u5206\u7c7b\u7ed3\u679c\uff0c\u5219\u83b7\u53d6\u5bf9\u5e94\u7684\u5206\u7c7b\u503c\u8fdb\u884c\u8fd4\u56de if with_probs : proposal_probs = tf . expand_dims ( tf . gather ( rpn_probs , indices ), axis = 1 ) proposals = tf . concat ([ proposals , proposal_probs ], axis = 1 ) # \u8fd4\u56de\u5019\u9009\u533a\u57df return proposals 4.3 ROIPooling \u00b6 RoI Pooling\u5c42\u5219\u8d1f\u8d23\u6536\u96c6proposal\uff0c\u5e76\u8ba1\u7b97\u51fa feature maps\u7684\u5019\u9009\u533a\u57df\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u3002 \u4ece\u7f51\u7edc\u67b6\u6784\u4e2d\u53ef\u4ee5\u770b\u51faRol pooling\u5c42\u67092\u4e2a\u8f93\u5165\uff1a CNN\u63d0\u53d6\u7684feature maps RPN\u8f93\u51fa\u7684\u5019\u9009\u533a\u57dfproposal boxes\uff08\u5927\u5c0f\u5404\u4e0d\u76f8\u540c\uff09 RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709pool_H\u00d7pool_W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0ffeature map\uff0c\u5176\u4e2dpool_H\u548cpool_W\u662f\u8d85\u53c2\u6570\uff0c\u6bd4\u5982\u8bbe\u7f6e\u4e3a7x7, \u5b83\u4eec\u72ec\u7acb\u4e8e\u4efb\u4f55\u7279\u5b9a\u7684RoI,\u5982\u4e0b\u56fe\u6240\u793a21\u00b7 RoI Pooling \u7684\u4f5c\u7528\u8fc7\u7a0b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8eRPN\u7f51\u7edc\u8f93\u51fa\u7684proposal\u662f\u5bf9\u5e94MxN\u5c3a\u5ea6\u7684\uff0c\u6240\u4ee5\u9996\u5148\u4f7f\u7528spatial_scale\u53c2\u6570\u5c06\u5176\u6620\u5c04\u56de\u7279\u5f81\u63d0\u53d6\u540e\uff08HxW\uff09\u5927\u5c0f\u7684feature map\u5c3a\u5ea6\uff1b \u518d\u5c06\u6bcf\u4e2aproposal\u5bf9\u5e94\u7684feature map\u533a\u57df\u6c34\u5e73\u5206\u4e3a \u7684\u7f51\u683c\uff1b \u5bf9\u7f51\u683c\u7684\u6bcf\u4e00\u4efd\u90fd\u8fdb\u884cmax pooling\u5904\u7406\u3002 \u8fd9\u6837\u5904\u7406\u540e\uff0c\u5373\u4f7f\u5927\u5c0f\u4e0d\u540c\u7684proposal\u8f93\u51fa\u7ed3\u679c\u90fd\u662f \u56fa\u5b9a\u5927\u5c0f\uff0c\u5b9e\u73b0\u4e86\u56fa\u5b9a\u957f\u5ea6\u8f93\u51fa,\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0cFPN\u7f51\u7edc\u4ea7\u751f\u4e86\u591a\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\uff0c\u90a3\u5019\u9009\u533a\u57df\u8981\u6620\u5c04\u5230\u54ea\u4e2a\u7279\u5f81\u56fe\u4e2d\u5462\uff1f \u5728\u8fd9\u91cc\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684ROI\u4f7f\u7528\u4e0d\u540c\u7279\u5f81\u5c42\u4f5c\u4e3aROI pooling\u5c42\u7684\u8f93\u5165\uff0c\u5927\u5c3a\u5ea6ROI\u5c31\u7528\u540e\u9762\u4e00\u4e9b\u7684\u91d1\u5b57\u5854\u5c42\uff0c\u6bd4\u5982P5\uff1b\u5c0f\u5c3a\u5ea6ROI\u5c31\u7528\u524d\u9762\u4e00\u70b9\u7684\u7279\u5f81\u5c42\uff0c\u6bd4\u5982P3\uff0c\u6211\u4eec\u4f7f\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u786e\u5b9aROI\u6240\u5728\u7684\u7279\u5f81\u5c42\uff1a \u5176\u4e2d\uff0c224\u662fImageNet\u7684\u6807\u51c6\u8f93\u5165\uff0ck0\u662f\u57fa\u51c6\u503c\uff0c\u8bbe\u7f6e\u4e3a4\uff0cw\u548ch\u662fROI\u533a\u57df\u7684\u957f\u548c\u5bbd\uff0c\u5047\u8bbeROI\u662f112x112\u7684\u5927\u5c0f\uff0c\u90a3\u4e48k = k0-1 = 4-1 = 3\uff0c\u610f\u5473\u7740\u8be5ROI\u5e94\u8be5\u4f7f\u7528P3\u7684\u7279\u5f81\u5c42\u3002k\u503c\u4f1a\u505a\u53d6\u6574\u5904\u7406\uff0c\u9632\u6b62\u7ed3\u679c\u4e0d\u662f\u6574\u6570\uff0c\u800c\u4e14\u4e3a\u4e86\u4fdd\u8bc1k\u503c\u57282-5\u4e4b\u95f4\uff0c\u8fd8\u4f1a\u505a\u622a\u65ad\u5904\u7406\u3002 \u6e90\u7801\u5728:fasterRCNN/detection/models/roi_extractors/roi_align.py class PyramidROIAlign ( tf . keras . layers . Layer ): def __init__ ( self , pool_shape , ** kwargs ): ''' \u5728\u591a\u4e2a\u7279\u5f81\u56fe\u4e0a\u5b8c\u6210ROIPooling \u53c2\u6570\uff1a pool_shape: (height, width)\u6307\u660epooling\u4e4b\u540e\u8f93\u51fa\u7684\u5927\u5c0f ''' super ( PyramidROIAlign , self ) . __init__ ( ** kwargs ) self . pool_shape = tuple ( pool_shape ) def call ( self , inputs , training = True ): # \u83b7\u53d6\u8f93\u5165\u4e2d\u7684roi\u533a\u57df\uff0c\u7279\u5f81\u56fe\u548c\u56fe\u50cf\u7684\u5143\u4fe1\u606f rois_list , feature_map_list , img_metas = inputs # \u83b7\u53d6\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f pad_shapes = calc_pad_shapes ( img_metas ) # \u56fe\u50cf\u7684\u5c3a\u5ea6\uff1a1216*1216 pad_areas = pad_shapes [:, 0 ] * pad_shapes [:, 1 ] # \u83b7\u53d6\u56fe\u50cf\u4e2dROI\u7684\u7c7b\u522bdata:[2000] num_rois_list = [ rois . shape . as_list ()[ 0 ] for rois in rois_list ] # \u83b7\u53d6\u56fe\u50cf\u4e2dROI\u7684\u7d22\u5f15 roi_indices = tf . constant ( [ i for i in range ( len ( rois_list )) for _ in range ( rois_list [ i ] . shape . as_list ()[ 0 ])], dtype = tf . int32 ) #[0.....], shape:[2000] # \u83b7\u53d6\u5bf9\u4e8e\u6bcf\u4e00\u4e2aROI\u7684\u56fe\u50cf\u5927\u5c0f areas = tf . constant ( # range(1) range(2000) [ pad_areas [ i ] for i in range ( pad_areas . shape [ 0 ]) for _ in range ( num_rois_list [ i ])], dtype = tf . float32 ) #[1216*1216, 1216*1216,...], shape:[2000] # ROI rois = tf . concat ( rois_list , axis = 0 ) # [2000, 4] # \u83b7\u53d6\u6bcf\u4e00\u4e2aROI\u5bf9\u5e94\u7684\u5750\u6807\u548c\u5bbd\u9ad8 y1 , x1 , y2 , x2 = tf . split ( rois , 4 , axis = 1 ) # 4 of [2000, 1] h = y2 - y1 # [2000, 1] w = x2 - x1 # [2000, 1] # \u5c06\u6bcf\u4e00\u4e2aROI\u5206\u914d\u5230\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u4e0a roi_level = tf . math . log ( # [2000] tf . sqrt ( tf . squeeze ( h * w , 1 )) / tf . cast (( 224.0 / tf . sqrt ( areas * 1.0 )), tf . float32 ) ) / tf . math . log ( 2.0 ) roi_level = tf . minimum ( 5 , tf . maximum ( # [2000], clamp to [2-5] 2 , 4 + tf . cast ( tf . round ( roi_level ), tf . int32 ))) # roi_level will indicates which level of feature to use # \u904d\u5386\u6240\u6709\u7684\u7279\u5f81\u56fe\uff0c\u8fdb\u884cROIpooling/ROIAlign pooled_rois = [] roi_to_level = [] for i , level in enumerate ( range ( 2 , 6 )): # 2,3,4,5 # \u627e\u5230ROI\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u5c3a\u5ea6 ix = tf . where ( tf . equal ( roi_level , level )) # \u83b7\u53d6\u5230\u5bf9\u5e94\u7684ROI\u533a\u57df level_rois = tf . gather_nd ( rois , ix ) # \u83b7\u53d6ROI\u5bf9\u5e94\u7684\u7d22\u5f15 level_roi_indices = tf . gather_nd ( roi_indices , ix ) # Keep track of which roi is mapped to which level roi_to_level . append ( ix ) # \u4e0d\u8fdb\u884c\u68af\u5ea6\u66f4\u65b0 level_rois = tf . stop_gradient ( level_rois ) level_roi_indices = tf . stop_gradient ( level_roi_indices ) # \u8fdb\u884cROI_align,\u662fROIpooling\u7684\u6539\u8fdb\u7248\u672c(\u5728MaskRCNN\u4e2d\u4ecb\u7ecd) pooled_rois . append ( tf . image . crop_and_resize ( feature_map_list [ i ], level_rois , level_roi_indices , self . pool_shape , method = \"bilinear\" )) [ # \u5c06\u7279\u5f81\u62fc\u63a5\u5728\u4e00\u8d77 [2000, 7, 7, 256] pooled_rois = tf . concat ( pooled_rois , axis = 0 ) # ..... # \u83b7\u53d6 2000\u4e2a\u5019\u9009\u533a\u57df 2000 of [7, 7, 256] pooled_rois_list = tf . split ( pooled_rois , num_rois_list , axis = 0 ) return pooled_rois_list 4.4 Classifier+Regression \u00b6 Classifier+Regression\u90e8\u5206\u5229\u7528\u83b7\u5f97\u7684\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u56fe\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u4e0esoftmax\u8ba1\u7b97\u6bcf\u4e2a\u5019\u9009\u533a\u57dfproposal\u5177\u4f53\u5c5e\u4e8e\u7684\u7c7b\u522b\uff08\u5982\u4eba\uff0c\u8f66\uff0c\u7535\u89c6\u7b49\uff09\uff0c\u8f93\u51facls_prob\u6982\u7387\uff1b\u540c\u65f6\u518d\u6b21\u5229\u7528bounding box regression\u83b7\u5f97\u6bcf\u4e2aproposal\u7684\u4f4d\u7f6e\u504f\u79fb\u91cfbbox_pred\uff0c\u7528\u4e8e\u56de\u5f52\u66f4\u52a0\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u6846\u3002Classifier\u90e8\u5206\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u4eceRoI Pooling\u83b7\u53d6\u52307x7=49\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\uff0c\u53ef\u4ee5\u770b\u5230\u505a\u4e86\u5982\u4e0b2\u4ef6\u4e8b\uff1a \u901a\u8fc7\u5168\u8fde\u63a5\u548csoftmax\u5bf9proposals\u8fdb\u884c\u5206\u7c7b \u518d\u6b21\u5bf9proposals\u8fdb\u884cbounding box regression\uff0c\u83b7\u53d6\u66f4\u9ad8\u7cbe\u5ea6\u7684rect box \u6e90\u7801\u5982\u4e0b\uff1afasterRCNN/detection/models/bbox_heads/bbox_head.py class BBoxHead ( tf . keras . Model ): def __init__ ( self , num_classes , pool_size = ( 7 , 7 ), target_means = ( 0. , 0. , 0. , 0. ), target_stds = ( 0.1 , 0.1 , 0.2 , 0.2 ), min_confidence = 0.7 , nms_threshold = 0.3 , max_instances = 100 , ** kwags ): super ( BBoxHead , self ) . __init__ ( ** kwags ) # \u7c7b\u522b\u4e2a\u6570 self . num_classes = num_classes # ROIpooling\u7684\u5c3a\u5bf8 self . pool_size = tuple ( pool_size ) # \u5747\u503c self . target_means = target_means # \u6807\u51c6\u5dee self . target_stds = target_stds # \u6700\u5c0f\u7684\u7f6e\u4fe1\u5ea6 self . min_confidence = min_confidence # NMS\u5c3a\u5ea6 self . nms_threshold = nms_threshold self . max_instances = max_instances # \u635f\u5931\u51fd\u6570 self . rcnn_class_loss = losses . rcnn_class_loss self . rcnn_bbox_loss = losses . rcnn_bbox_loss # \u5206\u7c7b\u5377\u79ef self . rcnn_class_conv1 = layers . Conv2D ( 1024 , self . pool_size , padding = 'valid' , name = 'rcnn_class_conv1' ) # \u5206\u7c7bBN self . rcnn_class_bn1 = layers . BatchNormalization ( name = 'rcnn_class_bn1' ) # \u5206\u7c7b\u5377\u79ef self . rcnn_class_conv2 = layers . Conv2D ( 1024 , ( 1 , 1 ), name = 'rcnn_class_conv2' ) # BN\u5c42 self . rcnn_class_bn2 = layers . BatchNormalization ( name = 'rcnn_class_bn2' ) # \u5206\u7c7b self . rcnn_class_logits = layers . Dense ( num_classes , name = 'rcnn_class_logits' ) # \u56de\u5f52 self . rcnn_delta_fc = layers . Dense ( num_classes * 4 , name = 'rcnn_bbox_fc' ) def call ( self , inputs , training = True ): ''' \u53c2\u6570\uff1a pooled_rois_list: List of [num_rois, pool_size, pool_size, channels] rpn\u751f\u6210\u7684\u5019\u9009\u533a\u57df \u8fd4\u56de\uff1a rcnn_class_logits_list: [num_rois, num_classes] \u5206\u7c7b\u7684logits rcnn_probs_list: List of [num_rois, num_classes] \u5206\u7c7b\u7684\u635f\u5931 rcnn_deltas_list: List of [num_rois, num_classes, (dy, dx, log(dh), log(dw))] \u56de\u5f52\u7ed3\u679c ''' pooled_rois_list = inputs num_pooled_rois_list = [ pooled_rois . shape [ 0 ] for pooled_rois in pooled_rois_list ] pooled_rois = tf . concat ( pooled_rois_list , axis = 0 ) # \u5377\u79ef+BN+relu x = self . rcnn_class_conv1 ( pooled_rois ) x = self . rcnn_class_bn1 ( x , training = training ) x = tf . nn . relu ( x ) # \u5377\u79ef+BN+relu x = self . rcnn_class_conv2 ( x ) x = self . rcnn_class_bn2 ( x , training = training ) x = tf . nn . relu ( x ) # flatten x = tf . squeeze ( tf . squeeze ( x , 2 ), 1 ) # \u5206\u7c7b\u7ed3\u679c logits = self . rcnn_class_logits ( x ) # \u5206\u7c7b\u6982\u7387 probs = tf . nn . softmax ( logits ) # \u56de\u5f52\u7ed3\u679c deltas = self . rcnn_delta_fc ( x ) deltas = tf . reshape ( deltas , ( - 1 , self . num_classes , 4 )) # \u5206\u7c7blogits rcnn_class_logits_list = tf . split ( logits , num_pooled_rois_list , 0 ) # \u5206\u7c7b\u6982\u7387 rcnn_probs_list = tf . split ( probs , num_pooled_rois_list , 0 ) # \u56de\u5f52\u7ed3\u679c rcnn_deltas_list = tf . split ( deltas , num_pooled_rois_list , 0 ) # \u7ed3\u679c\u8fd4\u56de return rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list \u5230\u8fd9\u6211\u4eec\u5c31\u5b8c\u6210\u4e86\u6574\u4e2a\u7f51\u7edc\u7684\u4ecb\u7ecd\u3002 4.5 FasterRCNN\u7684\u8bad\u7ec3 \u00b6 Faster R-CNN\u7684\u8bad\u7ec3\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5373RPN\u7f51\u7edc\u548c\u68c0\u6d4b\u7f51\u7edcfastRCNN\u7684\u8bad\u7ec3\uff1a \u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u5206\u4e3a\u56db\u6b65\uff1a \u7b2c\u4e00\u6b65\uff1aRPN\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u4f7f\u7528ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\uff0c\u5e76\u7aef\u5230\u7aef\u5fae\u8c03\u7528\u4e8e\u533a\u57df\u5efa\u8bae\u4efb\u52a1\u3002 \u7b2c\u4e8c\u6b65\uff1a\u5229\u7528\u7b2c\u4e00\u6b65\u7684RPN\u751f\u6210\u7684\u5efa\u8bae\u6846\uff0c\u7531Fast R-CNN\u8bad\u7ec3\u4e00\u4e2a\u5355\u72ec\u7684\u68c0\u6d4b\u7f51\u7edc\uff0c\u8fd9\u4e2a\u68c0\u6d4b\u7f51\u7edc\u540c\u6837\u662f\u7531ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\u7684\uff0c\u8fd9\u65f6\u5019\u4e24\u4e2a\u7f51\u7edc\u8fd8\u6ca1\u6709\u5171\u4eab\u5377\u79ef\u5c42\u3002 \u7b2c\u4e09\u6b65\uff1a\u7528\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\u3002 \u7b2c\u56db\u6b65\uff1a\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0c\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\u5404\u4e2a\u8bad\u7ec3\u6b65\u9aa4\uff1a 4.5.1 RPN\u7f51\u7edc\u7684\u8bad\u7ec3 \u00b6 RPN\u7f51\u7edc\u7684\u4f5c\u7528\u4ece\u4f17\u591a\u7684anchors\u4e2d\u63d0\u53d6\u5305\u542b\u76ee\u6807\u7684\uff0c\u5e76\u4e14\u7ecf\u8fc7\u56de\u5f52\u8c03\u6574\u7684\u5019\u9009\u533a\u57df\u3002\u4e3a\u4e86\u8bad\u7ec3RPN\uff0c\u7ed9\u6bcf\u4e2aanchor\u5206\u914d\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6807\u7b7e\uff0c\u4e5f\u5c31\u662f\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\uff0c\u7136\u540e\u8fdb\u884c\u8bad\u7ec3\u3002 1\u3001\u6b63\u8d1f\u6837\u672c\u6807\u8bb0 \u00b6 \u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.7\u7684anchor\u662f\u6b63\u6837\u672c\uff0c\u5373anchor\u4e2d\u5305\u542b\u76ee\u6807 \u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.3\u7684anchor\u662f\u8d1f\u6837\u672c\uff0c\u5373anchor\u4e2d\u4e0d\u5305\u542b\u76ee\u6807 \u5176\u4ed6\u7684anchor\u820d\u5f03\uff0c\u4e0d\u53c2\u4e0e\u7f51\u7edc\u7684\u8bad\u7ec3 \u8be5\u90e8\u5206\u6e90\u7801\u5728\uff1afasterRCNN/detection/core/anchor/anchor_target.py def _build_single_target ( self , anchors , valid_flags , gt_boxes , gt_class_ids ): ''' \u8ba1\u7b97\u6bcf\u5e45\u56fe\u50cf\u7684\u76ee\u6807\u503c \u53c2\u6570\uff1a anchors: [num_anchors, (y1, x1, y2, x2)] anchor\u7684\u4f4d\u7f6e\u4fe1\u606f valid_flags: [num_anchors] anchor\u7684\u8868\u793a gt_class_ids: [num_gt_boxes] \u771f\u5b9e\u503c\u7684\u7c7b\u522b gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)] \u771f\u5b9e\u6846\u7684\u4f4d\u7f6e \u8fd4\u56de\uff1a target_matchs: [num_anchors] anchor\u662f\u6b63\u8d1f\u6837\u672c target_deltas: [num_rpn_deltas, (dy, dx, log(dh), log(dw))] ''' # \u5220\u9664\u4e3a0\u7684\u771f\u5b9e\u6846 gt_boxes , _ = trim_zeros ( gt_boxes ) # \u521d\u59cb\u5316\u51680\u6570\u7ec4\uff0c\u5b58\u50a8anchor\u7684\u5206\u7c7b\u7ed3\u679c target_matchs = tf . zeros ( anchors . shape [ 0 ], dtype = tf . int32 ) # \u8ba1\u7b97anchor\u4e0egt\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4 326393 vs 10 => [326393, 10] overlaps = geometry . compute_overlaps ( anchors , gt_boxes ) # 1.\u8bbe\u7f6e\u8d1f\u6837\u672c # \u83b7\u53d6\u6bcf\u4e00\u4e2aanchor\u4e0e\u5404\u4e2aGT\u4ea4\u5e76\u6bd4\u7684\u6700\u5927\u503c\u53ca\u5176\u7d22\u5f15 anchor_iou_argmax = tf . argmax ( overlaps , axis = 1 ) anchor_iou_max = tf . reduce_max ( overlaps , axis = [ 1 ]) # \u9009\u62e9 IOU < 0.3 \u7684 anchor \u4e3a background\uff0c\u6807\u7b7e\u4e3a -1 target_matchs = tf . where ( anchor_iou_max < self . neg_iou_thr , - tf . ones ( anchors . shape [ 0 ], dtype = tf . int32 ), target_matchs ) # \u8fc7\u6ee4\u6389pad\u533a\u57df\u7684anchor target_matchs = tf . where ( tf . equal ( valid_flags , 1 ), target_matchs , tf . zeros ( anchors . shape [ 0 ], dtype = tf . int32 )) # 2\u3001\u9009\u62e9 IOU > 0.7 \u7684 anchor \u4e3a foreground\uff0c\u6807\u7b7e\u4e3a 1 target_matchs = tf . where ( anchor_iou_max >= self . pos_iou_thr , tf . ones ( anchors . shape [ 0 ], dtype = tf . int32 ), target_matchs ) # 3\u3001\u4e3a\u6bcf\u4e00GT\u5206\u914d\u4e00\u4e2aanchor\uff1a\u4e0d\u8003\u8651IOU\u7684\u5927\u5c0f # \u9009\u62e9\u4e0e\u6bcf\u4e00\u4e2aGT\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor\u7d22\u5f15 \uff1a[N_gt_boxes] gt_iou_argmax = tf . argmax ( overlaps , axis = 0 ) # \u5c06\u4ea4\u5e76\u6bd4\u6700\u5927\u7684\u8bbe\u7f6e\u4e3a\u6b63\u6837\u672c target_matchs = tf . compat . v1 . scatter_update ( tf . Variable ( target_matchs ), gt_iou_argmax , 1 ) # \u91c7\u6837\u83b7\u53d6\u6b63\u8d1f\u6837\u672c\uff0c\u4e3b\u8981\u4e0d\u8981\u4f7f\u6b63\u6837\u672c\u6bd4\u4f8b\u8d85\u8fc7\u4e00\u534a # [N_pos_anchors, 1], [15, 1] ids = tf . where ( tf . equal ( target_matchs , 1 )) # \u538b\u7f29\u6210\u4e00\u4e2a\u4e00\u7ef4\u5411\u91cf [15] ids = tf . squeeze ( ids , 1 ) # \u8ba1\u7b97\u771f\u5b9e\u6b63\u6837\u672c\u4e2a\u6570\u4e0e\u6240\u9700\u6837\u672c\u4e2a\u6570\u4e4b\u95f4\u7684\u5dee\u503c extra = ids . shape . as_list ()[ 0 ] - int ( self . num_rpn_deltas * self . positive_fraction ) # \u82e5\u5dee\u503c\u5927\u4e8e0\uff0c\u8bf4\u660e\u6709\u8db3\u591f\u7684\u6b63\u6837\u672c if extra > 0 : # \u5c06\u591a\u4f59\u7684\u6b63\u6837\u672c\u7684\u6807\u8bc6\u7f6e\u4e3a0 ids = tf . random . shuffle ( ids )[: extra ] target_matchs = tf . compat . v1 . scatter_update ( target_matchs , ids , 0 ) # \u83b7\u53d6\u8d1f\u6837\u672c ids = tf . where ( tf . equal ( target_matchs , - 1 )) # [213748, 1] ids = tf . squeeze ( ids , 1 ) # \u83b7\u53d6\u8d1f\u6837\u672c\u4e2a\u6570\u4e0e\u6240\u9700\u8d1f\u6837\u672c\u4e2a\u6570\u4e4b\u95f4\u7684\u5dee\u503c extra = ids . shape . as_list ()[ 0 ] - ( self . num_rpn_deltas - tf . reduce_sum ( tf . cast ( tf . equal ( target_matchs , 1 ), tf . int32 ))) # \u82e5\u5dee\u503c\u5927\u4e8e0\uff0c\u5219\u8bf4\u660e\u6709\u8db3\u591f\u7684\u8d1f\u6837\u672c if extra > 0 : # \u5c06\u591a\u4f59\u7684\u8d1f\u6837\u672c\u7f6e\u4e3a0 ids = tf . random . shuffle ( ids )[: extra ] target_matchs = tf . compat . v1 . scatter_update ( target_matchs , ids , 0 ) # \u8fd9\u65f6\u6211\u4eec\u5c31\u6709256\u4e2aanchor,\u5206\u522b\u5305\u542b\u6b63\u8d1f\u6837\u672c. # \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u8ba1\u7b97\u5176\u5bf9\u5e94\u7684\u5750\u6807\u4fee\u6b63\u503c # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u7d22\u5f15 ids = tf . where ( tf . equal ( target_matchs , 1 )) # [15] # \u83b7\u53d6\u6b63\u6837\u672c\u7684anchor a = tf . gather_nd ( anchors , ids ) # \u83b7\u53d6anchor\u5bf9\u5e94\u7684gt\u7684index anchor_idx = tf . gather_nd ( anchor_iou_argmax , ids ) # \u83b7\u53d6gt gt = tf . gather ( gt_boxes , anchor_idx ) # \u8ba1\u7b97anchor\u5230gt\u7684\u4fee\u6b63\u5750\u6807\u3002 target_deltas = transforms . bbox2delta ( a , gt , self . target_means , self . target_stds ) # \u83b7\u53d6\u8d1f\u6837\u672c\u7684\u4e2a\u6570 padding = tf . maximum ( self . num_rpn_deltas - tf . shape ( target_deltas )[ 0 ], 0 ) # \u76ee\u6807\u503c\uff0c\u6b63\u6837\u672c\u7684\u76ee\u6807\u503c\u662f\u504f\u79fb\uff0c\u8d1f\u6837\u672c\u7684\u76ee\u6807\u503c\u662f0 target_deltas = tf . pad ( target_deltas , [( 0 , padding ), ( 0 , 0 )]) return target_matchs , target_deltas 2\u3001RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570 \u00b6 RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570\u662f\uff1a \u5176\u4e2d i i \u8868\u793aanchor\u7684\u7d22\u5f15 p_i p_i \u662f\u7b2ci\u4e2aanchor \u9884\u6d4b\u4e3a\u76ee\u6807\u7684\u53ef\u80fd\u6027\uff0c p_i^{*} p_i^{*} \u4e3aground-truth\u6807\u7b7e\u3002\u5982\u679c\u8fd9\u4e2aanchor\u662fpositive\u7684\uff0c\u5219ground-truth\u6807\u7b7e\u4e3a1\uff0c\u5426\u5219\u4e3a0\u3002\uff08\u5373\u5f53\u7b2ci\u4e2aanchor\u4e0eGT\u95f4IoU>0.7\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fpositive\uff0c\u6807\u7b7e\u4e3a1\uff1b\u53cd\u4e4bIoU<0.3\u65f6\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fnegative\uff0c\u6807\u7b7e\u4e3a0\uff09 t_i t_i \u8868\u793a\u8868\u793a\u6b63\u6837\u672canchor\u5230\u9884\u6d4b\u533a\u57dfbounding box\u76844\u4e2a\u53c2\u6570\u5316\u9884\u6d4b\u7ed3\u679c, t_i^{*} t_i^{*} \u662f\u8fd9\u4e2apositive anchor\u5bf9\u5e94\u7684ground-truth box\u7684\u504f\u79fb\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9884\u6d4b\u503c\uff1a \u771f\u5b9e\u503c\uff1a \u5176\u4e2d\uff0cx\uff0cy\uff0cw\uff0ch\u8868\u793a\u7a97\u53e3\u4e2d\u5fc3\u5750\u6807\u548c\u7a97\u53e3\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u53d8\u91cfx\uff0c x_a \u548cx^{*} x_a \u548cx^{*} \u5206\u522b\u8868\u793a\u9884\u6d4b\u7a97\u53e3\u3001anchor\u7a97\u53e3\u548cGround Truth\u7684\u5750\u6807\uff08y\uff0cw\uff0ch\u540c\u7406\uff09 \u6574\u4e2aLoss\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u5206\u7c7b\u548c\u56de\u5f52\u7684\u635f\u5931 L_{cls} L_{cls} \u5206\u7c7b\u7684\u635f\u5931\uff08classification loss\uff09\uff0c\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u5668\u7684softmax loss\u3002 L_{reg} L_{reg} \u662f\u56de\u5f52\u635f\u5931\uff0c\u4e3a smooth(x) smooth(x) \u635f\u5931,\u5e76\u4e14\u53ea\u6709\u6b63\u6837\u672c\u624d\u53c2\u4e0e\u56de\u5f52\u635f\u5931\u8ba1\u7b97 N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u5206\u522b\u7528\u6765\u6807\u51c6\u5316\u5206\u7c7b\u635f\u5931\u9879 L_{cls} L_{cls} \u548c\u56de\u5f52\u635f\u5931\u9879 L_{reg} L_{reg} \uff0c\u9ed8\u8ba4\u7528batch size\u8bbe\u7f6e N_{cls} N_{cls} \uff0c\u7528anchor\u4f4d\u7f6e\u6570\u76ee~2000\u521d\u59cb\u5316 N_{reg} N_{reg} N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u76f8\u5dee\u8fc7\u5927\uff0c\u7528\u53c2\u6570\u03bb\u6765\u5e73\u8861\u4e24\u8005\uff0c\u4e00\u822c\u53d6\u503c\u4e3a N_{reg} N_{reg} \u548c N_{cls} N_{cls} \u7684\u6bd4\u503c10\u5373\u53ef\u3002 \u5206\u7c7b\u635f\u5931\u5b9e\u73b0\uff1afasterRCNN/detection/core/loss/losses.py def rpn_class_loss ( target_matchs , rpn_class_logits ): '''RPN\u5206\u7c7b\u635f\u5931 \u53c2\u6570\uff1a target_matchs: [batch_size, num_anchors]. anchor\u7684\u6807\u8bb0\u4fe1\u606f. 1=positive, -1=negative, 0=neutral anchor. rpn_class_logits: [batch_size, num_anchors, 2]. RPN\u7684\u5206\u7c7b\u7ed3\u679c FG/BG. ''' # \u83b7\u53d6anchor\u7684\u5206\u7c7b\u6807\u8bb0\u4fe1\u606f. \u5c06 -1/+1 \u8f6c\u6362\u4e3a 0/1 \u503c anchor_class = tf . cast ( tf . equal ( target_matchs , 1 ), tf . int32 ) # \u6b63\u8d1f\u6837\u672c\u5bf9\u635f\u5931\u90fd\u6709\u8d21\u732e\uff0c\u83b7\u53d6\u6b63\u8d1f\u6837\u672c\u7684\u7d22\u5f15 indices = tf . where ( tf . not_equal ( target_matchs , 0 )) # \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\u5bf9\u5e94\u7684\u9884\u6d4b\u503c rpn_class_logits = tf . gather_nd ( rpn_class_logits , indices ) # \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\u5bf9\u5e94\u7684\u771f\u5b9e\u7d2f\u5457 anchor_class = tf . gather_nd ( anchor_class , indices ) # \u83b7\u53d6\u7c7b\u522b\u4e2a\u6570 num_classes = rpn_class_logits . shape [ - 1 ] # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\u7ed3\u679c loss = keras . losses . categorical_crossentropy ( tf . one_hot ( anchor_class , depth = num_classes ), rpn_class_logits , from_logits = True ) # \u6c42\u5e73\u5747 loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) # \u8fd4\u56deloss\u503c return loss \u56de\u5f52\u635f\u5931\uff1a def rpn_bbox_loss ( target_deltas , target_matchs , rpn_deltas ): ''' rpn\u635f\u5931\u7684\u56de\u5f52\u7ed3\u679c \u53c2\u6570\uff1a target_deltas: [batch, num_rpn_deltas, (dy, dx, log(dh), log(dw))]. target_matchs: [batch, anchors]. Anchor match type. 1=positive, -1=negative, 0=neutral anchor. rpn_deltas: [batch, anchors, (dy, dx, log(dh), log(dw))] ''' def batch_pack ( x , counts , num_rows ): # \u83b7\u53d6\u6307\u5b9a\u7684\u4f4d\u7f6e\u7684\u503c outputs = [] for i in range ( num_rows ): outputs . append ( x [ i , : counts [ i ]]) return tf . concat ( outputs , axis = 0 ) # \u53ea\u6709\u6b63\u6837\u672c\u8ba1\u7b97\u635f\u5931\uff0c\u83b7\u53d6\u6b63\u6837\u672c\u7684\u7d22\u5f15 indices = tf . where ( tf . equal ( target_matchs , 1 )) # \u83b7\u53d6\u6b63\u6837\u672c\u5bf9\u5e94\u7684\u9884\u6d4b\u503c rpn_deltas = tf . gather_nd ( rpn_deltas , indices ) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u4e2a\u6570 batch_counts = tf . reduce_sum ( tf . cast ( tf . equal ( target_matchs , 1 ), tf . int32 ), axis = 1 ) # \u83b7\u53d6\u6b63\u6837\u672c\u5bf9\u5e94\u7684\u76ee\u6807\u503c target_deltas = batch_pack ( target_deltas , batch_counts , target_deltas . shape . as_list ()[ 0 ]) # \u8ba1\u7b97smoothL1\u635f\u5931 loss = smooth_l1_loss ( target_deltas , rpn_deltas ) # \u8ba1\u7b97\u5747\u503c loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) # \u8fd4\u56de\u635f\u5931 return loss 3\u3001\u8bad\u7ec3\u8fc7\u7a0b \u00b6 \u5728\u8bad\u7ec3\u65f6\u6bcf\u6b21\u8fed\u4ee3\u7684\u6b63\u8d1f\u6837\u672c\u662f\u7531\u4e00\u5e45\u56fe\u50cf\u7684\u6b63\u8d1f\u6837\u672c\u7ec4\u6210\u7684\uff1a \u968f\u673a\u91c7\u6837256\u4e2aanchor\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5176\u4e2d\u91c7\u6837\u7684\u6b63\u8d1fanchor\u7684\u6bd4\u4f8b\u662f1:1\u3002 \u901a\u8fc7\u4ece\u96f6\u5747\u503c\u6807\u51c6\u5dee\u4e3a0.01\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u83b7\u53d6\u7684\u6743\u91cd\u6765\u968f\u673a\u521d\u59cb\u5316\u6240\u6709\u65b0\u5c42\uff08\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u5176\u540e\u7684\u5c42\uff09\uff0c\u6240\u6709\u5176\u4ed6\u5c42\uff08\u5373\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff09\u662f\u901a\u8fc7\u5bf9ImageNet\u5206\u7c7b\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u6765\u521d\u59cb\u5316\u7684 \u91c7\u7528\u5e26\u52a8\u91cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3 4.5.2 FastRCNN\u7f51\u7edc\u7684\u8bad\u7ec3 \u00b6 \u4f7f\u7528RPN\u7f51\u7edc\u6536\u96c6\u5230\u7684\u5019\u9009\u533a\u57df\u548cimageNet\u9884\u8bad\u7ec3\u7684\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5bf9\u68c0\u6d4b\u7684FastRCNN\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002 1.\u6b63\u8d1f\u6837\u672c\u6807\u8bb0 \u00b6 \u5728FastRCNN\u7f51\u7edc\u8bad\u7ec3\u65f6\uff1a \u9996\u5148\u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u6b63\u6837\u672c \u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u8d1f\u6837\u672c \u6b63\u8d1f\u6837\u672c\u7684\u5206\u914d\u5982\u4e0b\u6240\u793a\uff1afasterRCNN/detection/core/bbox/bbox_target.py def _build_single_target ( self , proposals , gt_boxes , gt_class_ids , img_shape ): ''' \u751f\u6210\u4e00\u5e45\u56fe\u50cf\u4e2d\u7684\u6b63\u8d1f\u6837\u672c \u53c2\u6570\uff1a proposals: [num_proposals, (y1, x1, y2, x2)] rpn\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df\uff1a\u5f52\u4e00\u5316\u5750\u6807 gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)] \u56fe\u50cf\u4e2d\u771f\u5b9e\u503c\uff0cbbox\u7684\u5750\u6807\u503c\uff0c\u56fe\u50cf\u5750\u6807 gt_class_ids: [num_gt_boxes] \u56fe\u50cf\u4e2d\u7684gt\u5bf9\u5e94\u7684\u7c7b\u522b img_shape: np.ndarray. [2]. (img_height, img_width) \u56fe\u50cf\u7684\u5927\u5c0f \u8fd4\u56de\uff1a rois: [num_rois, (y1, x1, y2, x2)] \u5019\u9009\u533a\u57df\u7684\u5f52\u4e00\u5316\u5750\u6807 target_matchs: [num_positive_rois] \u91c7\u6837\u540e\u5019\u9009\u533a\u57df\u7684\u7c7b\u522b target_deltas: [num_positive_rois, (dy, dx, log(dh), log(dw))] \u91c7\u6837\u540e\u5019\u9009\u533a\u57df\u7684\u76ee\u6807\u503c ''' # \u56fe\u50cf\u7684\u5927\u5c0f H , W = img_shape # 1216, 1216 # \u79fb\u96640\u503c [7, 4] gt_boxes , non_zeros = trim_zeros ( gt_boxes ) # \u83b7\u53d6GT\u5bf9\u5e94\u7684\u7c7b\u522b gt_class_ids = tf . boolean_mask ( gt_class_ids , non_zeros ) # [7] # \u5f52\u4e00\u5316 (y1, x1, y2, x2) => 0~1 gt_boxes = gt_boxes / tf . constant ([ H , W , H , W ], dtype = tf . float32 ) # \u8ba1\u7b97\u5019\u9009\u533a\u57df\u548c\u771f\u5b9e\u6846\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4\uff1a[2k, 4] with [7, 4] => [2k, 7] overlaps = geometry . compute_overlaps ( proposals , gt_boxes ) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u6700\u76f8\u4f3c\u7684gtbox\u7684\u7d22\u5f15[2000] anchor_iou_argmax = tf . argmax ( overlaps , axis = 1 ) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u4e0e\u6700\u76f8\u4f3c\u7684gtbox\u7684\u4ea4\u5e76\u6bd4[2000] roi_iou_max = tf . reduce_max ( overlaps , axis = 1 ) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u7d22\u5f15[2000]=>[48, 1] =>[48] positive_roi_bool = ( roi_iou_max >= self . pos_iou_thr ) positive_indices = tf . where ( positive_roi_bool )[:, 0 ] # \u83b7\u53d6\u8d1f\u6837\u672c\u7684\u7d22\u5f15 negative_indices = tf . where ( roi_iou_max < self . neg_iou_thr )[:, 0 ] # \u5bf9\u83b7\u53d6\u7684ROI\u533a\u57df\u8fdb\u884c\u4e0b\u91c7\u6837 # \u9700\u8981\u7684\u6b63\u6837\u672c\u4e2a\u6570\uff0c\u901a\u8fc7\u6bd4\u4f8b\u8ba1\u7b97 positive_count = int ( self . num_rcnn_deltas * self . positive_fraction ) # \u5c06\u6b63\u6837\u672c\u6253\u4e71\uff0c\u8fdb\u884c\u622a\u53d6 positive_indices = tf . random . shuffle ( positive_indices )[: positive_count ] # \u6b63\u6837\u672c\u7684\u4e2a\u6570 positive_count = tf . shape ( positive_indices )[ 0 ] # \u8d1f\u6837\u672c\uff0c\u4fdd\u8bc1\u6b63\u6837\u672c\u7684\u6bd4\u4f8b r = 1.0 / self . positive_fraction # \u8ba1\u7b97\u6837\u672c\u603b\u6570\u5e76\u51cf\u53bb\u6b63\u6837\u672c\u4e2a\u6570\uff0c\u5373\u4e3a\u8d1f\u6837\u672c\u4e2a\u6570 negative_count = tf . cast ( r * tf . cast ( positive_count , tf . float32 ), tf . int32 ) - positive_count # \u83b7\u53d6\u8d1f\u6837\u672c negative_indices = tf . random . shuffle ( negative_indices )[: negative_count ] # \u9009\u53d6\u6b63\u8d1f\u6837\u672c\u7684\u5019\u9009\u533a\u57df positive_rois = tf . gather ( proposals , positive_indices ) negative_rois = tf . gather ( proposals , negative_indices ) # \u4e3a\u9009\u53d6\u7684\u5019\u9009\u533a\u57df\u5206\u914d\u76ee\u6807\u503c\uff0c\u83b7\u53d6\u6b63\u6837\u672c\u4e0eGT\u7684\u4ea4\u5e76\u6bd4 positive_overlaps = tf . gather ( overlaps , positive_indices ) # \u83b7\u53d6\u4e0e\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u6700\u76f8\u4f3c\u7684GT roi_gt_box_assignment = tf . argmax ( positive_overlaps , axis = 1 ) # \u5c06GT\u7684\u5750\u6807\u548c\u7c7b\u522b\u5206\u914d\u7ed9\u5bf9\u5e94\u7684\u5019\u9009\u533a\u57df roi_gt_boxes = tf . gather ( gt_boxes , roi_gt_box_assignment ) target_matchs = tf . gather ( gt_class_ids , roi_gt_box_assignment ) # \u5c06\u5750\u6807\u8f6c\u6362\u4e3a\u4fee\u6b63\u503c target_deltas = transforms . bbox2delta ( positive_rois , roi_gt_boxes , self . target_means , self . target_stds ) # \u5c06\u6b63\u8d1f\u6837\u672c\u62fc\u63a5\u5728\u4e00\u8d77 rois = tf . concat ([ positive_rois , negative_rois ], axis = 0 ) # \u83b7\u53d6\u8d1f\u6837\u672c\u7684\u6570\u91cf N = tf . shape ( negative_rois )[ 0 ] # \u5c06\u8d1f\u6837\u672c\u7c7b\u522b\u8bbe\u4e3a0 target_matchs = tf . pad ( target_matchs , [( 0 , N )]) # \u505c\u6b62\u68af\u5ea6\u66f4\u65b0 target_matchs = tf . stop_gradient ( target_matchs ) target_deltas = tf . stop_gradient ( target_deltas ) # \u8fd4\u56de\u7ed3\u679c return rois , target_matchs , target_deltas 2.FastRCNN\u7684\u635f\u5931\u51fd\u6570 \u00b6 FastRCNN\u7684\u8f93\u51fa\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u90e8\u5206\u662fsoftmax\u5c42\u8fdb\u884c\u5206\u7c7b\uff0c\u8f93\u51fa\u7c7b\u522b\u6709K\u4e2a\u7c7b\u522b\u52a0\u4e0a\u201d\u80cc\u666f\u201d\u7c7b\uff0c\u53e6\u4e00\u90e8\u5206\u662f\u56de\u5f52bounding box regressor\u3002\u4e5f\u5c31\u662f\uff1a \u4e00\u90e8\u5206\u8f93\u51fa\u5728K+1\u4e2a\u7c7b\u522b\u4e0a\u7684\u79bb\u6563\u6982\u7387\u5206\u5e03\uff08\u6bcf\u4e2a\u5019\u9009\u533a\u57df\uff09\uff0c p=(p0,p1,...,pk) p=(p0,p1,...,pk) \u3002\u901a\u5e38\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u7684K+1\u4e2a\u8f93\u51fa\u4e0a\u7684Softmax\u6765\u8ba1\u7b97p\u3002 \u53e6\u4e00\u90e8\u5206\u8f93\u51fa\u5bf9\u4e8e\u7531K\u4e2a\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u6846\u56de\u5f52\u504f\u79fb\uff0c t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k})\u200b t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k})\u200b \u3002\u5176\u4e2d t_k\u200b t_k\u200b \u6307\u5b9a\u76f8\u5bf9\u4e8e\u5019\u9009\u6846\u7684\u5c3a\u5ea6\u4e0d\u53d8\u8f6c\u6362\u548c\u5bf9\u6570\u7a7a\u95f4\u9ad8\u5ea6/\u5bbd\u5ea6\u79fb\u4f4d\uff0c\u4e0e\u5728RPN\u7f51\u7edc\u4e2d\u662f\u4e00\u6837\u7684\u3002 \u6bcf\u4e2a\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57df\u7528 \u5206\u7c7b\u76ee\u6807\u503cu\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u76ee\u6807\u503cv\u6807\u8bb0 \u3002\u80cc\u666f\u6837\u672c\u7528u=0\u6765\u8868\u793a\uff0c\u5bf9\u6bcf\u4e2a\u6807\u8bb0\u7684\u5019\u9009\u533a\u57df\u4f7f\u7528\u591a\u4efb\u52a1\u635f\u5931L\u4ee5\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\uff1a \u5176\u4e2d L_{cls}(p, u) = -\\log p_u L_{cls}(p, u) = -\\log p_u \uff0c\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u7b2c\u4e8c\u4e2a\u635f\u5931 L_{loc} L_{loc} \uff0c\u662f\u5b9a\u4e49\u76ee\u6807\u503c\u548c\u9884\u6d4b\u68c0\u6d4b\u6846\u7684\u56db\u5143\u7ec4\u4e4b\u95f4\u7684\u635f\u5931\u4f7f\u7528smoothL1\u635f\u5931\u8ba1\u7b97\uff0c\u540c\u6837\u662f\u53ea\u6709\u6b63\u6837\u672c\uff08\u975e\u80cc\u666f\uff09\u7684\u5019\u9009\u533a\u57df\u624d\u8ba1\u7b97\u56de\u5f52\u635f\u5931\uff0c\u53c2\u6570\u03bb\u8bbe\u4e3a1\u3002 \u635f\u5931\u51fd\u6570\u7684\u6e90\u7801\u5982\u4e0b\u6240\u793a\uff1afasterRCNN/detection/core/loss/losses.py def rcnn_class_loss ( target_matchs_list , rcnn_class_logits_list ): '''FastRCNN\u7684\u5206\u7c7b\u635f\u5931 \u53c2\u6570\uff1a target_matchs_list: [num_rois]. \u6b63\u6837\u672c\u7684\u5019\u9009\u533a\u57df rcnn_class_logits_list: list of [num_rois, num_classes] \u5206\u7c7b\u7ed3\u679c ''' # \u589e\u52a0\u80cc\u666f\u7c7b\u7684\u7c7b\u522b class_ids = tf . concat ( target_matchs_list , 0 ) # \u80cc\u666f\u7c7b\u7684\u5206\u6570 class_logits = tf . concat ( rcnn_class_logits_list , 0 ) # \u7c7b\u578b\u8f6c\u6362 class_ids = tf . cast ( class_ids , 'int64' ) # \u83b7\u53d6\u7c7b\u522b\u603b\u6570 num_classes = class_logits . shape [ - 1 ] # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 loss = keras . losses . categorical_crossentropy ( tf . one_hot ( class_ids , depth = num_classes ), class_logits , from_logits = True ) # \u6c42\u5e73\u5747\uff1a\u5927\u4e8e0\u8fd4\u56de\u7ed3\u679c\uff0c\u5176\u4ed6\u8fd4\u56de0 loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) return loss def rcnn_bbox_loss ( target_deltas_list , target_matchs_list , rcnn_deltas_list ): '''FastRCNN\u7684\u56de\u5f52\u635f\u5931 \u53c2\u6570\uff1a target_deltas_list: [num_positive_rois, (dy, dx, log(dh), log(dw))] \u6b63\u6837\u672c\u5bf9\u5e94\u7684\u771f\u5b9e\u503c target_matchs_list: list of [num_rois]. \u6b63\u6837\u672c\u5bf9\u5e94\u7684\u7c7b\u522b rcnn_deltas_list: list of [num_rois, num_classes, (dy, dx, log(dh), log(dw))] \u7f51\u7edc\u8fd4\u56de\u7684\u7ed3\u679c ''' # \u5176\u4ed6\u7ed3\u679c\u4e3a0 target_deltas = tf . concat ( target_deltas_list , 0 ) target_class_ids = tf . concat ( target_matchs_list , 0 ) rcnn_deltas = tf . concat ( rcnn_deltas_list , 0 ) # \u53ea\u6709\u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5e76\u4e14\u53ea\u6709\u7c7b\u522b\u9884\u6d4b\u6b63\u786e\u624d\u83b7\u53d6\u5176\u7d22\u5f15 # \u83b7\u53d6\u975e\u80cc\u666f\u7c7b\u7684\u7ed3\u679c positive_roi_ix = tf . where ( target_class_ids > 0 )[:, 0 ] # \u5c06\u7c7b\u522b\u548c\u56de\u5f52\u7ed3\u679c\u5408\u5e76\u5728\u4e00\u8d77 positive_roi_class_ids = tf . cast ( tf . gather ( target_class_ids , positive_roi_ix ), tf . int64 ) # \u83b7\u53d6\u7d22\u5f15 indices = tf . stack ([ positive_roi_ix , positive_roi_class_ids ], axis = 1 ) # \u83b7\u53d6\u6b63\u6837\u672c\u9884\u6d4b\u7ed3\u679c rcnn_deltas = tf . gather_nd ( rcnn_deltas , indices ) # \u8ba1\u7b97Smooth-L1\u635f\u5931 loss = smooth_l1_loss ( target_deltas , rcnn_deltas ) # \u5e73\u5747\uff1asize>0\u8fd4\u56de\u7ed3\u679c\uff0c\u5426\u5219\u8fd4\u56de0 loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) return loss 3.\u8bad\u7ec3\u8fc7\u7a0b \u00b6 FastRCNN\u7684\u8bad\u7ec3\u91c7\u7528\u591a\u5f20\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\uff0c\u83b7\u53d6\u6bcf\u5f20\u56fe\u7247\u4e2d\u7684\u6b63\u8d1f\u6837\u672c\uff1a \u5bf9\u6240\u6709\u6b63\u6837\u672c\u6839\u636eIOU\u503c\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u5f20\u56fe\u7247\u53d6\u524d64\u4e2a\u533a\u57df\uff0c\u5c06\u8fd9\u4e9b\u533a\u57df\u7684\u5750\u6807\u4fdd\u5b58\u4e0b\u6765\uff0c\u4f5c\u4e3a\u8be5\u56fe\u7247\u7684\u8bad\u7ec3\u6837\u672c \u7528\u4e8eSoftmax\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u5206\u522b\u4f7f\u7528\u5177\u6709\u65b9\u5dee0.01\u548c0.001\u7684\u96f6\u5747\u503c\u9ad8\u65af\u5206\u5e03\u521d\u59cb\u5316\uff0c\u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\uff0c\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4f7f\u7528ImageNet\u7684\u9884\u8bad\u7ec3\u7f51\u7edc \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316 4.5.3 \u5171\u4eab\u5377\u79ef\u8bad\u7ec3 \u00b6 \u7528fastRCNN\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\uff0c\u63a5\u4e0b\u6765\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0cRPN\u7f51\u7edc\u548cFast R-CNN\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 Faster R-CNN\u8fd8\u6709\u4e00\u79cdend-to-end\u7684\u8bad\u7ec3\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4e00\u6b21\u5b8c\u6210\u5b8c\u6210\uff0c\u5c06RPN loss\u4e0eFast RCNN loss\u76f8\u52a0\uff0c\u7136\u540e\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\uff0c\u66f4\u65b0\u53c2\u6570\u3002 \u603b\u7ed3 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u53ef\u4ee5\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 R-CNN\u7f51\u7edc\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\uff0c\u5229\u7528CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0cSVM\u5b8c\u6210\u5206\u7c7b\uff0c\u7ebf\u6027\u56de\u5f52\u8fdb\u884cbbox\u7684\u4fee\u6b63 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528SS\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u8fdb\u884c\u6620\u5c04\uff0c\u5e76\u4f7f\u7528ROIpooling\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u77e5\u9053anchor\u7684\u601d\u60f3 anchor\u6280\u672f\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u6362\u4e3a**\"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\"**\uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u901a\u8fc7softmax\u5224\u65adanchors\u5c5e\u4e8epositive\u6216\u8005negative\uff0c\u518d\u5229\u7528bounding box regression\u4fee\u6b63anchors\u83b7\u5f97\u7cbe\u786e\u7684proposals \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709H\u00d7W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0ffeature map \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 \u5206\u6b65\u8bad\u7ec3\uff1aRPN\u7f51\u7edc\uff0cfastrcnn\u8bad\u7ec3\uff0c\u5171\u4eab\u7f51\u7edc\u8bad\u7ec3","title":"RCNN\u7cfb\u5217\u7f51\u7edc"},{"location":"objectdection/02.RCNN/#42-r-cnn","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u77e5\u9053anchor\u7684\u601d\u60f3 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5","title":"4.2 R-CNN\u7cfb\u5217\u7f51\u7edc"},{"location":"objectdection/02.RCNN/#1overfeat","text":"Overfeat\u65b9\u6cd5\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u548c\u795e\u7ecf\u7f51\u7edc\u6765\u68c0\u6d4b\u76ee\u6807\u3002\u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u7ed3\u679c\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4f8b\u5982\u8981\u68c0\u6d4b\u6c7d\u8f66\uff0c\u5c31\u4f7f\u7528\u4e0b\u56fe\u4e2d\u7ea2\u8272\u6ed1\u52a8\u7a97\u53e3\u8fdb\u884c\u626b\u63cf\uff0c\u5c06\u6240\u6709\u7684\u626b\u63cf\u7ed3\u679c\u9001\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u6c7d\u8f66\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e00\u79cd\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u5f0f\uff0c\u4f1a\u6d88\u8017\u5927\u91cf\u7684\u8ba1\u7b97\u529b\uff0c\u5e76\u4e14\u7531\u4e8e\u7a97\u53e3\u5927\u5c0f\u95ee\u9898\u53ef\u80fd\u4f1a\u9020\u6210\u6548\u679c\u4e0d\u51c6\u786e\u3002","title":"1.Overfeat\u6a21\u578b"},{"location":"objectdection/02.RCNN/#2rcnn","text":"\u5728CVPR 2014\u5e74\u4e2dRoss Girshick\u63d0\u51faR-CNN\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u4e0d\u5728\u4f7f\u7528\u66b4\u529b\u7a77\u4e3e\u7684\u65b9\u6cd5\uff0c\u800c\u662f\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\uff0c\u521b\u5efa\u76ee\u6807\u68c0\u6d4b\u7684\u533a\u57df\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u7684\u4efb\u52a1\uff0cR-CNN\u662f\u4ee5\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e3a\u57fa\u7840\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6a21\u578b \uff0c\u4ee5R-CNN\u4e3a\u57fa\u70b9\uff0c\u540e\u7eed\u7684Fast R-CNN\u3001Faster R-CNN\u6a21\u578b\u90fd\u5ef6\u7eed\u4e86\u8fd9\u79cd\u76ee\u6807\u68c0\u6d4b\u601d\u8def\u3002","title":"2.RCNN\u6a21\u578b"},{"location":"objectdection/02.RCNN/#21","text":"RCNN\u7684\u68c0\u6d4b\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b65\u9aa4\u662f\uff1a \u5019\u9009\u533a\u57df \uff1a\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u7684\u65b9\u6cd5\u627e\u51fa\u56fe\u7247\u4e2d\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u7684\u4faf\u9009\u533a\u57dfregion proposal \u7f51\u7edc\u9009\u62e9 \uff1a\u9009\u53d6\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7f51\u7edc\uff08AlexNet\uff09\u7528\u4e8e\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 \u76ee\u6807\u5206\u7c7b \uff1a\u8bad\u7ec3\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u6765\u8fa8\u522b\u76ee\u6807\u7269\u4f53\u548c\u80cc\u666f\u3002\u5bf9\u6bcf\u4e2a\u7c7b\u522b\uff0c\u90fd\u8981\u8bad\u7ec3\u4e00\u4e2a\u4e8c\u5143SVM\u3002 \u76ee\u6807\u5b9a\u4f4d \uff1a\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u4e3a\u6bcf\u4e2a\u8fa8\u8bc6\u5230\u7684\u7269\u4f53\u751f\u6210\u66f4\u7cbe\u786e\u7684\u8fb9\u754c\u6846 \u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\u6765\u5c55\u793a\u8fd9\u4e2a\u6d41\u7a0b\uff1a \u9009\u62e9\u4e00\u4e2a\u56fe\u7247\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1a \u5229\u7528\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u5019\u9009\u533a\u57df \u5c06\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u8fdb\u884c\u53d8\u5f62\uff0c\u82e5\u662fAlexNet\u5c06\u56fe\u7247resize\u6210227*227\u540e\u9001\u5165\u5230CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002 \u5c06CNN\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c\u9001\u5165\u5230SVM\u4e2d\u8fdb\u884c\u5206\u7c7b\uff1a \u7528\u7ebf\u6027\u56de\u5f52\u7684\u65b9\u6cd5\u9884\u6d4b\u6bcf\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u4f4d\u7f6e \u8fd9\u5c31\u662f\u6574\u4e2aRCNN\u7b97\u6cd5\u7684\u6d41\u7a0b\u3002 \u3010\u4e86\u89e3\u3011\u9009\u62e9\u6027\u641c\u7d22\uff08SelectiveSearch\uff0cSS\uff09\u4e2d \uff0c\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5728\u50cf\u7d20\u7ea7\u7684\u6807\u6ce8\uff0c\u628a\u989c\u8272\u3001\u8fb9\u754c\u3001\u7eb9\u7406\u7b49\u4fe1\u606f\u4f5c\u4e3a\u5408\u5e76\u6761\u4ef6\uff0c\u591a\u5c3a\u5ea6\u7684\u7efc\u5408\u91c7\u6837\u65b9\u6cd5\uff0c\u5212\u5206\u51fa\u4e00\u7cfb\u5217\u7684\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u8981\u8fdc\u8fdc\u5c11\u4e8e\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u7684\u7a77\u4e3e\u6cd5\u4ea7\u751f\u7684\u5019\u9009\u533a\u57df\u3002 SelectiveSearch\u5728\u4e00\u5f20\u56fe\u7247\u4e0a\u63d0\u53d6\u51fa\u6765\u7ea62000\u4e2a\u4faf\u9009\u533a\u57df\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u7684\u957f\u5bbd\u4e0d\u56fa\u5b9a \u3002 \u800c\u4f7f\u7528CNN\u63d0\u53d6\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9700\u8981\u63a5\u53d7\u56fa\u5b9a\u957f\u5ea6\u7684\u8f93\u5165\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u5019\u9009\u533a\u57df\u505a\u4e00\u4e9b\u5c3a\u5bf8\u4e0a\u7684\u4fee\u6539\u3002","title":"2.1 \u7b97\u6cd5\u6d41\u7a0b"},{"location":"objectdection/02.RCNN/#22","text":"1\u3001\u8bad\u7ec3\u9636\u6bb5\u591a\uff1a\u6b65\u9aa4\u7e41\u7410: \u5fae\u8c03\u7f51\u7edc+\u8bad\u7ec3SVM+\u8bad\u7ec3\u8fb9\u6846\u56de\u5f52\u5668\u3002 2\u3001\u8bad\u7ec3\u8017\u65f6\uff1a\u5360\u7528\u78c1\u76d8\u7a7a\u95f4\u5927\uff1a5000\u5f20\u56fe\u50cf\u4ea7\u751f\u51e0\u767eG\u7684\u7279\u5f81\u6587\u4ef6\u3002 3\u3001\u5904\u7406\u901f\u5ea6\u6162: \u4f7f\u7528GPU, VGG16\u6a21\u578b\u5904\u7406\u4e00\u5f20\u56fe\u50cf\u9700\u898147s \u3002 4\u3001\u56fe\u7247\u5f62\u72b6\u53d8\u5316\uff1a\u5019\u9009\u533a\u57df\u8981\u7ecf\u8fc7crop/warp\u8fdb\u884c\u56fa\u5b9a\u5927\u5c0f\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u56fe\u7247\u4e0d\u53d8\u5f62","title":"2.2 \u7b97\u6cd5\u603b\u7ed3"},{"location":"objectdection/02.RCNN/#3-fast-rcnn","text":"\u8003\u8651\u5230R-CNN\u901f\u5ea6\u5f88\u6162, \u63d0\u51fa\u4e86\u4e00\u4e2a\u6539\u5584\u6a21\u578b:Fast R-CNN\u3002 \u76f8\u6bd4R-CNN, Fast R-CNN\u7684\u4f18\u70b9\u5728\u4e8e\u52a0\u5feb\u4e86selective search\u7684\u6b65\u9aa4\u548c\u540c\u65f6\u8bad\u7ec3\u5206\u7c7b\u548c\u56de\u5f52\u8fc7\u7a0b, \u4ece\u6574\u4f53\u4e0a\u52a0\u5feb\u4e86\u901f\u5ea6\u3002 Fast R-CNN\u5bf9R-CNN\u7684\u6539\u8fdb\u90e8\u5206: \u5c06R-CNN\u4e2d\u4e09\u4e2a\u6a21\u5757(CNN, SVM, Regression)\u6574\u5408, \u6781\u5927\u4e86\u51cf\u5c11\u4e86\u8ba1\u7b97\u91cf\u548c\u52a0\u5feb\u4e86\u901f\u5ea6 \u4e0d\u5bf9\u539f\u59cb\u56fe\u50cf\u8fdb\u884cselective search\u63d0\u53d6, \u800c\u662f\u5148\u7ecf\u8fc7\u4e00\u6b21CNN, \u5728feature map\u4e0a\u4f7f\u7528selective search\u751f\u6210\u5019\u9009\u533a\u57df\u8fdb\u884c\u6620\u5c04, \u5e76\u8fdb\u884c\u5206\u7c7b\u56de\u5f52 \u4e3a\u4e86\u517c\u5bb9\u4e0d\u540c\u56fe\u7247\u5c3a\u5ea6, \u4f7f\u7528\u4e86ROI Pooling \u7b97\u6cd5, \u5c06\u7279\u5f81\u56fe\u6c60\u5316\u5230\u56fa\u5b9a\u7ef4\u5ea6\u7684\u7279\u5f81\u5411\u91cf\u3002 fastRCNN\u7684\u5de5\u4f5c\u6d41\u7a0b\u63cf\u8ff0\u5982\u4e0b\uff1a \u8f93\u5165\u56fe\u50cf\uff1a \u56fe\u50cf\u88ab\u9001\u5165\u5230\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u901a\u8fc7\u9009\u62e9\u6027\u641c\u7d22\u83b7\u53d6\u7684\u5019\u9009\u533a\u57df\u6620\u5c04\u5230\u7279\u5f81\u56fe\u4e2d\uff1a \u5728\u7279\u5f81\u56fe\u4e0aRol\u4e2d\u5e94\u7528RoIPooling\uff0c\u83b7\u53d6\u5c3a\u5bf8\u76f8\u540c\u7684\u7279\u5f81\u5411\u91cf \u5c06\u8fd9\u4e9b\u533a\u57df\u4f20\u9012\u5230\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u5f97\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u7ed3\u679c\u3002","title":"3. Fast RCNN\u6a21\u578b"},{"location":"objectdection/02.RCNN/#4fasterrcnn","text":"\u5728R-CNN\u548cFast RCNN\u7684\u57fa\u7840\u4e0a\uff0cRoss B. Girshick\u57282016\u5e74\u63d0\u51fa\u4e86Faster RCNN\uff0c\u5728\u7ed3\u6784\u4e0a\uff0cFaster RCNN\u5df2\u7ecf\u5c06\u7279\u5f81\u62bd\u53d6(feature extraction)\uff0cproposal\u63d0\u53d6\uff0cbounding box regression(rect refine)\uff0cclassification\u90fd\u6574\u5408\u5728\u4e86\u4e00\u4e2a\u7f51\u7edc\u4e2d\uff0c\u4f7f\u5f97\u7efc\u5408\u6027\u80fd\u6709\u8f83\u5927\u63d0\u9ad8\uff0c\u5728\u68c0\u6d4b\u901f\u5ea6\u65b9\u9762\u5c24\u4e3a\u660e\u663e\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u7ed9\u5927\u5bb6\u8be6\u7ec6\u4ecb\u7ecdfasterRCNN\u7f51\u7edc\u6a21\u578b\u3002\u7f51\u7edc\u57fa\u672c\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u7f51\u7edc\u4e3b\u8981\u53ef\u5206\u4e3a\u56db\u90e8\u5206\uff1a Backbone \uff1abackbone\u7531\u4e00\u7ec4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6784\u6210\uff0cFaster RCNN\u9996\u5148\u4f7f\u7528\u4e00\u7ec4\u57fa\u7840\u7684conv+relu+pooling\u5c42\u63d0\u53d6\u56fe\u50cf\u4e2d\u7684\u7279\u5f81\uff0c\u83b7\u53d6\u56fe\u50cf\u7684\u7279\u5f81\u56fefeaturemaps\u3002\u8be5feature maps\u88ab\u5171\u4eab\u7528\u4e8e\u540e\u7eedRPN\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u3002 RPN\u7f51\u7edc \uff1aRPN\u7f51\u7edc\u7528\u4e8e\u751f\u6210\u5019\u9009\u533a\u57dfregion proposals\u3002\u8be5\u90e8\u5206\u901a\u8fc7softmax\u5224\u65adanchors\u5c5e\u4e8epositive\u6216\u8005negative\uff0c\u5373\u662f\u5426\u5305\u542b\u76ee\u6807\uff0c\u518d\u5229\u7528bounding box regression\u4fee\u6b63anchors\u83b7\u5f97\u7cbe\u786e\u7684proposals\u3002 Roi Pooling : \u8be5\u90e8\u5206\u6536\u96c6\u8f93\u5165\u56fe\u50cf\u7684feature maps\u548cproposals\uff0c\u7efc\u5408\u4fe1\u606f\u540e\u63d0\u53d6proposal\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9001\u5165\u540e\u7eed\u5168\u8fde\u63a5\u5c42\u5224\u5b9a\u76ee\u6807\u7c7b\u522b\u548c\u786e\u5b9a\u76ee\u6807\u4f4d\u7f6e\u3002 Classifier : \u8be5\u90e8\u5206\u5229\u7528\u7279\u5f81\u5411\u91cf\u8ba1\u7b97proposal\u7684\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7bounding box regression\u83b7\u5f97\u68c0\u6d4b\u6846\u6700\u7ec8\u7684\u7cbe\u786e\u4f4d\u7f6e \u5c06\u4e0a\u8ff0\u7ed3\u6784\u5c55\u5f00\u540e\u5982\u4e0b\u6240\u793a\uff0c\u4e0b\u56fe\u4e2d\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u662fVGG16\uff1a \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u4e8e\u4e00\u526f\u4efb\u610f\u5927\u5c0fPxQ\u7684\u56fe\u50cf\uff1a \u9996\u5148\u5c06\u56fe\u50cf\u7f29\u653e\u81f3\u56fa\u5b9a\u5927\u5c0fMxN\uff0c\u7136\u540e\u5c06MxN\u56fe\u50cf\u9001\u5165\u7f51\u7edc\uff1b \u800cConv layers\u4e2d\u5305\u542b\u4e8613\u4e2aconv\u5c42+13\u4e2arelu\u5c42+4\u4e2apooling\u5c42\uff0c\u5728\u8fd9\u91cc\u4f7f\u7528VGG16\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u820d\u5f03\u3002\u5728\u6574\u4e2aConv layers\u4e2d\uff0cconv\u548crelu\u5c42\u4e0d\u6539\u53d8\u8f93\u5165\u8f93\u51fa\u5927\u5c0f\uff0c\u53ea\u6709pooling\u5c42\u4f7f\u8f93\u51fa\u957f\u5bbd\u90fd\u53d8\u4e3a\u8f93\u5165\u7684\u00bd\uff0c\u4e00\u5171\u67094\u4e2a\u6c60\u5316\u5c42\uff0c\u6240\u4ee5\uff1a \u4e00\u4e2aMxN\u5927\u5c0f\u7684\u77e9\u9635\u7ecf\u8fc7Conv layers\u56fa\u5b9a\u53d8\u4e3a(M/16)x(N/16\uff09\uff1b RPN\u7f51\u7edc\u9996\u5148\u7ecf\u8fc73x3\u5377\u79ef\uff0c\u518d\u5206\u522b\u751f\u6210positive anchors\u548c\u5bf9\u5e94bounding box regression\u504f\u79fb\u91cf\uff0c\u7136\u540e\u8ba1\u7b97\u51faproposals\uff1b \u800cRoi Pooling\u5c42\u5219\u5229\u7528proposals\u4ecefeature maps\u4e2d\u63d0\u53d6proposal feature\u9001\u5165\u540e\u7eed\u5168\u8fde\u63a5\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u4ece\u8fd9\u56db\u4e2a\u65b9\u9762\u6765\u8be6\u7ec6fasterRCNN\u7f51\u7edc\u5e76\u7ed3\u5408\u6e90\u7801\u5206\u6790\u5176\u5b9e\u73b0\u8fc7\u7a0b\u3002","title":"4.FasterRCNN\u6a21\u578b"},{"location":"objectdection/02.RCNN/#41backbone","text":"backbone\u4e00\u822c\u4e3aVGG\uff0cResNet\u7b49\u7f51\u7edc\u6784\u6210\uff0c\u4e3b\u8981\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u820d\u5f03\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u8fdb\u884c\u540e\u7eed\u5904\u7406\u3002 \u5728\u6e90\u7801\u4e2d\u6211\u4eec\u4f7f\u7528ResNet + FPN \u7ed3\u6784\uff0c\u6765\u63d0\u53d6\u7279\u5f81\u3002\u666e\u901a\u7684 FasterRCNN \u53ea\u9700\u8981\u5c06 feature_map \u8f93\u5165\u5230 rpn \u7f51\u7edc\u751f\u6210 proposals \u5373\u53ef\u3002\u4f46\u662f\u7531\u4e8e\u52a0\u5165 FPN\uff0c\u9700\u8981\u5c06\u591a\u4e2a feature_map \u9010\u4e2a\u8f93\u5165\u5230 rpn \u7f51\u7edc\u548c\u68c0\u6d4b\u7f51\u7edc\u4e2d\uff1a \u5728\u8fd9\u91ccResNet\u548cFPN\u7684\u5b8c\u6574\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0cRPN\u8f93\u5165\u7684feature map\u662f[p2,p3,p4,p5,p6] \uff0c\u800c\u4f5c\u4e3a\u540e\u7eed\u76ee\u6807\u68c0\u6d4b\u7f51\u7edcFastRCNN\u7684\u8f93\u5165\u5219\u662f [p2,p3,p4,p5] \u3002 \u90a3\u7f51\u7edc\u7684\u6574\u4f53\u67b6\u6784\u8868\u793a\u6210\uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790\u4e0b\u76f8\u5173\u5185\u5bb9\u53ca\u6e90\u7801\uff1a","title":"4.1backbone"},{"location":"objectdection/02.RCNN/#411-resnet","text":"\u6e90\u7801\u4f4d\u7f6e\uff1afasterRCNN/detection/models/backbones/reset.py","title":"4.1.1 ResNet"},{"location":"objectdection/02.RCNN/#1","text":"\u8981\u6784\u5efaresnet\u7f51\u7edc\u9996\u5148\u6784\u5efa\u74f6\u9888\u6a21\u5757\u5982\u4e0b\u6240\u793a\uff1a class _Bottleneck ( tf . keras . Model ): \"\"\" \u74f6\u9888\u6a21\u5757\u7684\u5b9e\u73b0 \"\"\" def __init__ ( self , filters , block , downsampling = False , stride = 1 , ** kwargs ): super ( _Bottleneck , self ) . __init__ ( ** kwargs ) # \u83b7\u53d6\u4e09\u4e2a\u5377\u79ef\u7684\u5377\u79ef\u6838\u6570\u91cf filters1 , filters2 , filters3 = filters # \u5377\u79ef\u5c42\u547d\u540d\u65b9\u5f0f conv_name_base = 'res' + block + '_branch' # BN\u5c42\u547d\u540d\u65b9\u5f0f bn_name_base = 'bn' + block + '_branch' # \u662f\u5426\u8fdb\u884c\u4e0b\u91c7\u6837 self . downsampling = downsampling # \u5377\u79ef\u6b65\u957f self . stride = stride # \u74f6\u9888\u6a21\u5757\u8f93\u51fa\u7684\u901a\u9053\u6570 self . out_channel = filters3 # 1*1 \u5377\u79ef self . conv2a = layers . Conv2D ( filters1 , ( 1 , 1 ), strides = ( stride , stride ), kernel_initializer = 'he_normal' , name = conv_name_base + '2a' ) # BN\u5c42 self . bn2a = layers . BatchNormalization ( name = bn_name_base + '2a' ) # 3*3 \u5377\u79ef self . conv2b = layers . Conv2D ( filters2 , ( 3 , 3 ), padding = 'same' , kernel_initializer = 'he_normal' , name = conv_name_base + '2b' ) # BN\u5c42 self . bn2b = layers . BatchNormalization ( name = bn_name_base + '2b' ) # 1*1\u5377\u79ef self . conv2c = layers . Conv2D ( filters3 , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = conv_name_base + '2c' ) # BN\u5c42 self . bn2c = layers . BatchNormalization ( name = bn_name_base + '2c' ) # \u4e0b\u91c7\u6837 if self . downsampling : # \u5728\u77ed\u8fde\u63a5\u5904\u8fdb\u884c\u4e0b\u91c7\u6837 self . conv_shortcut = layers . Conv2D ( filters3 , ( 1 , 1 ), strides = ( stride , stride ), kernel_initializer = 'he_normal' , name = conv_name_base + '1' ) # BN\u5c42 self . bn_shortcut = layers . BatchNormalization ( name = bn_name_base + '1' ) def call ( self , inputs , training = False ): \"\"\" \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b :param inputs: :param training: :return: \"\"\" # \u7b2c\u4e00\u7ec4\u5377\u79ef+BN+Relu x = self . conv2a ( inputs ) x = self . bn2a ( x , training = training ) x = tf . nn . relu ( x ) # \u7b2c\u4e8c\u7ec4\u5377\u79ef+BN+Relu x = self . conv2b ( x ) x = self . bn2b ( x , training = training ) x = tf . nn . relu ( x ) # \u7b2c\u4e09\u7ec4\u5377\u79ef+BN x = self . conv2c ( x ) x = self . bn2c ( x , training = training ) # \u77ed\u8fde\u63a5 if self . downsampling : shortcut = self . conv_shortcut ( inputs ) shortcut = self . bn_shortcut ( shortcut , training = training ) else : shortcut = inputs # \u76f8\u52a0\u6c42\u548c x += shortcut # \u6fc0\u6d3b x = tf . nn . relu ( x ) # \u6700\u7ec8\u8f93\u51fa return x","title":"1.\u74f6\u9888\u6a21\u5757"},{"location":"objectdection/02.RCNN/#2-resnet","text":"\u5229\u7528\u74f6\u9888\u6a21\u5757\u6784\u5efabackbone\u4e2d\u7684resNet. class ResNet ( tf . keras . Model ): \"\u6784\u5efa50\u6216101\u5c42\u7684resnet\u7f51\u7edc\" def __init__ ( self , depth , ** kwargs ): super ( ResNet , self ) . __init__ ( ** kwargs ) # \u82e5\u6df1\u5ea6\u4e0d\u662f50\u6216101\u62a5\u9519 if depth not in [ 50 , 101 ]: raise AssertionError ( 'depth must be 50 or 101.' ) self . depth = depth # padding self . padding = layers . ZeroPadding2D (( 3 , 3 )) # \u8f93\u5165\u7684\u5377\u79ef self . conv1 = layers . Conv2D ( 64 , ( 7 , 7 ), strides = ( 2 , 2 ), kernel_initializer = 'he_normal' , name = 'conv1' ) # BN\u5c42 self . bn_conv1 = layers . BatchNormalization ( name = 'bn_conv1' ) # maxpooling self . max_pool = layers . MaxPooling2D (( 3 , 3 ), strides = ( 2 , 2 ), padding = 'same' ) # \u7b2c\u4e00\u7ec4\u74f6\u9888\u6a21\u5757 self . res2a = _Bottleneck ([ 64 , 64 , 256 ], block = '2a' , downsampling = True , stride = 1 ) self . res2b = _Bottleneck ([ 64 , 64 , 256 ], block = '2b' ) self . res2c = _Bottleneck ([ 64 , 64 , 256 ], block = '2c' ) # \u7b2c\u4e8c\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u9996\u4e2a\u8fdb\u884c\u4e0b\u91c7\u6837 self . res3a = _Bottleneck ([ 128 , 128 , 512 ], block = '3a' , downsampling = True , stride = 2 ) self . res3b = _Bottleneck ([ 128 , 128 , 512 ], block = '3b' ) self . res3c = _Bottleneck ([ 128 , 128 , 512 ], block = '3c' ) self . res3d = _Bottleneck ([ 128 , 128 , 512 ], block = '3d' ) # \u7b2c\u4e09\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u9996\u4e2a\u8fdb\u884c\u4e0b\u91c7\u6837 self . res4a = _Bottleneck ([ 256 , 256 , 1024 ], block = '4a' , downsampling = True , stride = 2 ) self . res4b = _Bottleneck ([ 256 , 256 , 1024 ], block = '4b' ) self . res4c = _Bottleneck ([ 256 , 256 , 1024 ], block = '4c' ) self . res4d = _Bottleneck ([ 256 , 256 , 1024 ], block = '4d' ) self . res4e = _Bottleneck ([ 256 , 256 , 1024 ], block = '4e' ) self . res4f = _Bottleneck ([ 256 , 256 , 1024 ], block = '4f' ) # \u82e5\u6df1\u5ea6\u4e3a101\u8fd8\u9700\u8fdb\u884c\u74f6\u9888\u6a21\u5757\u7684\u4e32\u8054 if self . depth == 101 : self . res4g = _Bottleneck ([ 256 , 256 , 1024 ], block = '4g' ) self . res4h = _Bottleneck ([ 256 , 256 , 1024 ], block = '4h' ) self . res4i = _Bottleneck ([ 256 , 256 , 1024 ], block = '4i' ) self . res4j = _Bottleneck ([ 256 , 256 , 1024 ], block = '4j' ) self . res4k = _Bottleneck ([ 256 , 256 , 1024 ], block = '4k' ) self . res4l = _Bottleneck ([ 256 , 256 , 1024 ], block = '4l' ) self . res4m = _Bottleneck ([ 256 , 256 , 1024 ], block = '4m' ) self . res4n = _Bottleneck ([ 256 , 256 , 1024 ], block = '4n' ) self . res4o = _Bottleneck ([ 256 , 256 , 1024 ], block = '4o' ) self . res4p = _Bottleneck ([ 256 , 256 , 1024 ], block = '4p' ) self . res4q = _Bottleneck ([ 256 , 256 , 1024 ], block = '4q' ) self . res4r = _Bottleneck ([ 256 , 256 , 1024 ], block = '4r' ) self . res4s = _Bottleneck ([ 256 , 256 , 1024 ], block = '4s' ) self . res4t = _Bottleneck ([ 256 , 256 , 1024 ], block = '4t' ) self . res4u = _Bottleneck ([ 256 , 256 , 1024 ], block = '4u' ) self . res4v = _Bottleneck ([ 256 , 256 , 1024 ], block = '4v' ) self . res4w = _Bottleneck ([ 256 , 256 , 1024 ], block = '4w' ) # \u7b2c\u56db\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u9996\u4e2a\u8fdb\u884c\u4e0b\u91c7\u6837 self . res5a = _Bottleneck ([ 512 , 512 , 2048 ], block = '5a' , downsampling = True , stride = 2 ) self . res5b = _Bottleneck ([ 512 , 512 , 2048 ], block = '5b' ) self . res5c = _Bottleneck ([ 512 , 512 , 2048 ], block = '5c' ) # \u8f93\u51fa\u901a\u9053\u6570\uff1aC2,C3,C4,C5\u7684\u8f93\u51fa\u901a\u9053\u6570 self . out_channel = ( 256 , 512 , 1024 , 2048 ) def call ( self , inputs , training = True ): \"\u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0c\u6bcf\u7ec4\u74f6\u9888\u6a21\u5757\u5747\u8f93\u51fa\u7ed3\u679c\" x = self . padding ( inputs ) x = self . conv1 ( x ) x = self . bn_conv1 ( x , training = training ) x = tf . nn . relu ( x ) x = self . max_pool ( x ) # \u7b2c1\u7ec4\u74f6\u9888\u6a21\u5757\uff1a\u8f93\u51fac2 x = self . res2a ( x , training = training ) x = self . res2b ( x , training = training ) C2 = x = self . res2c ( x , training = training ) # \u7b2c2\u7ec4\u74f6\u9888\u6a21\u5757:\u8f93\u51fac3 x = self . res3a ( x , training = training ) x = self . res3b ( x , training = training ) x = self . res3c ( x , training = training ) C3 = x = self . res3d ( x , training = training ) # \u7b2c3\u7ec4\u74f6\u9888\u6a21\u5757:\u8f93\u51fac4 x = self . res4a ( x , training = training ) x = self . res4b ( x , training = training ) x = self . res4c ( x , training = training ) x = self . res4d ( x , training = training ) x = self . res4e ( x , training = training ) x = self . res4f ( x , training = training ) if self . depth == 101 : x = self . res4g ( x , training = training ) x = self . res4h ( x , training = training ) x = self . res4i ( x , training = training ) x = self . res4j ( x , training = training ) x = self . res4k ( x , training = training ) x = self . res4l ( x , training = training ) x = self . res4m ( x , training = training ) x = self . res4n ( x , training = training ) x = self . res4o ( x , training = training ) x = self . res4p ( x , training = training ) x = self . res4q ( x , training = training ) x = self . res4r ( x , training = training ) x = self . res4s ( x , training = training ) x = self . res4t ( x , training = training ) x = self . res4u ( x , training = training ) x = self . res4v ( x , training = training ) x = self . res4w ( x , training = training ) C4 = x # \u7b2c4\u7ec4\u74f6\u9888\u6a21\u5757:\u8f93\u51fac5 x = self . res5a ( x , training = training ) x = self . res5b ( x , training = training ) C5 = x = self . res5c ( x , training = training ) # \u8fd4\u56de\u6240\u6709\u7684\u8f93\u51fa\u9001\u5165\u5230fpn\u4e2d return ( C2 , C3 , C4 , C5 )","title":"2. resnet"},{"location":"objectdection/02.RCNN/#412-fpn","text":"FPN\u7684\u4f5c\u7528\u662f\u5f53\u524d\u5c42\u7684feature map\u4f1a\u5bf9\u672a\u6765\u5c42\u7684feature map\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684feature map\u5c31\u53ef\u4ee5\u83b7\u5f97\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u8fd9\u6837\u7684\u8bdd\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u67b6\u6784\u4e2d\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6e90\u7801\u4f4d\u7f6e\uff1afasterRCNN/detection/models/necks/fpn.py class FPN ( tf . keras . Model ): def __init__ ( self , out_channels = 256 , ** kwargs ): ''' \u6784\u5efaFPN\u6a21\u5757\uff1a out_channels:\u662f\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570 ''' super ( FPN , self ) . __init__ ( ** kwargs ) # \u8f93\u51fa\u901a\u9053\u6570 self . out_channels = out_channels # \u4f7f\u75281*1\u5377\u79ef\u5bf9\u6bcf\u4e2a\u8f93\u5165\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u901a\u9053\u6570\u8c03\u6574 self . fpn_c2p2 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c2p2' ) self . fpn_c3p3 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c3p3' ) self . fpn_c4p4 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c4p4' ) self . fpn_c5p5 = layers . Conv2D ( out_channels , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'fpn_c5p5' ) # \u5bf9\u6df1\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u4f7f\u5176\u4e0e\u524d\u4e00\u5c42\u7684\u5927\u5c0f\u76f8\u540c self . fpn_p3upsampled = layers . UpSampling2D ( size = ( 2 , 2 ), name = 'fpn_p3upsampled' ) self . fpn_p4upsampled = layers . UpSampling2D ( size = ( 2 , 2 ), name = 'fpn_p4upsampled' ) self . fpn_p5upsampled = layers . UpSampling2D ( size = ( 2 , 2 ), name = 'fpn_p5upsampled' ) # 3*3\u5377\u79ef\uff0c\u4f5c\u7528\u4e8e\u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u4e2d\u5f97\u5230\u6700\u7ec8\u7684\u7ed3\u679c self . fpn_p2 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p2' ) self . fpn_p3 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p3' ) self . fpn_p4 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p4' ) self . fpn_p5 = layers . Conv2D ( out_channels , ( 3 , 3 ), padding = 'SAME' , kernel_initializer = 'he_normal' , name = 'fpn_p5' ) # \u5bf9\u4e0a\u4e00\u5c42\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0b\u91c7\u6837\u5f97\u5230\u7ed3\u679c self . fpn_p6 = layers . MaxPooling2D ( pool_size = ( 1 , 1 ), strides = 2 , name = 'fpn_p6' ) def call ( self , inputs , training = True ): # \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b # \u83b7\u53d6\u4eceresnet\u4e2d\u5f97\u5230\u76844\u4e2a\u7279\u5f81\u56fe C2 , C3 , C4 , C5 = inputs # \u5bf9\u8fd9\u4e9b\u7279\u5f81\u56fe\u8fdb\u884c1*1\u5377\u79ef\u548c\u4e0a\u91c7\u6837\u540e\u8fdb\u884c\u878d\u5408 P5 = self . fpn_c5p5 ( C5 ) P4 = self . fpn_c4p4 ( C4 ) + self . fpn_p5upsampled ( P5 ) P3 = self . fpn_c3p3 ( C3 ) + self . fpn_p4upsampled ( P4 ) P2 = self . fpn_c2p2 ( C2 ) + self . fpn_p3upsampled ( P3 ) # \u5bf9\u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u8fdb\u884c3*3\u5377\u79ef\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ed3\u679c P2 = self . fpn_p2 ( P2 ) P3 = self . fpn_p3 ( P3 ) P4 = self . fpn_p4 ( P4 ) P5 = self . fpn_p5 ( P5 ) # \u5bf9p5\u8fdb\u884c\u4e0b\u91c7\u6837\u5f97\u5230p6\u7279\u5f81\u56fe P6 = self . fpn_p6 ( P5 ) # \u8fd4\u56de\u6700\u7ec8\u7684\u7ed3\u679c return [ P2 , P3 , P4 , P5 , P6 ]","title":"4.1.2 fpn"},{"location":"objectdection/02.RCNN/#42-rpn","text":"\u7ecf\u5178\u7684\u68c0\u6d4b\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u90fd\u975e\u5e38\u8017\u65f6\uff0c\u5982OpenCV adaboost\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3+\u56fe\u50cf\u91d1\u5b57\u5854\u751f\u6210\u68c0\u6d4b\u6846\uff1b\u6216\u5982R-CNN\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u65b9\u6cd5\u751f\u6210\u68c0\u6d4b\u6846\u3002\u800cFaster RCNN\u5219\u629b\u5f03\u4e86\u4f20\u7edf\u7684\u6ed1\u52a8\u7a97\u53e3\u548cSS\u65b9\u6cd5\uff0c\u76f4\u63a5\u4f7f\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u80fd\u6781\u5927\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u3002 RPN\u7f51\u7edc\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u662f\u901a\u8fc7softmax\u5206\u7c7b\u5224\u65adanchor\u4e2d\u662f\u5426\u5305\u542b\u76ee\u6807\uff0c\u53e6\u4e00\u90e8\u5206\u7528\u4e8e\u8ba1\u7b97\u5bf9\u4e8eanchors\u7684\u504f\u79fb\u91cf\uff0c\u4ee5\u83b7\u5f97\u7cbe\u786e\u7684\u5019\u9009\u533a\u57df\u3002\u800c\u6700\u540e\u7684Proposal\u5c42\u5219\u8d1f\u8d23\u7efc\u5408\u542b\u6709\u76ee\u6807\u7684anchors\u548c\u5bf9\u5e94bbox\u56de\u5f52\u504f\u79fb\u91cf\u83b7\u53d6\u5019\u9009\u533a\u57df\uff0c\u540c\u65f6\u5254\u9664\u592a\u5c0f\u548c\u8d85\u51fa\u8fb9\u754c\u7684\u5019\u9009\u533a\u57df\u3002","title":"4.2 RPN\u7f51\u7edc"},{"location":"objectdection/02.RCNN/#421-anchors","text":"anchor\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u8868\u793a \u56fa\u5b9a\u7684\u53c2\u8003\u6846 \uff0c\u9996\u5148\u9884\u8bbe\u4e00\u7ec4\u4e0d\u540c\u5c3a\u5ea6\u4e0d\u540c\u957f\u5bbd\u6bd4\u7684\u56fa\u5b9a\u53c2\u8003\u6846\uff0c\u8986\u76d6\u51e0\u4e4e\u6240\u6709\u4f4d\u7f6e\uff0c \u6bcf\u4e2a\u53c2\u8003\u6846\u8d1f\u8d23\u68c0\u6d4b\u4e0e\u5176\u4ea4\u5e76\u6bd4\u5927\u4e8e\u9608\u503c (\u8bad\u7ec3\u9884\u8bbe\u503c\uff0c\u5e38\u75280.5\u62160.7) \u7684\u76ee\u6807 \uff0canchor\u6280\u672f\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u6362\u4e3a \"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\" \uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97\uff0c\u771f\u6b63\u5b9e\u73b0\u4e86\u53c8\u597d\u53c8\u5feb\u3002 \u5728fasterRCNN\u4e2d\u6846\u51fa\u591a\u5c3a\u5ea6\u3001\u591a\u79cd\u957f\u5bbd\u6bd4\u7684anchors,\u591a\u79cd\u5c3a\u5ea6\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u70b9\u591a\u4e2a\u6846\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8e\u6709 FPN \u7f51\u7edc\uff0c\u6240\u4ee5\u4f1a\u5728\u591a\u4e2a\u7279\u5f81\u56fe\u4e2d\u751f\u6210anchor\uff0c\u5047\u8bbe\u67d0\u4e00\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u4e3ahxw\uff0c\u9996\u5148\u4f1a\u8ba1\u7b97\u8fd9\u4e2a\u7279\u5f81\u76f8\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u4e0b\u91c7\u6837\u500d\u6570 stride\uff1a \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5728\u8fd9\u91cc\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u5bf9\u5e94\u4e00\u4e2a\u5c3a\u5ea6\u7684anchor\u3002 \u6e90\u7801\u4e2danchor\u7684\u751f\u6210\u65b9\u6cd5\uff1afasterRCNN/detection/core/anchor/anchor_generator.py \u4e3b\u8981\u65b9\u6cd5\u662f\uff1a _generate_level_anchors\uff1a\u901a\u8fc7\u5e7f\u64ad\u7684\u65b9\u6cd5\u751f\u6210\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u7684anchorbox _generate_valid_flags\uff1a\u6807\u8bb0\u771f\u5b9e\u56fe\u50cf\u4e2d\u7684anchor generate_pyramid_anchors:\u8c03\u7528\u4e0a\u8ff0\u4e24\u4e2a\u65b9\u6cd5\u5b8c\u6210\u56fe\u50cf\u7684anchor\u7684\u751f\u6210 class AnchorGenerator : def __init__ ( self , scales = ( 32 , 64 , 128 , 256 , 512 ), ratios = ( 0.5 , 1 , 2 ), feature_strides = ( 4 , 8 , 16 , 32 , 64 )): ''' \u521d\u59cb\u5316anchor ''' # scales: \u751f\u6210\u7684anchor\u7684\u5c3a\u5ea6 self . scales = scales # ratios: anchor\u7684\u957f\u5bbd\u6bd4 self . ratios = ratios # feature_strides: \u56e0\u4e3afpn\u751f\u6210\u4e86\u4e94\u79cd\u7279\u5f81\u56fe\uff0c\u5728\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0a\u79fb\u52a8\u4e00\u4e2a\u4f4d\u7f6e\u76f8\u5f53\u4e8e\u539f\u56fe\u7684\u5927\u5c0f self . feature_strides = feature_strides def generate_pyramid_anchors ( self , img_metas ): ''' \u751f\u6210anchor \u53c2\u6570\uff1a img_metas: [batch_size, 11]\uff0c\u56fe\u50cf\u7684\u4fe1\u606f\uff0c\u5305\u62ec\u539f\u59cb\u56fe\u50cf\u7684\u5927\u5c0f\uff0cresize\u7684\u5927\u5c0f\u548c\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f \u8fd4\u56de\uff1a anchors: [num_anchors, (y1, x1, y2, x2)] anchor\u7684\u5750\u6807\uff0c\u5728\u539f\u56fe\u50cf\u4e2d\u7684\u5750\u6807 valid_flags: [batch_size, num_anchors] \u662f\u5426\u4e3a\u7a7a\u7684\u6807\u5fd7 ''' # \u83b7\u53d6\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\u56fe\u50cf\u7684\u5927\u5c0f\uff1a[1216, 1216] pad_shape = calc_batch_padded_shape ( img_metas ) # \u83b7\u53d6\u56fe\u50cf\u7684\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff1a[(304, 304), (152, 152), (76, 76), (38, 38), (19, 19)] feature_shapes = [( pad_shape [ 0 ] // stride , pad_shape [ 1 ] // stride ) for stride in self . feature_strides ] # \u751f\u6210\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0aanchor\u7684\u4f4d\u7f6e\u4fe1\u606f\uff1a [277248, 4], [69312, 4], [17328, 4], [4332, 4], [1083, 4] anchors = [ self . _generate_level_anchors ( level , feature_shape ) for level , feature_shape in enumerate ( feature_shapes ) ] # \u5c06\u6240\u6709\u7684anchor\u4e32\u8054\u5728\u4e00\u4e2a\u5217\u8868\u4e2d\uff1a[369303, 4] anchors = tf . concat ( anchors , axis = 0 ) # \u83b7\u53d6\u56fe\u50cf\u975e0\u4f4d\u7f6e\u7684\u5927\u5c0f\uff1a(800, 1067) img_shapes = calc_img_shapes ( img_metas ) # \u83b7\u53d6anchor\u7684\u975e\u96f6\u6807\u8bc6 valid_flags = [ self . _generate_valid_flags ( anchors , img_shapes [ i ]) for i in range ( img_shapes . shape [ 0 ]) ] # \u5806\u53e0\u4e3a\u4e00\u4e2a\u4e00\u7ef4\u5411\u91cf valid_flags = tf . stack ( valid_flags , axis = 0 ) # \u505c\u6b62\u68af\u5ea6\u8ba1\u7b97 anchors = tf . stop_gradient ( anchors ) valid_flags = tf . stop_gradient ( valid_flags ) # \u8fd4\u56deanchor\u548c\u5bf9\u5e94\u975e\u96f6\u6807\u5fd7 return anchors , valid_flags def _generate_valid_flags ( self , anchors , img_shape ): ''' \u79fb\u9664padding\u4f4d\u7f6e\u7684anchor \u53c2\u6570\uff1a anchors: [num_anchors, (y1, x1, y2, x2)] \u6240\u6709\u7684anchor img_shape: Tuple. (height, width, channels) \u975e0\u50cf\u7d20\u70b9\u7684\u56fe\u50cf\u7684\u5927\u5c0f \u8fd4\u56de\uff1a valid_flags: [num_anchors] \u8fd4\u56de\u975e0\u4f4d\u7f6e\u7684anchor ''' # \u8ba1\u7b97\u6240\u6709anchor\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\uff1a[369300] y_center = ( anchors [:, 2 ] + anchors [:, 0 ]) / 2 x_center = ( anchors [:, 3 ] + anchors [:, 1 ]) / 2 # \u521d\u59cb\u5316flags\u4e3a\u51681\u6570\u7ec4\uff1a[369300] valid_flags = tf . ones ( anchors . shape [ 0 ], dtype = tf . int32 ) # \u521d\u59cb\u5316\u76f8\u540c\u5927\u5c0f\u7684\u51680\u6570\u7ec4 zeros = tf . zeros ( anchors . shape [ 0 ], dtype = tf . int32 ) # \u5c06anchor\u4e2d\u5fc3\u70b9\u5728\u975e0\u533a\u57df\u7684\u7f6e\u4e3a1\uff0c\u5176\u4ed6\u7f6e\u4e3a0 valid_flags = tf . where ( y_center <= img_shape [ 0 ], valid_flags , zeros ) valid_flags = tf . where ( x_center <= img_shape [ 1 ], valid_flags , zeros ) # \u8fd4\u56de\u6807\u5fd7\u7ed3\u679c return valid_flags def _generate_level_anchors ( self , level , feature_shape ): '''\u751f\u6210fpn\u8f93\u51fa\u7684\u67d0\u4e00\u4e2a\u7279\u5f81\u56fe\u7684anchor \u53c2\u6570\uff1a feature_shape: (height, width) \u7279\u5f81\u56fe\u5927\u5c0f \u8fd4\u56de\uff1a numpy.ndarray [anchors_num, (y1, x1, y2, x2)]\uff1a\u751f\u6210\u7684anchor\u7ed3\u679c ''' # \u83b7\u53d6\u5bf9\u5e94\u7684\u5c3a\u5ea6 scale = self . scales [ level ] # \u83b7\u53d6\u957f\u5bbd\u6bd4 ratios = self . ratios # \u83b7\u53d6\u5bf9\u5e94\u6b65\u957f feature_stride = self . feature_strides [ level ] # \u83b7\u53d6\u4e0d\u540c\u957f\u5bbd\u6bd4\u4e0b\u7684scale scales , ratios = tf . meshgrid ([ float ( scale )], ratios ) # \u5c3a\u5ea6 [32, 32, 32] scales = tf . reshape ( scales , [ - 1 ]) # \u957f\u5bbd\u6bd4 [0.5, 1, 2] ratios = tf . reshape ( ratios , [ - 1 ]) # \u83b7\u53d6\u4e0d\u540c\u5bbd\u9ad8\u6bd4\u60c5\u51b5\u4e0b\u7684H\u548cw # [45, 32, 22] heights = scales / tf . sqrt ( ratios ) # [22, 32, 45] widths = scales * tf . sqrt ( ratios ) # \u83b7\u53d6\u751f\u6210anchor\u5bf9\u5e94\u7684\u4f4d\u7f6e,\u5047\u8bbe\u6b65\u957f\u4e3a4\u65f6\u7684\u7ed3\u679c\uff1a [0, 4, ..., 1216-4] shifts_y = tf . multiply ( tf . range ( feature_shape [ 0 ]), feature_stride ) shifts_x = tf . multiply ( tf . range ( feature_shape [ 1 ]), feature_stride ) # \u7c7b\u578b\u8f6c\u6362 shifts_x , shifts_y = tf . cast ( shifts_x , tf . float32 ), tf . cast ( shifts_y , tf . float32 ) # \u83b7\u53d6\u5728\u56fe\u50cf\u4e2d\u751f\u6210anchor\u7684\u4f4d\u7f6e shifts_x , shifts_y = tf . meshgrid ( shifts_x , shifts_y ) # \u5c06\u5bbd\u9ad8\u5206\u522b\u76f8\u5bf9\u4e8ex,y\u8fdb\u884c\u5e7f\u64ad\uff0c \u5f97\u5230\u5bbd\u9ad8\u548c\u4e2d\u5fc3\u70b9\u5750\u6807 box_widths , box_centers_x = tf . meshgrid ( widths , shifts_x ) box_heights , box_centers_y = tf . meshgrid ( heights , shifts_y ) # \u8fdb\u884creshape\u5f97\u5230anchor\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8 box_centers = tf . reshape ( tf . stack ([ box_centers_y , box_centers_x ], axis = 2 ), ( - 1 , 2 )) box_sizes = tf . reshape ( tf . stack ([ box_heights , box_widths ], axis = 2 ), ( - 1 , 2 )) # \u62fc\u63a5\u6210\u4e00\u7ef4\u5411\u91cf\uff0c\u5e76\u4ee5\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u7684\u5f62\u5f0f\u8868\u793a [304x304, 3, 4] => [277448, 4] boxes = tf . concat ([ box_centers - 0.5 * box_sizes , box_centers + 0.5 * box_sizes ], axis = 1 ) # \u8fd4\u56de\u6700\u7ec8\u7684anchorbox return boxes \u90a3\u8fd9\u4e9banchors\u662f\u5982\u4f55\u4f7f\u7528\u7684\u5462\uff1f\u5bf9\u4e8eConv layers\u7279\u5f81\u63d0\u53d6\u5f97\u5230\u7684feature maps\uff0c\u4e3a\u6bcf\u4e00\u4e2a\u70b9\u90fd\u5206\u914d\u8fd9k\u4e2aanchors\u4f5c\u4e3a\u521d\u59cb\u7684\u53c2\u8003\u6846\uff0c\u9001\u5165\u5230softmax\u548c\u5168\u8fde\u63a5\u5c42\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u8fc7\u7a0b\uff0c\u5224\u65adanchor\u4e2d\u662f\u5426\u5305\u542b\u76ee\u6807\uff0c\u5e76\u5bf9anchors\u8fdb\u884c\u4fee\u6b63\u3002","title":"4.2.1 anchors"},{"location":"objectdection/02.RCNN/#422-rpn","text":"\u4e00\u526fMxN\u5927\u5c0f\u7684\u77e9\u9635\u9001\u5165Faster RCNN\u7f51\u7edc\u540e\uff0c\u7ecf\u8fc7backbone\u7279\u5f81\u63d0\u53d6\u5230RPN\u7f51\u7edc\u53d8\u4e3aHxW\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u662fRPN\u8fdb\u884c\u5206\u7c7b\u7684\u7f51\u7edc\u7ed3\u6784\uff1a(k=9) \u5148\u505a\u4e00\u4e2a1x1\u7684\u5377\u79ef\uff0c\u5f97\u5230[batchsize,H,W,18]\u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u8fdb\u884creshape,\u5c06\u7279\u5f81\u56fe\u8f6c\u6362\u4e3a[batchsize,9xH,W,2]\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165softmax\u4e2d\u8fdb\u884c\u5206\u7c7b\uff0c\u5f97\u5230\u5206\u7c7b\u7ed3\u679c\u540e\uff0c\u518d\u8fdb\u884creshape\u6700\u7ec8\u5f97\u5230[batchsize,H,W,18]\u5927\u5c0f\u7684\u7ed3\u679c,18\u8868\u793ak=9\u4e2aanchor\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6982\u7387\u503c\u3002","title":"4.2.2 RPN\u5206\u7c7b"},{"location":"objectdection/02.RCNN/#423-rpn","text":"RPN\u56de\u5f52\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a(k=9) \u7ecf\u8fc7\u8be5\u5377\u79ef\u8f93\u51fa\u7279\u5f81\u56fe\u4e3a\u4e3a[1, H, W,4x9]\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8efeature maps\u6bcf\u4e2a\u70b9\u90fd\u67099\u4e2aanchors\uff0c\u6bcf\u4e2aanchors\u53c8\u90fd\u67094\u4e2a\u7528\u4e8e\u56de\u5f52\u7684: \u53d8\u6362\u91cf\u3002 \u8be5\u53d8\u6362\u91cf\u9884\u6d4b\u7684\u662fanchor\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5e73\u79fb\u91cf\u548c\u5c3a\u5ea6\u56e0\u5b50\uff1a \u5750\u6807\u53d8\u6362\u7684\u6e90\u7801\u4e3a\uff1afasterRCNN/detection/core/bbox/transforms.py def bbox2delta ( box , gt_box , target_means , target_stds ): '''\u8ba1\u7b97box\u5230gtbox\u7684\u4fee\u6b63\u503c. \u53c2\u6570 box: [..., (y1, x1, y2, x2)] : \u8981\u4fee\u6b63\u7684box gt_box: [..., (y1, x1, y2, x2)] : GT\u503c target_means: [4] :\u5747\u503c target_stds: [4]:\u65b9\u5dee ''' # \u8f6c\u5316\u4e3atensor target_means = tf . constant ( target_means , dtype = tf . float32 ) target_stds = tf . constant ( target_stds , dtype = tf . float32 ) # \u7c7b\u578b\u8f6c\u6362 box = tf . cast ( box , tf . float32 ) gt_box = tf . cast ( gt_box , tf . float32 ) # \u83b7\u53d6box\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8 height = box [ ... , 2 ] - box [ ... , 0 ] width = box [ ... , 3 ] - box [ ... , 1 ] center_y = box [ ... , 0 ] + 0.5 * height center_x = box [ ... , 1 ] + 0.5 * width # \u83b7\u53d6Gtbox\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8 gt_height = gt_box [ ... , 2 ] - gt_box [ ... , 0 ] gt_width = gt_box [ ... , 3 ] - gt_box [ ... , 1 ] gt_center_y = gt_box [ ... , 0 ] + 0.5 * gt_height gt_center_x = gt_box [ ... , 1 ] + 0.5 * gt_width # \u8ba1\u7b97\u4e24\u8005\u4e4b\u95f4\u7684\u5e73\u79fb\u503c\u548c\u5c3a\u5ea6\u53d8\u6362 dy = ( gt_center_y - center_y ) / height dx = ( gt_center_x - center_x ) / width dh = tf . math . log ( gt_height / height ) dw = tf . math . log ( gt_width / width ) # \u7ec4\u6210\u4e00\u7ef4\u5411\u91cf delta = tf . stack ([ dy , dx , dh , dw ], axis =- 1 ) # \u6807\u51c6\u5316 delta = ( delta - target_means ) / target_stds # \u8fd4\u56de\u7ed3\u679c return delta RPN\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7684\u6e90\u7801\u5982\u4e0b\uff1afasterRCNN/detection/models/rpn_heads/rpn_head.py class RPNHead ( tf . keras . Model ): \"\"\" \u5b8c\u6210RPN\u7f51\u7edc\u4e2d\u7684\u76f8\u5173\u64cd\u4f5c \"\"\" def __init__ ( self , anchor_scales = ( 32 , 64 , 128 , 256 , 512 ), anchor_ratios = ( 0.5 , 1 , 2 ), anchor_feature_strides = ( 4 , 8 , 16 , 32 , 64 ), proposal_count = 2000 , nms_threshold = 0.7 , target_means = ( 0. , 0. , 0. , 0. ), target_stds = ( 0.1 , 0.1 , 0.2 , 0.2 ), num_rpn_deltas = 256 , positive_fraction = 0.5 , pos_iou_thr = 0.7 , neg_iou_thr = 0.3 , ** kwags ): ''' RPN\u7f51\u7edc\u7ed3\u6784\uff0c\u5982\u4e0b\u6240\u793a\uff1a / - rpn_cls \u5206\u7c7b(1x1 conv) \u8f93\u5165 - rpn_conv \u5377\u79ef(3x3 conv) - \\ - rpn_reg \u56de\u5f52(1x1 conv) \u53c2\u6570 anchor_scales: anchorbox\u7684\u9762\u79ef\uff0c\u76f8\u5bf9\u4e8e\u539f\u56fe\u50cf\u50cf\u7d20\u7684 anchor_ratios: anchorbox\u7684\u957f\u5bbd\u6bd4 anchor_feature_strides: \u751f\u6210anchor\u7684\u6b65\u957f\uff0c\u76f8\u5bf9\u4e8e\u539f\u56fe\u50cf\u7d20\u7684 proposal_count:RPN\u6700\u540e\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u7684\u4e2a\u6570\uff0c\u7ecf\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236 nms_threshold: \u5bf9RPN\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u8fdb\u884cNMS\u7684\u53c2\u6570\u9608\u503c target_means: [4] Bounding box refinement mean. target_stds: [4] Bounding box refinement standard deviation. num_rpn_deltas: int. positive_fraction: float. pos_iou_thr: \u4e0eGT\u7684IOU\u5927\u4e8e\u8be5\u503c\u7684anchor\u4e3a\u6b63\u4f8b neg_iou_thr: \u4e0eGT\u7684IOU\u5c0f\u4e8e\u8be5\u503c\u7684anchor\u4e3a\u8d1f\u4f8b ''' super ( RPNHead , self ) . __init__ ( ** kwags ) # \u53c2\u6570\u521d\u59cb\u5316 # RPN\u6700\u540e\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u7684\u4e2a\u6570\uff0c\u7ecf\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236 self . proposal_count = proposal_count # \u5bf9RPN\u751f\u6210\u7684\u5019\u9009\u533a\u57df\u8fdb\u884cNMS\u7684\u53c2\u6570\u9608\u503c self . nms_threshold = nms_threshold self . target_means = target_means self . target_stds = target_stds # \u8c03\u7528anchor\u751f\u6210\u5668\u751f\u6210\u5bf9\u5e94\u7684anchor self . generator = anchor_generator . AnchorGenerator ( scales = anchor_scales , ratios = anchor_ratios , feature_strides = anchor_feature_strides ) # \u5c06anchor\u5212\u5206\u4e3a\u6b63\u8d1f\u6837\u672c self . anchor_target = anchor_target . AnchorTarget ( target_means = target_means , target_stds = target_stds , num_rpn_deltas = num_rpn_deltas , positive_fraction = positive_fraction , pos_iou_thr = pos_iou_thr , neg_iou_thr = neg_iou_thr ) # \u8bbe\u7f6eRPN\u7f51\u7edc\u7684\u5206\u7c7b\u548c\u56de\u5f52\u635f\u5931 self . rpn_class_loss = losses . rpn_class_loss self . rpn_bbox_loss = losses . rpn_bbox_loss # 3*3\u5377\u79ef self . rpn_conv_shared = layers . Conv2D ( 512 , ( 3 , 3 ), padding = 'same' , kernel_initializer = 'he_normal' , name = 'rpn_conv_shared' ) # 1*1\u5377\u79ef \u5206\u7c7b \u6bcf\u4e00\u4e2aanchor\u5206\u4e3a2\u7c7b self . rpn_class_raw = layers . Conv2D ( len ( anchor_ratios ) * 2 , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'rpn_class_raw' ) # 1*1\u5377\u79ef \u56de\u5f52 \u6bcf\u4e00\u4e2aanchor\u7684\u56de\u5f52\u7ed3\u679c self . rpn_delta_pred = layers . Conv2D ( len ( anchor_ratios ) * 4 , ( 1 , 1 ), kernel_initializer = 'he_normal' , name = 'rpn_bbox_pred' ) def call ( self , inputs , training = True ): ''' \u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b \u53c2\u6570\uff1a inputs: [batch_size, feat_map_height, feat_map_width, channels] FPN\u8f93\u51fa\u7684\u4e00\u4e2a\u7279\u5f81\u56fe \u8fd4\u56de\uff1a rpn_class_logits: [batch_size, num_anchors, 2] \u5206\u7c7b\u7ed3\u679c\uff0c\u4ee5logits\u8868\u793a rpn_probs: [batch_size, num_anchors, 2] \u5206\u7c7b\u7ed3\u679c\uff0c\u7ecfsoftmax\u4e4b\u540e\u7684\u6982\u7387\u8868\u793a\u5f62\u5f0f rpn_deltas: [batch_size, num_anchors, 4] \u56de\u5f52\u7ed3\u679c\uff0canchor\u7684\u4f4d\u7f6e\u4fe1\u606f ''' # \u8f93\u51fa\u7ed3\u679c layer_outputs = [] # \u904d\u5386\u8f93\u5165\u4e2d\u7684\u6bcf\u4e00\u7279\u5f81\u56fe for feat in inputs : # 3*3 \u5377\u79ef\uff0c\u5047\u8bbe\u7279\u5f81\u56fe\u5927\u5c0f\u4e3a\uff1a(1, 304, 304, 256) shared = self . rpn_conv_shared ( feat ) # \u6fc0\u6d3b\uff1a(1, 304, 304, 256) shared = tf . nn . relu ( shared ) # \u5206\u7c7b\u8fc7\u7a0b # 1*1\u5377\u79ef\uff1a\u8f93\u51fa\u5927\u5c0f\u4e3a(1, 304, 304, 6) x = self . rpn_class_raw ( shared ) # reshape:(1, 277248, 2) rpn_class_logits = tf . reshape ( x , [ tf . shape ( x )[ 0 ], - 1 , 2 ]) # softmax\u8fdb\u884c\u5206\u7c7b\uff1a(1, 277248, 2)\uff0c\u4e00\u5171\u6709277248\u4e2aanchor\uff0c\u6bcf\u4e2aanchor\u67092\u4e2a\u5206\u7c7b\u7ed3\u679c rpn_probs = tf . nn . softmax ( rpn_class_logits ) # \u56de\u5f52\u8fc7\u7a0b # 1*1 \u5377\u79ef\uff0c\u8f93\u51fa\u5927\u5c0f\u4e3a(1, 304, 304, 12) x = self . rpn_delta_pred ( shared ) # reshape:(1, 277248, 4),\u4e00\u5171\u6709277248\u4e2aanchor\uff0c\u6bcf\u4e2aanchor\u67094\u4e2a\u4f4d\u7f6e\u4fe1\u606f rpn_deltas = tf . reshape ( x , [ tf . shape ( x )[ 0 ], - 1 , 4 ]) # \u5c06\u7f51\u7edc\u7684\u5206\u7c7b\u548c\u8f93\u51fa\u7ed3\u679c\u5b58\u653e\u5728layer_outputs layer_outputs . append ([ rpn_class_logits , rpn_probs , rpn_deltas ]) # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u8f93\u51fa\u7ed3\u679c\u7684\u5927\u5c0f\u4e3a\uff1a \"\"\" (1, 277248, 2) (1, 277248, 2) (1, 277248, 4) (1, 69312, 2) (1, 69312, 2) (1, 69312, 4) (1, 17328, 2) (1, 17328, 2) (1, 17328, 4) (1, 4332, 2) (1, 4332, 2) (1, 4332, 4) (1, 1083, 2) (1, 1083, 2) (1, 1083, 4) \"\"\" # \u5c06\u8f93\u51fa\u7ed3\u679c\u8f6c\u6362\u4e3a\u5217\u8868 outputs = list ( zip ( * layer_outputs )) # \u904d\u5386\u8f93\u51fa\uff0c\u5c06\u4e0d\u540c\u7279\u5f81\u56fe\u4e2d\u540c\u4e00\u7c7b\u522b\u7684\u8f93\u51fa\u7ed3\u679c\u4e32\u8054\u5728\u4e00\u8d77 outputs = [ tf . concat ( list ( o ), axis = 1 ) for o in outputs ] # \u83b7\u53d6\u6bcf\u4e00\u79cd\u8f93\u51fa\uff1a5\u4e2a\u7279\u5f81\u56fe\u7684\u8f93\u51fa\u5927\u5c0f\u4e3a\uff1a(1, 369303, 2) (1, 369303, 2) (1, 369303, 4) rpn_class_logits , rpn_probs , rpn_deltas = outputs # \u8fd4\u56de\u8f93\u51fa\u7ed3\u679c return rpn_class_logits , rpn_probs , rpn_deltas","title":"4.2.3 RPN\u56de\u5f52"},{"location":"objectdection/02.RCNN/#424-proposal-layer","text":"Proposal Layer\u8d1f\u8d23\u7efc\u5408\u6240\u6709 \u53d8\u6362\u91cf\u548c\u5305\u542b\u76ee\u6807\u7684anchors\uff0c\u8ba1\u7b97\u51fa\u5019\u9009\u533a\u57dfproposal\uff0c\u9001\u5165\u540e\u7eedRoI Pooling Layer\u3002 Proposal Layer\u67093\u4e2a\u8f93\u5165\uff1aanchors\u5206\u7c7b\u5668\u7ed3\u679c\uff0c\u5bf9\u5e94\u7684bbox reg\u7684 \u53d8\u6362\u91cf\uff0c\u4ee5\u53caim_info\uff1b\u53e6\u5916\u8fd8\u6709\u53c2\u6570feat_stride\uff0c\u7528\u4e8e\u8ba1\u7b97anchor\u7684\u6b65\u957f\u3002 Proposal Layer \u5b8c\u6210\u4ee5\u4e0b\u5904\u7406\uff1a \u751f\u6210anchors\uff0c\u5229\u7528 \u5bf9\u6240\u6709\u7684anchors\u505abbox regression\u56de\u5f52 \u6309\u7167\u8f93\u5165\u7684positive softmax scores\u7531\u5927\u5230\u5c0f\u6392\u5e8fanchors\uff0c\u63d0\u53d6\u524dpre_nms_topN(e.g. 6000)\u4e2aanchors\uff0c\u5373\u63d0\u53d6\u4fee\u6b63\u4f4d\u7f6e\u540e\u7684positive anchors \u9650\u5b9a\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u7684positive anchors\u4e3a\u56fe\u50cf\u8fb9\u754c\uff0c\u9632\u6b62\u540e\u7eedroi pooling\u65f6proposal\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u3002 \u5254\u9664\u5c3a\u5bf8\u975e\u5e38\u5c0f\u7684positive anchors \u5bf9\u5269\u4f59\u7684positive anchors\u8fdb\u884cNMS\uff08nonmaximum suppression\uff09 Proposal Layer\u7684\u8f93\u51fa\u662f\u5bf9\u5e94MxN\u8f93\u5165\u56fe\u50cf\u5c3a\u5ea6\u7684\u5750\u6807\u503c[x1, y1, x2, y2]\u3002 \u5230\u6b64RPN\u7f51\u7edc\u7684\u5de5\u4f5c\u5c31\u7ed3\u675f\u4e86\u3002 \u8be5\u90e8\u5206\u7684\u6e90\u7801\u5728\uff1afasterRCNN/detection/models/rpn_heads/rpn_head.py def _get_proposals_single ( self , rpn_probs , rpn_deltas , anchors , valid_flags , img_shape , with_probs ): ''' \u8ba1\u7b97\u5019\u9009\u533a\u57df\u7ed3\u679c \u53c2\u6570\uff1a rpn_probs: [num_anchors] anchor\u662f\u76ee\u6807\u7684\u6982\u7387\u503c rpn_deltas: [num_anchors, (dy, dx, log(dh), log(dw))] \u56de\u5f52\u5f97\u5230\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5bf9anchor\u8fdb\u884c\u4fee\u6b63 anchors: [num_anchors, (y1, x1, y2, x2)] anchor\u7684\u4f4d\u7f6e valid_flags: [num_anchors] anchor\u5c5e\u4e8e\u56fe\u50cf\u4f4d\u7f6e\u7684\u6807\u8bb0\u4fe1\u606f img_shape: np.ndarray. [2]. (img_height, img_width) \u56fe\u50cf\u7684\u5927\u5c0f with_probs: bool. \u662f\u5426\u8f93\u51fa\u5206\u7c7b\u7ed3\u679c \u8fd4\u56de proposals: \u8fd4\u56de\u5019\u9009\u533a\u57df\u7684\u5217\u8868 \u82e5with_probs = False\uff0c\u5219\u8fd4\u56de\uff1a[num_proposals, (y1, x1, y2, x2)] \u82e5with_probs = True\uff0c\u5219\u8fd4\u56de\uff1a[num_proposals, (y1, x1, y2, x2, score)] \u5728\u8fd9\u91ccnum_proposals\u4e0d\u4f1a\u5927\u4e8eproposal_count ''' # \u56fe\u50cf\u7684\u9ad8\u5bbd H , W = img_shape # \u5c06anchor\u7684\u6807\u8bb0\u4fe1\u606f\u8f6c\u6362\u4e3a\u5e03\u5c14\u578b, int => bool valid_flags = tf . cast ( valid_flags , tf . bool ) # \u5c06\u65e0\u7528\u7684anchor\u8fc7\u6ee4 \uff0c\u5e76\u5bf9\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\u8fdb\u884c\u5904\u7406[369303] => [215169], respectively rpn_probs = tf . boolean_mask ( rpn_probs , valid_flags ) rpn_deltas = tf . boolean_mask ( rpn_deltas , valid_flags ) anchors = tf . boolean_mask ( anchors , valid_flags ) # \u81f3\u591a6000\u4e2a\u7ed3\u679c\u4f1a\u8fdb\u884c\u540e\u7eed\u64cd\u4f5c min(6000, 215169) => 6000 pre_nms_limit = min ( 6000 , anchors . shape [ 0 ]) # \u83b7\u53d6\u81f3\u591a6000\u4e2a\u5206\u7c7b\u6982\u7387\u6700\u9ad8\u7684anchor\u7684\u7d22\u5f15 ix = tf . nn . top_k ( rpn_probs , pre_nms_limit , sorted = True ) . indices # \u6839\u636e\u5f97\u5230\u7684\u7d22\u5f15\u503c\u83b7\u53d6\u5bf9\u5e94\u7684\u5206\u7c7b\uff0c\u56de\u5f52\u548canchor [215169] => [6000] rpn_probs = tf . gather ( rpn_probs , ix ) rpn_deltas = tf . gather ( rpn_deltas , ix ) anchors = tf . gather ( anchors , ix ) # \u5229\u7528\u56de\u5f52\u5f97\u5230\u7684\u7ed3\u679c\u5bf9anchor\u8fdb\u884c\u4fee\u6b63, [6000, 4] proposals = transforms . delta2bbox ( anchors , rpn_deltas , self . target_means , self . target_stds ) # \u82e5\u4fee\u6b63\u540e\u7684\u7ed3\u679c\u8d85\u51fa\u56fe\u50cf\u8303\u56f4\u5219\u8fdb\u884c\u88c1\u526a, [6000, 4] window = tf . constant ([ 0. , 0. , H , W ], dtype = tf . float32 ) proposals = transforms . bbox_clip ( proposals , window ) # \u5bf9\u5750\u6807\u503c\u8fdb\u884c\u5f52\u4e00\u5316, (y1, x1, y2, x2) proposals = proposals / tf . constant ([ H , W , H , W ], dtype = tf . float32 ) # \u8fdb\u884cNMS\uff0c\u83b7\u53d6\u6700\u7ec8\u5927\u69822000\u4e2a\u5019\u9009\u533a\u57df: [2000] indices = tf . image . non_max_suppression ( proposals , rpn_probs , self . proposal_count , self . nms_threshold ) proposals = tf . gather ( proposals , indices ) # [2000, 4] # \u82e5\u8981\u8fd4\u56de\u5206\u7c7b\u7ed3\u679c\uff0c\u5219\u83b7\u53d6\u5bf9\u5e94\u7684\u5206\u7c7b\u503c\u8fdb\u884c\u8fd4\u56de if with_probs : proposal_probs = tf . expand_dims ( tf . gather ( rpn_probs , indices ), axis = 1 ) proposals = tf . concat ([ proposals , proposal_probs ], axis = 1 ) # \u8fd4\u56de\u5019\u9009\u533a\u57df return proposals","title":"4.2.4 Proposal Layer"},{"location":"objectdection/02.RCNN/#43-roipooling","text":"RoI Pooling\u5c42\u5219\u8d1f\u8d23\u6536\u96c6proposal\uff0c\u5e76\u8ba1\u7b97\u51fa feature maps\u7684\u5019\u9009\u533a\u57df\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\u3002 \u4ece\u7f51\u7edc\u67b6\u6784\u4e2d\u53ef\u4ee5\u770b\u51faRol pooling\u5c42\u67092\u4e2a\u8f93\u5165\uff1a CNN\u63d0\u53d6\u7684feature maps RPN\u8f93\u51fa\u7684\u5019\u9009\u533a\u57dfproposal boxes\uff08\u5927\u5c0f\u5404\u4e0d\u76f8\u540c\uff09 RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709pool_H\u00d7pool_W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0ffeature map\uff0c\u5176\u4e2dpool_H\u548cpool_W\u662f\u8d85\u53c2\u6570\uff0c\u6bd4\u5982\u8bbe\u7f6e\u4e3a7x7, \u5b83\u4eec\u72ec\u7acb\u4e8e\u4efb\u4f55\u7279\u5b9a\u7684RoI,\u5982\u4e0b\u56fe\u6240\u793a21\u00b7 RoI Pooling \u7684\u4f5c\u7528\u8fc7\u7a0b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8eRPN\u7f51\u7edc\u8f93\u51fa\u7684proposal\u662f\u5bf9\u5e94MxN\u5c3a\u5ea6\u7684\uff0c\u6240\u4ee5\u9996\u5148\u4f7f\u7528spatial_scale\u53c2\u6570\u5c06\u5176\u6620\u5c04\u56de\u7279\u5f81\u63d0\u53d6\u540e\uff08HxW\uff09\u5927\u5c0f\u7684feature map\u5c3a\u5ea6\uff1b \u518d\u5c06\u6bcf\u4e2aproposal\u5bf9\u5e94\u7684feature map\u533a\u57df\u6c34\u5e73\u5206\u4e3a \u7684\u7f51\u683c\uff1b \u5bf9\u7f51\u683c\u7684\u6bcf\u4e00\u4efd\u90fd\u8fdb\u884cmax pooling\u5904\u7406\u3002 \u8fd9\u6837\u5904\u7406\u540e\uff0c\u5373\u4f7f\u5927\u5c0f\u4e0d\u540c\u7684proposal\u8f93\u51fa\u7ed3\u679c\u90fd\u662f \u56fa\u5b9a\u5927\u5c0f\uff0c\u5b9e\u73b0\u4e86\u56fa\u5b9a\u957f\u5ea6\u8f93\u51fa,\u9001\u5165\u540e\u7eed\u7f51\u7edc\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0cFPN\u7f51\u7edc\u4ea7\u751f\u4e86\u591a\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\uff0c\u90a3\u5019\u9009\u533a\u57df\u8981\u6620\u5c04\u5230\u54ea\u4e2a\u7279\u5f81\u56fe\u4e2d\u5462\uff1f \u5728\u8fd9\u91cc\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684ROI\u4f7f\u7528\u4e0d\u540c\u7279\u5f81\u5c42\u4f5c\u4e3aROI pooling\u5c42\u7684\u8f93\u5165\uff0c\u5927\u5c3a\u5ea6ROI\u5c31\u7528\u540e\u9762\u4e00\u4e9b\u7684\u91d1\u5b57\u5854\u5c42\uff0c\u6bd4\u5982P5\uff1b\u5c0f\u5c3a\u5ea6ROI\u5c31\u7528\u524d\u9762\u4e00\u70b9\u7684\u7279\u5f81\u5c42\uff0c\u6bd4\u5982P3\uff0c\u6211\u4eec\u4f7f\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u786e\u5b9aROI\u6240\u5728\u7684\u7279\u5f81\u5c42\uff1a \u5176\u4e2d\uff0c224\u662fImageNet\u7684\u6807\u51c6\u8f93\u5165\uff0ck0\u662f\u57fa\u51c6\u503c\uff0c\u8bbe\u7f6e\u4e3a4\uff0cw\u548ch\u662fROI\u533a\u57df\u7684\u957f\u548c\u5bbd\uff0c\u5047\u8bbeROI\u662f112x112\u7684\u5927\u5c0f\uff0c\u90a3\u4e48k = k0-1 = 4-1 = 3\uff0c\u610f\u5473\u7740\u8be5ROI\u5e94\u8be5\u4f7f\u7528P3\u7684\u7279\u5f81\u5c42\u3002k\u503c\u4f1a\u505a\u53d6\u6574\u5904\u7406\uff0c\u9632\u6b62\u7ed3\u679c\u4e0d\u662f\u6574\u6570\uff0c\u800c\u4e14\u4e3a\u4e86\u4fdd\u8bc1k\u503c\u57282-5\u4e4b\u95f4\uff0c\u8fd8\u4f1a\u505a\u622a\u65ad\u5904\u7406\u3002 \u6e90\u7801\u5728:fasterRCNN/detection/models/roi_extractors/roi_align.py class PyramidROIAlign ( tf . keras . layers . Layer ): def __init__ ( self , pool_shape , ** kwargs ): ''' \u5728\u591a\u4e2a\u7279\u5f81\u56fe\u4e0a\u5b8c\u6210ROIPooling \u53c2\u6570\uff1a pool_shape: (height, width)\u6307\u660epooling\u4e4b\u540e\u8f93\u51fa\u7684\u5927\u5c0f ''' super ( PyramidROIAlign , self ) . __init__ ( ** kwargs ) self . pool_shape = tuple ( pool_shape ) def call ( self , inputs , training = True ): # \u83b7\u53d6\u8f93\u5165\u4e2d\u7684roi\u533a\u57df\uff0c\u7279\u5f81\u56fe\u548c\u56fe\u50cf\u7684\u5143\u4fe1\u606f rois_list , feature_map_list , img_metas = inputs # \u83b7\u53d6\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f pad_shapes = calc_pad_shapes ( img_metas ) # \u56fe\u50cf\u7684\u5c3a\u5ea6\uff1a1216*1216 pad_areas = pad_shapes [:, 0 ] * pad_shapes [:, 1 ] # \u83b7\u53d6\u56fe\u50cf\u4e2dROI\u7684\u7c7b\u522bdata:[2000] num_rois_list = [ rois . shape . as_list ()[ 0 ] for rois in rois_list ] # \u83b7\u53d6\u56fe\u50cf\u4e2dROI\u7684\u7d22\u5f15 roi_indices = tf . constant ( [ i for i in range ( len ( rois_list )) for _ in range ( rois_list [ i ] . shape . as_list ()[ 0 ])], dtype = tf . int32 ) #[0.....], shape:[2000] # \u83b7\u53d6\u5bf9\u4e8e\u6bcf\u4e00\u4e2aROI\u7684\u56fe\u50cf\u5927\u5c0f areas = tf . constant ( # range(1) range(2000) [ pad_areas [ i ] for i in range ( pad_areas . shape [ 0 ]) for _ in range ( num_rois_list [ i ])], dtype = tf . float32 ) #[1216*1216, 1216*1216,...], shape:[2000] # ROI rois = tf . concat ( rois_list , axis = 0 ) # [2000, 4] # \u83b7\u53d6\u6bcf\u4e00\u4e2aROI\u5bf9\u5e94\u7684\u5750\u6807\u548c\u5bbd\u9ad8 y1 , x1 , y2 , x2 = tf . split ( rois , 4 , axis = 1 ) # 4 of [2000, 1] h = y2 - y1 # [2000, 1] w = x2 - x1 # [2000, 1] # \u5c06\u6bcf\u4e00\u4e2aROI\u5206\u914d\u5230\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u4e0a roi_level = tf . math . log ( # [2000] tf . sqrt ( tf . squeeze ( h * w , 1 )) / tf . cast (( 224.0 / tf . sqrt ( areas * 1.0 )), tf . float32 ) ) / tf . math . log ( 2.0 ) roi_level = tf . minimum ( 5 , tf . maximum ( # [2000], clamp to [2-5] 2 , 4 + tf . cast ( tf . round ( roi_level ), tf . int32 ))) # roi_level will indicates which level of feature to use # \u904d\u5386\u6240\u6709\u7684\u7279\u5f81\u56fe\uff0c\u8fdb\u884cROIpooling/ROIAlign pooled_rois = [] roi_to_level = [] for i , level in enumerate ( range ( 2 , 6 )): # 2,3,4,5 # \u627e\u5230ROI\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u5c3a\u5ea6 ix = tf . where ( tf . equal ( roi_level , level )) # \u83b7\u53d6\u5230\u5bf9\u5e94\u7684ROI\u533a\u57df level_rois = tf . gather_nd ( rois , ix ) # \u83b7\u53d6ROI\u5bf9\u5e94\u7684\u7d22\u5f15 level_roi_indices = tf . gather_nd ( roi_indices , ix ) # Keep track of which roi is mapped to which level roi_to_level . append ( ix ) # \u4e0d\u8fdb\u884c\u68af\u5ea6\u66f4\u65b0 level_rois = tf . stop_gradient ( level_rois ) level_roi_indices = tf . stop_gradient ( level_roi_indices ) # \u8fdb\u884cROI_align,\u662fROIpooling\u7684\u6539\u8fdb\u7248\u672c(\u5728MaskRCNN\u4e2d\u4ecb\u7ecd) pooled_rois . append ( tf . image . crop_and_resize ( feature_map_list [ i ], level_rois , level_roi_indices , self . pool_shape , method = \"bilinear\" )) [ # \u5c06\u7279\u5f81\u62fc\u63a5\u5728\u4e00\u8d77 [2000, 7, 7, 256] pooled_rois = tf . concat ( pooled_rois , axis = 0 ) # ..... # \u83b7\u53d6 2000\u4e2a\u5019\u9009\u533a\u57df 2000 of [7, 7, 256] pooled_rois_list = tf . split ( pooled_rois , num_rois_list , axis = 0 ) return pooled_rois_list","title":"4.3 ROIPooling"},{"location":"objectdection/02.RCNN/#44-classifierregression","text":"Classifier+Regression\u90e8\u5206\u5229\u7528\u83b7\u5f97\u7684\u5019\u9009\u533a\u57df\u7684\u7279\u5f81\u56fe\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u4e0esoftmax\u8ba1\u7b97\u6bcf\u4e2a\u5019\u9009\u533a\u57dfproposal\u5177\u4f53\u5c5e\u4e8e\u7684\u7c7b\u522b\uff08\u5982\u4eba\uff0c\u8f66\uff0c\u7535\u89c6\u7b49\uff09\uff0c\u8f93\u51facls_prob\u6982\u7387\uff1b\u540c\u65f6\u518d\u6b21\u5229\u7528bounding box regression\u83b7\u5f97\u6bcf\u4e2aproposal\u7684\u4f4d\u7f6e\u504f\u79fb\u91cfbbox_pred\uff0c\u7528\u4e8e\u56de\u5f52\u66f4\u52a0\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u6846\u3002Classifier\u90e8\u5206\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a \u4eceRoI Pooling\u83b7\u53d6\u52307x7=49\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u540e\uff0c\u9001\u5165\u540e\u7eed\u7f51\u7edc\uff0c\u53ef\u4ee5\u770b\u5230\u505a\u4e86\u5982\u4e0b2\u4ef6\u4e8b\uff1a \u901a\u8fc7\u5168\u8fde\u63a5\u548csoftmax\u5bf9proposals\u8fdb\u884c\u5206\u7c7b \u518d\u6b21\u5bf9proposals\u8fdb\u884cbounding box regression\uff0c\u83b7\u53d6\u66f4\u9ad8\u7cbe\u5ea6\u7684rect box \u6e90\u7801\u5982\u4e0b\uff1afasterRCNN/detection/models/bbox_heads/bbox_head.py class BBoxHead ( tf . keras . Model ): def __init__ ( self , num_classes , pool_size = ( 7 , 7 ), target_means = ( 0. , 0. , 0. , 0. ), target_stds = ( 0.1 , 0.1 , 0.2 , 0.2 ), min_confidence = 0.7 , nms_threshold = 0.3 , max_instances = 100 , ** kwags ): super ( BBoxHead , self ) . __init__ ( ** kwags ) # \u7c7b\u522b\u4e2a\u6570 self . num_classes = num_classes # ROIpooling\u7684\u5c3a\u5bf8 self . pool_size = tuple ( pool_size ) # \u5747\u503c self . target_means = target_means # \u6807\u51c6\u5dee self . target_stds = target_stds # \u6700\u5c0f\u7684\u7f6e\u4fe1\u5ea6 self . min_confidence = min_confidence # NMS\u5c3a\u5ea6 self . nms_threshold = nms_threshold self . max_instances = max_instances # \u635f\u5931\u51fd\u6570 self . rcnn_class_loss = losses . rcnn_class_loss self . rcnn_bbox_loss = losses . rcnn_bbox_loss # \u5206\u7c7b\u5377\u79ef self . rcnn_class_conv1 = layers . Conv2D ( 1024 , self . pool_size , padding = 'valid' , name = 'rcnn_class_conv1' ) # \u5206\u7c7bBN self . rcnn_class_bn1 = layers . BatchNormalization ( name = 'rcnn_class_bn1' ) # \u5206\u7c7b\u5377\u79ef self . rcnn_class_conv2 = layers . Conv2D ( 1024 , ( 1 , 1 ), name = 'rcnn_class_conv2' ) # BN\u5c42 self . rcnn_class_bn2 = layers . BatchNormalization ( name = 'rcnn_class_bn2' ) # \u5206\u7c7b self . rcnn_class_logits = layers . Dense ( num_classes , name = 'rcnn_class_logits' ) # \u56de\u5f52 self . rcnn_delta_fc = layers . Dense ( num_classes * 4 , name = 'rcnn_bbox_fc' ) def call ( self , inputs , training = True ): ''' \u53c2\u6570\uff1a pooled_rois_list: List of [num_rois, pool_size, pool_size, channels] rpn\u751f\u6210\u7684\u5019\u9009\u533a\u57df \u8fd4\u56de\uff1a rcnn_class_logits_list: [num_rois, num_classes] \u5206\u7c7b\u7684logits rcnn_probs_list: List of [num_rois, num_classes] \u5206\u7c7b\u7684\u635f\u5931 rcnn_deltas_list: List of [num_rois, num_classes, (dy, dx, log(dh), log(dw))] \u56de\u5f52\u7ed3\u679c ''' pooled_rois_list = inputs num_pooled_rois_list = [ pooled_rois . shape [ 0 ] for pooled_rois in pooled_rois_list ] pooled_rois = tf . concat ( pooled_rois_list , axis = 0 ) # \u5377\u79ef+BN+relu x = self . rcnn_class_conv1 ( pooled_rois ) x = self . rcnn_class_bn1 ( x , training = training ) x = tf . nn . relu ( x ) # \u5377\u79ef+BN+relu x = self . rcnn_class_conv2 ( x ) x = self . rcnn_class_bn2 ( x , training = training ) x = tf . nn . relu ( x ) # flatten x = tf . squeeze ( tf . squeeze ( x , 2 ), 1 ) # \u5206\u7c7b\u7ed3\u679c logits = self . rcnn_class_logits ( x ) # \u5206\u7c7b\u6982\u7387 probs = tf . nn . softmax ( logits ) # \u56de\u5f52\u7ed3\u679c deltas = self . rcnn_delta_fc ( x ) deltas = tf . reshape ( deltas , ( - 1 , self . num_classes , 4 )) # \u5206\u7c7blogits rcnn_class_logits_list = tf . split ( logits , num_pooled_rois_list , 0 ) # \u5206\u7c7b\u6982\u7387 rcnn_probs_list = tf . split ( probs , num_pooled_rois_list , 0 ) # \u56de\u5f52\u7ed3\u679c rcnn_deltas_list = tf . split ( deltas , num_pooled_rois_list , 0 ) # \u7ed3\u679c\u8fd4\u56de return rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list \u5230\u8fd9\u6211\u4eec\u5c31\u5b8c\u6210\u4e86\u6574\u4e2a\u7f51\u7edc\u7684\u4ecb\u7ecd\u3002","title":"4.4 Classifier+Regression"},{"location":"objectdection/02.RCNN/#45-fasterrcnn","text":"Faster R-CNN\u7684\u8bad\u7ec3\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5373RPN\u7f51\u7edc\u548c\u68c0\u6d4b\u7f51\u7edcfastRCNN\u7684\u8bad\u7ec3\uff1a \u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u5206\u4e3a\u56db\u6b65\uff1a \u7b2c\u4e00\u6b65\uff1aRPN\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u4f7f\u7528ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\uff0c\u5e76\u7aef\u5230\u7aef\u5fae\u8c03\u7528\u4e8e\u533a\u57df\u5efa\u8bae\u4efb\u52a1\u3002 \u7b2c\u4e8c\u6b65\uff1a\u5229\u7528\u7b2c\u4e00\u6b65\u7684RPN\u751f\u6210\u7684\u5efa\u8bae\u6846\uff0c\u7531Fast R-CNN\u8bad\u7ec3\u4e00\u4e2a\u5355\u72ec\u7684\u68c0\u6d4b\u7f51\u7edc\uff0c\u8fd9\u4e2a\u68c0\u6d4b\u7f51\u7edc\u540c\u6837\u662f\u7531ImageNet\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u521d\u59cb\u5316\u7684\uff0c\u8fd9\u65f6\u5019\u4e24\u4e2a\u7f51\u7edc\u8fd8\u6ca1\u6709\u5171\u4eab\u5377\u79ef\u5c42\u3002 \u7b2c\u4e09\u6b65\uff1a\u7528\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\u3002 \u7b2c\u56db\u6b65\uff1a\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0c\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\u5404\u4e2a\u8bad\u7ec3\u6b65\u9aa4\uff1a","title":"4.5 FasterRCNN\u7684\u8bad\u7ec3"},{"location":"objectdection/02.RCNN/#451-rpn","text":"RPN\u7f51\u7edc\u7684\u4f5c\u7528\u4ece\u4f17\u591a\u7684anchors\u4e2d\u63d0\u53d6\u5305\u542b\u76ee\u6807\u7684\uff0c\u5e76\u4e14\u7ecf\u8fc7\u56de\u5f52\u8c03\u6574\u7684\u5019\u9009\u533a\u57df\u3002\u4e3a\u4e86\u8bad\u7ec3RPN\uff0c\u7ed9\u6bcf\u4e2aanchor\u5206\u914d\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u6807\u7b7e\uff0c\u4e5f\u5c31\u662f\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\uff0c\u7136\u540e\u8fdb\u884c\u8bad\u7ec3\u3002","title":"4.5.1 RPN\u7f51\u7edc\u7684\u8bad\u7ec3"},{"location":"objectdection/02.RCNN/#1_1","text":"\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.7\u7684anchor\u662f\u6b63\u6837\u672c\uff0c\u5373anchor\u4e2d\u5305\u542b\u76ee\u6807 \u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.3\u7684anchor\u662f\u8d1f\u6837\u672c\uff0c\u5373anchor\u4e2d\u4e0d\u5305\u542b\u76ee\u6807 \u5176\u4ed6\u7684anchor\u820d\u5f03\uff0c\u4e0d\u53c2\u4e0e\u7f51\u7edc\u7684\u8bad\u7ec3 \u8be5\u90e8\u5206\u6e90\u7801\u5728\uff1afasterRCNN/detection/core/anchor/anchor_target.py def _build_single_target ( self , anchors , valid_flags , gt_boxes , gt_class_ids ): ''' \u8ba1\u7b97\u6bcf\u5e45\u56fe\u50cf\u7684\u76ee\u6807\u503c \u53c2\u6570\uff1a anchors: [num_anchors, (y1, x1, y2, x2)] anchor\u7684\u4f4d\u7f6e\u4fe1\u606f valid_flags: [num_anchors] anchor\u7684\u8868\u793a gt_class_ids: [num_gt_boxes] \u771f\u5b9e\u503c\u7684\u7c7b\u522b gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)] \u771f\u5b9e\u6846\u7684\u4f4d\u7f6e \u8fd4\u56de\uff1a target_matchs: [num_anchors] anchor\u662f\u6b63\u8d1f\u6837\u672c target_deltas: [num_rpn_deltas, (dy, dx, log(dh), log(dw))] ''' # \u5220\u9664\u4e3a0\u7684\u771f\u5b9e\u6846 gt_boxes , _ = trim_zeros ( gt_boxes ) # \u521d\u59cb\u5316\u51680\u6570\u7ec4\uff0c\u5b58\u50a8anchor\u7684\u5206\u7c7b\u7ed3\u679c target_matchs = tf . zeros ( anchors . shape [ 0 ], dtype = tf . int32 ) # \u8ba1\u7b97anchor\u4e0egt\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4 326393 vs 10 => [326393, 10] overlaps = geometry . compute_overlaps ( anchors , gt_boxes ) # 1.\u8bbe\u7f6e\u8d1f\u6837\u672c # \u83b7\u53d6\u6bcf\u4e00\u4e2aanchor\u4e0e\u5404\u4e2aGT\u4ea4\u5e76\u6bd4\u7684\u6700\u5927\u503c\u53ca\u5176\u7d22\u5f15 anchor_iou_argmax = tf . argmax ( overlaps , axis = 1 ) anchor_iou_max = tf . reduce_max ( overlaps , axis = [ 1 ]) # \u9009\u62e9 IOU < 0.3 \u7684 anchor \u4e3a background\uff0c\u6807\u7b7e\u4e3a -1 target_matchs = tf . where ( anchor_iou_max < self . neg_iou_thr , - tf . ones ( anchors . shape [ 0 ], dtype = tf . int32 ), target_matchs ) # \u8fc7\u6ee4\u6389pad\u533a\u57df\u7684anchor target_matchs = tf . where ( tf . equal ( valid_flags , 1 ), target_matchs , tf . zeros ( anchors . shape [ 0 ], dtype = tf . int32 )) # 2\u3001\u9009\u62e9 IOU > 0.7 \u7684 anchor \u4e3a foreground\uff0c\u6807\u7b7e\u4e3a 1 target_matchs = tf . where ( anchor_iou_max >= self . pos_iou_thr , tf . ones ( anchors . shape [ 0 ], dtype = tf . int32 ), target_matchs ) # 3\u3001\u4e3a\u6bcf\u4e00GT\u5206\u914d\u4e00\u4e2aanchor\uff1a\u4e0d\u8003\u8651IOU\u7684\u5927\u5c0f # \u9009\u62e9\u4e0e\u6bcf\u4e00\u4e2aGT\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor\u7d22\u5f15 \uff1a[N_gt_boxes] gt_iou_argmax = tf . argmax ( overlaps , axis = 0 ) # \u5c06\u4ea4\u5e76\u6bd4\u6700\u5927\u7684\u8bbe\u7f6e\u4e3a\u6b63\u6837\u672c target_matchs = tf . compat . v1 . scatter_update ( tf . Variable ( target_matchs ), gt_iou_argmax , 1 ) # \u91c7\u6837\u83b7\u53d6\u6b63\u8d1f\u6837\u672c\uff0c\u4e3b\u8981\u4e0d\u8981\u4f7f\u6b63\u6837\u672c\u6bd4\u4f8b\u8d85\u8fc7\u4e00\u534a # [N_pos_anchors, 1], [15, 1] ids = tf . where ( tf . equal ( target_matchs , 1 )) # \u538b\u7f29\u6210\u4e00\u4e2a\u4e00\u7ef4\u5411\u91cf [15] ids = tf . squeeze ( ids , 1 ) # \u8ba1\u7b97\u771f\u5b9e\u6b63\u6837\u672c\u4e2a\u6570\u4e0e\u6240\u9700\u6837\u672c\u4e2a\u6570\u4e4b\u95f4\u7684\u5dee\u503c extra = ids . shape . as_list ()[ 0 ] - int ( self . num_rpn_deltas * self . positive_fraction ) # \u82e5\u5dee\u503c\u5927\u4e8e0\uff0c\u8bf4\u660e\u6709\u8db3\u591f\u7684\u6b63\u6837\u672c if extra > 0 : # \u5c06\u591a\u4f59\u7684\u6b63\u6837\u672c\u7684\u6807\u8bc6\u7f6e\u4e3a0 ids = tf . random . shuffle ( ids )[: extra ] target_matchs = tf . compat . v1 . scatter_update ( target_matchs , ids , 0 ) # \u83b7\u53d6\u8d1f\u6837\u672c ids = tf . where ( tf . equal ( target_matchs , - 1 )) # [213748, 1] ids = tf . squeeze ( ids , 1 ) # \u83b7\u53d6\u8d1f\u6837\u672c\u4e2a\u6570\u4e0e\u6240\u9700\u8d1f\u6837\u672c\u4e2a\u6570\u4e4b\u95f4\u7684\u5dee\u503c extra = ids . shape . as_list ()[ 0 ] - ( self . num_rpn_deltas - tf . reduce_sum ( tf . cast ( tf . equal ( target_matchs , 1 ), tf . int32 ))) # \u82e5\u5dee\u503c\u5927\u4e8e0\uff0c\u5219\u8bf4\u660e\u6709\u8db3\u591f\u7684\u8d1f\u6837\u672c if extra > 0 : # \u5c06\u591a\u4f59\u7684\u8d1f\u6837\u672c\u7f6e\u4e3a0 ids = tf . random . shuffle ( ids )[: extra ] target_matchs = tf . compat . v1 . scatter_update ( target_matchs , ids , 0 ) # \u8fd9\u65f6\u6211\u4eec\u5c31\u6709256\u4e2aanchor,\u5206\u522b\u5305\u542b\u6b63\u8d1f\u6837\u672c. # \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u8ba1\u7b97\u5176\u5bf9\u5e94\u7684\u5750\u6807\u4fee\u6b63\u503c # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u7d22\u5f15 ids = tf . where ( tf . equal ( target_matchs , 1 )) # [15] # \u83b7\u53d6\u6b63\u6837\u672c\u7684anchor a = tf . gather_nd ( anchors , ids ) # \u83b7\u53d6anchor\u5bf9\u5e94\u7684gt\u7684index anchor_idx = tf . gather_nd ( anchor_iou_argmax , ids ) # \u83b7\u53d6gt gt = tf . gather ( gt_boxes , anchor_idx ) # \u8ba1\u7b97anchor\u5230gt\u7684\u4fee\u6b63\u5750\u6807\u3002 target_deltas = transforms . bbox2delta ( a , gt , self . target_means , self . target_stds ) # \u83b7\u53d6\u8d1f\u6837\u672c\u7684\u4e2a\u6570 padding = tf . maximum ( self . num_rpn_deltas - tf . shape ( target_deltas )[ 0 ], 0 ) # \u76ee\u6807\u503c\uff0c\u6b63\u6837\u672c\u7684\u76ee\u6807\u503c\u662f\u504f\u79fb\uff0c\u8d1f\u6837\u672c\u7684\u76ee\u6807\u503c\u662f0 target_deltas = tf . pad ( target_deltas , [( 0 , padding ), ( 0 , 0 )]) return target_matchs , target_deltas","title":"1\u3001\u6b63\u8d1f\u6837\u672c\u6807\u8bb0"},{"location":"objectdection/02.RCNN/#2rpn","text":"RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570\u662f\uff1a \u5176\u4e2d i i \u8868\u793aanchor\u7684\u7d22\u5f15 p_i p_i \u662f\u7b2ci\u4e2aanchor \u9884\u6d4b\u4e3a\u76ee\u6807\u7684\u53ef\u80fd\u6027\uff0c p_i^{*} p_i^{*} \u4e3aground-truth\u6807\u7b7e\u3002\u5982\u679c\u8fd9\u4e2aanchor\u662fpositive\u7684\uff0c\u5219ground-truth\u6807\u7b7e\u4e3a1\uff0c\u5426\u5219\u4e3a0\u3002\uff08\u5373\u5f53\u7b2ci\u4e2aanchor\u4e0eGT\u95f4IoU>0.7\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fpositive\uff0c\u6807\u7b7e\u4e3a1\uff1b\u53cd\u4e4bIoU<0.3\u65f6\uff0c\u8ba4\u4e3a\u662f\u8be5anchor\u662fnegative\uff0c\u6807\u7b7e\u4e3a0\uff09 t_i t_i \u8868\u793a\u8868\u793a\u6b63\u6837\u672canchor\u5230\u9884\u6d4b\u533a\u57dfbounding box\u76844\u4e2a\u53c2\u6570\u5316\u9884\u6d4b\u7ed3\u679c, t_i^{*} t_i^{*} \u662f\u8fd9\u4e2apositive anchor\u5bf9\u5e94\u7684ground-truth box\u7684\u504f\u79fb\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u9884\u6d4b\u503c\uff1a \u771f\u5b9e\u503c\uff1a \u5176\u4e2d\uff0cx\uff0cy\uff0cw\uff0ch\u8868\u793a\u7a97\u53e3\u4e2d\u5fc3\u5750\u6807\u548c\u7a97\u53e3\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u53d8\u91cfx\uff0c x_a \u548cx^{*} x_a \u548cx^{*} \u5206\u522b\u8868\u793a\u9884\u6d4b\u7a97\u53e3\u3001anchor\u7a97\u53e3\u548cGround Truth\u7684\u5750\u6807\uff08y\uff0cw\uff0ch\u540c\u7406\uff09 \u6574\u4e2aLoss\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u5206\u7c7b\u548c\u56de\u5f52\u7684\u635f\u5931 L_{cls} L_{cls} \u5206\u7c7b\u7684\u635f\u5931\uff08classification loss\uff09\uff0c\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u5668\u7684softmax loss\u3002 L_{reg} L_{reg} \u662f\u56de\u5f52\u635f\u5931\uff0c\u4e3a smooth(x) smooth(x) \u635f\u5931,\u5e76\u4e14\u53ea\u6709\u6b63\u6837\u672c\u624d\u53c2\u4e0e\u56de\u5f52\u635f\u5931\u8ba1\u7b97 N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u5206\u522b\u7528\u6765\u6807\u51c6\u5316\u5206\u7c7b\u635f\u5931\u9879 L_{cls} L_{cls} \u548c\u56de\u5f52\u635f\u5931\u9879 L_{reg} L_{reg} \uff0c\u9ed8\u8ba4\u7528batch size\u8bbe\u7f6e N_{cls} N_{cls} \uff0c\u7528anchor\u4f4d\u7f6e\u6570\u76ee~2000\u521d\u59cb\u5316 N_{reg} N_{reg} N_{cls} N_{cls} \u548c N_{reg} N_{reg} \u76f8\u5dee\u8fc7\u5927\uff0c\u7528\u53c2\u6570\u03bb\u6765\u5e73\u8861\u4e24\u8005\uff0c\u4e00\u822c\u53d6\u503c\u4e3a N_{reg} N_{reg} \u548c N_{cls} N_{cls} \u7684\u6bd4\u503c10\u5373\u53ef\u3002 \u5206\u7c7b\u635f\u5931\u5b9e\u73b0\uff1afasterRCNN/detection/core/loss/losses.py def rpn_class_loss ( target_matchs , rpn_class_logits ): '''RPN\u5206\u7c7b\u635f\u5931 \u53c2\u6570\uff1a target_matchs: [batch_size, num_anchors]. anchor\u7684\u6807\u8bb0\u4fe1\u606f. 1=positive, -1=negative, 0=neutral anchor. rpn_class_logits: [batch_size, num_anchors, 2]. RPN\u7684\u5206\u7c7b\u7ed3\u679c FG/BG. ''' # \u83b7\u53d6anchor\u7684\u5206\u7c7b\u6807\u8bb0\u4fe1\u606f. \u5c06 -1/+1 \u8f6c\u6362\u4e3a 0/1 \u503c anchor_class = tf . cast ( tf . equal ( target_matchs , 1 ), tf . int32 ) # \u6b63\u8d1f\u6837\u672c\u5bf9\u635f\u5931\u90fd\u6709\u8d21\u732e\uff0c\u83b7\u53d6\u6b63\u8d1f\u6837\u672c\u7684\u7d22\u5f15 indices = tf . where ( tf . not_equal ( target_matchs , 0 )) # \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\u5bf9\u5e94\u7684\u9884\u6d4b\u503c rpn_class_logits = tf . gather_nd ( rpn_class_logits , indices ) # \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\u5bf9\u5e94\u7684\u771f\u5b9e\u7d2f\u5457 anchor_class = tf . gather_nd ( anchor_class , indices ) # \u83b7\u53d6\u7c7b\u522b\u4e2a\u6570 num_classes = rpn_class_logits . shape [ - 1 ] # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\u7ed3\u679c loss = keras . losses . categorical_crossentropy ( tf . one_hot ( anchor_class , depth = num_classes ), rpn_class_logits , from_logits = True ) # \u6c42\u5e73\u5747 loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) # \u8fd4\u56deloss\u503c return loss \u56de\u5f52\u635f\u5931\uff1a def rpn_bbox_loss ( target_deltas , target_matchs , rpn_deltas ): ''' rpn\u635f\u5931\u7684\u56de\u5f52\u7ed3\u679c \u53c2\u6570\uff1a target_deltas: [batch, num_rpn_deltas, (dy, dx, log(dh), log(dw))]. target_matchs: [batch, anchors]. Anchor match type. 1=positive, -1=negative, 0=neutral anchor. rpn_deltas: [batch, anchors, (dy, dx, log(dh), log(dw))] ''' def batch_pack ( x , counts , num_rows ): # \u83b7\u53d6\u6307\u5b9a\u7684\u4f4d\u7f6e\u7684\u503c outputs = [] for i in range ( num_rows ): outputs . append ( x [ i , : counts [ i ]]) return tf . concat ( outputs , axis = 0 ) # \u53ea\u6709\u6b63\u6837\u672c\u8ba1\u7b97\u635f\u5931\uff0c\u83b7\u53d6\u6b63\u6837\u672c\u7684\u7d22\u5f15 indices = tf . where ( tf . equal ( target_matchs , 1 )) # \u83b7\u53d6\u6b63\u6837\u672c\u5bf9\u5e94\u7684\u9884\u6d4b\u503c rpn_deltas = tf . gather_nd ( rpn_deltas , indices ) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u4e2a\u6570 batch_counts = tf . reduce_sum ( tf . cast ( tf . equal ( target_matchs , 1 ), tf . int32 ), axis = 1 ) # \u83b7\u53d6\u6b63\u6837\u672c\u5bf9\u5e94\u7684\u76ee\u6807\u503c target_deltas = batch_pack ( target_deltas , batch_counts , target_deltas . shape . as_list ()[ 0 ]) # \u8ba1\u7b97smoothL1\u635f\u5931 loss = smooth_l1_loss ( target_deltas , rpn_deltas ) # \u8ba1\u7b97\u5747\u503c loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) # \u8fd4\u56de\u635f\u5931 return loss","title":"2\u3001RPN\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570"},{"location":"objectdection/02.RCNN/#3","text":"\u5728\u8bad\u7ec3\u65f6\u6bcf\u6b21\u8fed\u4ee3\u7684\u6b63\u8d1f\u6837\u672c\u662f\u7531\u4e00\u5e45\u56fe\u50cf\u7684\u6b63\u8d1f\u6837\u672c\u7ec4\u6210\u7684\uff1a \u968f\u673a\u91c7\u6837256\u4e2aanchor\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5176\u4e2d\u91c7\u6837\u7684\u6b63\u8d1fanchor\u7684\u6bd4\u4f8b\u662f1:1\u3002 \u901a\u8fc7\u4ece\u96f6\u5747\u503c\u6807\u51c6\u5dee\u4e3a0.01\u7684\u9ad8\u65af\u5206\u5e03\u4e2d\u83b7\u53d6\u7684\u6743\u91cd\u6765\u968f\u673a\u521d\u59cb\u5316\u6240\u6709\u65b0\u5c42\uff08\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u5176\u540e\u7684\u5c42\uff09\uff0c\u6240\u6709\u5176\u4ed6\u5c42\uff08\u5373\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff09\u662f\u901a\u8fc7\u5bf9ImageNet\u5206\u7c7b\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u6765\u521d\u59cb\u5316\u7684 \u91c7\u7528\u5e26\u52a8\u91cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3","title":"3\u3001\u8bad\u7ec3\u8fc7\u7a0b"},{"location":"objectdection/02.RCNN/#452-fastrcnn","text":"\u4f7f\u7528RPN\u7f51\u7edc\u6536\u96c6\u5230\u7684\u5019\u9009\u533a\u57df\u548cimageNet\u9884\u8bad\u7ec3\u7684\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5bf9\u68c0\u6d4b\u7684FastRCNN\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002","title":"4.5.2 FastRCNN\u7f51\u7edc\u7684\u8bad\u7ec3"},{"location":"objectdection/02.RCNN/#1_2","text":"\u5728FastRCNN\u7f51\u7edc\u8bad\u7ec3\u65f6\uff1a \u9996\u5148\u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5927\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u6b63\u6837\u672c \u5c06\u4e0e\u771f\u5b9e\u6846ground truth\uff08GT\uff09\u4ea4\u5e76\u6bd4IOU\u5c0f\u4e8e0.5\u7684\u5019\u9009\u533a\u57df\u8bbe\u4e3a\u8d1f\u6837\u672c \u6b63\u8d1f\u6837\u672c\u7684\u5206\u914d\u5982\u4e0b\u6240\u793a\uff1afasterRCNN/detection/core/bbox/bbox_target.py def _build_single_target ( self , proposals , gt_boxes , gt_class_ids , img_shape ): ''' \u751f\u6210\u4e00\u5e45\u56fe\u50cf\u4e2d\u7684\u6b63\u8d1f\u6837\u672c \u53c2\u6570\uff1a proposals: [num_proposals, (y1, x1, y2, x2)] rpn\u7f51\u7edc\u751f\u6210\u7684\u5019\u9009\u533a\u57df\uff1a\u5f52\u4e00\u5316\u5750\u6807 gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)] \u56fe\u50cf\u4e2d\u771f\u5b9e\u503c\uff0cbbox\u7684\u5750\u6807\u503c\uff0c\u56fe\u50cf\u5750\u6807 gt_class_ids: [num_gt_boxes] \u56fe\u50cf\u4e2d\u7684gt\u5bf9\u5e94\u7684\u7c7b\u522b img_shape: np.ndarray. [2]. (img_height, img_width) \u56fe\u50cf\u7684\u5927\u5c0f \u8fd4\u56de\uff1a rois: [num_rois, (y1, x1, y2, x2)] \u5019\u9009\u533a\u57df\u7684\u5f52\u4e00\u5316\u5750\u6807 target_matchs: [num_positive_rois] \u91c7\u6837\u540e\u5019\u9009\u533a\u57df\u7684\u7c7b\u522b target_deltas: [num_positive_rois, (dy, dx, log(dh), log(dw))] \u91c7\u6837\u540e\u5019\u9009\u533a\u57df\u7684\u76ee\u6807\u503c ''' # \u56fe\u50cf\u7684\u5927\u5c0f H , W = img_shape # 1216, 1216 # \u79fb\u96640\u503c [7, 4] gt_boxes , non_zeros = trim_zeros ( gt_boxes ) # \u83b7\u53d6GT\u5bf9\u5e94\u7684\u7c7b\u522b gt_class_ids = tf . boolean_mask ( gt_class_ids , non_zeros ) # [7] # \u5f52\u4e00\u5316 (y1, x1, y2, x2) => 0~1 gt_boxes = gt_boxes / tf . constant ([ H , W , H , W ], dtype = tf . float32 ) # \u8ba1\u7b97\u5019\u9009\u533a\u57df\u548c\u771f\u5b9e\u6846\u4e4b\u95f4\u7684\u4ea4\u5e76\u6bd4\uff1a[2k, 4] with [7, 4] => [2k, 7] overlaps = geometry . compute_overlaps ( proposals , gt_boxes ) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u6700\u76f8\u4f3c\u7684gtbox\u7684\u7d22\u5f15[2000] anchor_iou_argmax = tf . argmax ( overlaps , axis = 1 ) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u4e0e\u6700\u76f8\u4f3c\u7684gtbox\u7684\u4ea4\u5e76\u6bd4[2000] roi_iou_max = tf . reduce_max ( overlaps , axis = 1 ) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u7d22\u5f15[2000]=>[48, 1] =>[48] positive_roi_bool = ( roi_iou_max >= self . pos_iou_thr ) positive_indices = tf . where ( positive_roi_bool )[:, 0 ] # \u83b7\u53d6\u8d1f\u6837\u672c\u7684\u7d22\u5f15 negative_indices = tf . where ( roi_iou_max < self . neg_iou_thr )[:, 0 ] # \u5bf9\u83b7\u53d6\u7684ROI\u533a\u57df\u8fdb\u884c\u4e0b\u91c7\u6837 # \u9700\u8981\u7684\u6b63\u6837\u672c\u4e2a\u6570\uff0c\u901a\u8fc7\u6bd4\u4f8b\u8ba1\u7b97 positive_count = int ( self . num_rcnn_deltas * self . positive_fraction ) # \u5c06\u6b63\u6837\u672c\u6253\u4e71\uff0c\u8fdb\u884c\u622a\u53d6 positive_indices = tf . random . shuffle ( positive_indices )[: positive_count ] # \u6b63\u6837\u672c\u7684\u4e2a\u6570 positive_count = tf . shape ( positive_indices )[ 0 ] # \u8d1f\u6837\u672c\uff0c\u4fdd\u8bc1\u6b63\u6837\u672c\u7684\u6bd4\u4f8b r = 1.0 / self . positive_fraction # \u8ba1\u7b97\u6837\u672c\u603b\u6570\u5e76\u51cf\u53bb\u6b63\u6837\u672c\u4e2a\u6570\uff0c\u5373\u4e3a\u8d1f\u6837\u672c\u4e2a\u6570 negative_count = tf . cast ( r * tf . cast ( positive_count , tf . float32 ), tf . int32 ) - positive_count # \u83b7\u53d6\u8d1f\u6837\u672c negative_indices = tf . random . shuffle ( negative_indices )[: negative_count ] # \u9009\u53d6\u6b63\u8d1f\u6837\u672c\u7684\u5019\u9009\u533a\u57df positive_rois = tf . gather ( proposals , positive_indices ) negative_rois = tf . gather ( proposals , negative_indices ) # \u4e3a\u9009\u53d6\u7684\u5019\u9009\u533a\u57df\u5206\u914d\u76ee\u6807\u503c\uff0c\u83b7\u53d6\u6b63\u6837\u672c\u4e0eGT\u7684\u4ea4\u5e76\u6bd4 positive_overlaps = tf . gather ( overlaps , positive_indices ) # \u83b7\u53d6\u4e0e\u6bcf\u4e00\u4e2a\u5019\u9009\u533a\u57df\u6700\u76f8\u4f3c\u7684GT roi_gt_box_assignment = tf . argmax ( positive_overlaps , axis = 1 ) # \u5c06GT\u7684\u5750\u6807\u548c\u7c7b\u522b\u5206\u914d\u7ed9\u5bf9\u5e94\u7684\u5019\u9009\u533a\u57df roi_gt_boxes = tf . gather ( gt_boxes , roi_gt_box_assignment ) target_matchs = tf . gather ( gt_class_ids , roi_gt_box_assignment ) # \u5c06\u5750\u6807\u8f6c\u6362\u4e3a\u4fee\u6b63\u503c target_deltas = transforms . bbox2delta ( positive_rois , roi_gt_boxes , self . target_means , self . target_stds ) # \u5c06\u6b63\u8d1f\u6837\u672c\u62fc\u63a5\u5728\u4e00\u8d77 rois = tf . concat ([ positive_rois , negative_rois ], axis = 0 ) # \u83b7\u53d6\u8d1f\u6837\u672c\u7684\u6570\u91cf N = tf . shape ( negative_rois )[ 0 ] # \u5c06\u8d1f\u6837\u672c\u7c7b\u522b\u8bbe\u4e3a0 target_matchs = tf . pad ( target_matchs , [( 0 , N )]) # \u505c\u6b62\u68af\u5ea6\u66f4\u65b0 target_matchs = tf . stop_gradient ( target_matchs ) target_deltas = tf . stop_gradient ( target_deltas ) # \u8fd4\u56de\u7ed3\u679c return rois , target_matchs , target_deltas","title":"1.\u6b63\u8d1f\u6837\u672c\u6807\u8bb0"},{"location":"objectdection/02.RCNN/#2fastrcnn","text":"FastRCNN\u7684\u8f93\u51fa\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u90e8\u5206\u662fsoftmax\u5c42\u8fdb\u884c\u5206\u7c7b\uff0c\u8f93\u51fa\u7c7b\u522b\u6709K\u4e2a\u7c7b\u522b\u52a0\u4e0a\u201d\u80cc\u666f\u201d\u7c7b\uff0c\u53e6\u4e00\u90e8\u5206\u662f\u56de\u5f52bounding box regressor\u3002\u4e5f\u5c31\u662f\uff1a \u4e00\u90e8\u5206\u8f93\u51fa\u5728K+1\u4e2a\u7c7b\u522b\u4e0a\u7684\u79bb\u6563\u6982\u7387\u5206\u5e03\uff08\u6bcf\u4e2a\u5019\u9009\u533a\u57df\uff09\uff0c p=(p0,p1,...,pk) p=(p0,p1,...,pk) \u3002\u901a\u5e38\uff0c\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u7684K+1\u4e2a\u8f93\u51fa\u4e0a\u7684Softmax\u6765\u8ba1\u7b97p\u3002 \u53e6\u4e00\u90e8\u5206\u8f93\u51fa\u5bf9\u4e8e\u7531K\u4e2a\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u6846\u56de\u5f52\u504f\u79fb\uff0c t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k})\u200b t^{k}=(t_{x}^{k},t_{y}^{k},t_{w}^{k},t_{h}^{k})\u200b \u3002\u5176\u4e2d t_k\u200b t_k\u200b \u6307\u5b9a\u76f8\u5bf9\u4e8e\u5019\u9009\u6846\u7684\u5c3a\u5ea6\u4e0d\u53d8\u8f6c\u6362\u548c\u5bf9\u6570\u7a7a\u95f4\u9ad8\u5ea6/\u5bbd\u5ea6\u79fb\u4f4d\uff0c\u4e0e\u5728RPN\u7f51\u7edc\u4e2d\u662f\u4e00\u6837\u7684\u3002 \u6bcf\u4e2a\u8bad\u7ec3\u7684\u5019\u9009\u533a\u57df\u7528 \u5206\u7c7b\u76ee\u6807\u503cu\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u76ee\u6807\u503cv\u6807\u8bb0 \u3002\u80cc\u666f\u6837\u672c\u7528u=0\u6765\u8868\u793a\uff0c\u5bf9\u6bcf\u4e2a\u6807\u8bb0\u7684\u5019\u9009\u533a\u57df\u4f7f\u7528\u591a\u4efb\u52a1\u635f\u5931L\u4ee5\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\uff1a \u5176\u4e2d L_{cls}(p, u) = -\\log p_u L_{cls}(p, u) = -\\log p_u \uff0c\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u7b2c\u4e8c\u4e2a\u635f\u5931 L_{loc} L_{loc} \uff0c\u662f\u5b9a\u4e49\u76ee\u6807\u503c\u548c\u9884\u6d4b\u68c0\u6d4b\u6846\u7684\u56db\u5143\u7ec4\u4e4b\u95f4\u7684\u635f\u5931\u4f7f\u7528smoothL1\u635f\u5931\u8ba1\u7b97\uff0c\u540c\u6837\u662f\u53ea\u6709\u6b63\u6837\u672c\uff08\u975e\u80cc\u666f\uff09\u7684\u5019\u9009\u533a\u57df\u624d\u8ba1\u7b97\u56de\u5f52\u635f\u5931\uff0c\u53c2\u6570\u03bb\u8bbe\u4e3a1\u3002 \u635f\u5931\u51fd\u6570\u7684\u6e90\u7801\u5982\u4e0b\u6240\u793a\uff1afasterRCNN/detection/core/loss/losses.py def rcnn_class_loss ( target_matchs_list , rcnn_class_logits_list ): '''FastRCNN\u7684\u5206\u7c7b\u635f\u5931 \u53c2\u6570\uff1a target_matchs_list: [num_rois]. \u6b63\u6837\u672c\u7684\u5019\u9009\u533a\u57df rcnn_class_logits_list: list of [num_rois, num_classes] \u5206\u7c7b\u7ed3\u679c ''' # \u589e\u52a0\u80cc\u666f\u7c7b\u7684\u7c7b\u522b class_ids = tf . concat ( target_matchs_list , 0 ) # \u80cc\u666f\u7c7b\u7684\u5206\u6570 class_logits = tf . concat ( rcnn_class_logits_list , 0 ) # \u7c7b\u578b\u8f6c\u6362 class_ids = tf . cast ( class_ids , 'int64' ) # \u83b7\u53d6\u7c7b\u522b\u603b\u6570 num_classes = class_logits . shape [ - 1 ] # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 loss = keras . losses . categorical_crossentropy ( tf . one_hot ( class_ids , depth = num_classes ), class_logits , from_logits = True ) # \u6c42\u5e73\u5747\uff1a\u5927\u4e8e0\u8fd4\u56de\u7ed3\u679c\uff0c\u5176\u4ed6\u8fd4\u56de0 loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) return loss def rcnn_bbox_loss ( target_deltas_list , target_matchs_list , rcnn_deltas_list ): '''FastRCNN\u7684\u56de\u5f52\u635f\u5931 \u53c2\u6570\uff1a target_deltas_list: [num_positive_rois, (dy, dx, log(dh), log(dw))] \u6b63\u6837\u672c\u5bf9\u5e94\u7684\u771f\u5b9e\u503c target_matchs_list: list of [num_rois]. \u6b63\u6837\u672c\u5bf9\u5e94\u7684\u7c7b\u522b rcnn_deltas_list: list of [num_rois, num_classes, (dy, dx, log(dh), log(dw))] \u7f51\u7edc\u8fd4\u56de\u7684\u7ed3\u679c ''' # \u5176\u4ed6\u7ed3\u679c\u4e3a0 target_deltas = tf . concat ( target_deltas_list , 0 ) target_class_ids = tf . concat ( target_matchs_list , 0 ) rcnn_deltas = tf . concat ( rcnn_deltas_list , 0 ) # \u53ea\u6709\u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5e76\u4e14\u53ea\u6709\u7c7b\u522b\u9884\u6d4b\u6b63\u786e\u624d\u83b7\u53d6\u5176\u7d22\u5f15 # \u83b7\u53d6\u975e\u80cc\u666f\u7c7b\u7684\u7ed3\u679c positive_roi_ix = tf . where ( target_class_ids > 0 )[:, 0 ] # \u5c06\u7c7b\u522b\u548c\u56de\u5f52\u7ed3\u679c\u5408\u5e76\u5728\u4e00\u8d77 positive_roi_class_ids = tf . cast ( tf . gather ( target_class_ids , positive_roi_ix ), tf . int64 ) # \u83b7\u53d6\u7d22\u5f15 indices = tf . stack ([ positive_roi_ix , positive_roi_class_ids ], axis = 1 ) # \u83b7\u53d6\u6b63\u6837\u672c\u9884\u6d4b\u7ed3\u679c rcnn_deltas = tf . gather_nd ( rcnn_deltas , indices ) # \u8ba1\u7b97Smooth-L1\u635f\u5931 loss = smooth_l1_loss ( target_deltas , rcnn_deltas ) # \u5e73\u5747\uff1asize>0\u8fd4\u56de\u7ed3\u679c\uff0c\u5426\u5219\u8fd4\u56de0 loss = tf . reduce_mean ( loss ) if tf . size ( loss ) > 0 else tf . constant ( 0.0 ) return loss","title":"2.FastRCNN\u7684\u635f\u5931\u51fd\u6570"},{"location":"objectdection/02.RCNN/#3_1","text":"FastRCNN\u7684\u8bad\u7ec3\u91c7\u7528\u591a\u5f20\u56fe\u7247\u8fdb\u884c\u8bad\u7ec3\uff0c\u83b7\u53d6\u6bcf\u5f20\u56fe\u7247\u4e2d\u7684\u6b63\u8d1f\u6837\u672c\uff1a \u5bf9\u6240\u6709\u6b63\u6837\u672c\u6839\u636eIOU\u503c\u8fdb\u884c\u6392\u5e8f\uff0c\u6bcf\u5f20\u56fe\u7247\u53d6\u524d64\u4e2a\u533a\u57df\uff0c\u5c06\u8fd9\u4e9b\u533a\u57df\u7684\u5750\u6807\u4fdd\u5b58\u4e0b\u6765\uff0c\u4f5c\u4e3a\u8be5\u56fe\u7247\u7684\u8bad\u7ec3\u6837\u672c \u7528\u4e8eSoftmax\u5206\u7c7b\u548c\u68c0\u6d4b\u6846\u56de\u5f52\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u5206\u522b\u4f7f\u7528\u5177\u6709\u65b9\u5dee0.01\u548c0.001\u7684\u96f6\u5747\u503c\u9ad8\u65af\u5206\u5e03\u521d\u59cb\u5316\uff0c\u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\uff0c\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4f7f\u7528ImageNet\u7684\u9884\u8bad\u7ec3\u7f51\u7edc \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316","title":"3.\u8bad\u7ec3\u8fc7\u7a0b"},{"location":"objectdection/02.RCNN/#453","text":"\u7528fastRCNN\u68c0\u6d4b\u7f51\u7edc\u521d\u59cb\u5316RPN\u8bad\u7ec3\uff0c\u4f46\u662f\u56fa\u5b9a\u5171\u4eab\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u53ea\u5fae\u8c03RPN\u72ec\u6709\u7684\u5c42\uff0c\u73b0\u5728\u4e24\u4e2a\u7f51\u7edc\u5171\u4eab\u5377\u79ef\u5c42\u4e86\uff0c\u63a5\u4e0b\u6765\u4fdd\u6301\u5171\u4eab\u7684\u5377\u79ef\u5c42\u56fa\u5b9a\uff0c\u5fae\u8c03Fast R-CNN\u7684fc\u5c42\u3002\u8fd9\u6837\uff0cRPN\u7f51\u7edc\u548cFast R-CNN\u7f51\u7edc\u5171\u4eab\u76f8\u540c\u7684\u5377\u79ef\u5c42\uff0c\u6784\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u3002 Faster R-CNN\u8fd8\u6709\u4e00\u79cdend-to-end\u7684\u8bad\u7ec3\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4e00\u6b21\u5b8c\u6210\u5b8c\u6210\uff0c\u5c06RPN loss\u4e0eFast RCNN loss\u76f8\u52a0\uff0c\u7136\u540e\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\uff0c\u66f4\u65b0\u53c2\u6570\u3002 \u603b\u7ed3 \u4e86\u89e3Overfeat\u6a21\u578b\u7684\u79fb\u52a8\u7a97\u53e3\u65b9\u6cd5 \u6ed1\u52a8\u7a97\u53e3\u4f7f\u7528\u56fa\u5b9a\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u77e9\u5f62\u533a\u57df\uff0c\u53ef\u4ee5\u5728\u56fe\u50cf\u4e0a\u201c\u6ed1\u52a8\u201d\uff0c\u5e76\u5c06\u626b\u63cf\u9001\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\u3002 \u4e86\u89e3RCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 R-CNN\u7f51\u7edc\u4f7f\u7528\u5019\u9009\u533a\u57df\u65b9\u6cd5\uff08region proposal method\uff09\uff0c\u5229\u7528CNN\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0cSVM\u5b8c\u6210\u5206\u7c7b\uff0c\u7ebf\u6027\u56de\u5f52\u8fdb\u884cbbox\u7684\u4fee\u6b63 \u4e86\u89e3fastRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528SS\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u8fdb\u884c\u6620\u5c04\uff0c\u5e76\u4f7f\u7528ROIpooling\u8fdb\u884c\u7ef4\u5ea6\u8c03\u6574\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u719f\u6089FasterRCNN\u76ee\u6807\u68c0\u6d4b\u7684\u601d\u60f3 \u5229\u7528CNN\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528RPN\u751f\u6210\u5019\u9009\u533a\u57df\uff0c\u6700\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52 \u77e5\u9053anchor\u7684\u601d\u60f3 anchor\u6280\u672f\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u6362\u4e3a**\"\u8fd9\u4e2a\u56fa\u5b9a\u53c2\u8003\u6846\u4e2d\u6709\u6ca1\u6709\u76ee\u6807\uff0c\u76ee\u6807\u6846\u504f\u79bb\u53c2\u8003\u6846\u591a\u8fdc\"**\uff0c\u4e0d\u518d\u9700\u8981\u591a\u5c3a\u5ea6\u904d\u5386\u6ed1\u7a97 \u638c\u63e1RPN\u7f51\u7edc\u662f\u5982\u4f55\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u751f\u6210\u7684 \u901a\u8fc7softmax\u5224\u65adanchors\u5c5e\u4e8epositive\u6216\u8005negative\uff0c\u518d\u5229\u7528bounding box regression\u4fee\u6b63anchors\u83b7\u5f97\u7cbe\u786e\u7684proposals \u638c\u63e1ROIPooling\u7684\u4f7f\u7528\u65b9\u6cd5 RoIpooling\u4f7f\u7528\u6700\u5927\u6c60\u5316\u5c06\u4efb\u4f55\u6709\u6548\u7684RoI\u533a\u57df\u5185\u7684\u7279\u5f81\u8f6c\u6362\u6210\u5177\u6709H\u00d7W\u7684\u56fa\u5b9a\u7a7a\u95f4\u8303\u56f4\u7684\u5c0ffeature map \u77e5\u9053fasterRCNN\u7684\u8bad\u7ec3\u65b9\u6cd5 \u5206\u6b65\u8bad\u7ec3\uff1aRPN\u7f51\u7edc\uff0cfastrcnn\u8bad\u7ec3\uff0c\u5171\u4eab\u7f51\u7edc\u8bad\u7ec3","title":"4.5.3 \u5171\u4eab\u5377\u79ef\u8bad\u7ec3"},{"location":"objectdection/03.RCNN-demo/","text":"4.3 Faster RCNN\u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528 \u7406\u89e3fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b 1. VOC\u6570\u636e\u96c6\u7b80\u4ecb \u00b6 Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230\uff0c\u5f88\u591a\u4f18\u79c0\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u6bd4\u5982\u5206\u7c7b\uff0c\u5b9a\u4f4d\uff0c\u68c0\u6d4b\uff0c\u5206\u5272\uff0c\u52a8\u4f5c\u8bc6\u522b\u7b49\u6a21\u578b\u90fd\u662f\u57fa\u4e8ePASCAL VOC\u6311\u6218\u8d5b\u53ca\u5176\u6570\u636e\u96c6\u4e0a\u63a8\u51fa\u7684\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff08\u6bd4\u5982RCNN\u7cfb\u5217\uff0c\u4ee5\u53ca\u540e\u9762\u8981\u4ecb\u7ecd\u7684YOLO\uff0cSSD\u7b49\uff09\u3002 1.1 \u6570\u636e\u60c5\u51b5 \u00b6 \u5e38\u7528\u7684\u7248\u672c\u67092007\u548c2012\u4e24\u4e2a\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528VOC2007\u4f5c\u4e3a\u6848\u4f8b\u5b9e\u73b0\u7684\u6570\u636e\uff0c\u8be5\u6570\u636e\u96c6\u603b\u5171\u6709\u56db\u5927\u7c7b\uff0c20\u4e2a\u5c0f\u7c7b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4ece2007\u5e74\u5f00\u59cb\uff0cPASCAL VOC\u6bcf\u5e74\u7684\u6570\u636e\u96c6\u90fd\u662f\u8fd9\u4e2a\u5c42\u7ea7\u7ed3\u6784 \u603b\u5171\u56db\u4e2a\u5927\u7c7b\uff1avehicle,household,animal,person \u603b\u517120\u4e2a\u5c0f\u7c7b\uff0c\u9884\u6d4b\u7684\u65f6\u5019\u662f\u53ea\u8f93\u51fa\u56fe\u4e2d\u9ed1\u8272\u7c97\u4f53\u7684\u7c7b\u522b \u7ec4\u7ec7\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a Annotations \u8fdb\u884c detection \u4efb\u52a1\u65f6\u7684\u6807\u7b7e\u6587\u4ef6\uff0cxml \u5f62\u5f0f\uff0c\u6587\u4ef6\u540d\u4e0e\u56fe\u7247\u540d\u4e00\u4e00\u5bf9\u5e94 ImageSets \u5305\u542b\u4e09\u4e2a\u5b50\u6587\u4ef6\u5939 Layout\u3001Main\u3001Segmentation\uff0c\u5176\u4e2d Main \u5b58\u653e\u7684\u662f\u5206\u7c7b\u548c\u68c0\u6d4b\u7684\u6570\u636e\u96c6\u5206\u5272\u6587\u4ef6 JPEGImages \u5b58\u653e .jpg \u683c\u5f0f\u7684\u56fe\u7247\u6587\u4ef6 SegmentationClass \u5b58\u653e\u6309\u7167 class \u5206\u5272\u7684\u56fe\u7247 SegmentationObject \u5b58\u653e\u6309\u7167 object \u5206\u5272\u7684\u56fe\u7247 \u6211\u4eec\u4f7f\u7528\u7684\u5c31\u662fAnnotations\u548cJPEGImages\u4e24\u90e8\u5206\u5185\u5bb9\uff0c\u53e6\u5916\u6211\u4eec\u901a\u8fc7Main\u6587\u4ef6\u5939\u4e0b\u7684\u6587\u672c\u6587\u4ef6\u83b7\u53d6\u5bf9\u5e94\u7684\u8bad\u7ec3\u96c6\u53ca\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a train.txt \u5199\u7740\u7528\u4e8e\u8bad\u7ec3\u7684\u56fe\u7247\u540d\u79f0\uff0c \u5171 2501 \u4e2a val.txt \u5199\u7740\u7528\u4e8e\u9a8c\u8bc1\u7684\u56fe\u7247\u540d\u79f0\uff0c\u5171 2510 \u4e2a trainval.txt train\u4e0eval\u7684\u5408\u96c6\u3002\u5171 5011 \u4e2a 1.2 \u6807\u6ce8\u4fe1\u606f \u00b6 \u6570\u636e\u96c6\u7684\u6807\u6ce8\u6709\u4e13\u95e8\u7684\u6807\u6ce8\u56e2\u961f\uff0c\u5e76\u9075\u4ece\u7edf\u4e00\u7684\u6807\u6ce8\u6807\u51c6\uff0c\u6807\u6ce8\u4fe1\u606f\u662f\u7528 xml \u6587\u4ef6\u7ec4\u7ec7\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6807\u6ce8\u4fe1\u606f\u5982\u4e0b\u6240\u793a\uff1a <annotation> <!--\u6570\u636e\u96c6\u7248\u672c\u4f4d\u7f6e--> <folder> VOC2007 </folder> <!--\u6587\u4ef6\u540d--> <filename> 000001.jpg </filename> <!--\u6587\u4ef6\u6765\u6e90--> <source> <database> The VOC2007 Database </database> <annotation> PASCAL VOC2007 </annotation> <image> flickr </image> <flickrid> 341012865 </flickrid> </source> <!--\u62e5\u6709\u8005--> <owner> <flickrid> Fried Camels </flickrid> <name> Jinky the Fruit Bat </name> </owner> <!--\u56fe\u7247\u5927\u5c0f--> <size> <width> 353 </width> <height> 500 </height> <depth> 3 </depth> </size> <!--\u662f\u5426\u5206\u5272--> <segmented> 0 </segmented> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <!--object\u540d\u79f0\uff0c20\u4e2a\u7c7b\u522b--> <name> dog </name> <!--\u62cd\u6444\u89d2\u5ea6\uff1afront, rear, left, right\u3002\u3002--> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <!--\u68c0\u6d4b\u96be\u6613\u7a0b\u5ea6--> <difficult> 0 </difficult> <!--bounding box \u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u89d2\u70b9\u7684\u5750\u6807\u503c--> <bndbox> <xmin> 48 </xmin> <ymin> 240 </ymin> <xmax> 195 </xmax> <ymax> 371 </ymax> </bndbox> </object> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <name> person </name> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <difficult> 0 </difficult> <bndbox> <xmin> 8 </xmin> <ymin> 12 </ymin> <xmax> 352 </xmax> <ymax> 498 </ymax> </bndbox> </object> </annotation> 2 \u6570\u636e\u96c6\u89e3\u6790 \u00b6 \u8be5\u6570\u636e\u96c6\u7684\u89e3\u6790\u5728fasterRCNN/detection/datasets/pascal_voc.py\u4e2d: \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790\u6574\u4e2a\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff1a 2.1 \u6307\u5b9a\u6570\u636e\u96c6 \u00b6 \u6839\u636e\u6307\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u83b7\u53d6\u5bf9\u5e94\u7684\u6587\u4ef6\u4fe1\u606f\uff0c\u8fdb\u884c\u5904\u7406,\u5176\u4e2dmain\u4e2dtxt\u4e2d\u7684\u5185\u5bb9\u5982\u4e0b\u6240\u793a: \u56e0\u6b64\u6211\u4eec\u6839\u636etxt\u4e2d\u7684\u5185\u5bb9\u52a0\u8f7d\u5bf9\u5e94\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6: def load_labels ( self ): # \u6839\u636e\u6807\u7b7e\u4fe1\u606f\u52a0\u8f7d\u76f8\u5e94\u7684\u6570\u636e if self . phase == 'train' : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'trainval.txt' ) else : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'val.txt' ) # \u83b7\u53d6\u56fe\u50cf\u7684\u7d22\u5f15 with open ( txtname , 'r' ) as f : self . image_index = [ x . strip () for x in f . readlines ()] self . num_image = len ( self . image_index ) # \u56fe\u50cf\u5bf9\u5e94\u7684\u7d22\u5f15\u653e\u5230\u5217\u8868gt_labels\u4e2d gt_labels = [] # \u904d\u5386\u6bcf\u4e00\u4efd\u56fe\u50cf\u83b7\u53d6\u6807\u6ce8\u4fe1\u606f for index in self . image_index : # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\uff0c\u5305\u62ecobjet box\u5750\u6807\u4fe1\u606f \u4ee5\u53ca\u7c7b\u522b\u4fe1\u606f gt_label = self . load_pascal_annotation ( index ) # \u6dfb\u52a0\u5230\u5217\u8868\u4e2d gt_labels . append ( gt_label ) # \u5c06\u6807\u6ce8\u4fe1\u606f\u8d4b\u503c\u7ed9\u5c5e\u6027\uff1aself.gt_labels self . gt_labels = gt_labels 2.2\u56fe\u50cf\u8bfb\u53d6 \u00b6 \u5229\u7528OpenCV\u8bfb\u53d6\u56fe\u50cf\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u901a\u9053\u7684\u8f6c\u6362\uff1a def image_read ( self , imname ): # opencv \u4e2d\u9ed8\u8ba4\u56fe\u7247\u8272\u5f69\u683c\u5f0f\u4e3aBGR image = cv2 . imread ( imname ) # \u5c06\u56fe\u7247\u8f6c\u6210RGB\u683c\u5f0f image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) . astype ( np . float32 ) return image 2.3 \u6807\u51c6\u4fe1\u606f\u7684\u8bfb\u53d6 \u00b6 \u6807\u6ce8\u4fe1\u606f\u7684\u8bfb\u53d6\u4e3b\u8981\u662f\u6839\u636e\u56fe\u50cf\u7684\u6587\u4ef6\u540d\u83b7\u53d6\u7d22\u5f15\u540e\uff0c\u627e\u5230\u5bf9\u5e94\u7684XML\u6587\u4ef6\uff0c\u8bfb\u53d6\u5176\u4e2d\u7684\u5185\u5bb9\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u6807\u6ce8\u4fe1\u606f\u3002 def load_pascal_annotation ( self , index ): \"\"\" \u5728PASCAL VOC\u7684XML\u6587\u4ef6\u83b7\u53d6\u8fb9\u6846\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f \"\"\" # \u83b7\u53d6XML\u6587\u4ef6\u7684\u5730\u5740 filename = os . path . join ( self . data_path , 'Annotations' , index + '.xml' ) # \u5c06XML\u4e2d\u7684\u5185\u5bb9\u83b7\u53d6\u51fa\u6765 tree = ET . parse ( filename ) # \u83b7\u53d6\u8282\u70b9\u56fe\u50cf\u7684size image_size = tree . find ( 'size' ) # \u5c06\u56fe\u50cf\u7684size\u4fe1\u606f\u5b58\u653e\u5230sizeinfo\u4e2d size_info = np . zeros (( 2 ,), dtype = np . float32 ) # \u5bbd size_info [ 0 ] = float ( image_size . find ( 'width' ) . text ) # \u9ad8 size_info [ 1 ] = float ( image_size . find ( 'height' ) . text ) # \u627e\u5230\u6240\u6709\u7684object\u8282\u70b9 objs = tree . findall ( 'object' ) # object\u7684\u6570\u91cf num_objs = len ( objs ) # boxes \u5750\u6807 (num_objs,4) boxes = np . zeros (( num_objs , 4 ), dtype = np . float32 ) # class \u7684\u6570\u91cfnum_objs\u4e2a\uff0c\u6bcf\u4e2a\u76ee\u6807\u4e00\u4e2a\u7c7b\u522b gt_classes = np . zeros (( num_objs ), dtype = np . int32 ) # \u904d\u5386\u6240\u6709\u7684\u76ee\u6807 for ix , obj in enumerate ( objs ): # \u627e\u5230bndbox\u8282\u70b9 bbox = obj . find ( 'bndbox' ) # \u83b7\u53d6\u5750\u6807\u6846\u7684\u4f4d\u7f6e\u4fe1\u606f x1 = float ( bbox . find ( 'xmin' ) . text ) - 1 y1 = float ( bbox . find ( 'ymin' ) . text ) - 1 x2 = float ( bbox . find ( 'xmax' ) . text ) - 1 y2 = float ( bbox . find ( 'ymax' ) . text ) - 1 # \u5c06\u4f4d\u7f6e\u4fe1\u606f\u5b58\u50a8\u5728bbox\u4e2d\uff0c\u6ce8\u610fboxes\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs,4] boxes [ ix , :] = [ y1 , x1 , y2 , x2 ] # \u627e\u5230class\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f cls = self . class_to_ind [ obj . find ( 'name' ) . text . lower () . strip ()] # \u5c06class\u4fe1\u606f\u5b58\u5165gt_classses\u4e2d\uff0c\u6ce8\u610fgt_classes\u4e5f\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs] \u662fint\u503c \u5bf9\u5e94\u4e8ename gt_classes [ ix ] = cls # \u83b7\u53d6\u56fe\u50cf\u7684\u5b58\u50a8\u8def\u5f84 imname = os . path . join ( self . data_path , 'JPEGImages' , index + '.jpg' ) # \u8fd4\u56de\u7ed3\u679c return { 'boxes' : boxes , 'gt_classs' : gt_classes , 'imname' : imname , 'image_size' : size_info , 'image_index' : index } 2.4 \u56fe\u50cf\u7684\u5927\u5c0f\u5904\u7406 \u00b6 \u5728\u5c06\u56fe\u50cf\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u65f6\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176\u8fdb\u884c\u5927\u5c0f\u7684\u8c03\u6574\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4e3a\u4e86\u4fdd\u8bc1\u957f\u5bbd\u6bd4\uff0c\u4f7f\u6700\u957f\u8fb9resize\u4e3a1024\uff0c\u77ed\u8fb9\u8fdb\u884cpad: def prep_im_for_blob ( self , im , pixel_means , target_size , max_size ): \"\u5bf9\u8f93\u5165\u7684\u56fe\u50cf\u8fdb\u884c\u5904\u7406\" im = im . astype ( np . float32 , copy = False ) # \u51cf\u53bb\u5747\u503c im -= pixel_means # \u56fe\u50cf\u7684\u5927\u5c0f im_shape = im . shape # \u6700\u77ed\u8fb9 im_size_min = np . min ( im_shape [ 0 : 2 ]) # \u6700\u957f\u8fb9 im_size_max = np . max ( im_shape [ 0 : 2 ]) # \u77ed\u8fb9\u53d8\u6362\u5230800\u7684\u6bd4\u4f8b im_scale = float ( target_size ) / float ( im_size_min ) # 600/\u6700\u77ed\u8fb9 # \u82e5\u957f\u8fb9\u4ee5\u4e0a\u8ff0\u6bd4\u4f8b\u53d8\u6362\u540e\u5927\u4e8e1024\uff0c\u5219\u4fee\u6b63\u53d8\u6362\u6bd4\u4f8b if np . round ( im_scale * im_size_max ) > max_size : im_scale = float ( max_size ) / float ( im_size_max ) # \u6839\u636e\u53d8\u6362\u6bd4\u4f8b\u5bf9\u56fe\u50cf\u8fdb\u884cresize im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = cv2 . INTER_LINEAR ) shape = ( 1024 , 1024 , im . shape [ - 1 ]) pad = np . zeros ( shape , dtype = im . dtype ) pad [: im . shape [ 0 ], : im . shape [ 1 ], ... ] = im # \u8fd4\u56deim \u548c im_scale return pad , im_scale , im . shape 2.5 \u6784\u5efa\u6570\u636e\u8bfb\u53d6\u7684\u7c7b \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras.utils.Sequence\u6765\u5b8c\u6210\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u7ee7\u627fSequence\u7c7b\u5fc5\u987b\u91cd\u8f7d\u4e09\u4e2a\u79c1\u6709\u65b9\u6cd5__init__\u3001 len__\u548c__getitem \uff0c\u4e3b\u8981\u662f__getitem__\u3002 \u0015__init__\u662f\u6784\u9020\u65b9\u6cd5\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u6570\u636e\u7684\u3002 __len__\u7528\u4e8e\u8ba1\u7b97\u6837\u672c\u6570\u636e\u957f\u5ea6\u3002 __getitem__\u7528\u4e8e\u751f\u6210\u6574\u4e2abatch\u7684\u6570\u636e\uff0c\u9001\u5165\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5176\u8f93\u51fa\u683c\u5f0f\u662f\u5143\u7ec4\u3002__getitem__\u76f8\u5f53\u4e8e\u751f\u6210\u5668\u7684\u4f5c\u7528\u3002 Sequence \u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002 \u4f8b\u5982\uff1a class CIFAR10Sequence ( Sequence ): # \u5b9a\u4e49\u4e00\u4e2a\u7c7b\u7ee7\u627f\u81eaSequence # _init_\u65b9\u6cd5\u8fdb\u884c\u521d\u59cb\u5316\u6570\u636e\uff0c\u6307\u5b9a\u76f8\u5e94\u7684\u5c5e\u6027\u5373\u53ef def __init__ ( self , x_set , y_set , batch_size ): # \u6570\u636e\u96c6 self . x , self . y = x_set , y_set # batch\u7684\u5927\u5c0f self . batch_size = batch_size # \u5b9a\u4e49\u4e00\u4e2aepoch\u4e2d\u7684\u8fed\u4ee3\u6b21\u6570 def __len__ ( self ): return math . ceil ( len ( self . x ) / self . batch_size ) # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u6570\u636e def __getitem__ ( self , idx ): # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u7279\u5f81\u503c\u6570\u636e batch_x = self . x [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u76ee\u6807\u503c\u6570\u636e batch_y = self . y [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u8fd4\u56de\u7ed3\u679c return np . array ([ resize ( imread ( file_name )) for file_name in batch_x ]), np . array ( batch_y ) \u90a3\u5728VOC\u6570\u636e\u96c6\u7684\u8bfb\u53d6\u4e2d\u6211\u4eec\u4e5f\u7c7b\u4f3c\u7684\u8fdb\u884c\u5904\u7406\uff1a class pascal_voc ( keras . utils . Sequence ): def __init__ ( self , phase ): # pascal_voc 2007\u6570\u636e\u7684\u5b58\u50a8\u8def\u5f84 self . data_path = os . path . join ( '../VOCdevkit' , 'VOC2007' ) # batch_size self . batch_size = 1 # \u56fe\u7247\u7684\u6700\u5c0f\u5c3a\u5bf8 self . target_size = 800 # \u56fe\u7247\u7684\u6700\u5927\u5c3a\u5bf8 self . max_size = 1024 # \u8f93\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u5c3a\u5bf8 self . scale = ( 1024 , 1024 ) # \u7c7b\u522b\u4fe1\u606f ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus'....] self . classes = [ 'background' , 'aeroplane' , 'bicycle' , 'bird' , 'boat' , 'bottle' , 'bus' , 'car' , 'cat' , 'chair' , 'cow' , 'diningtable' , 'dog' , 'horse' , 'motorbike' , 'person' , 'pottedplant' , 'sheep' , 'sofa' , 'train' , 'tvmonitor' ] # \u6784\u5efa\u76ee\u6807\u7c7b\u522b\u7684\u5b57\u5178{'background': 0, 'aeroplane': 1, \"bicycle\": 2....} self . class_to_ind = dict ( zip ( self . classes , range ( len ( self . classes )))) # \u50cf\u7d20RGB\u7684\u5747\u503c self . pixel_means = np . array ([[[ 122.7717 , 115.9465 , 102.9801 ]]]) # \u7528\u6765\u6307\u660e\u83b7\u53d6\u8bad\u7ec3\u96c6\u6216\u8005\u662f\u9a8c\u8bc1\u96c6\u6570\u636e self . phase = phase # \u83b7\u53d6\u56fe\u50cf\u6570\u91cf\uff0c\u5e76\u52a0\u8f7d\u76f8\u5e94\u7684\u6807\u7b7e self . load_labels () # \u76ee\u6807\u603b\u6570\u91cf self . num_gtlabels = len ( self . gt_labels ) self . img_transform = transforms . ImageTransform ( self . scale , self . pixel_means , [ 1. , 1. , 1. ], 'fixed' ) self . bbox_transform = transforms . BboxTransform () self . flip_ratio = 0.5 def __len__ ( self ): # \u8fd4\u56de\u8fed\u4ee3\u6b21\u6570 return np . round ( self . num_image / self . batch_size ) def __getitem__ ( self , idx ): # \u83b7\u53d6\u5f53\u524dbatch\u7684\u8d77\u59cb\u7d22\u5f15\u503c i = idx * self . batch_size batch_images = [] batch_imgmeta = [] batch_box = [] bacth_labels = [] for c in range ( self . batch_size ): # \u83b7\u53d6\u76f8\u5e94\u7684\u56fe\u50cf imname = self . gt_labels [ i + c ][ 'imname' ] # \u8bfb\u53d6\u56fe\u50cf image = self . image_read ( imname ) # \u83b7\u53d6\u539f\u59cb\u56fe\u50cf\u7684\u5c3a\u5bf8 ori_shape = image . shape # \u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574\u540e\u7684\u56fe\u50cf\u53ca\u8c03\u6574\u7684\u5c3a\u5ea6 image , image_scale , image_shape = self . prep_im_for_blob ( image , self . pixel_means , self . target_size , self . max_size ) # \u83b7\u53d6\u5c3a\u5ea6\u53d8\u6362\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8 pad_shape = image . shape # \u5c06gt_boxlabel\u4e0escale\u76f8\u4e58\u83b7\u53d6\u56fe\u50cf\u8c03\u6574\u540e\u7684\u6807\u6ce8\u6846\u7684\u5927\u5c0f\uff1aboxes.shape=[num_obj,4] bboxes = self . gt_labels [ i + c ][ 'boxes' ] * image_scale # \u83b7\u53d6\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f labels = self . gt_labels [ i + c ][ 'gt_classs' ] # print(labels) # \u56fe\u50cf\u7684\u57fa\u672c\u4fe1\u606f img_meta_dict = dict ({ 'ori_shape' : ori_shape , 'img_shape' : image_shape , 'pad_shape' : pad_shape , 'scale_factor' : image_scale }) # \u5c06\u5b57\u5178\u8f6c\u6362\u4e3a\u5217\u8868\u7684\u5f62\u5f0f image_meta = self . compose_image_meta ( img_meta_dict ) # print(image_meta) batch_images . append ( image ) bacth_labels . append ( labels ) batch_imgmeta . append ( image_meta ) batch_box . append ( bboxes ) # \u5c06\u56fe\u50cf\u8f6c\u6362\u6210tensorflow\u8f93\u5165\u7684\u5f62\u5f0f:\u3010batch_size,H,W,C\u3011 batch_images = np . reshape ( batch_images , ( self . batch_size , image . shape [ 0 ], image . shape [ 1 ], 3 )) # \u56fe\u50cf\u5143\u4fe1\u606f batch_imgmeta = np . reshape ( batch_imgmeta ,( self . batch_size , 11 )) # \u6807\u6ce8\u6846\u4fe1\u606f batch_box = np . reshape ( batch_box ,( self . batch_size , bboxes . shape [ 0 ], 4 )) # \u6807\u6ce8\u7c7b\u522b\u4fe1\u606f bacth_labels = np . reshape ( bacth_labels ,(( self . batch_size , labels . shape [ 0 ]))) # \u8fd4\u56de\u7ed3\u679c\uff1a\u5c3a\u5ea6\u53d8\u6362\u540e\u7684\u56fe\u50cf\uff0c\u56fe\u50cf\u5143\u4fe1\u606f\uff0c\u76ee\u6807\u6846\u4f4d\u7f6e\uff0c\u76ee\u6807\u7c7b\u522b return batch_images , batch_imgmeta , batch_box , bacth_labels 2.6 \u6570\u636e\u89e3\u6790\u7c7b\u6f14\u793a \u00b6 \u6211\u4eec\u5229\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u89e3\u6790\u65b9\u6cd5\u6765\u5bf9VOC\u6570\u636e\u96c6\u8fdb\u884c\u89e3\u6790\uff1a \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc from detection.datasets.utils import get_original_image import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt \u83b7\u53d6\u56fe\u50cf\u5e76\u8bbe\u7f6e\u56fe\u50cf\u7684\u5747\u503c\u4e0e\u65b9\u5dee # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) \u539f\u56fe\u50cf\u5c55\u793a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) . astype ( np . uint8 ) # \u56fe\u50cf\u5c55\u793a plt . imshow ( ori_img ) plt . show () \u0015\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u4e86resize\u548cpasding # \u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u5c06\u6807\u6ce8\u4fe1\u606f\u663e\u793a\u51fa\u6765 # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize visualize . display_instances ( rgb_img [ 0 ], bboxes [ 0 ], labels [ 0 ], pascal . classes ) 3.\u6a21\u578b\u8bad\u7ec3 \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\uff1a \u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c \u4f7f\u7528 tape.gradient(ys, xs) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 \u4f7f\u7528 optimizer.apply_gradients(grads_and_vars) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u6765\u770b\u4e0b\u5b9e\u73b0\u6d41\u7a0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 from detection.datasets import pascal_voc import tensorflow as tf import numpy as np from matplotlib import pyplot as plt from detection.models.detectors import faster_rcnn \u52a0\u8f7d\u6570\u636e\u83b7\u53d6\u6570\u636e\u7c7b\u522b # \u52a0\u8f7d\u6570\u636e\u96c6 train_dataset = pascal_voc . pascal_voc ( 'train' ) # \u6570\u636e\u7c7b\u522b num_classes = len ( train_dataset . classes ) \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = num_classes ) \u5b9a\u4e49\u4f18\u5316\u5668 # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( 1e-3 , momentum = 0.9 , nesterov = True ) \u6a21\u578b\u8bad\u7ec3 # \u6a21\u578b\u4f18\u5316 loss_his = [] for epoch in range ( 10 ): # \u83b7\u53d6\u6837\u672c\u7684index indices = np . arange ( train_dataset . num_gtlabels ) # \u6253\u4e71 np . random . shuffle ( indices ) # \u8fed\u4ee3\u6b21\u6570 iter = np . round ( train_dataset . num_gtlabels / train_dataset . batch_size ) . astype ( np . uint8 ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3 for idx in range ( iter ): # \u83b7\u53d6\u67d0\u4e00\u4e2abacth idx = indices [ idx ] # \u83b7\u53d6\u5f53\u524dbatch\u7684\u7ed3\u679c batch_imgs , batch_metas , batch_bboxes , batch_labels = train_dataset [ idx ] # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8ba1\u7b97\u635f\u5931 rpn_class_loss , rpn_bbox_loss , rcnn_class_loss , rcnn_bbox_loss = \\ model (( batch_imgs , batch_metas , batch_bboxes , batch_labels ), training = True ) # \u6c42\u603b\u635f\u5931 loss = rpn_class_loss + rpn_bbox_loss + rcnn_class_loss + rcnn_bbox_loss # \u8ba1\u7b97\u68af\u5ea6\u503c grads = tape . gradient ( loss , model . trainable_variables ) # \u66f4\u65b0\u53c2\u6570\u503c optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) # \u6253\u5370\u635f\u5931\u7ed3\u679c print ( \"epoch\uff1a %d , loss\uff1a %f \" % ( epoch + 1 , loss )) loss_his . append ( loss ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u4e2d\u53ea\u8fd0\u884c\u4e00\u4e2a\u56fe\u50cf continue # \u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c\u4e00\u6b21\u8fed\u4ee3 continue \u7ed3\u679c\u4e3a\uff1a epoch \uff1a 1 , loss \uff1a 147.117371 epoch \uff1a 2 , loss \uff1a 72.580498 epoch \uff1a 3 , loss \uff1a 79.347351 epoch \uff1a 4 , loss \uff1a 41.220577 epoch \uff1a 5 , loss \uff1a 5.238140 epoch \uff1a 6 , loss \uff1a 2.924250 epoch \uff1a 7 , loss \uff1a 5.287500 \u635f\u5931\u51fd\u6570\u7684\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u66f2\u7ebf plt . plot ( range ( len ( loss_his )),[ loss . numpy () for loss in loss_his ]) plt . grid () 4.\u6a21\u578b\u6d4b\u8bd5 \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u9996\u5148\u52a0\u8f7d\u6a21\u578b\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7f51\u7edc\u7684\u8f93\u51fa\u3002 \u5bfc\u5165\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize # \u6a21\u578b\u52a0\u8f7d from detection.models.detectors import faster_rcnn import tensorflow as tf from detection.core.bbox import transforms from detection.datasets.utils import get_original_image 4.1 \u6570\u636e\u548c\u6a21\u578b\u52a0\u8f7d \u00b6 \u9996\u5148\u52a0\u8f7d\u8981\u8fdb\u884c\u9884\u6d4b\u7684\u6570\u636e\u548c\u8bad\u7ec3\u597d\u7684\u6a21\u578b: \u6570\u636e\u96c6\u52a0\u8f7d # \u6570\u636e\u96c6\u52a0\u8f7d # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) # \u83b7\u53d6\u56fe\u50cf\uff0c\u663e\u793a rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u6a21\u578b\u52a0\u8f7d # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'bg' , 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] # \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = len ( classes )) # \u5c06\u6570\u636e\u9001\u5165\u5230\u7f51\u7edc\u4e2d _ = model (( image , image_meta , bboxes , labels ), training = True ) # \u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6743\u91cd model . load_weights ( 'weights/faster_rcnn.h5' ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7684\u8f93\u51fa\u3002 4.2 RPN\u7f51\u7edc \u00b6 4.2.1 RPN\u7684\u76ee\u6807\u503c \u00b6 \u83b7\u53d6\u56fe\u50cf\u7684anchor,\u5e76\u5339\u914d\u76ee\u6807\u503c # \u6839\u636e\u56fe\u50cf\u4fe1\u606f\u4ea7\u751fanchor anchors , valid_flags = model . rpn_head . generator . generate_pyramid_anchors ( image_meta ) # \u5e76\u8bbe\u7f6eanchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c rpn_target_matchs , rpn_target_deltas = model . rpn_head . anchor_target . build_targets ( anchors , valid_flags , bboxes , labels ) \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\uff0c\u53ca\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c # \u83b7\u53d6\u6b63\u6837\u672c positive_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 1 ))[:, 1 ]) # \u83b7\u53d6\u8d1f\u6837\u672c negative_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , - 1 ))[:, 1 ]) # \u83b7\u53d6\u975e\u6b63\u975e\u8d1f\u6837\u672c neutral_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 0 ))[:, 1 ]) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c positive_target_deltas = rpn_target_deltas [ 0 , : tf . where ( tf . equal ( rpn_target_matchs , 1 )) . shape [ 0 ]] # \u83b7\u53d6anchor\u4fee\u6b63\u7684\u76ee\u6807\u503c refined_anchors = transforms . delta2bbox ( positive_anchors , positive_target_deltas , ( 0. , 0. , 0. , 0. ), ( 0.1 , 0.1 , 0.2 , 0.2 )) \u6b63\u8d1f\u6837\u672c\u7684\u7ed3\u679c # \u6b63\u8d1f\u6837\u672c\u7684\u4e2a\u6570 print ( 'rpn_target_matchs: \\t ' , rpn_target_matchs [ 0 ] . shape . as_list ()) print ( 'rpn_target_deltas: \\t ' , rpn_target_deltas [ 0 ] . shape . as_list ()) print ( 'positive_anchors: \\t ' , positive_anchors . shape . as_list ()) print ( 'negative_anchors: \\t ' , negative_anchors . shape . as_list ()) print ( 'neutral_anchors: \\t ' , neutral_anchors . shape . as_list ()) print ( 'refined_anchors: \\t ' , refined_anchors . shape . as_list () rpn_target_matchs : [ 261888 ] rpn_target_deltas : [ 256 , 4 ] positive_anchors : [ 4 , 4 ] negative_anchors : [ 252 , 4 ] neutral_anchors : [ 261632 , 4 ] refined_anchors : [ 4 , 4 ] \u5c06\u6b63\u6837\u672c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u5c06\u6b63\u6837\u672c\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = positive_anchors . numpy (), refined_boxes = refined_anchors . numpy ()) plt . show () 4.2.2 RPN\u7684\u9884\u6d4b\u7ed3\u679c \u00b6 \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u4e0d\u53ef\u8bad\u7ec3 training = False # \u83b7\u53d6backbone\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c C2 , C3 , C4 , C5 = model . backbone ( image , training = training ) # \u83b7\u53d6fcn\u7684\u7279\u5f81\u7ed3\u679c P2 , P3 , P4 , P5 , P6 = model . neck ([ C2 , C3 , C4 , C5 ], training = training ) \u83b7\u53d6\u9001\u5165\u5230RPN\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u9001\u5165RPN\u7f51\u7edc\u4e2d # \u83b7\u53d6\u7279\u5f81\u56fe rpn_feature_maps = [ P2 , P3 , P4 , P5 , P6 ] # \u83b7\u53d6RPN\u7684\u9884\u6d4b\u7ed3\u679c:\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c rpn_class_logits , rpn_probs , rpn_deltas = model . rpn_head ( rpn_feature_maps , training = training ) \u5c06\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a # [batch_size, num_anchors, (bg prob, fg prob)] rpn\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u53bb\u7b2c\u4e00\u4e2abatch,\u6240\u6709anchor\u524d\u666f\u7684\u6982\u7387 rpn_probs_tmp = rpn_probs [ 0 , :, 1 ] # \u5c06\u7f6e\u4fe1\u5ea6top100\u7684\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a limit = 100 ix = tf . nn . top_k ( rpn_probs_tmp , k = limit ) . indices [:: - 1 ] # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tf . gather ( anchors , ix ) . numpy ()) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 4.3 fastRCNN\u7f51\u7edc \u00b6 \u5c06RPN\u7684\u7ed3\u679c\u9001\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u8fdb\u884c\u68c0\u6d4b\uff1a \u0015\u83b7\u53d6\u5019\u9009\u533a\u57df # \u5019\u9009\u533a\u57df proposals_list = model . rpn_head . get_proposals ( rpn_probs , rpn_deltas , image_meta ) \u8fdb\u884cROIPooling rois_list = proposals_list # roipooling pooled_regions_list = model . roi_align ( ( rois_list , rcnn_feature_maps , image_meta ), training = training ) \u9884\u6d4b # \u8fdb\u884c\u9884\u6d4b rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list = \\ model . bbox_head ( pooled_regions_list , training = training ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c detections_list = model . bbox_head . get_bboxes ( rcnn_probs_list , rcnn_deltas_list , rois_list , image_meta ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u7684\u5750\u6807\uff0c\u5e76\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u83b7\u5f97\u5750\u6807\u503c tmp = detections_list [ 0 ][:, : 4 ] # \u5c06\u68c0\u6d4b\u68c0\u6d4b\u7684\u6846\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tmp . numpy ()) 4.4 \u76ee\u6807\u68c0\u6d4b \u00b6 \u4e0a\u8ff0\u6211\u4eec\u662f\u5206\u6b65\u8fdb\u884c\u9884\u6d4b\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u5728\u539f\u56fe\u50cf\u4e0a\u8fdb\u884c\u9884\u6d4b\uff1a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) # \u83b7\u53d6\u5019\u9009\u533a\u57df proposals = model . simple_test_rpn ( image [ 0 ], image_meta [ 0 ]) # \u68c0\u6d4b\u7ed3\u679c res = model . simple_test_bboxes ( image [ 0 ], image_meta [ 0 ], proposals ) # \u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . display_instances ( ori_img , res [ 'rois' ], res [ 'class_ids' ], classes , scores = res [ 'scores' ]) \u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c\u4e3a\uff1a \u603b\u7ed3 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528\u7406\u89e3 Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230 fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u4e3b\u8981\u6709RPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7684\u751f\u6210\uff0c\u7136\u540e\u4f7f\u7528fastRCNN\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"Faster RCNN\u6848\u4f8b"},{"location":"objectdection/03.RCNN-demo/#43-faster-rcnn","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528 \u7406\u89e3fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.3 Faster RCNN\u6848\u4f8b"},{"location":"objectdection/03.RCNN-demo/#1-voc","text":"Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230\uff0c\u5f88\u591a\u4f18\u79c0\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u6bd4\u5982\u5206\u7c7b\uff0c\u5b9a\u4f4d\uff0c\u68c0\u6d4b\uff0c\u5206\u5272\uff0c\u52a8\u4f5c\u8bc6\u522b\u7b49\u6a21\u578b\u90fd\u662f\u57fa\u4e8ePASCAL VOC\u6311\u6218\u8d5b\u53ca\u5176\u6570\u636e\u96c6\u4e0a\u63a8\u51fa\u7684\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff08\u6bd4\u5982RCNN\u7cfb\u5217\uff0c\u4ee5\u53ca\u540e\u9762\u8981\u4ecb\u7ecd\u7684YOLO\uff0cSSD\u7b49\uff09\u3002","title":"1. VOC\u6570\u636e\u96c6\u7b80\u4ecb"},{"location":"objectdection/03.RCNN-demo/#11","text":"\u5e38\u7528\u7684\u7248\u672c\u67092007\u548c2012\u4e24\u4e2a\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528VOC2007\u4f5c\u4e3a\u6848\u4f8b\u5b9e\u73b0\u7684\u6570\u636e\uff0c\u8be5\u6570\u636e\u96c6\u603b\u5171\u6709\u56db\u5927\u7c7b\uff0c20\u4e2a\u5c0f\u7c7b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4ece2007\u5e74\u5f00\u59cb\uff0cPASCAL VOC\u6bcf\u5e74\u7684\u6570\u636e\u96c6\u90fd\u662f\u8fd9\u4e2a\u5c42\u7ea7\u7ed3\u6784 \u603b\u5171\u56db\u4e2a\u5927\u7c7b\uff1avehicle,household,animal,person \u603b\u517120\u4e2a\u5c0f\u7c7b\uff0c\u9884\u6d4b\u7684\u65f6\u5019\u662f\u53ea\u8f93\u51fa\u56fe\u4e2d\u9ed1\u8272\u7c97\u4f53\u7684\u7c7b\u522b \u7ec4\u7ec7\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a Annotations \u8fdb\u884c detection \u4efb\u52a1\u65f6\u7684\u6807\u7b7e\u6587\u4ef6\uff0cxml \u5f62\u5f0f\uff0c\u6587\u4ef6\u540d\u4e0e\u56fe\u7247\u540d\u4e00\u4e00\u5bf9\u5e94 ImageSets \u5305\u542b\u4e09\u4e2a\u5b50\u6587\u4ef6\u5939 Layout\u3001Main\u3001Segmentation\uff0c\u5176\u4e2d Main \u5b58\u653e\u7684\u662f\u5206\u7c7b\u548c\u68c0\u6d4b\u7684\u6570\u636e\u96c6\u5206\u5272\u6587\u4ef6 JPEGImages \u5b58\u653e .jpg \u683c\u5f0f\u7684\u56fe\u7247\u6587\u4ef6 SegmentationClass \u5b58\u653e\u6309\u7167 class \u5206\u5272\u7684\u56fe\u7247 SegmentationObject \u5b58\u653e\u6309\u7167 object \u5206\u5272\u7684\u56fe\u7247 \u6211\u4eec\u4f7f\u7528\u7684\u5c31\u662fAnnotations\u548cJPEGImages\u4e24\u90e8\u5206\u5185\u5bb9\uff0c\u53e6\u5916\u6211\u4eec\u901a\u8fc7Main\u6587\u4ef6\u5939\u4e0b\u7684\u6587\u672c\u6587\u4ef6\u83b7\u53d6\u5bf9\u5e94\u7684\u8bad\u7ec3\u96c6\u53ca\u9a8c\u8bc1\u96c6\u6570\u636e\uff0c\u5185\u5bb9\u5982\u4e0b\u6240\u793a\uff1a train.txt \u5199\u7740\u7528\u4e8e\u8bad\u7ec3\u7684\u56fe\u7247\u540d\u79f0\uff0c \u5171 2501 \u4e2a val.txt \u5199\u7740\u7528\u4e8e\u9a8c\u8bc1\u7684\u56fe\u7247\u540d\u79f0\uff0c\u5171 2510 \u4e2a trainval.txt train\u4e0eval\u7684\u5408\u96c6\u3002\u5171 5011 \u4e2a","title":"1.1 \u6570\u636e\u60c5\u51b5"},{"location":"objectdection/03.RCNN-demo/#12","text":"\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6709\u4e13\u95e8\u7684\u6807\u6ce8\u56e2\u961f\uff0c\u5e76\u9075\u4ece\u7edf\u4e00\u7684\u6807\u6ce8\u6807\u51c6\uff0c\u6807\u6ce8\u4fe1\u606f\u662f\u7528 xml \u6587\u4ef6\u7ec4\u7ec7\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6807\u6ce8\u4fe1\u606f\u5982\u4e0b\u6240\u793a\uff1a <annotation> <!--\u6570\u636e\u96c6\u7248\u672c\u4f4d\u7f6e--> <folder> VOC2007 </folder> <!--\u6587\u4ef6\u540d--> <filename> 000001.jpg </filename> <!--\u6587\u4ef6\u6765\u6e90--> <source> <database> The VOC2007 Database </database> <annotation> PASCAL VOC2007 </annotation> <image> flickr </image> <flickrid> 341012865 </flickrid> </source> <!--\u62e5\u6709\u8005--> <owner> <flickrid> Fried Camels </flickrid> <name> Jinky the Fruit Bat </name> </owner> <!--\u56fe\u7247\u5927\u5c0f--> <size> <width> 353 </width> <height> 500 </height> <depth> 3 </depth> </size> <!--\u662f\u5426\u5206\u5272--> <segmented> 0 </segmented> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <!--object\u540d\u79f0\uff0c20\u4e2a\u7c7b\u522b--> <name> dog </name> <!--\u62cd\u6444\u89d2\u5ea6\uff1afront, rear, left, right\u3002\u3002--> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <!--\u68c0\u6d4b\u96be\u6613\u7a0b\u5ea6--> <difficult> 0 </difficult> <!--bounding box \u7684\u5de6\u4e0a\u89d2\u70b9\u548c\u53f3\u4e0b\u89d2\u70b9\u7684\u5750\u6807\u503c--> <bndbox> <xmin> 48 </xmin> <ymin> 240 </ymin> <xmax> 195 </xmax> <ymax> 371 </ymax> </bndbox> </object> <!--\u4e00\u4e2a\u76ee\u6807\uff0c\u91cc\u9762\u7684\u5185\u5bb9\u662f\u76ee\u6807\u7684\u76f8\u5173\u4fe1\u606f--> <object> <name> person </name> <pose> Left </pose> <!--\u76ee\u6807\u662f\u5426\u88ab\u622a\u65ad\uff0c\u6216\u8005\u88ab\u906e\u6321\uff08\u8d85\u8fc715%\uff09--> <truncated> 1 </truncated> <difficult> 0 </difficult> <bndbox> <xmin> 8 </xmin> <ymin> 12 </ymin> <xmax> 352 </xmax> <ymax> 498 </ymax> </bndbox> </object> </annotation>","title":"1.2 \u6807\u6ce8\u4fe1\u606f"},{"location":"objectdection/03.RCNN-demo/#2","text":"\u8be5\u6570\u636e\u96c6\u7684\u89e3\u6790\u5728fasterRCNN/detection/datasets/pascal_voc.py\u4e2d: \u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790\u6574\u4e2a\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff1a","title":"2 \u6570\u636e\u96c6\u89e3\u6790"},{"location":"objectdection/03.RCNN-demo/#21","text":"\u6839\u636e\u6307\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u83b7\u53d6\u5bf9\u5e94\u7684\u6587\u4ef6\u4fe1\u606f\uff0c\u8fdb\u884c\u5904\u7406,\u5176\u4e2dmain\u4e2dtxt\u4e2d\u7684\u5185\u5bb9\u5982\u4e0b\u6240\u793a: \u56e0\u6b64\u6211\u4eec\u6839\u636etxt\u4e2d\u7684\u5185\u5bb9\u52a0\u8f7d\u5bf9\u5e94\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6: def load_labels ( self ): # \u6839\u636e\u6807\u7b7e\u4fe1\u606f\u52a0\u8f7d\u76f8\u5e94\u7684\u6570\u636e if self . phase == 'train' : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'trainval.txt' ) else : txtname = os . path . join ( self . data_path , 'ImageSets' , 'Main' , 'val.txt' ) # \u83b7\u53d6\u56fe\u50cf\u7684\u7d22\u5f15 with open ( txtname , 'r' ) as f : self . image_index = [ x . strip () for x in f . readlines ()] self . num_image = len ( self . image_index ) # \u56fe\u50cf\u5bf9\u5e94\u7684\u7d22\u5f15\u653e\u5230\u5217\u8868gt_labels\u4e2d gt_labels = [] # \u904d\u5386\u6bcf\u4e00\u4efd\u56fe\u50cf\u83b7\u53d6\u6807\u6ce8\u4fe1\u606f for index in self . image_index : # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\uff0c\u5305\u62ecobjet box\u5750\u6807\u4fe1\u606f \u4ee5\u53ca\u7c7b\u522b\u4fe1\u606f gt_label = self . load_pascal_annotation ( index ) # \u6dfb\u52a0\u5230\u5217\u8868\u4e2d gt_labels . append ( gt_label ) # \u5c06\u6807\u6ce8\u4fe1\u606f\u8d4b\u503c\u7ed9\u5c5e\u6027\uff1aself.gt_labels self . gt_labels = gt_labels","title":"2.1 \u6307\u5b9a\u6570\u636e\u96c6"},{"location":"objectdection/03.RCNN-demo/#22","text":"\u5229\u7528OpenCV\u8bfb\u53d6\u56fe\u50cf\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u901a\u9053\u7684\u8f6c\u6362\uff1a def image_read ( self , imname ): # opencv \u4e2d\u9ed8\u8ba4\u56fe\u7247\u8272\u5f69\u683c\u5f0f\u4e3aBGR image = cv2 . imread ( imname ) # \u5c06\u56fe\u7247\u8f6c\u6210RGB\u683c\u5f0f image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) . astype ( np . float32 ) return image","title":"2.2\u56fe\u50cf\u8bfb\u53d6"},{"location":"objectdection/03.RCNN-demo/#23","text":"\u6807\u6ce8\u4fe1\u606f\u7684\u8bfb\u53d6\u4e3b\u8981\u662f\u6839\u636e\u56fe\u50cf\u7684\u6587\u4ef6\u540d\u83b7\u53d6\u7d22\u5f15\u540e\uff0c\u627e\u5230\u5bf9\u5e94\u7684XML\u6587\u4ef6\uff0c\u8bfb\u53d6\u5176\u4e2d\u7684\u5185\u5bb9\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u6807\u6ce8\u4fe1\u606f\u3002 def load_pascal_annotation ( self , index ): \"\"\" \u5728PASCAL VOC\u7684XML\u6587\u4ef6\u83b7\u53d6\u8fb9\u6846\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f \"\"\" # \u83b7\u53d6XML\u6587\u4ef6\u7684\u5730\u5740 filename = os . path . join ( self . data_path , 'Annotations' , index + '.xml' ) # \u5c06XML\u4e2d\u7684\u5185\u5bb9\u83b7\u53d6\u51fa\u6765 tree = ET . parse ( filename ) # \u83b7\u53d6\u8282\u70b9\u56fe\u50cf\u7684size image_size = tree . find ( 'size' ) # \u5c06\u56fe\u50cf\u7684size\u4fe1\u606f\u5b58\u653e\u5230sizeinfo\u4e2d size_info = np . zeros (( 2 ,), dtype = np . float32 ) # \u5bbd size_info [ 0 ] = float ( image_size . find ( 'width' ) . text ) # \u9ad8 size_info [ 1 ] = float ( image_size . find ( 'height' ) . text ) # \u627e\u5230\u6240\u6709\u7684object\u8282\u70b9 objs = tree . findall ( 'object' ) # object\u7684\u6570\u91cf num_objs = len ( objs ) # boxes \u5750\u6807 (num_objs,4) boxes = np . zeros (( num_objs , 4 ), dtype = np . float32 ) # class \u7684\u6570\u91cfnum_objs\u4e2a\uff0c\u6bcf\u4e2a\u76ee\u6807\u4e00\u4e2a\u7c7b\u522b gt_classes = np . zeros (( num_objs ), dtype = np . int32 ) # \u904d\u5386\u6240\u6709\u7684\u76ee\u6807 for ix , obj in enumerate ( objs ): # \u627e\u5230bndbox\u8282\u70b9 bbox = obj . find ( 'bndbox' ) # \u83b7\u53d6\u5750\u6807\u6846\u7684\u4f4d\u7f6e\u4fe1\u606f x1 = float ( bbox . find ( 'xmin' ) . text ) - 1 y1 = float ( bbox . find ( 'ymin' ) . text ) - 1 x2 = float ( bbox . find ( 'xmax' ) . text ) - 1 y2 = float ( bbox . find ( 'ymax' ) . text ) - 1 # \u5c06\u4f4d\u7f6e\u4fe1\u606f\u5b58\u50a8\u5728bbox\u4e2d\uff0c\u6ce8\u610fboxes\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs,4] boxes [ ix , :] = [ y1 , x1 , y2 , x2 ] # \u627e\u5230class\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f cls = self . class_to_ind [ obj . find ( 'name' ) . text . lower () . strip ()] # \u5c06class\u4fe1\u606f\u5b58\u5165gt_classses\u4e2d\uff0c\u6ce8\u610fgt_classes\u4e5f\u662f\u4e00\u4e2anp\u7c7b\u7684\u77e9\u9635 \u5927\u5c0f\u4e3a[num_objs] \u662fint\u503c \u5bf9\u5e94\u4e8ename gt_classes [ ix ] = cls # \u83b7\u53d6\u56fe\u50cf\u7684\u5b58\u50a8\u8def\u5f84 imname = os . path . join ( self . data_path , 'JPEGImages' , index + '.jpg' ) # \u8fd4\u56de\u7ed3\u679c return { 'boxes' : boxes , 'gt_classs' : gt_classes , 'imname' : imname , 'image_size' : size_info , 'image_index' : index }","title":"2.3 \u6807\u51c6\u4fe1\u606f\u7684\u8bfb\u53d6"},{"location":"objectdection/03.RCNN-demo/#24","text":"\u5728\u5c06\u56fe\u50cf\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u65f6\uff0c\u6211\u4eec\u9700\u8981\u5c06\u5176\u8fdb\u884c\u5927\u5c0f\u7684\u8c03\u6574\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4e3a\u4e86\u4fdd\u8bc1\u957f\u5bbd\u6bd4\uff0c\u4f7f\u6700\u957f\u8fb9resize\u4e3a1024\uff0c\u77ed\u8fb9\u8fdb\u884cpad: def prep_im_for_blob ( self , im , pixel_means , target_size , max_size ): \"\u5bf9\u8f93\u5165\u7684\u56fe\u50cf\u8fdb\u884c\u5904\u7406\" im = im . astype ( np . float32 , copy = False ) # \u51cf\u53bb\u5747\u503c im -= pixel_means # \u56fe\u50cf\u7684\u5927\u5c0f im_shape = im . shape # \u6700\u77ed\u8fb9 im_size_min = np . min ( im_shape [ 0 : 2 ]) # \u6700\u957f\u8fb9 im_size_max = np . max ( im_shape [ 0 : 2 ]) # \u77ed\u8fb9\u53d8\u6362\u5230800\u7684\u6bd4\u4f8b im_scale = float ( target_size ) / float ( im_size_min ) # 600/\u6700\u77ed\u8fb9 # \u82e5\u957f\u8fb9\u4ee5\u4e0a\u8ff0\u6bd4\u4f8b\u53d8\u6362\u540e\u5927\u4e8e1024\uff0c\u5219\u4fee\u6b63\u53d8\u6362\u6bd4\u4f8b if np . round ( im_scale * im_size_max ) > max_size : im_scale = float ( max_size ) / float ( im_size_max ) # \u6839\u636e\u53d8\u6362\u6bd4\u4f8b\u5bf9\u56fe\u50cf\u8fdb\u884cresize im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = cv2 . INTER_LINEAR ) shape = ( 1024 , 1024 , im . shape [ - 1 ]) pad = np . zeros ( shape , dtype = im . dtype ) pad [: im . shape [ 0 ], : im . shape [ 1 ], ... ] = im # \u8fd4\u56deim \u548c im_scale return pad , im_scale , im . shape","title":"2.4 \u56fe\u50cf\u7684\u5927\u5c0f\u5904\u7406"},{"location":"objectdection/03.RCNN-demo/#25","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras.utils.Sequence\u6765\u5b8c\u6210\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u7ee7\u627fSequence\u7c7b\u5fc5\u987b\u91cd\u8f7d\u4e09\u4e2a\u79c1\u6709\u65b9\u6cd5__init__\u3001 len__\u548c__getitem \uff0c\u4e3b\u8981\u662f__getitem__\u3002 \u0015__init__\u662f\u6784\u9020\u65b9\u6cd5\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u6570\u636e\u7684\u3002 __len__\u7528\u4e8e\u8ba1\u7b97\u6837\u672c\u6570\u636e\u957f\u5ea6\u3002 __getitem__\u7528\u4e8e\u751f\u6210\u6574\u4e2abatch\u7684\u6570\u636e\uff0c\u9001\u5165\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5176\u8f93\u51fa\u683c\u5f0f\u662f\u5143\u7ec4\u3002__getitem__\u76f8\u5f53\u4e8e\u751f\u6210\u5668\u7684\u4f5c\u7528\u3002 Sequence \u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\u3002 \u4f8b\u5982\uff1a class CIFAR10Sequence ( Sequence ): # \u5b9a\u4e49\u4e00\u4e2a\u7c7b\u7ee7\u627f\u81eaSequence # _init_\u65b9\u6cd5\u8fdb\u884c\u521d\u59cb\u5316\u6570\u636e\uff0c\u6307\u5b9a\u76f8\u5e94\u7684\u5c5e\u6027\u5373\u53ef def __init__ ( self , x_set , y_set , batch_size ): # \u6570\u636e\u96c6 self . x , self . y = x_set , y_set # batch\u7684\u5927\u5c0f self . batch_size = batch_size # \u5b9a\u4e49\u4e00\u4e2aepoch\u4e2d\u7684\u8fed\u4ee3\u6b21\u6570 def __len__ ( self ): return math . ceil ( len ( self . x ) / self . batch_size ) # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u6570\u636e def __getitem__ ( self , idx ): # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u7279\u5f81\u503c\u6570\u636e batch_x = self . x [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u76ee\u6807\u503c\u6570\u636e batch_y = self . y [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] # \u8fd4\u56de\u7ed3\u679c return np . array ([ resize ( imread ( file_name )) for file_name in batch_x ]), np . array ( batch_y ) \u90a3\u5728VOC\u6570\u636e\u96c6\u7684\u8bfb\u53d6\u4e2d\u6211\u4eec\u4e5f\u7c7b\u4f3c\u7684\u8fdb\u884c\u5904\u7406\uff1a class pascal_voc ( keras . utils . Sequence ): def __init__ ( self , phase ): # pascal_voc 2007\u6570\u636e\u7684\u5b58\u50a8\u8def\u5f84 self . data_path = os . path . join ( '../VOCdevkit' , 'VOC2007' ) # batch_size self . batch_size = 1 # \u56fe\u7247\u7684\u6700\u5c0f\u5c3a\u5bf8 self . target_size = 800 # \u56fe\u7247\u7684\u6700\u5927\u5c3a\u5bf8 self . max_size = 1024 # \u8f93\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u5c3a\u5bf8 self . scale = ( 1024 , 1024 ) # \u7c7b\u522b\u4fe1\u606f ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus'....] self . classes = [ 'background' , 'aeroplane' , 'bicycle' , 'bird' , 'boat' , 'bottle' , 'bus' , 'car' , 'cat' , 'chair' , 'cow' , 'diningtable' , 'dog' , 'horse' , 'motorbike' , 'person' , 'pottedplant' , 'sheep' , 'sofa' , 'train' , 'tvmonitor' ] # \u6784\u5efa\u76ee\u6807\u7c7b\u522b\u7684\u5b57\u5178{'background': 0, 'aeroplane': 1, \"bicycle\": 2....} self . class_to_ind = dict ( zip ( self . classes , range ( len ( self . classes )))) # \u50cf\u7d20RGB\u7684\u5747\u503c self . pixel_means = np . array ([[[ 122.7717 , 115.9465 , 102.9801 ]]]) # \u7528\u6765\u6307\u660e\u83b7\u53d6\u8bad\u7ec3\u96c6\u6216\u8005\u662f\u9a8c\u8bc1\u96c6\u6570\u636e self . phase = phase # \u83b7\u53d6\u56fe\u50cf\u6570\u91cf\uff0c\u5e76\u52a0\u8f7d\u76f8\u5e94\u7684\u6807\u7b7e self . load_labels () # \u76ee\u6807\u603b\u6570\u91cf self . num_gtlabels = len ( self . gt_labels ) self . img_transform = transforms . ImageTransform ( self . scale , self . pixel_means , [ 1. , 1. , 1. ], 'fixed' ) self . bbox_transform = transforms . BboxTransform () self . flip_ratio = 0.5 def __len__ ( self ): # \u8fd4\u56de\u8fed\u4ee3\u6b21\u6570 return np . round ( self . num_image / self . batch_size ) def __getitem__ ( self , idx ): # \u83b7\u53d6\u5f53\u524dbatch\u7684\u8d77\u59cb\u7d22\u5f15\u503c i = idx * self . batch_size batch_images = [] batch_imgmeta = [] batch_box = [] bacth_labels = [] for c in range ( self . batch_size ): # \u83b7\u53d6\u76f8\u5e94\u7684\u56fe\u50cf imname = self . gt_labels [ i + c ][ 'imname' ] # \u8bfb\u53d6\u56fe\u50cf image = self . image_read ( imname ) # \u83b7\u53d6\u539f\u59cb\u56fe\u50cf\u7684\u5c3a\u5bf8 ori_shape = image . shape # \u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574\u540e\u7684\u56fe\u50cf\u53ca\u8c03\u6574\u7684\u5c3a\u5ea6 image , image_scale , image_shape = self . prep_im_for_blob ( image , self . pixel_means , self . target_size , self . max_size ) # \u83b7\u53d6\u5c3a\u5ea6\u53d8\u6362\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8 pad_shape = image . shape # \u5c06gt_boxlabel\u4e0escale\u76f8\u4e58\u83b7\u53d6\u56fe\u50cf\u8c03\u6574\u540e\u7684\u6807\u6ce8\u6846\u7684\u5927\u5c0f\uff1aboxes.shape=[num_obj,4] bboxes = self . gt_labels [ i + c ][ 'boxes' ] * image_scale # \u83b7\u53d6\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f labels = self . gt_labels [ i + c ][ 'gt_classs' ] # print(labels) # \u56fe\u50cf\u7684\u57fa\u672c\u4fe1\u606f img_meta_dict = dict ({ 'ori_shape' : ori_shape , 'img_shape' : image_shape , 'pad_shape' : pad_shape , 'scale_factor' : image_scale }) # \u5c06\u5b57\u5178\u8f6c\u6362\u4e3a\u5217\u8868\u7684\u5f62\u5f0f image_meta = self . compose_image_meta ( img_meta_dict ) # print(image_meta) batch_images . append ( image ) bacth_labels . append ( labels ) batch_imgmeta . append ( image_meta ) batch_box . append ( bboxes ) # \u5c06\u56fe\u50cf\u8f6c\u6362\u6210tensorflow\u8f93\u5165\u7684\u5f62\u5f0f:\u3010batch_size,H,W,C\u3011 batch_images = np . reshape ( batch_images , ( self . batch_size , image . shape [ 0 ], image . shape [ 1 ], 3 )) # \u56fe\u50cf\u5143\u4fe1\u606f batch_imgmeta = np . reshape ( batch_imgmeta ,( self . batch_size , 11 )) # \u6807\u6ce8\u6846\u4fe1\u606f batch_box = np . reshape ( batch_box ,( self . batch_size , bboxes . shape [ 0 ], 4 )) # \u6807\u6ce8\u7c7b\u522b\u4fe1\u606f bacth_labels = np . reshape ( bacth_labels ,(( self . batch_size , labels . shape [ 0 ]))) # \u8fd4\u56de\u7ed3\u679c\uff1a\u5c3a\u5ea6\u53d8\u6362\u540e\u7684\u56fe\u50cf\uff0c\u56fe\u50cf\u5143\u4fe1\u606f\uff0c\u76ee\u6807\u6846\u4f4d\u7f6e\uff0c\u76ee\u6807\u7c7b\u522b return batch_images , batch_imgmeta , batch_box , bacth_labels","title":"2.5 \u6784\u5efa\u6570\u636e\u8bfb\u53d6\u7684\u7c7b"},{"location":"objectdection/03.RCNN-demo/#26","text":"\u6211\u4eec\u5229\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u89e3\u6790\u65b9\u6cd5\u6765\u5bf9VOC\u6570\u636e\u96c6\u8fdb\u884c\u89e3\u6790\uff1a \u5bfc\u5165\u6240\u9700\u7684\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc from detection.datasets.utils import get_original_image import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt \u83b7\u53d6\u56fe\u50cf\u5e76\u8bbe\u7f6e\u56fe\u50cf\u7684\u5747\u503c\u4e0e\u65b9\u5dee # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) \u539f\u56fe\u50cf\u5c55\u793a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) . astype ( np . uint8 ) # \u56fe\u50cf\u5c55\u793a plt . imshow ( ori_img ) plt . show () \u0015\u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u4e86resize\u548cpasding # \u9001\u5165\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u5c06\u6807\u6ce8\u4fe1\u606f\u663e\u793a\u51fa\u6765 # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize visualize . display_instances ( rgb_img [ 0 ], bboxes [ 0 ], labels [ 0 ], pascal . classes )","title":"2.6 \u6570\u636e\u89e3\u6790\u7c7b\u6f14\u793a"},{"location":"objectdection/03.RCNN-demo/#3","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\uff1a \u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c \u4f7f\u7528 tape.gradient(ys, xs) \u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 \u4f7f\u7528 optimizer.apply_gradients(grads_and_vars) \u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u6765\u770b\u4e0b\u5b9e\u73b0\u6d41\u7a0b\uff1a # \u5bfc\u5165\u5de5\u5177\u5305 from detection.datasets import pascal_voc import tensorflow as tf import numpy as np from matplotlib import pyplot as plt from detection.models.detectors import faster_rcnn \u52a0\u8f7d\u6570\u636e\u83b7\u53d6\u6570\u636e\u7c7b\u522b # \u52a0\u8f7d\u6570\u636e\u96c6 train_dataset = pascal_voc . pascal_voc ( 'train' ) # \u6570\u636e\u7c7b\u522b num_classes = len ( train_dataset . classes ) \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = num_classes ) \u5b9a\u4e49\u4f18\u5316\u5668 # \u4f18\u5316\u5668 optimizer = tf . keras . optimizers . SGD ( 1e-3 , momentum = 0.9 , nesterov = True ) \u6a21\u578b\u8bad\u7ec3 # \u6a21\u578b\u4f18\u5316 loss_his = [] for epoch in range ( 10 ): # \u83b7\u53d6\u6837\u672c\u7684index indices = np . arange ( train_dataset . num_gtlabels ) # \u6253\u4e71 np . random . shuffle ( indices ) # \u8fed\u4ee3\u6b21\u6570 iter = np . round ( train_dataset . num_gtlabels / train_dataset . batch_size ) . astype ( np . uint8 ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3 for idx in range ( iter ): # \u83b7\u53d6\u67d0\u4e00\u4e2abacth idx = indices [ idx ] # \u83b7\u53d6\u5f53\u524dbatch\u7684\u7ed3\u679c batch_imgs , batch_metas , batch_bboxes , batch_labels = train_dataset [ idx ] # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8ba1\u7b97\u635f\u5931 rpn_class_loss , rpn_bbox_loss , rcnn_class_loss , rcnn_bbox_loss = \\ model (( batch_imgs , batch_metas , batch_bboxes , batch_labels ), training = True ) # \u6c42\u603b\u635f\u5931 loss = rpn_class_loss + rpn_bbox_loss + rcnn_class_loss + rcnn_bbox_loss # \u8ba1\u7b97\u68af\u5ea6\u503c grads = tape . gradient ( loss , model . trainable_variables ) # \u66f4\u65b0\u53c2\u6570\u503c optimizer . apply_gradients ( zip ( grads , model . trainable_variables )) # \u6253\u5370\u635f\u5931\u7ed3\u679c print ( \"epoch\uff1a %d , loss\uff1a %f \" % ( epoch + 1 , loss )) loss_his . append ( loss ) # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u4e2d\u53ea\u8fd0\u884c\u4e00\u4e2a\u56fe\u50cf continue # \u6bcf\u4e00\u4e2aepoch\u4e2d\u53ea\u8fd0\u884c\u4e00\u6b21\u8fed\u4ee3 continue \u7ed3\u679c\u4e3a\uff1a epoch \uff1a 1 , loss \uff1a 147.117371 epoch \uff1a 2 , loss \uff1a 72.580498 epoch \uff1a 3 , loss \uff1a 79.347351 epoch \uff1a 4 , loss \uff1a 41.220577 epoch \uff1a 5 , loss \uff1a 5.238140 epoch \uff1a 6 , loss \uff1a 2.924250 epoch \uff1a 7 , loss \uff1a 5.287500 \u635f\u5931\u51fd\u6570\u7684\u53d8\u6362\u5982\u4e0b\u56fe\u6240\u793a\uff1a # \u7ed8\u5236\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u66f2\u7ebf plt . plot ( range ( len ( loss_his )),[ loss . numpy () for loss in loss_his ]) plt . grid ()","title":"3.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/03.RCNN-demo/#4","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u9996\u5148\u52a0\u8f7d\u6a21\u578b\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7f51\u7edc\u7684\u8f93\u51fa\u3002 \u5bfc\u5165\u5de5\u5177\u5305 # \u5bfc\u5165\u6570\u636e\u96c6 VOC data from detection.datasets import pascal_voc import numpy as np # \u56fe\u50cf\u5c55\u793a from matplotlib import pyplot as plt # \u663e\u793a\u56fe\u50cf\uff0c\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c import visualize # \u6a21\u578b\u52a0\u8f7d from detection.models.detectors import faster_rcnn import tensorflow as tf from detection.core.bbox import transforms from detection.datasets.utils import get_original_image","title":"4.\u6a21\u578b\u6d4b\u8bd5"},{"location":"objectdection/03.RCNN-demo/#41","text":"\u9996\u5148\u52a0\u8f7d\u8981\u8fdb\u884c\u9884\u6d4b\u7684\u6570\u636e\u548c\u8bad\u7ec3\u597d\u7684\u6a21\u578b: \u6570\u636e\u96c6\u52a0\u8f7d # \u6570\u636e\u96c6\u52a0\u8f7d # \u5b9e\u4f8b\u5316 pascal = pascal_voc . pascal_voc ( 'train' ) # \u83b7\u53d6\u56fe\u50cf image , image_meta , bboxes , labels = pascal [ 8 ] # \u56fe\u50cf\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee img_mean = ( 122.7717 , 115.9465 , 102.9801 ) img_std = ( 1. , 1. , 1. ) # \u83b7\u53d6\u56fe\u50cf\uff0c\u663e\u793a rgb_img = np . round ( image + img_mean ) . astype ( np . uint8 ) plt . imshow ( rgb_img [ 0 ]) plt . show () \u6a21\u578b\u52a0\u8f7d # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'bg' , 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] # \u6a21\u578b\u52a0\u8f7d model = faster_rcnn . FasterRCNN ( num_classes = len ( classes )) # \u5c06\u6570\u636e\u9001\u5165\u5230\u7f51\u7edc\u4e2d _ = model (( image , image_meta , bboxes , labels ), training = True ) # \u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684\u6743\u91cd model . load_weights ( 'weights/faster_rcnn.h5' ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u6765\u770b\u4e0bRPN\u7f51\u7edc\u548cfastRCNN\u7684\u8f93\u51fa\u3002","title":"4.1 \u6570\u636e\u548c\u6a21\u578b\u52a0\u8f7d"},{"location":"objectdection/03.RCNN-demo/#42-rpn","text":"","title":"4.2 RPN\u7f51\u7edc"},{"location":"objectdection/03.RCNN-demo/#421-rpn","text":"\u83b7\u53d6\u56fe\u50cf\u7684anchor,\u5e76\u5339\u914d\u76ee\u6807\u503c # \u6839\u636e\u56fe\u50cf\u4fe1\u606f\u4ea7\u751fanchor anchors , valid_flags = model . rpn_head . generator . generate_pyramid_anchors ( image_meta ) # \u5e76\u8bbe\u7f6eanchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c rpn_target_matchs , rpn_target_deltas = model . rpn_head . anchor_target . build_targets ( anchors , valid_flags , bboxes , labels ) \u83b7\u53d6\u6b63\u8d1f\u6837\u672c\uff0c\u53ca\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c # \u83b7\u53d6\u6b63\u6837\u672c positive_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 1 ))[:, 1 ]) # \u83b7\u53d6\u8d1f\u6837\u672c negative_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , - 1 ))[:, 1 ]) # \u83b7\u53d6\u975e\u6b63\u975e\u8d1f\u6837\u672c neutral_anchors = tf . gather ( anchors , tf . where ( tf . equal ( rpn_target_matchs , 0 ))[:, 1 ]) # \u83b7\u53d6\u6b63\u6837\u672c\u7684\u56de\u5f52\u503c positive_target_deltas = rpn_target_deltas [ 0 , : tf . where ( tf . equal ( rpn_target_matchs , 1 )) . shape [ 0 ]] # \u83b7\u53d6anchor\u4fee\u6b63\u7684\u76ee\u6807\u503c refined_anchors = transforms . delta2bbox ( positive_anchors , positive_target_deltas , ( 0. , 0. , 0. , 0. ), ( 0.1 , 0.1 , 0.2 , 0.2 )) \u6b63\u8d1f\u6837\u672c\u7684\u7ed3\u679c # \u6b63\u8d1f\u6837\u672c\u7684\u4e2a\u6570 print ( 'rpn_target_matchs: \\t ' , rpn_target_matchs [ 0 ] . shape . as_list ()) print ( 'rpn_target_deltas: \\t ' , rpn_target_deltas [ 0 ] . shape . as_list ()) print ( 'positive_anchors: \\t ' , positive_anchors . shape . as_list ()) print ( 'negative_anchors: \\t ' , negative_anchors . shape . as_list ()) print ( 'neutral_anchors: \\t ' , neutral_anchors . shape . as_list ()) print ( 'refined_anchors: \\t ' , refined_anchors . shape . as_list () rpn_target_matchs : [ 261888 ] rpn_target_deltas : [ 256 , 4 ] positive_anchors : [ 4 , 4 ] negative_anchors : [ 252 , 4 ] neutral_anchors : [ 261632 , 4 ] refined_anchors : [ 4 , 4 ] \u5c06\u6b63\u6837\u672c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u5c06\u6b63\u6837\u672c\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = positive_anchors . numpy (), refined_boxes = refined_anchors . numpy ()) plt . show ()","title":"4.2.1 RPN\u7684\u76ee\u6807\u503c"},{"location":"objectdection/03.RCNN-demo/#422-rpn","text":"\u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u4e0d\u53ef\u8bad\u7ec3 training = False # \u83b7\u53d6backbone\u63d0\u53d6\u7684\u7279\u5f81\u7ed3\u679c C2 , C3 , C4 , C5 = model . backbone ( image , training = training ) # \u83b7\u53d6fcn\u7684\u7279\u5f81\u7ed3\u679c P2 , P3 , P4 , P5 , P6 = model . neck ([ C2 , C3 , C4 , C5 ], training = training ) \u83b7\u53d6\u9001\u5165\u5230RPN\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u9001\u5165RPN\u7f51\u7edc\u4e2d # \u83b7\u53d6\u7279\u5f81\u56fe rpn_feature_maps = [ P2 , P3 , P4 , P5 , P6 ] # \u83b7\u53d6RPN\u7684\u9884\u6d4b\u7ed3\u679c:\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c rpn_class_logits , rpn_probs , rpn_deltas = model . rpn_head ( rpn_feature_maps , training = training ) \u5c06\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684anchor\u663e\u793a\u5728\u56fe\u50cf\u4e0a # [batch_size, num_anchors, (bg prob, fg prob)] rpn\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u53bb\u7b2c\u4e00\u4e2abatch,\u6240\u6709anchor\u524d\u666f\u7684\u6982\u7387 rpn_probs_tmp = rpn_probs [ 0 , :, 1 ] # \u5c06\u7f6e\u4fe1\u5ea6top100\u7684\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a limit = 100 ix = tf . nn . top_k ( rpn_probs_tmp , k = limit ) . indices [:: - 1 ] # \u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tf . gather ( anchors , ix ) . numpy ()) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"4.2.2 RPN\u7684\u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/03.RCNN-demo/#43-fastrcnn","text":"\u5c06RPN\u7684\u7ed3\u679c\u9001\u5165\u5230\u540e\u7eed\u7f51\u7edc\u4e2d\uff0c\u8fdb\u884c\u68c0\u6d4b\uff1a \u0015\u83b7\u53d6\u5019\u9009\u533a\u57df # \u5019\u9009\u533a\u57df proposals_list = model . rpn_head . get_proposals ( rpn_probs , rpn_deltas , image_meta ) \u8fdb\u884cROIPooling rois_list = proposals_list # roipooling pooled_regions_list = model . roi_align ( ( rois_list , rcnn_feature_maps , image_meta ), training = training ) \u9884\u6d4b # \u8fdb\u884c\u9884\u6d4b rcnn_class_logits_list , rcnn_probs_list , rcnn_deltas_list = \\ model . bbox_head ( pooled_regions_list , training = training ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c detections_list = model . bbox_head . get_bboxes ( rcnn_probs_list , rcnn_deltas_list , rois_list , image_meta ) \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\u7684\u5750\u6807\uff0c\u5e76\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a # \u83b7\u5f97\u5750\u6807\u503c tmp = detections_list [ 0 ][:, : 4 ] # \u5c06\u68c0\u6d4b\u68c0\u6d4b\u7684\u6846\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . draw_boxes ( rgb_img [ 0 ], boxes = tmp . numpy ())","title":"4.3 fastRCNN\u7f51\u7edc"},{"location":"objectdection/03.RCNN-demo/#44","text":"\u4e0a\u8ff0\u6211\u4eec\u662f\u5206\u6b65\u8fdb\u884c\u9884\u6d4b\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u5728\u539f\u56fe\u50cf\u4e0a\u8fdb\u884c\u9884\u6d4b\uff1a # \u83b7\u53d6\u539f\u56fe\u50cf ori_img = get_original_image ( image [ 0 ], image_meta [ 0 ], img_mean ) # \u83b7\u53d6\u5019\u9009\u533a\u57df proposals = model . simple_test_rpn ( image [ 0 ], image_meta [ 0 ]) # \u68c0\u6d4b\u7ed3\u679c res = model . simple_test_bboxes ( image [ 0 ], image_meta [ 0 ], proposals ) # \u5c06\u68c0\u6d4b\u7ed3\u679c\u7ed8\u5236\u5728\u56fe\u50cf\u4e0a visualize . display_instances ( ori_img , res [ 'rois' ], res [ 'class_ids' ], classes , scores = res [ 'scores' ]) \u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c\u4e3a\uff1a \u603b\u7ed3 \u4e86\u89e3VOC\u6570\u636e\u96c6\u7684\u5e94\u7528\u7406\u89e3 Pascal VOC\u6570\u636e\u96c6\u4f5c\u4e3a\u57fa\u51c6\u6570\u636e\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u88ab\u4f7f\u7528\u5230 fasterRCNN\u6a21\u578b\u7684\u6784\u6210 \u4e3b\u8981\u6709RPN\u7f51\u7edc\u8fdb\u884c\u5019\u9009\u533a\u57df\u7684\u7684\u751f\u6210\uff0c\u7136\u540e\u4f7f\u7528fastRCNN\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b \u80fd\u591f\u5229\u7528fasterRCNN\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.4 \u76ee\u6807\u68c0\u6d4b"},{"location":"objectdection/04.yolo/","text":"4.4.yolo\u7cfb\u5217 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u77e5\u9053yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784\u53ca\u7f51\u7edc\u8f93\u51fa \u4e86\u89e3yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u4e86\u89e3yoloV4\u6a21\u578b YOLO\u7cfb\u5217\u7b97\u6cd5\u662f\u4e00\u7c7b\u5178\u578b\u7684one-stage\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5176\u5229\u7528anchor box\u5c06\u5206\u7c7b\u4e0e\u76ee\u6807\u5b9a\u4f4d\u7684\u56de\u5f52\u95ee\u9898\u7ed3\u5408\u8d77\u6765\uff0c\u4ece\u800c\u505a\u5230\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u548c\u6cdb\u5316\u6027\u80fd\u597d\uff0c\u6240\u4ee5\u5728\u5de5\u4e1a\u754c\u4e5f\u5341\u5206\u53d7\u6b22\u8fce\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4ecb\u7ecdYOLO \u7cfb\u5217\u7b97\u6cd5\u3002 1.yolo\u7b97\u6cd5 \u00b6 Yolo\u7b97\u6cd5\u91c7\u7528\u4e00\u4e2a\u5355\u72ec\u7684CNN\u6a21\u578b\u5b9e\u73b0end-to-end\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u5229\u7528\u6574\u5f20\u56fe\u4f5c\u4e3a\u7f51\u7edc\u7684\u8f93\u5165\uff0c\u76f4\u63a5\u5728\u8f93\u51fa\u5c42\u56de\u5f52 bounding box\uff08\u8fb9\u754c\u6846\uff09 \u7684\u4f4d\u7f6e\u53ca\u5176\u6240\u5c5e\u7684\u7c7b\u522b\uff0c\u6574\u4e2a\u7cfb\u7edf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u5c06\u8f93\u5165\u56fe\u7247resize\u5230448x448\uff0c\u7136\u540e\u9001\u5165CNN\u7f51\u7edc\uff0c\u6700\u540e\u5904\u7406\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u5f97\u5230\u68c0\u6d4b\u7684\u76ee\u6807\u3002\u76f8\u6bd4R-CNN\u7b97\u6cd5\uff0c\u5176\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5176\u901f\u5ea6\u66f4\u5feb\u3002 1.1 Yolo\u7b97\u6cd5\u601d\u60f3 \u00b6 \u5728\u4ecb\u7ecdYolo\u7b97\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u56de\u5fc6\u4e0bRCNN\u6a21\u578b\uff0cRCNN\u6a21\u578b\u63d0\u51fa\u4e86\u5019\u9009\u533a(Region Proposals)\u7684\u65b9\u6cd5\uff0c\u5148\u4ece\u56fe\u7247\u4e2d\u641c\u7d22\u51fa\u4e00\u4e9b\u53ef\u80fd\u5b58\u5728\u5bf9\u8c61\u7684\u5019\u9009\u533a\uff08Selective Search\uff09\uff0c\u5927\u69822000\u4e2a\u5de6\u53f3\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u5019\u9009\u533a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\uff0c\u4f46\u5904\u7406\u901f\u5ea6\u8f83\u6162\u3002 Yolo\u610f\u601d\u662fYou Only Look Once\uff0c\u5b83\u5e76\u6ca1\u6709\u771f\u6b63\u7684\u53bb\u6389\u5019\u9009\u533a\u57df\uff0c\u800c\u662f\u521b\u9020\u6027\u7684\u5c06\u5019\u9009\u533a\u548c\u76ee\u6807\u5206\u7c7b\u5408\u4e8c\u4e3a\u4e00\uff0c\u770b\u4e00\u773c\u56fe\u7247\u5c31\u80fd\u77e5\u9053\u6709\u54ea\u4e9b\u5bf9\u8c61\u4ee5\u53ca\u5b83\u4eec\u7684\u4f4d\u7f6e\u3002 Yolo\u6a21\u578b\u91c7\u7528\u9884\u5b9a\u4e49\u9884\u6d4b\u533a\u57df\u7684\u65b9\u6cd5\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\uff0c\u5177\u4f53\u800c\u8a00\u662f\u5c06\u539f\u59cb\u56fe\u50cf\u5212\u5206\u4e3a 7x7=49 \u4e2a\u7f51\u683c\uff08grid\uff09\uff0c\u6bcf\u4e2a\u7f51\u683c\u5141\u8bb8\u9884\u6d4b\u51fa2\u4e2a\u8fb9\u6846\uff08bounding box\uff0c\u5305\u542b\u67d0\u4e2a\u5bf9\u8c61\u7684\u77e9\u5f62\u6846\uff09\uff0c\u603b\u5171 49x2=98 \u4e2abounding box\u3002\u6211\u4eec\u5c06\u5176\u7406\u89e3\u4e3a98\u4e2a\u9884\u6d4b\u533a\uff0c\u5f88\u7c97\u7565\u7684\u8986\u76d6\u4e86\u56fe\u7247\u7684\u6574\u4e2a\u533a\u57df\uff0c\u5c31\u5728\u8fd998\u4e2a\u9884\u6d4b\u533a\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 \u53ea\u8981\u5f97\u5230\u8fd998\u4e2a\u533a\u57df\u7684\u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u518d\u8fdb\u884cNMS\u5c31\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u3002\u90a3\u5177\u4f53\u8981\u600e\u6837\u5b9e\u73b0\u5462\uff1f 1.2 Yolo\u7684\u7f51\u7edc\u7ed3\u6784 \u00b6 YOLO\u7684\u7ed3\u6784\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u5355\u7eaf\u7684\u5377\u79ef\u3001\u6c60\u5316\u6700\u540e\u52a0\u4e86\u4e24\u5c42\u5168\u8fde\u63a5\uff0c\u4ece\u7f51\u7edc\u7ed3\u6784\u4e0a\u770b\uff0c\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684CNN\u5206\u7c7b\u7f51\u7edc\u6ca1\u6709\u672c\u8d28\u7684\u533a\u522b\uff0c\u6700\u5927\u7684\u5dee\u5f02\u662f\u8f93\u51fa\u5c42\u7528\u7ebf\u6027\u51fd\u6570\u505a\u6fc0\u6d3b\u51fd\u6570\uff0c\u56e0\u4e3a\u9700\u8981\u9884\u6d4bbounding box\u7684\u4f4d\u7f6e\uff08\u6570\u503c\u578b\uff09\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5bf9\u8c61\u7684\u6982\u7387\u3002\u6240\u4ee5\u7c97\u7565\u6765\u8bf4\uff0cYOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7f51\u7edc\u7ed3\u6784\u6bd4\u8f83\u7b80\u5355\uff0c\u91cd\u70b9\u662f\u6211\u4eec\u8981\u7406\u89e3\u7f51\u7edc\u8f93\u5165\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 1.2.1 \u7f51\u7edc\u8f93\u5165 \u00b6 \u7f51\u7edc\u7684\u8f93\u5165\u662f\u539f\u59cb\u56fe\u50cf\uff0c\u552f\u4e00\u7684\u8981\u6c42\u662f\u7f29\u653e\u5230448x448\u7684\u5927\u5c0f\u3002\u4e3b\u8981\u662f\u56e0\u4e3aYolo\u7684\u7f51\u7edc\u4e2d\uff0c\u5377\u79ef\u5c42\u6700\u540e\u63a5\u4e86\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5168\u8fde\u63a5\u5c42\u662f\u8981\u6c42\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u6240\u4ee5Yolo\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u56fa\u5b9a\u4e3a448x448\u3002 1.2.2 \u7f51\u7edc\u8f93\u51fa \u00b6 \u7f51\u7edc\u7684\u8f93\u51fa\u5c31\u662f\u4e00\u4e2a7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u3002\u90a3\u8fd9\u4e2a\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u8981\u600e\u4e48\u7406\u89e3\u90a3\uff1f 1.7x7\u7f51\u683c \u00b6 \u6839\u636eYOLO\u7684\u8bbe\u8ba1\uff0c\u8f93\u5165\u56fe\u50cf\u88ab\u5212\u5206\u4e3a 7x7 \u7684\u7f51\u683c\uff08grid\uff09\uff0c\u8f93\u51fa\u5f20\u91cf\u4e2d\u7684 7x7 \u5c31\u5bf9\u5e94\u7740\u8f93\u5165\u56fe\u50cf\u7684 7x7 \u7f51\u683c\u3002\u6216\u8005\u6211\u4eec\u628a 7x7x30 \u7684\u5f20\u91cf\u770b\u4f5c 7x7=49\u4e2a30\u7ef4\u7684\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u7f51\u683c\u5bf9\u5e94\u8f93\u51fa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6bd4\u5982\u8f93\u5165\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u7f51\u683c\u5bf9\u5e94\u5230\u8f93\u51fa\u5f20\u91cf\u4e2d\u5de6\u4e0a\u89d2\u7684\u5411\u91cf\u3002 2.30\u7ef4\u5411\u91cf \u00b6 30\u7ef4\u7684\u5411\u91cf\u5305\u542b\uff1a2\u4e2abbox\u7684\u4f4d\u7f6e\u548c\u7f6e\u4fe1\u5ea6\u4ee5\u53ca\u8be5\u7f51\u683c\u5c5e\u4e8e20\u4e2a\u7c7b\u522b\u7684\u6982\u7387 2\u4e2abounding box\u7684\u4f4d\u7f6e \u6bcf\u4e2abounding box\u9700\u89814\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\uff0c(Center_x,Center_y,width,height)\uff0c\u5373(bounding box\u7684\u4e2d\u5fc3\u70b9\u7684x\u5750\u6807\uff0cy\u5750\u6807\uff0cbounding box\u7684\u5bbd\u5ea6\uff0c\u9ad8\u5ea6)\uff0c2\u4e2abounding box\u5171\u9700\u89818\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 bounding box\u7684\u7f6e\u4fe1\u5ea6 = \u8be5bounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 * \u8be5bounding box\u4e0e\u8be5\u5bf9\u8c61\u5b9e\u9645bounding box\u7684IOU\uff0c\u7528\u516c\u5f0f\u8868\u793a\u5c31\u662f\uff1a Pr(Object)\u662fbounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 Yolo\u652f\u6301\u8bc6\u522b20\u79cd\u4e0d\u540c\u7684\u5bf9\u8c61\uff08\u4eba\u3001\u9e1f\u3001\u732b\u3001\u6c7d\u8f66\u3001\u6905\u5b50\u7b49\uff09\uff0c\u6240\u4ee5\u8fd9\u91cc\u670920\u4e2a\u503c\u8868\u793a\u8be5\u7f51\u683c\u4f4d\u7f6e\u5b58\u5728\u4efb\u4e00\u79cd\u5bf9\u8c61\u7684\u6982\u7387. 1.3Yolo\u6a21\u578b\u7684\u8bad\u7ec3 \u00b6 \u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6211\u4eec\u9700\u8981\u6784\u9020\u8bad\u7ec3\u6837\u672c\u548c\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\uff0c\u624d\u80fd\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002 1.3.1\u8bad\u7ec3\u6837\u672c\u7684\u6784\u5efa \u00b6 \u5c06\u4e00\u5e45\u56fe\u7247\u8f93\u5165\u5230yolo\u6a21\u578b\u4e2d\uff0c\u5bf9\u5e94\u7684\u8f93\u51fa\u662f\u4e00\u4e2a7x7x30\u5f20\u91cf\uff0c\u6784\u5efa\u6807\u7b7elabel\u65f6\u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5bf9\u7167\u4e0b\u56fe\u6211\u4eec\u6765\u6784\u5efa\u76ee\u6807\u5411\u91cf\uff1a 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 \u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\uff0c\u5148\u627e\u5230\u5176\u4e2d\u5fc3\u70b9\u3002\u6bd4\u5982\u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\uff0c\u5176\u4e2d\u5fc3\u70b9\u5728\u9ec4\u8272\u5706\u70b9\u4f4d\u7f6e\uff0c\u4e2d\u5fc3\u70b9\u843d\u5728\u9ec4\u8272\u7f51\u683c\u5185\uff0c\u6240\u4ee5\u8fd9\u4e2a\u9ec4\u8272\u7f51\u683c\u5bf9\u5e94\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u81ea\u884c\u8f66\u7684\u6982\u7387\u662f1\uff0c\u5176\u5b83\u5bf9\u8c61\u7684\u6982\u7387\u662f0\u3002\u6240\u6709\u5176\u5b8348\u4e2a\u7f51\u683c\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u8be5\u81ea\u884c\u8f66\u7684\u6982\u7387\u90fd\u662f0\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\"\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u5bf9\u9884\u6d4b\u8be5\u5bf9\u8c61\u8d1f\u8d23\"\u3002\u72d7\u548c\u6c7d\u8f66\u7684\u5206\u7c7b\u6982\u7387\u4e5f\u662f\u540c\u6837\u7684\u65b9\u6cd5\u586b\u5199 2\u4e2abounding box\u7684\u4f4d\u7f6e \u8bad\u7ec3\u6837\u672c\u7684bbox\u4f4d\u7f6e\u5e94\u8be5\u586b\u5199\u5bf9\u8c61\u771f\u5b9e\u7684\u4f4d\u7f6ebbox\uff0c\u4f46\u4e00\u4e2a\u5bf9\u8c61\u5bf9\u5e94\u4e862\u4e2abounding box\uff0c\u8be5\u586b\u54ea\u4e00\u4e2a\u5462\uff1f\u9700\u8981\u6839\u636e\u7f51\u7edc\u8f93\u51fa\u7684bbox\u4e0e\u5bf9\u8c61\u5b9e\u9645bbox\u7684IOU\u6765\u9009\u62e9\uff0c\u6240\u4ee5\u8981\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u51b3\u5b9a\u5230\u5e95\u586b\u54ea\u4e00\u4e2abbox\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 \u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u516c\u5f0f\u4e3a\uff1a IOU_{pred}^{truth} IOU_{pred}^{truth} \u5229\u7528\u7f51\u7edc\u8f93\u51fa\u76842\u4e2abounding box\u4e0e\u5bf9\u8c61\u771f\u5b9ebounding box\u8ba1\u7b97\u51fa\u6765\u3002\u7136\u540e\u770b\u8fd92\u4e2abounding box\u7684IOU\uff0c\u54ea\u4e2a\u6bd4\u8f83\u5927\uff0c\u5c31\u7531\u54ea\u4e2abounding box\u6765\u8d1f\u8d23\u9884\u6d4b\u8be5\u5bf9\u8c61\u662f\u5426\u5b58\u5728\uff0c\u5373\u8be5bounding box\u7684Pr(Object)=1\uff0c\u540c\u65f6\u5bf9\u8c61\u771f\u5b9ebounding box\u7684\u4f4d\u7f6e\u4e5f\u5c31\u586b\u5165\u8be5bounding box\u3002\u53e6\u4e00\u4e2a\u4e0d\u8d1f\u8d23\u9884\u6d4b\u7684bounding box\u7684Pr(Object)=0\u3002 \u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\u6240\u5728\u7684grid\u5bf9\u5e94\u7684\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.3.2 \u635f\u5931\u51fd\u6570 \u00b6 \u635f\u5931\u5c31\u662f\u7f51\u7edc\u5b9e\u9645\u8f93\u51fa\u503c\u4e0e\u6837\u672c\u6807\u7b7e\u503c\u4e4b\u95f4\u7684\u504f\u5dee\uff1a yolo\u7ed9\u51fa\u7684\u635f\u5931\u51fd\u6570\uff1a \u6ce8\uff1a\u5176\u4e2d 1_{i}^{obj} 1_{i}^{obj} \u8868\u793a\u76ee\u6807\u662f\u5426\u51fa\u73b0\u5728\u7f51\u683c\u5355\u5143i\u4e2d\uff0c 1_{ij}^{obj} 1_{ij}^{obj} \u8868\u793a\u5355\u5143\u683ci\u4e2d\u7684\u7b2cj\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u8d1f\u8d23\u8be5\u9884\u6d4b\uff0cYOLO\u8bbe\u7f6e \\lambda_{coord} = 5 \\lambda_{coord} = 5 \u6765\u8c03\u9ad8\u4f4d\u7f6e\u8bef\u5dee\u7684\u6743\u91cd\uff0c \\lambda_{noobj} = 0.5 \\lambda_{noobj} = 0.5 \u5373\u8c03\u4f4e\u4e0d\u5b58\u5728\u5bf9\u8c61\u7684bounding box\u7684\u7f6e\u4fe1\u5ea6\u8bef\u5dee\u7684\u6743\u91cd\u3002 1.3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 Yolo\u5148\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u5bf9\u524d20\u5c42\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u4f7f\u7528\u5b8c\u6574\u7684\u7f51\u7edc\uff0c\u5728PASCAL VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\u548c\u5b9a\u4f4d\u7684\u8bad\u7ec3\u3002 Yolo\u7684\u6700\u540e\u4e00\u5c42\u91c7\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u5176\u5b83\u5c42\u90fd\u662fLeaky ReLU\u3002\u8bad\u7ec3\u4e2d\u91c7\u7528\u4e86drop out\u548c\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u6765\u9632\u6b62\u8fc7\u62df\u5408. 1.4 \u6a21\u578b\u9884\u6d4b \u00b6 \u5c06\u56fe\u7247resize\u6210448x448\u7684\u5927\u5c0f\uff0c\u9001\u5165\u5230yolo\u7f51\u7edc\u4e2d\uff0c\u8f93\u51fa\u4e00\u4e2a 7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u6765\u8868\u793a\u56fe\u7247\u4e2d\u6240\u6709\u7f51\u683c\u5305\u542b\u7684\u5bf9\u8c61\uff08\u6982\u7387\uff09\u4ee5\u53ca\u8be5\u5bf9\u8c61\u53ef\u80fd\u76842\u4e2a\u4f4d\u7f6e\uff08bounding box\uff09\u548c\u53ef\u4fe1\u7a0b\u5ea6\uff08\u7f6e\u4fe1\u5ea6\uff09\u3002\u5728\u91c7\u7528NMS\uff08Non-maximal suppression\uff0c\u975e\u6781\u5927\u503c\u6291\u5236\uff09\u7b97\u6cd5\u9009\u51fa\u6700\u6709\u53ef\u80fd\u662f\u76ee\u6807\u7684\u7ed3\u679c\u3002 1.5 yolo\u603b\u7ed3 \u00b6 \u4f18\u70b9 \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u5904\u7406\u901f\u5ea6\u53ef\u4ee5\u8fbe\u523045fps\uff0c\u5176\u5feb\u901f\u7248\u672c\uff08\u7f51\u7edc\u8f83\u5c0f\uff09\u751a\u81f3\u53ef\u4ee5\u8fbe\u5230155fps\u3002 \u8bad\u7ec3\u548c\u9884\u6d4b\u53ef\u4ee5\u7aef\u5230\u7aef\u7684\u8fdb\u884c\uff0c\u975e\u5e38\u7b80\u4fbf\u3002 \u7f3a\u70b9 \u51c6\u786e\u7387\u4f1a\u6253\u6298\u6263 \u5bf9\u4e8e\u5c0f\u76ee\u6807\u548c\u9760\u7684\u5f88\u8fd1\u7684\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u5e76\u4e0d\u597d 2.yoloV2 \u00b6 YOLOv2\u76f8\u5bf9v1\u7248\u672c\uff0c\u5728\u7ee7\u7eed\u4fdd\u6301\u5904\u7406\u901f\u5ea6\u7684\u57fa\u7840\u4e0a\uff0c\u4ece\u9884\u6d4b\u66f4\u51c6\u786e\uff08Better\uff09\uff0c\u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09\uff0c\u8bc6\u522b\u5bf9\u8c61\u66f4\u591a\uff08Stronger\uff09\u8fd9\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6539\u8fdb\u3002\u5176\u4e2d\u8bc6\u522b\u66f4\u591a\u5bf9\u8c61\u4e5f\u5c31\u662f\u6269\u5c55\u5230\u80fd\u591f\u68c0\u6d4b9000\u79cd\u4e0d\u540c\u5bf9\u8c61\uff0c\u79f0\u4e4b\u4e3aYOLO9000\u3002 \u4e0b\u9762\u6211\u4eec\u770b\u4e0byoloV2\u7684\u90fd\u505a\u4e86\u54ea\u4e9b\u6539\u8fdb\uff1f 2.1 \u9884\u6d4b\u66f4\u51c6\u786e\uff08better\uff09 \u00b6 2.1.1 batch normalization \u00b6 \u6279\u6807\u51c6\u5316\u6709\u52a9\u4e8e\u89e3\u51b3\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8\u95ee\u9898\uff0c\u964d\u4f4e\u5bf9\u4e00\u4e9b\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\uff0c\u5e76\u4e14\u6bcf\u4e2abatch\u5206\u522b\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u65f6\u5019\uff0c\u8d77\u5230\u4e86\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff0c\u4ece\u800c\u80fd\u591f\u83b7\u5f97\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u6536\u655b\u6548\u679c\u3002\u5728yoloV2\u4e2d\u5377\u79ef\u540e\u5168\u90e8\u52a0\u5165Batch Normalization\uff0c\u7f51\u7edc\u4f1a\u63d0\u53472%\u7684mAP\u3002 2.1.2 \u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5fae\u8c03\u5206\u7c7b\u6a21\u578b \u00b6 YOLO v1\u4f7f\u7528ImageNet\u7684\u56fe\u50cf\u5206\u7c7b\u6837\u672c\u91c7\u7528 224x224 \u4f5c\u4e3a\u8f93\u5165\uff0c\u6765\u8bad\u7ec3CNN\u5377\u79ef\u5c42\u3002\u7136\u540e\u5728\u8bad\u7ec3\u5bf9\u8c61\u68c0\u6d4b\u65f6\uff0c\u68c0\u6d4b\u7528\u7684\u56fe\u50cf\u6837\u672c\u91c7\u7528\u66f4\u9ad8\u5206\u8fa8\u7387\u7684 448x448 \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\u3002\u4f46\u8fd9\u6837\u5207\u6362\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u4e00\u5b9a\u5f71\u54cd\u3002 YOLOV2\u5728\u91c7\u7528 224x224 \u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u9884\u8bad\u7ec3\u540e\uff0c\u518d\u91c7\u7528 448x448 \u7684\u9ad8\u5206\u8fa8\u7387\u6837\u672c\u5bf9\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0810\u4e2aepoch\uff09\uff0c\u4f7f\u7f51\u7edc\u7279\u5f81\u9010\u6e10\u9002\u5e94 448x448 \u7684\u5206\u8fa8\u7387\u3002\u7136\u540e\u518d\u4f7f\u7528 448x448 \u7684\u68c0\u6d4b\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u7f13\u89e3\u4e86\u5206\u8fa8\u7387\u7a81\u7136\u5207\u6362\u9020\u6210\u7684\u5f71\u54cd\u3002 \u4f7f\u7528\u8be5\u6280\u5de7\u540e\u7f51\u7edc\u7684mAP\u63d0\u5347\u4e86\u7ea64%\u3002 2.1.3 \u91c7\u7528Anchor Boxes \u00b6 YOLO1\u5e76\u6ca1\u6709\u91c7\u7528\u5148\u9a8c\u6846\uff0c\u5e76\u4e14\u6bcf\u4e2agrid\u53ea\u9884\u6d4b\u4e24\u4e2abounding box\uff0c\u6574\u4e2a\u56fe\u50cf98\u4e2a\u3002YOLO2\u5982\u679c\u6bcf\u4e2agrid\u91c7\u75285\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u670913x13x5=845\u4e2a\u5148\u9a8c\u6846\u3002\u901a\u8fc7\u5f15\u5165anchor boxes\uff0c\u4f7f\u5f97\u9884\u6d4b\u7684box\u6570\u91cf\u66f4\u591a\uff0813x13xn\uff09\u3002 2.2.4 \u805a\u7c7b\u63d0\u53d6anchor\u5c3a\u5ea6 \u00b6 Faster-rcnn\u9009\u62e9\u7684anchor\u6bd4\u4f8b\u90fd\u662f\u624b\u52a8\u6307\u5b9a\u7684\uff0c\u4f46\u662f\u4e0d\u4e00\u5b9a\u5b8c\u5168\u9002\u5408\u6570\u636e\u96c6\u3002YOLO2\u5c1d\u8bd5\u7edf\u8ba1\u51fa\u66f4\u7b26\u5408\u6837\u672c\u4e2d\u5bf9\u8c61\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u51cf\u5c11\u7f51\u7edc\u5fae\u8c03\u5148\u9a8c\u6846\u5230\u5b9e\u9645\u4f4d\u7f6e\u7684\u96be\u5ea6\u3002YOLO2\u7684\u505a\u6cd5\u662f\u5bf9\u8bad\u7ec3\u96c6\u4e2d\u6807\u6ce8\u7684\u8fb9\u6846\u8fdb\u884c\u805a\u7c7b\u5206\u6790\uff0c\u4ee5\u5bfb\u627e\u5c3d\u53ef\u80fd\u5339\u914d\u6837\u672c\u7684\u8fb9\u6846\u5c3a\u5bf8\u3002 YoloV2\u9009\u62e9\u4e86\u805a\u7c7b\u7684\u4e94\u79cd\u5c3a\u5bf8\u6700\u4e3aanchor box\u3002 2.1.5 \u8fb9\u6846\u4f4d\u7f6e\u7684\u9884\u6d4b \u00b6 Yolov2\u4e2d\u5c06\u8fb9\u6846\u7684\u7ed3\u679c\u7ea6\u675f\u5728\u7279\u5b9a\u7684\u7f51\u683c\u4e2d\uff1a \u5176\u4e2d\uff0c b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\u3002 Pr(object)\u2217IOU(b,object) Pr(object)\u2217IOU(b,object) \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cYOLO1\u662f\u76f4\u63a5\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u503c\uff0c\u8fd9\u91cc\u5bf9\u9884\u6d4b\u53c2\u6570 t_o t_o \u8fdb\u884c\u03c3\u53d8\u6362\u540e\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u7684\u503c\u3002 c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c\u8981\u5148\u5c06\u7f51\u683c\u5927\u5c0f\u5f52\u4e00\u5316\uff0c\u5373\u4ee4\u4e00\u4e2a\u7f51\u683c\u7684\u5bbd=1\uff0c\u9ad8=1\u3002 p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002 \u03c3\u662fsigmoid\u51fd\u6570\u3002 t_x,t_y,t_w,t_h,t_o t_x,t_y,t_w,t_h,t_o \u662f\u8981\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5206\u522b\u7528\u4e8e\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\uff0c\u4ee5\u53ca\u7f6e\u4fe1\u5ea6\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8e\u03c3\u51fd\u6570\u5c06 t_x,t_y t_x,t_y \u7ea6\u675f\u5728(0,1)\u8303\u56f4\u5185\uff0c\u9884\u6d4b\u8fb9\u6846\u7684\u84dd\u8272\u4e2d\u5fc3\u70b9\u88ab\u7ea6\u675f\u5728\u84dd\u8272\u80cc\u666f\u7684\u7f51\u683c\u5185\u3002\u7ea6\u675f\u8fb9\u6846\u4f4d\u7f6e\u4f7f\u5f97\u6a21\u578b\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4e14\u9884\u6d4b\u66f4\u4e3a\u7a33\u5b9a\u3002 \u5047\u8bbe\u7f51\u7edc\u9884\u6d4b\u503c\u4e3a\uff1a anchor\u6846\u4e3a\uff1a \u5219\u76ee\u6807\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff1a \u5728\u539f\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff1a 2.1.6 \u7ec6\u7c92\u5ea6\u7279\u5f81\u878d\u5408 \u00b6 \u56fe\u50cf\u4e2d\u5bf9\u8c61\u4f1a\u6709\u5927\u6709\u5c0f\uff0c\u8f93\u5165\u56fe\u50cf\u7ecf\u8fc7\u591a\u5c42\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u4e2d\uff0c\u8f83\u5c0f\u7684\u5bf9\u8c61\u53ef\u80fd\u7279\u5f81\u5df2\u7ecf\u4e0d\u660e\u663e\u751a\u81f3\u88ab\u5ffd\u7565\u6389\u4e86\u3002\u4e3a\u4e86\u66f4\u597d\u7684\u68c0\u6d4b\u51fa\u4e00\u4e9b\u6bd4\u8f83\u5c0f\u7684\u5bf9\u8c61\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u9700\u8981\u4fdd\u7559\u4e00\u4e9b\u66f4\u7ec6\u8282\u7684\u4fe1\u606f\u3002 YOLO2\u5f15\u5165\u4e00\u79cd\u79f0\u4e3apassthrough\u5c42\u7684\u65b9\u6cd5\u5728\u7279\u5f81\u56fe\u4e2d\u4fdd\u7559\u4e00\u4e9b\u7ec6\u8282\u4fe1\u606f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u5728\u6700\u540e\u4e00\u4e2apooling\u4e4b\u524d\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u662f26x26x512\uff0c\u5c06\u51761\u62c64\uff0c\u76f4\u63a5\u4f20\u9012\uff08passthrough\uff09\u5230pooling\u540e\uff08\u5e76\u4e14\u53c8\u7ecf\u8fc7\u4e00\u7ec4\u5377\u79ef\uff09\u7684\u7279\u5f81\u56fe\uff0c\u4e24\u8005\u53e0\u52a0\u5230\u4e00\u8d77\u4f5c\u4e3a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u3002 \u5177\u4f53\u7684\u62c6\u5206\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a 2.1.7 \u591a\u5c3a\u5ea6\u8bad\u7ec3 \u00b6 YOLO2\u4e2d\u6ca1\u6709\u5168\u8fde\u63a5\u5c42\uff0c\u53ef\u4ee5\u8f93\u5165\u4efb\u4f55\u5c3a\u5bf8\u7684\u56fe\u50cf\u3002\u56e0\u4e3a\u6574\u4e2a\u7f51\u7edc\u4e0b\u91c7\u6837\u500d\u6570\u662f32\uff0c\u91c7\u7528\u4e86{320,352,...,608}\u7b4910\u79cd\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u8fd9\u4e9b\u5c3a\u5bf8\u7684\u8f93\u5165\u56fe\u50cf\u5bf9\u5e94\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5bbd\u548c\u9ad8\u662f{10,11,...19}\u3002\u8bad\u7ec3\u65f6\u6bcf10\u4e2abatch\u5c31\u968f\u673a\u66f4\u6362\u4e00\u79cd\u5c3a\u5bf8\uff0c\u4f7f\u7f51\u7edc\u80fd\u591f\u9002\u5e94\u5404\u79cd\u5927\u5c0f\u7684\u5bf9\u8c61\u68c0\u6d4b\u3002 2.2 \u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09 \u00b6 yoloV2\u63d0\u51fa\u4e86Darknet-19\uff08\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxPooling\u5c42\uff09\u7f51\u7edc\u7ed3\u6784\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002DarkNet-19\u6bd4VGG-16\u5c0f\u4e00\u4e9b\uff0c\u7cbe\u5ea6\u4e0d\u5f31\u4e8eVGG-16\uff0c\u4f46\u6d6e\u70b9\u8fd0\u7b97\u91cf\u51cf\u5c11\u5230\u7ea6\u2155\uff0c\u4ee5\u4fdd\u8bc1\u66f4\u5feb\u7684\u8fd0\u7b97\u901f\u5ea6\u3002 yoloV2\u7684\u7f51\u7edc\u4e2d\u53ea\u6709\u5377\u79ef+pooling\uff0c\u4ece416x416x3 \u53d8\u6362\u5230 13x13x5x25\u3002\u589e\u52a0\u4e86batch normalization\uff0c\u589e\u52a0\u4e86\u4e00\u4e2apassthrough\u5c42\uff0c\u53bb\u6389\u4e86\u5168\u8fde\u63a5\u5c42\uff0c\u4ee5\u53ca\u91c7\u7528\u4e865\u4e2a\u5148\u9a8c\u6846,\u7f51\u7edc\u7684\u8f93\u51fa\u5982\u4e0b\u56fe\u6240\u793a\uff1a 2.3 \u8bc6\u522b\u5bf9\u8c61\u66f4\u591a \u00b6 VOC\u6570\u636e\u96c6\u53ef\u4ee5\u68c0\u6d4b20\u79cd\u5bf9\u8c61\uff0c\u4f46\u5b9e\u9645\u4e0a\u5bf9\u8c61\u7684\u79cd\u7c7b\u975e\u5e38\u591a\uff0c\u53ea\u662f\u7f3a\u5c11\u76f8\u5e94\u7684\u7528\u4e8e\u5bf9\u8c61\u68c0\u6d4b\u7684\u8bad\u7ec3\u6837\u672c\u3002YOLO2\u5c1d\u8bd5\u5229\u7528ImageNet\u975e\u5e38\u5927\u91cf\u7684\u5206\u7c7b\u6837\u672c\uff0c\u8054\u5408COCO\u7684\u5bf9\u8c61\u68c0\u6d4b\u6570\u636e\u96c6\u4e00\u8d77\u8bad\u7ec3\uff0c\u4f7f\u5f97YOLO2\u5373\u4f7f\u6ca1\u6709\u5b66\u8fc7\u5f88\u591a\u5bf9\u8c61\u7684\u68c0\u6d4b\u6837\u672c\uff0c\u4e5f\u80fd\u68c0\u6d4b\u51fa\u8fd9\u4e9b\u5bf9\u8c61\u3002 3.yoloV3 \u00b6 yoloV3\u4ee5V1\uff0cV2\u4e3a\u57fa\u7840\u8fdb\u884c\u7684\u6539\u8fdb\uff0c\u4e3b\u8981\u6709\uff1a\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1b\u5148\u9a8c\u6846\u66f4\u4e30\u5bcc\uff1b\u8c03\u6574\u4e86\u7f51\u7edc\u7ed3\u6784\uff1b\u5bf9\u8c61\u5206\u7c7b\u4f7f\u7528logistic\u4ee3\u66ff\u4e86softmax,\u66f4\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u3002 3.1\u7b97\u6cd5\u7b80\u4ecb \u00b6 YOLOv3\u662fYOLO (You Only Look Once)\u7cfb\u5217\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7684\u7b2c\u4e09\u7248\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u7b97\u6cd5\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u5c0f\u76ee\u6807\uff0c\u7cbe\u5ea6\u6709\u663e\u8457\u63d0\u5347\u3002 yoloV3\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u5e45\u8f93\u5165\u56fe\u50cf\uff0cYOLOv3\u4f1a\u9884\u6d4b\u4e09\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u76ee\u7684\u662f\u68c0\u6d4b\u51fa\u4e0d\u540c\u5927\u5c0f\u7684\u76ee\u6807\u3002 3.2\u591a\u5c3a\u5ea6\u68c0\u6d4b \u00b6 \u901a\u5e38\u4e00\u5e45\u56fe\u50cf\u5305\u542b\u5404\u79cd\u4e0d\u540c\u7684\u7269\u4f53\uff0c\u5e76\u4e14\u6709\u5927\u6709\u5c0f\u3002\u6bd4\u8f83\u7406\u60f3\u7684\u662f\u4e00\u6b21\u5c31\u53ef\u4ee5\u5c06\u6240\u6709\u5927\u5c0f\u7684\u7269\u4f53\u540c\u65f6\u68c0\u6d4b\u51fa\u6765\u3002\u56e0\u6b64\uff0c\u7f51\u7edc\u5fc5\u987b\u5177\u5907\u80fd\u591f\u201c\u770b\u5230\u201d\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53\u7684\u80fd\u529b\u3002\u56e0\u4e3a\u7f51\u7edc\u8d8a\u6df1\uff0c\u7279\u5f81\u56fe\u5c31\u4f1a\u8d8a\u5c0f\uff0c\u6240\u4ee5\u7f51\u7edc\u8d8a\u6df1\u5c0f\u7684\u7269\u4f53\u4e5f\u5c31\u8d8a\u96be\u68c0\u6d4b\u51fa\u6765\u3002 \u5728\u5b9e\u9645\u7684feature map\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u6df1\u5ea6\u7684\u52a0\u6df1\uff0c\u6d45\u5c42\u7684feature map\u4e2d\u4e3b\u8981\u5305\u542b\u4f4e\u7ea7\u7684\u4fe1\u606f\uff08\u7269\u4f53\u8fb9\u7f18\uff0c\u989c\u8272\uff0c\u521d\u7ea7\u4f4d\u7f6e\u4fe1\u606f\u7b49\uff09\uff0c\u6df1\u5c42\u7684feature map\u4e2d\u5305\u542b\u9ad8\u7b49\u4fe1\u606f\uff08\u4f8b\u5982\u7269\u4f53\u7684\u8bed\u4e49\u4fe1\u606f\uff1a\u72d7\uff0c\u732b\uff0c\u6c7d\u8f66\u7b49\u7b49\uff09\u3002\u56e0\u6b64\u5728\u4e0d\u540c\u7ea7\u522b\u7684feature map\u5bf9\u5e94\u4e0d\u540c\u7684scale\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u540c\u7ea7\u522b\u7684\u7279\u5f81\u56fe\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cdscale\u53d8\u6362\u7684\u7ecf\u5178\u65b9\u6cd5\u3002 (a) \u8fd9\u79cd\u65b9\u6cd5\u9996\u5148\u5efa\u7acb\u56fe\u50cf\u91d1\u5b57\u5854\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684\u91d1\u5b57\u5854\u56fe\u50cf\u88ab\u8f93\u5165\u5230\u5bf9\u5e94\u7684\u7f51\u7edc\u5f53\u4e2d\uff0c\u7528\u4e8e\u4e0d\u540cscale\u7269\u4f53\u7684\u68c0\u6d4b\u3002\u4f46\u8fd9\u6837\u505a\u7684\u7ed3\u679c\u5c31\u662f\u6bcf\u4e2a\u7ea7\u522b\u7684\u91d1\u5b57\u5854\u90fd\u9700\u8981\u8fdb\u884c\u4e00\u6b21\u5904\u7406\uff0c\u901f\u5ea6\u5f88\u6162\u3002 (b) \u68c0\u6d4b\u53ea\u5728\u6700\u540e\u4e00\u5c42feature map\u9636\u6bb5\u8fdb\u884c\uff0c\u8fd9\u4e2a\u7ed3\u6784\u65e0\u6cd5\u68c0\u6d4b\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53 \u00a9 \u5bf9\u4e0d\u540c\u6df1\u5ea6\u7684feature map\u5206\u522b\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002SSD\u4e2d\u91c7\u7528\u7684\u4fbf\u662f\u8fd9\u6837\u7684\u7ed3\u6784\u3002\u8fd9\u6837\u5c0f\u7684\u7269\u4f53\u4f1a\u5728\u6d45\u5c42\u7684feature map\u4e2d\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u800c\u5927\u7684\u7269\u4f53\u4f1a\u5728\u6df1\u5c42\u7684feature map\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u4ece\u800c\u8fbe\u5230\u5bf9\u5e94\u4e0d\u540cscale\u7684\u7269\u4f53\u7684\u76ee\u7684\uff0c\u7f3a\u70b9\u662f\u6bcf\u4e00\u4e2afeature map\u83b7\u5f97\u7684\u4fe1\u606f\u4ec5\u6765\u6e90\u4e8e\u4e4b\u524d\u7684\u5c42\uff0c\u4e4b\u540e\u7684\u5c42\u7684\u7279\u5f81\u4fe1\u606f\u65e0\u6cd5\u83b7\u53d6\u5e76\u52a0\u4ee5\u5229\u7528\u3002 (d) \u4e0e\u00a9\u5f88\u63a5\u8fd1\uff0c\u4f46\u4e0d\u540c\u7684\u662f\uff0c\u5f53\u524d\u5c42\u7684feature map\u4f1a\u5bf9\u672a\u6765\u5c42\u7684feature map\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684feature map\u5c31\u53ef\u4ee5\u83b7\u5f97\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u8fd9\u6837\u7684\u8bdd\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5728YOLOv3\u4e2d\uff0c\u5c31\u662f\u91c7\u7528\u8fd9\u79cd\u65b9\u5f0f\u6765\u5b9e\u73b0\u76ee\u6807\u591a\u5c3a\u5ea6\u7684\u53d8\u6362\u7684\u3002 3.3\u7f51\u7edc\u6a21\u578b\u7ed3\u6784 \u00b6 \u5728\u57fa\u672c\u7684\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u65b9\u9762\uff0cYOLO3\u91c7\u7528\u4e86Darknet-53\u7684\u7f51\u7edc\u7ed3\u6784\uff08\u542b\u670953\u4e2a\u5377\u79ef\u5c42\uff09\uff0c\u5b83\u501f\u9274\u4e86\u6b8b\u5dee\u7f51\u7edcResNet\u7684\u505a\u6cd5\uff0c\u5728\u5c42\u4e4b\u95f4\u8bbe\u7f6e\u4e86shortcut\uff0c\u6765\u89e3\u51b3\u6df1\u5c42\u7f51\u7edc\u68af\u5ea6\u7684\u95ee\u9898\uff0cshortcut\u5982\u4e0b\u56fe\u6240\u793a\uff1a\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2ashortcut connections\u3002 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 \u4e0b\u9762\u6211\u4eec\u770b\u4e0b\u7f51\u7edc\u7ed3\u6784\uff1a \u57fa\u672c\u7ec4\u4ef6\uff1a\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206 1\u3001CBL\uff1aYolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 2\u3001Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 3\u3001ResX\uff1a\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u7ecf\u8fc75\u6b21Res\u6a21\u5757\u540e\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u662f608->304->152->76->38->19\u5927\u5c0f\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a 1\u3001Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u4f1a\u6269\u5145\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u4f8b\u598226\u00d726\u00d7256\u548c26\u00d726\u00d7512\u4e24\u4e2a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ed3\u679c\u662f26\u00d726\u00d7768\u3002 2\u3001Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u5f20\u91cf\u76f4\u63a5\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u4f8b\u5982104\u00d7104\u00d7128\u548c104\u00d7104\u00d7128\u76f8\u52a0\uff0c\u7ed3\u679c\u8fd8\u662f104\u00d7104\u00d7128\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aResX\u4e2d\u5305\u542b1+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b1+\uff081+2\u00d71\uff09+\uff081+2\u00d72\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d74\uff09=52\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2aFC\u5168\u8fde\u63a5\u5c42\uff0c\u5373\u53ef\u4ee5\u7ec4\u6210\u4e00\u4e2aDarknet53\u5206\u7c7b\u7f51\u7edc\u3002\u4e0d\u8fc7\u5728\u76ee\u6807\u68c0\u6d4bYolov3\u4e2d\uff0c\u53bb\u6389FC\u5c42\uff0c\u4ecd\u7136\u628aYolov3\u7684\u4e3b\u5e72\u7f51\u7edc\u53eb\u505aDarknet53\u7ed3\u6784\u3002 3.4\u5148\u9a8c\u6846 \u00b6 yoloV3\u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 \u5728COCO\u6570\u636e\u96c6\u8fd99\u4e2a\u5148\u9a8c\u6846\u662f\uff1a(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c(116x90)\uff0c(156x198)\uff0c(373x326)\u3002\u5728\u6700\u5c0f\u7684(13x13)\u7279\u5f81\u56fe\u4e0a\uff08\u6709\u6700\u5927\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528\u8f83\u5927\u7684\u5148\u9a8c\u6846(116x90)\uff0c(156x198)\uff0c(373x326)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u5bf9\u8c61\u3002\u4e2d\u7b49\u7684(26x26)\u7279\u5f81\u56fe\u4e0a\uff08\u4e2d\u7b49\u611f\u53d7\u91ce\uff09\u5e94\u7528\u4e2d\u7b49\u7684\u5148\u9a8c\u6846(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c\u9002\u5408\u68c0\u6d4b\u4e2d\u7b49\u5927\u5c0f\u7684\u5bf9\u8c61\u3002\u8f83\u5927\u7684(52x52)\u7279\u5f81\u56fe\u4e0a\uff08\u8f83\u5c0f\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528,\u5176\u4e2d\u8f83\u5c0f\u7684\u5148\u9a8c\u6846(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u5bf9\u8c61\u3002 \u76f4\u89c2\u4e0a\u611f\u53d79\u79cd\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e0b\u56fe\u4e2d\u84dd\u8272\u6846\u4e3a\u805a\u7c7b\u5f97\u5230\u7684\u5148\u9a8c\u6846\u3002\u9ec4\u8272\u6846\u5f0fground truth\uff0c\u7ea2\u6846\u662f\u5bf9\u8c61\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u3002 3.5 logistic\u56de\u5f52 \u00b6 \u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u88ab\u66ff\u6362\u4e3a\u4e00\u4e2a1x1\u7684\u5377\u79ef\u5c42+logistic\u6fc0\u6d3b\u51fd\u6570\u7684\u7ed3\u6784\u3002\u4f7f\u7528softmax\u5c42\u7684\u65f6\u5019\u5176\u5b9e\u5df2\u7ecf\u5047\u8bbe\u6bcf\u4e2a\u8f93\u51fa\u4ec5\u5bf9\u5e94\u67d0\u4e00\u4e2a\u5355\u4e2a\u7684class\uff0c\u4f46\u662f\u5728\u67d0\u4e9bclass\u5b58\u5728\u91cd\u53e0\u60c5\u51b5\uff08\u4f8b\u5982woman\u548cperson\uff09\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u4f7f\u7528softmax\u5c31\u4e0d\u80fd\u4f7f\u7f51\u7edc\u5bf9\u6570\u636e\u8fdb\u884c\u5f88\u597d\u7684\u9884\u6d4b\u3002 3.6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u4e0e\u8f93\u51fa \u00b6 YoloV3\u7684\u8f93\u5165\u8f93\u51fa\u5f62\u5f0f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165416\u00d7416\u00d73\u7684\u56fe\u50cf\uff0c\u901a\u8fc7darknet\u7f51\u7edc\u5f97\u5230\u4e09\u79cd\u4e0d\u540c\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u90fd\u5bf9\u5e94N\u4e2a\u901a\u9053\uff0c\u5305\u542b\u7740\u9884\u6d4b\u7684\u4fe1\u606f\uff1b \u6bcf\u4e2a\u7f51\u683c\u6bcf\u4e2a\u5c3a\u5bf8\u7684anchors\u7684\u9884\u6d4b\u7ed3\u679c\u3002 YOLOv3\u5171\u670913\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73\u4e2a\u9884\u6d4b \u3002\u6bcf\u4e2a\u9884\u6d4b\u5bf9\u5e9485\u7ef4\uff0c\u5206\u522b\u662f4\uff08\u5750\u6807\u503c\uff09\u30011\uff08\u7f6e\u4fe1\u5ea6\u5206\u6570\uff09\u300180\uff08coco\u7c7b\u522b\u6982\u7387\uff09\u3002 4.yoloV4[\u4e86\u89e3] \u00b6 YOLO\u4e4b\u7236\u57282020\u5e74\u521d\u5ba3\u5e03\u9000\u51faCV\u754c\uff0cYOLOv4 \u7684\u4f5c\u8005\u5e76\u4e0d\u662fYOLO\u7cfb\u5217 \u7684\u539f\u4f5c\u8005\u3002YOLO V4\u662fYOLO\u7cfb\u5217\u4e00\u4e2a\u91cd\u5927\u7684\u66f4\u65b0\uff0c\u5176\u5728COCO\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u7cbe\u5ea6(AP)\u548c\u5e27\u7387\u7cbe\u5ea6(FPS)\u5206\u522b\u63d0\u9ad8\u4e8610% \u548c12%\uff0c\u5e76\u5f97\u5230\u4e86Joseph Redmon\u7684\u5b98\u65b9\u8ba4\u53ef\uff0c\u88ab\u8ba4\u4e3a\u662f\u5f53\u524d\u6700\u5f3a\u7684\u5b9e\u65f6\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u4e4b\u4e00\u3002 yoloV4\u603b\u7ed3\u4e86\u5927\u90e8\u5206\u68c0\u6d4b\u6280\u5de7\uff0c\u7136\u540e\u7ecf\u8fc7\u7b5b\u9009\uff0c\u6392\u5217\u7ec4\u5408\uff0c\u6328\u4e2a\u5b9e\u9a8c\uff08ablation study\uff09\u54ea\u4e9b\u65b9\u6cd5\u6709\u6548\uff0c\u603b\u4f53\u6765\u8bf4\uff0cYolov4\u5e76\u6ca1\u6709\u521b\u9020\u65b0\u7684\u6539\u8fdb\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u5927\u91cf\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6280\u5de7\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u7ed9\u5927\u5bb6\u770b\u4e0b\u5b83\u7684\u7f51\u7edc\u67b6\u6784\uff1a Yolov4\u7684\u7ed3\u6784\u56fe\u548cYolov3\u662f\u76f8\u4f3c\u7684\uff0c\u4e0d\u8fc7\u4f7f\u7528\u5404\u79cd\u65b0\u7684\u7b97\u6cd5\u601d\u60f3\u5bf9\u5404\u4e2a\u5b50\u7ed3\u6784\u90fd\u8fdb\u884c\u4e86\u6539\u8fdb\u3002 \u5148\u6574\u7406\u4e0bYolov4\u7684\u7ed3\u6784\u7ec4\u4ef6 \u57fa\u672c\u7ec4\u4ef6\uff1a CBM\uff1aYolov4\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Mish\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 CBL\uff1a\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 CSPX\uff1a\u7531\u4e09\u4e2a\u5377\u79ef\u5c42\u548cX\u4e2aRes unint\u6a21\u5757Concate\u7ec4\u6210\u3002 SPP\uff1a\u91c7\u75281\u00d71\uff0c5\u00d75\uff0c9\u00d79\uff0c13\u00d713\u7684\u6700\u5927\u6c60\u5316\u7684\u65b9\u5f0f\uff0c\u8fdb\u884c\u591a\u5c3a\u5ea6\u878d\u5408\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ef4\u5ea6\u4f1a\u6269\u5145\uff0c\u548cYolov3\u4e2d\u7684\u89e3\u91ca\u4e00\u6837\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684route\u64cd\u4f5c\u3002 Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684shortcut\u64cd\u4f5c\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aCSPX\u4e2d\u5305\u542b3+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b2+\uff083+2\u00d71\uff09+2+\uff083+2\u00d72\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d74\uff09+1=72\u3002 \u6ce8\u610f\uff1a \u7f51\u7edc\u7684\u8f93\u5165\u5927\u5c0f\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u5728yoloV3\u4e2d\u8f93\u5165\u9ed8\u8ba4\u662f416\u00d7416\uff0c\u5728yoloV4\u4e2d\u9ed8\u8ba4\u662f608\u00d7608\uff0c\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u4e5f\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4fee\u6539\uff0c\u6bd4\u5982320\u00d7320\uff0c\u4e00\u822c\u662f32\u7684\u500d\u6570\u3002 \u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u548c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e5f\u662f\u5bf9\u5e94\u7684\uff0c\u6bd4\u5982416\u00d7416\u7684\u8f93\u5165\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u662f13\u00d713\uff0c26\u00d726\uff0c52\u00d752\uff0c \u5982\u679c\u662f608\u00d7608\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u5219\u662f19\u00d719\uff0c38\u00d738\uff0c76\u00d776\u3002 \u603b\u7ed3 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa YOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\uff1a\u5206\u7c7b\uff0c\u7f6e\u4fe1\u5ea6\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503c \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u635f\u5931\u51fd\u6570\u5206\u4e3a3\u90e8\u5206\uff1a\u5206\u7c7b\u635f\u5931\uff0c\u56de\u5f52\u635f\u5931\uff0c\u7f6e\u4fe1\u5ea6\u635f\u5931 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u4f7f\u7528\u4e86BN\u5c42\uff0c\u9ad8\u5206\u8fa8\u7387\u8bad\u7ec3\uff0c\u91c7\u7528Anchorbox\uff0c\u805a\u7c7b\u5f97\u5230anchorbox\u7684\u5c3a\u5bf8\uff0c\u6539\u8fdb\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u7279\u5f81\u878d\u5408\uff0c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u7f51\u7edc\u6a21\u578b\u4f7f\u7528darknet19\uff0c\u5229\u7528imagenet\u6570\u636e\u96c6\u8bc6\u522b\u66f4\u591a\u7684\u76ee\u6807 yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u5728YOLOv3\u4e2d\u91c7\u7528FPN\u7ed3\u6784\u6765\u63d0\u9ad8\u5bf9\u5e94\u591a\u5c3a\u5ea6\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\uff0c\u5f53\u524d\u7684feature map\u5229\u7528\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u5c06\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u8fdb\u884c\u878d\u5408\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002 yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784 \u4ee5darknet-53\u4e3a\u57fa\u7840\uff0c\u501f\u9274resnet\u7684\u601d\u60f3\uff0c\u5728\u7f51\u7edc\u4e2d\u52a0\u5165\u4e86\u6b8b\u5dee\u6a21\u5757\uff0c\u5229\u4e8e\u89e3\u51b3\u6df1\u5c42\u6b21\u7f51\u7edc\u7684\u68af\u5ea6\u95ee\u9898 \u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u53ea\u6709\u5377\u79ef\u5c42 \u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684 yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u4f7f\u7528logistic\u7684\u8f93\u51fa\u8fdb\u884c\u9884\u6d4b yoloV3\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa \u5bf9\u4e8e416\u00d7416\u00d73\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u7684\u6bcf\u4e2a\u7f51\u683c\u8bbe\u7f6e3\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u6709 13\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73 = 10647 \u4e2a\u9884\u6d4b\u3002\u6bcf\u4e00\u4e2a\u9884\u6d4b\u662f\u4e00\u4e2a(4+1+80)=85\u7ef4\u5411\u91cf\uff0c\u8fd9\u4e2a85\u7ef4\u5411\u91cf\u5305\u542b\u8fb9\u6846\u5750\u6807\uff084\u4e2a\u6570\u503c\uff09\uff0c\u8fb9\u6846\u7f6e\u4fe1\u5ea6\uff081\u4e2a\u6570\u503c\uff09\uff0c\u5bf9\u8c61\u7c7b\u522b\u7684\u6982\u7387\uff08\u5bf9\u4e8eCOCO\u6570\u636e\u96c6\uff0c\u670980\u79cd\u5bf9\u8c61\uff09\u3002","title":"YOLO\u7cfb\u5217\u7b97\u6cd5"},{"location":"objectdection/04.yolo/#44yolo","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u77e5\u9053yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784\u53ca\u7f51\u7edc\u8f93\u51fa \u4e86\u89e3yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u77e5\u9053yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u4e86\u89e3yoloV4\u6a21\u578b YOLO\u7cfb\u5217\u7b97\u6cd5\u662f\u4e00\u7c7b\u5178\u578b\u7684one-stage\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5176\u5229\u7528anchor box\u5c06\u5206\u7c7b\u4e0e\u76ee\u6807\u5b9a\u4f4d\u7684\u56de\u5f52\u95ee\u9898\u7ed3\u5408\u8d77\u6765\uff0c\u4ece\u800c\u505a\u5230\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u548c\u6cdb\u5316\u6027\u80fd\u597d\uff0c\u6240\u4ee5\u5728\u5de5\u4e1a\u754c\u4e5f\u5341\u5206\u53d7\u6b22\u8fce\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4ecb\u7ecdYOLO \u7cfb\u5217\u7b97\u6cd5\u3002","title":"4.4.yolo\u7cfb\u5217"},{"location":"objectdection/04.yolo/#1yolo","text":"Yolo\u7b97\u6cd5\u91c7\u7528\u4e00\u4e2a\u5355\u72ec\u7684CNN\u6a21\u578b\u5b9e\u73b0end-to-end\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u5229\u7528\u6574\u5f20\u56fe\u4f5c\u4e3a\u7f51\u7edc\u7684\u8f93\u5165\uff0c\u76f4\u63a5\u5728\u8f93\u51fa\u5c42\u56de\u5f52 bounding box\uff08\u8fb9\u754c\u6846\uff09 \u7684\u4f4d\u7f6e\u53ca\u5176\u6240\u5c5e\u7684\u7c7b\u522b\uff0c\u6574\u4e2a\u7cfb\u7edf\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u9996\u5148\u5c06\u8f93\u5165\u56fe\u7247resize\u5230448x448\uff0c\u7136\u540e\u9001\u5165CNN\u7f51\u7edc\uff0c\u6700\u540e\u5904\u7406\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u5f97\u5230\u68c0\u6d4b\u7684\u76ee\u6807\u3002\u76f8\u6bd4R-CNN\u7b97\u6cd5\uff0c\u5176\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5176\u901f\u5ea6\u66f4\u5feb\u3002","title":"1.yolo\u7b97\u6cd5"},{"location":"objectdection/04.yolo/#11-yolo","text":"\u5728\u4ecb\u7ecdYolo\u7b97\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u56de\u5fc6\u4e0bRCNN\u6a21\u578b\uff0cRCNN\u6a21\u578b\u63d0\u51fa\u4e86\u5019\u9009\u533a(Region Proposals)\u7684\u65b9\u6cd5\uff0c\u5148\u4ece\u56fe\u7247\u4e2d\u641c\u7d22\u51fa\u4e00\u4e9b\u53ef\u80fd\u5b58\u5728\u5bf9\u8c61\u7684\u5019\u9009\u533a\uff08Selective Search\uff09\uff0c\u5927\u69822000\u4e2a\u5de6\u53f3\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u5019\u9009\u533a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\uff0c\u4f46\u5904\u7406\u901f\u5ea6\u8f83\u6162\u3002 Yolo\u610f\u601d\u662fYou Only Look Once\uff0c\u5b83\u5e76\u6ca1\u6709\u771f\u6b63\u7684\u53bb\u6389\u5019\u9009\u533a\u57df\uff0c\u800c\u662f\u521b\u9020\u6027\u7684\u5c06\u5019\u9009\u533a\u548c\u76ee\u6807\u5206\u7c7b\u5408\u4e8c\u4e3a\u4e00\uff0c\u770b\u4e00\u773c\u56fe\u7247\u5c31\u80fd\u77e5\u9053\u6709\u54ea\u4e9b\u5bf9\u8c61\u4ee5\u53ca\u5b83\u4eec\u7684\u4f4d\u7f6e\u3002 Yolo\u6a21\u578b\u91c7\u7528\u9884\u5b9a\u4e49\u9884\u6d4b\u533a\u57df\u7684\u65b9\u6cd5\u6765\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\uff0c\u5177\u4f53\u800c\u8a00\u662f\u5c06\u539f\u59cb\u56fe\u50cf\u5212\u5206\u4e3a 7x7=49 \u4e2a\u7f51\u683c\uff08grid\uff09\uff0c\u6bcf\u4e2a\u7f51\u683c\u5141\u8bb8\u9884\u6d4b\u51fa2\u4e2a\u8fb9\u6846\uff08bounding box\uff0c\u5305\u542b\u67d0\u4e2a\u5bf9\u8c61\u7684\u77e9\u5f62\u6846\uff09\uff0c\u603b\u5171 49x2=98 \u4e2abounding box\u3002\u6211\u4eec\u5c06\u5176\u7406\u89e3\u4e3a98\u4e2a\u9884\u6d4b\u533a\uff0c\u5f88\u7c97\u7565\u7684\u8986\u76d6\u4e86\u56fe\u7247\u7684\u6574\u4e2a\u533a\u57df\uff0c\u5c31\u5728\u8fd998\u4e2a\u9884\u6d4b\u533a\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 \u53ea\u8981\u5f97\u5230\u8fd998\u4e2a\u533a\u57df\u7684\u76ee\u6807\u5206\u7c7b\u548c\u56de\u5f52\u7ed3\u679c\uff0c\u518d\u8fdb\u884cNMS\u5c31\u53ef\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u3002\u90a3\u5177\u4f53\u8981\u600e\u6837\u5b9e\u73b0\u5462\uff1f","title":"1.1 Yolo\u7b97\u6cd5\u601d\u60f3"},{"location":"objectdection/04.yolo/#12-yolo","text":"YOLO\u7684\u7ed3\u6784\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u5355\u7eaf\u7684\u5377\u79ef\u3001\u6c60\u5316\u6700\u540e\u52a0\u4e86\u4e24\u5c42\u5168\u8fde\u63a5\uff0c\u4ece\u7f51\u7edc\u7ed3\u6784\u4e0a\u770b\uff0c\u4e0e\u524d\u9762\u4ecb\u7ecd\u7684CNN\u5206\u7c7b\u7f51\u7edc\u6ca1\u6709\u672c\u8d28\u7684\u533a\u522b\uff0c\u6700\u5927\u7684\u5dee\u5f02\u662f\u8f93\u51fa\u5c42\u7528\u7ebf\u6027\u51fd\u6570\u505a\u6fc0\u6d3b\u51fd\u6570\uff0c\u56e0\u4e3a\u9700\u8981\u9884\u6d4bbounding box\u7684\u4f4d\u7f6e\uff08\u6570\u503c\u578b\uff09\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5bf9\u8c61\u7684\u6982\u7387\u3002\u6240\u4ee5\u7c97\u7565\u6765\u8bf4\uff0cYOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7f51\u7edc\u7ed3\u6784\u6bd4\u8f83\u7b80\u5355\uff0c\u91cd\u70b9\u662f\u6211\u4eec\u8981\u7406\u89e3\u7f51\u7edc\u8f93\u5165\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u5173\u7cfb\u3002","title":"1.2 Yolo\u7684\u7f51\u7edc\u7ed3\u6784"},{"location":"objectdection/04.yolo/#121","text":"\u7f51\u7edc\u7684\u8f93\u5165\u662f\u539f\u59cb\u56fe\u50cf\uff0c\u552f\u4e00\u7684\u8981\u6c42\u662f\u7f29\u653e\u5230448x448\u7684\u5927\u5c0f\u3002\u4e3b\u8981\u662f\u56e0\u4e3aYolo\u7684\u7f51\u7edc\u4e2d\uff0c\u5377\u79ef\u5c42\u6700\u540e\u63a5\u4e86\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5168\u8fde\u63a5\u5c42\u662f\u8981\u6c42\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u6240\u4ee5Yolo\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u56fa\u5b9a\u4e3a448x448\u3002","title":"1.2.1 \u7f51\u7edc\u8f93\u5165"},{"location":"objectdection/04.yolo/#122","text":"\u7f51\u7edc\u7684\u8f93\u51fa\u5c31\u662f\u4e00\u4e2a7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u3002\u90a3\u8fd9\u4e2a\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u8981\u600e\u4e48\u7406\u89e3\u90a3\uff1f","title":"1.2.2 \u7f51\u7edc\u8f93\u51fa"},{"location":"objectdection/04.yolo/#17x7","text":"\u6839\u636eYOLO\u7684\u8bbe\u8ba1\uff0c\u8f93\u5165\u56fe\u50cf\u88ab\u5212\u5206\u4e3a 7x7 \u7684\u7f51\u683c\uff08grid\uff09\uff0c\u8f93\u51fa\u5f20\u91cf\u4e2d\u7684 7x7 \u5c31\u5bf9\u5e94\u7740\u8f93\u5165\u56fe\u50cf\u7684 7x7 \u7f51\u683c\u3002\u6216\u8005\u6211\u4eec\u628a 7x7x30 \u7684\u5f20\u91cf\u770b\u4f5c 7x7=49\u4e2a30\u7ef4\u7684\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u7f51\u683c\u5bf9\u5e94\u8f93\u51fa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6bd4\u5982\u8f93\u5165\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u7f51\u683c\u5bf9\u5e94\u5230\u8f93\u51fa\u5f20\u91cf\u4e2d\u5de6\u4e0a\u89d2\u7684\u5411\u91cf\u3002","title":"1.7x7\u7f51\u683c"},{"location":"objectdection/04.yolo/#230","text":"30\u7ef4\u7684\u5411\u91cf\u5305\u542b\uff1a2\u4e2abbox\u7684\u4f4d\u7f6e\u548c\u7f6e\u4fe1\u5ea6\u4ee5\u53ca\u8be5\u7f51\u683c\u5c5e\u4e8e20\u4e2a\u7c7b\u522b\u7684\u6982\u7387 2\u4e2abounding box\u7684\u4f4d\u7f6e \u6bcf\u4e2abounding box\u9700\u89814\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\uff0c(Center_x,Center_y,width,height)\uff0c\u5373(bounding box\u7684\u4e2d\u5fc3\u70b9\u7684x\u5750\u6807\uff0cy\u5750\u6807\uff0cbounding box\u7684\u5bbd\u5ea6\uff0c\u9ad8\u5ea6)\uff0c2\u4e2abounding box\u5171\u9700\u89818\u4e2a\u6570\u503c\u6765\u8868\u793a\u5176\u4f4d\u7f6e\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 bounding box\u7684\u7f6e\u4fe1\u5ea6 = \u8be5bounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 * \u8be5bounding box\u4e0e\u8be5\u5bf9\u8c61\u5b9e\u9645bounding box\u7684IOU\uff0c\u7528\u516c\u5f0f\u8868\u793a\u5c31\u662f\uff1a Pr(Object)\u662fbounding box\u5185\u5b58\u5728\u5bf9\u8c61\u7684\u6982\u7387 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 Yolo\u652f\u6301\u8bc6\u522b20\u79cd\u4e0d\u540c\u7684\u5bf9\u8c61\uff08\u4eba\u3001\u9e1f\u3001\u732b\u3001\u6c7d\u8f66\u3001\u6905\u5b50\u7b49\uff09\uff0c\u6240\u4ee5\u8fd9\u91cc\u670920\u4e2a\u503c\u8868\u793a\u8be5\u7f51\u683c\u4f4d\u7f6e\u5b58\u5728\u4efb\u4e00\u79cd\u5bf9\u8c61\u7684\u6982\u7387.","title":"2.30\u7ef4\u5411\u91cf"},{"location":"objectdection/04.yolo/#13yolo","text":"\u5728\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6211\u4eec\u9700\u8981\u6784\u9020\u8bad\u7ec3\u6837\u672c\u548c\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\uff0c\u624d\u80fd\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002","title":"1.3Yolo\u6a21\u578b\u7684\u8bad\u7ec3"},{"location":"objectdection/04.yolo/#131","text":"\u5c06\u4e00\u5e45\u56fe\u7247\u8f93\u5165\u5230yolo\u6a21\u578b\u4e2d\uff0c\u5bf9\u5e94\u7684\u8f93\u51fa\u662f\u4e00\u4e2a7x7x30\u5f20\u91cf\uff0c\u6784\u5efa\u6807\u7b7elabel\u65f6\u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\u3002\u5bf9\u7167\u4e0b\u56fe\u6211\u4eec\u6765\u6784\u5efa\u76ee\u6807\u5411\u91cf\uff1a 20\u4e2a\u5bf9\u8c61\u5206\u7c7b\u7684\u6982\u7387 \u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\uff0c\u5148\u627e\u5230\u5176\u4e2d\u5fc3\u70b9\u3002\u6bd4\u5982\u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\uff0c\u5176\u4e2d\u5fc3\u70b9\u5728\u9ec4\u8272\u5706\u70b9\u4f4d\u7f6e\uff0c\u4e2d\u5fc3\u70b9\u843d\u5728\u9ec4\u8272\u7f51\u683c\u5185\uff0c\u6240\u4ee5\u8fd9\u4e2a\u9ec4\u8272\u7f51\u683c\u5bf9\u5e94\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u81ea\u884c\u8f66\u7684\u6982\u7387\u662f1\uff0c\u5176\u5b83\u5bf9\u8c61\u7684\u6982\u7387\u662f0\u3002\u6240\u6709\u5176\u5b8348\u4e2a\u7f51\u683c\u768430\u7ef4\u5411\u91cf\u4e2d\uff0c\u8be5\u81ea\u884c\u8f66\u7684\u6982\u7387\u90fd\u662f0\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\"\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u5bf9\u9884\u6d4b\u8be5\u5bf9\u8c61\u8d1f\u8d23\"\u3002\u72d7\u548c\u6c7d\u8f66\u7684\u5206\u7c7b\u6982\u7387\u4e5f\u662f\u540c\u6837\u7684\u65b9\u6cd5\u586b\u5199 2\u4e2abounding box\u7684\u4f4d\u7f6e \u8bad\u7ec3\u6837\u672c\u7684bbox\u4f4d\u7f6e\u5e94\u8be5\u586b\u5199\u5bf9\u8c61\u771f\u5b9e\u7684\u4f4d\u7f6ebbox\uff0c\u4f46\u4e00\u4e2a\u5bf9\u8c61\u5bf9\u5e94\u4e862\u4e2abounding box\uff0c\u8be5\u586b\u54ea\u4e00\u4e2a\u5462\uff1f\u9700\u8981\u6839\u636e\u7f51\u7edc\u8f93\u51fa\u7684bbox\u4e0e\u5bf9\u8c61\u5b9e\u9645bbox\u7684IOU\u6765\u9009\u62e9\uff0c\u6240\u4ee5\u8981\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u51b3\u5b9a\u5230\u5e95\u586b\u54ea\u4e00\u4e2abbox\u3002 2\u4e2abounding box\u7684\u7f6e\u4fe1\u5ea6 \u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u516c\u5f0f\u4e3a\uff1a IOU_{pred}^{truth} IOU_{pred}^{truth} \u5229\u7528\u7f51\u7edc\u8f93\u51fa\u76842\u4e2abounding box\u4e0e\u5bf9\u8c61\u771f\u5b9ebounding box\u8ba1\u7b97\u51fa\u6765\u3002\u7136\u540e\u770b\u8fd92\u4e2abounding box\u7684IOU\uff0c\u54ea\u4e2a\u6bd4\u8f83\u5927\uff0c\u5c31\u7531\u54ea\u4e2abounding box\u6765\u8d1f\u8d23\u9884\u6d4b\u8be5\u5bf9\u8c61\u662f\u5426\u5b58\u5728\uff0c\u5373\u8be5bounding box\u7684Pr(Object)=1\uff0c\u540c\u65f6\u5bf9\u8c61\u771f\u5b9ebounding box\u7684\u4f4d\u7f6e\u4e5f\u5c31\u586b\u5165\u8be5bounding box\u3002\u53e6\u4e00\u4e2a\u4e0d\u8d1f\u8d23\u9884\u6d4b\u7684bounding box\u7684Pr(Object)=0\u3002 \u4e0a\u56fe\u4e2d\u81ea\u884c\u8f66\u6240\u5728\u7684grid\u5bf9\u5e94\u7684\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.3.1\u8bad\u7ec3\u6837\u672c\u7684\u6784\u5efa"},{"location":"objectdection/04.yolo/#132","text":"\u635f\u5931\u5c31\u662f\u7f51\u7edc\u5b9e\u9645\u8f93\u51fa\u503c\u4e0e\u6837\u672c\u6807\u7b7e\u503c\u4e4b\u95f4\u7684\u504f\u5dee\uff1a yolo\u7ed9\u51fa\u7684\u635f\u5931\u51fd\u6570\uff1a \u6ce8\uff1a\u5176\u4e2d 1_{i}^{obj} 1_{i}^{obj} \u8868\u793a\u76ee\u6807\u662f\u5426\u51fa\u73b0\u5728\u7f51\u683c\u5355\u5143i\u4e2d\uff0c 1_{ij}^{obj} 1_{ij}^{obj} \u8868\u793a\u5355\u5143\u683ci\u4e2d\u7684\u7b2cj\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u8d1f\u8d23\u8be5\u9884\u6d4b\uff0cYOLO\u8bbe\u7f6e \\lambda_{coord} = 5 \\lambda_{coord} = 5 \u6765\u8c03\u9ad8\u4f4d\u7f6e\u8bef\u5dee\u7684\u6743\u91cd\uff0c \\lambda_{noobj} = 0.5 \\lambda_{noobj} = 0.5 \u5373\u8c03\u4f4e\u4e0d\u5b58\u5728\u5bf9\u8c61\u7684bounding box\u7684\u7f6e\u4fe1\u5ea6\u8bef\u5dee\u7684\u6743\u91cd\u3002","title":"1.3.2 \u635f\u5931\u51fd\u6570"},{"location":"objectdection/04.yolo/#133","text":"Yolo\u5148\u4f7f\u7528ImageNet\u6570\u636e\u96c6\u5bf9\u524d20\u5c42\u5377\u79ef\u7f51\u7edc\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u4f7f\u7528\u5b8c\u6574\u7684\u7f51\u7edc\uff0c\u5728PASCAL VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5bf9\u8c61\u8bc6\u522b\u548c\u5b9a\u4f4d\u7684\u8bad\u7ec3\u3002 Yolo\u7684\u6700\u540e\u4e00\u5c42\u91c7\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u5176\u5b83\u5c42\u90fd\u662fLeaky ReLU\u3002\u8bad\u7ec3\u4e2d\u91c7\u7528\u4e86drop out\u548c\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u6765\u9632\u6b62\u8fc7\u62df\u5408.","title":"1.3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/04.yolo/#14","text":"\u5c06\u56fe\u7247resize\u6210448x448\u7684\u5927\u5c0f\uff0c\u9001\u5165\u5230yolo\u7f51\u7edc\u4e2d\uff0c\u8f93\u51fa\u4e00\u4e2a 7x7x30 \u7684\u5f20\u91cf\uff08tensor\uff09\u6765\u8868\u793a\u56fe\u7247\u4e2d\u6240\u6709\u7f51\u683c\u5305\u542b\u7684\u5bf9\u8c61\uff08\u6982\u7387\uff09\u4ee5\u53ca\u8be5\u5bf9\u8c61\u53ef\u80fd\u76842\u4e2a\u4f4d\u7f6e\uff08bounding box\uff09\u548c\u53ef\u4fe1\u7a0b\u5ea6\uff08\u7f6e\u4fe1\u5ea6\uff09\u3002\u5728\u91c7\u7528NMS\uff08Non-maximal suppression\uff0c\u975e\u6781\u5927\u503c\u6291\u5236\uff09\u7b97\u6cd5\u9009\u51fa\u6700\u6709\u53ef\u80fd\u662f\u76ee\u6807\u7684\u7ed3\u679c\u3002","title":"1.4 \u6a21\u578b\u9884\u6d4b"},{"location":"objectdection/04.yolo/#15-yolo","text":"\u4f18\u70b9 \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u5904\u7406\u901f\u5ea6\u53ef\u4ee5\u8fbe\u523045fps\uff0c\u5176\u5feb\u901f\u7248\u672c\uff08\u7f51\u7edc\u8f83\u5c0f\uff09\u751a\u81f3\u53ef\u4ee5\u8fbe\u5230155fps\u3002 \u8bad\u7ec3\u548c\u9884\u6d4b\u53ef\u4ee5\u7aef\u5230\u7aef\u7684\u8fdb\u884c\uff0c\u975e\u5e38\u7b80\u4fbf\u3002 \u7f3a\u70b9 \u51c6\u786e\u7387\u4f1a\u6253\u6298\u6263 \u5bf9\u4e8e\u5c0f\u76ee\u6807\u548c\u9760\u7684\u5f88\u8fd1\u7684\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u5e76\u4e0d\u597d","title":"1.5 yolo\u603b\u7ed3"},{"location":"objectdection/04.yolo/#2yolov2","text":"YOLOv2\u76f8\u5bf9v1\u7248\u672c\uff0c\u5728\u7ee7\u7eed\u4fdd\u6301\u5904\u7406\u901f\u5ea6\u7684\u57fa\u7840\u4e0a\uff0c\u4ece\u9884\u6d4b\u66f4\u51c6\u786e\uff08Better\uff09\uff0c\u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09\uff0c\u8bc6\u522b\u5bf9\u8c61\u66f4\u591a\uff08Stronger\uff09\u8fd9\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u6539\u8fdb\u3002\u5176\u4e2d\u8bc6\u522b\u66f4\u591a\u5bf9\u8c61\u4e5f\u5c31\u662f\u6269\u5c55\u5230\u80fd\u591f\u68c0\u6d4b9000\u79cd\u4e0d\u540c\u5bf9\u8c61\uff0c\u79f0\u4e4b\u4e3aYOLO9000\u3002 \u4e0b\u9762\u6211\u4eec\u770b\u4e0byoloV2\u7684\u90fd\u505a\u4e86\u54ea\u4e9b\u6539\u8fdb\uff1f","title":"2.yoloV2"},{"location":"objectdection/04.yolo/#21-better","text":"","title":"2.1 \u9884\u6d4b\u66f4\u51c6\u786e\uff08better\uff09"},{"location":"objectdection/04.yolo/#211-batch-normalization","text":"\u6279\u6807\u51c6\u5316\u6709\u52a9\u4e8e\u89e3\u51b3\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8\u95ee\u9898\uff0c\u964d\u4f4e\u5bf9\u4e00\u4e9b\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\uff0c\u5e76\u4e14\u6bcf\u4e2abatch\u5206\u522b\u8fdb\u884c\u5f52\u4e00\u5316\u7684\u65f6\u5019\uff0c\u8d77\u5230\u4e86\u4e00\u5b9a\u7684\u6b63\u5219\u5316\u6548\u679c\uff0c\u4ece\u800c\u80fd\u591f\u83b7\u5f97\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u6536\u655b\u6548\u679c\u3002\u5728yoloV2\u4e2d\u5377\u79ef\u540e\u5168\u90e8\u52a0\u5165Batch Normalization\uff0c\u7f51\u7edc\u4f1a\u63d0\u53472%\u7684mAP\u3002","title":"2.1.1 batch normalization"},{"location":"objectdection/04.yolo/#212","text":"YOLO v1\u4f7f\u7528ImageNet\u7684\u56fe\u50cf\u5206\u7c7b\u6837\u672c\u91c7\u7528 224x224 \u4f5c\u4e3a\u8f93\u5165\uff0c\u6765\u8bad\u7ec3CNN\u5377\u79ef\u5c42\u3002\u7136\u540e\u5728\u8bad\u7ec3\u5bf9\u8c61\u68c0\u6d4b\u65f6\uff0c\u68c0\u6d4b\u7528\u7684\u56fe\u50cf\u6837\u672c\u91c7\u7528\u66f4\u9ad8\u5206\u8fa8\u7387\u7684 448x448 \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\u3002\u4f46\u8fd9\u6837\u5207\u6362\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u4e00\u5b9a\u5f71\u54cd\u3002 YOLOV2\u5728\u91c7\u7528 224x224 \u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u9884\u8bad\u7ec3\u540e\uff0c\u518d\u91c7\u7528 448x448 \u7684\u9ad8\u5206\u8fa8\u7387\u6837\u672c\u5bf9\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0810\u4e2aepoch\uff09\uff0c\u4f7f\u7f51\u7edc\u7279\u5f81\u9010\u6e10\u9002\u5e94 448x448 \u7684\u5206\u8fa8\u7387\u3002\u7136\u540e\u518d\u4f7f\u7528 448x448 \u7684\u68c0\u6d4b\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u7f13\u89e3\u4e86\u5206\u8fa8\u7387\u7a81\u7136\u5207\u6362\u9020\u6210\u7684\u5f71\u54cd\u3002 \u4f7f\u7528\u8be5\u6280\u5de7\u540e\u7f51\u7edc\u7684mAP\u63d0\u5347\u4e86\u7ea64%\u3002","title":"2.1.2 \u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5fae\u8c03\u5206\u7c7b\u6a21\u578b"},{"location":"objectdection/04.yolo/#213-anchor-boxes","text":"YOLO1\u5e76\u6ca1\u6709\u91c7\u7528\u5148\u9a8c\u6846\uff0c\u5e76\u4e14\u6bcf\u4e2agrid\u53ea\u9884\u6d4b\u4e24\u4e2abounding box\uff0c\u6574\u4e2a\u56fe\u50cf98\u4e2a\u3002YOLO2\u5982\u679c\u6bcf\u4e2agrid\u91c7\u75285\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u670913x13x5=845\u4e2a\u5148\u9a8c\u6846\u3002\u901a\u8fc7\u5f15\u5165anchor boxes\uff0c\u4f7f\u5f97\u9884\u6d4b\u7684box\u6570\u91cf\u66f4\u591a\uff0813x13xn\uff09\u3002","title":"2.1.3 \u91c7\u7528Anchor Boxes"},{"location":"objectdection/04.yolo/#224-anchor","text":"Faster-rcnn\u9009\u62e9\u7684anchor\u6bd4\u4f8b\u90fd\u662f\u624b\u52a8\u6307\u5b9a\u7684\uff0c\u4f46\u662f\u4e0d\u4e00\u5b9a\u5b8c\u5168\u9002\u5408\u6570\u636e\u96c6\u3002YOLO2\u5c1d\u8bd5\u7edf\u8ba1\u51fa\u66f4\u7b26\u5408\u6837\u672c\u4e2d\u5bf9\u8c61\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u51cf\u5c11\u7f51\u7edc\u5fae\u8c03\u5148\u9a8c\u6846\u5230\u5b9e\u9645\u4f4d\u7f6e\u7684\u96be\u5ea6\u3002YOLO2\u7684\u505a\u6cd5\u662f\u5bf9\u8bad\u7ec3\u96c6\u4e2d\u6807\u6ce8\u7684\u8fb9\u6846\u8fdb\u884c\u805a\u7c7b\u5206\u6790\uff0c\u4ee5\u5bfb\u627e\u5c3d\u53ef\u80fd\u5339\u914d\u6837\u672c\u7684\u8fb9\u6846\u5c3a\u5bf8\u3002 YoloV2\u9009\u62e9\u4e86\u805a\u7c7b\u7684\u4e94\u79cd\u5c3a\u5bf8\u6700\u4e3aanchor box\u3002","title":"2.2.4 \u805a\u7c7b\u63d0\u53d6anchor\u5c3a\u5ea6"},{"location":"objectdection/04.yolo/#215","text":"Yolov2\u4e2d\u5c06\u8fb9\u6846\u7684\u7ed3\u679c\u7ea6\u675f\u5728\u7279\u5b9a\u7684\u7f51\u683c\u4e2d\uff1a \u5176\u4e2d\uff0c b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\u3002 Pr(object)\u2217IOU(b,object) Pr(object)\u2217IOU(b,object) \u662f\u9884\u6d4b\u8fb9\u6846\u7684\u7f6e\u4fe1\u5ea6\uff0cYOLO1\u662f\u76f4\u63a5\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u503c\uff0c\u8fd9\u91cc\u5bf9\u9884\u6d4b\u53c2\u6570 t_o t_o \u8fdb\u884c\u03c3\u53d8\u6362\u540e\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u7684\u503c\u3002 c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c\u8981\u5148\u5c06\u7f51\u683c\u5927\u5c0f\u5f52\u4e00\u5316\uff0c\u5373\u4ee4\u4e00\u4e2a\u7f51\u683c\u7684\u5bbd=1\uff0c\u9ad8=1\u3002 p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002 \u03c3\u662fsigmoid\u51fd\u6570\u3002 t_x,t_y,t_w,t_h,t_o t_x,t_y,t_w,t_h,t_o \u662f\u8981\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5206\u522b\u7528\u4e8e\u9884\u6d4b\u8fb9\u6846\u7684\u4e2d\u5fc3\u548c\u5bbd\u9ad8\uff0c\u4ee5\u53ca\u7f6e\u4fe1\u5ea6\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff1a \u7531\u4e8e\u03c3\u51fd\u6570\u5c06 t_x,t_y t_x,t_y \u7ea6\u675f\u5728(0,1)\u8303\u56f4\u5185\uff0c\u9884\u6d4b\u8fb9\u6846\u7684\u84dd\u8272\u4e2d\u5fc3\u70b9\u88ab\u7ea6\u675f\u5728\u84dd\u8272\u80cc\u666f\u7684\u7f51\u683c\u5185\u3002\u7ea6\u675f\u8fb9\u6846\u4f4d\u7f6e\u4f7f\u5f97\u6a21\u578b\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4e14\u9884\u6d4b\u66f4\u4e3a\u7a33\u5b9a\u3002 \u5047\u8bbe\u7f51\u7edc\u9884\u6d4b\u503c\u4e3a\uff1a anchor\u6846\u4e3a\uff1a \u5219\u76ee\u6807\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff1a \u5728\u539f\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\uff1a","title":"2.1.5 \u8fb9\u6846\u4f4d\u7f6e\u7684\u9884\u6d4b"},{"location":"objectdection/04.yolo/#216","text":"\u56fe\u50cf\u4e2d\u5bf9\u8c61\u4f1a\u6709\u5927\u6709\u5c0f\uff0c\u8f93\u5165\u56fe\u50cf\u7ecf\u8fc7\u591a\u5c42\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u4e2d\uff0c\u8f83\u5c0f\u7684\u5bf9\u8c61\u53ef\u80fd\u7279\u5f81\u5df2\u7ecf\u4e0d\u660e\u663e\u751a\u81f3\u88ab\u5ffd\u7565\u6389\u4e86\u3002\u4e3a\u4e86\u66f4\u597d\u7684\u68c0\u6d4b\u51fa\u4e00\u4e9b\u6bd4\u8f83\u5c0f\u7684\u5bf9\u8c61\uff0c\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u9700\u8981\u4fdd\u7559\u4e00\u4e9b\u66f4\u7ec6\u8282\u7684\u4fe1\u606f\u3002 YOLO2\u5f15\u5165\u4e00\u79cd\u79f0\u4e3apassthrough\u5c42\u7684\u65b9\u6cd5\u5728\u7279\u5f81\u56fe\u4e2d\u4fdd\u7559\u4e00\u4e9b\u7ec6\u8282\u4fe1\u606f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u5728\u6700\u540e\u4e00\u4e2apooling\u4e4b\u524d\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u662f26x26x512\uff0c\u5c06\u51761\u62c64\uff0c\u76f4\u63a5\u4f20\u9012\uff08passthrough\uff09\u5230pooling\u540e\uff08\u5e76\u4e14\u53c8\u7ecf\u8fc7\u4e00\u7ec4\u5377\u79ef\uff09\u7684\u7279\u5f81\u56fe\uff0c\u4e24\u8005\u53e0\u52a0\u5230\u4e00\u8d77\u4f5c\u4e3a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u3002 \u5177\u4f53\u7684\u62c6\u5206\u65b9\u6cd5\u5982\u4e0b\u6240\u793a\uff1a","title":"2.1.6 \u7ec6\u7c92\u5ea6\u7279\u5f81\u878d\u5408"},{"location":"objectdection/04.yolo/#217","text":"YOLO2\u4e2d\u6ca1\u6709\u5168\u8fde\u63a5\u5c42\uff0c\u53ef\u4ee5\u8f93\u5165\u4efb\u4f55\u5c3a\u5bf8\u7684\u56fe\u50cf\u3002\u56e0\u4e3a\u6574\u4e2a\u7f51\u7edc\u4e0b\u91c7\u6837\u500d\u6570\u662f32\uff0c\u91c7\u7528\u4e86{320,352,...,608}\u7b4910\u79cd\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\uff0c\u8fd9\u4e9b\u5c3a\u5bf8\u7684\u8f93\u5165\u56fe\u50cf\u5bf9\u5e94\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5bbd\u548c\u9ad8\u662f{10,11,...19}\u3002\u8bad\u7ec3\u65f6\u6bcf10\u4e2abatch\u5c31\u968f\u673a\u66f4\u6362\u4e00\u79cd\u5c3a\u5bf8\uff0c\u4f7f\u7f51\u7edc\u80fd\u591f\u9002\u5e94\u5404\u79cd\u5927\u5c0f\u7684\u5bf9\u8c61\u68c0\u6d4b\u3002","title":"2.1.7 \u591a\u5c3a\u5ea6\u8bad\u7ec3"},{"location":"objectdection/04.yolo/#22-faster","text":"yoloV2\u63d0\u51fa\u4e86Darknet-19\uff08\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxPooling\u5c42\uff09\u7f51\u7edc\u7ed3\u6784\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3002DarkNet-19\u6bd4VGG-16\u5c0f\u4e00\u4e9b\uff0c\u7cbe\u5ea6\u4e0d\u5f31\u4e8eVGG-16\uff0c\u4f46\u6d6e\u70b9\u8fd0\u7b97\u91cf\u51cf\u5c11\u5230\u7ea6\u2155\uff0c\u4ee5\u4fdd\u8bc1\u66f4\u5feb\u7684\u8fd0\u7b97\u901f\u5ea6\u3002 yoloV2\u7684\u7f51\u7edc\u4e2d\u53ea\u6709\u5377\u79ef+pooling\uff0c\u4ece416x416x3 \u53d8\u6362\u5230 13x13x5x25\u3002\u589e\u52a0\u4e86batch normalization\uff0c\u589e\u52a0\u4e86\u4e00\u4e2apassthrough\u5c42\uff0c\u53bb\u6389\u4e86\u5168\u8fde\u63a5\u5c42\uff0c\u4ee5\u53ca\u91c7\u7528\u4e865\u4e2a\u5148\u9a8c\u6846,\u7f51\u7edc\u7684\u8f93\u51fa\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"2.2 \u901f\u5ea6\u66f4\u5feb\uff08Faster\uff09"},{"location":"objectdection/04.yolo/#23","text":"VOC\u6570\u636e\u96c6\u53ef\u4ee5\u68c0\u6d4b20\u79cd\u5bf9\u8c61\uff0c\u4f46\u5b9e\u9645\u4e0a\u5bf9\u8c61\u7684\u79cd\u7c7b\u975e\u5e38\u591a\uff0c\u53ea\u662f\u7f3a\u5c11\u76f8\u5e94\u7684\u7528\u4e8e\u5bf9\u8c61\u68c0\u6d4b\u7684\u8bad\u7ec3\u6837\u672c\u3002YOLO2\u5c1d\u8bd5\u5229\u7528ImageNet\u975e\u5e38\u5927\u91cf\u7684\u5206\u7c7b\u6837\u672c\uff0c\u8054\u5408COCO\u7684\u5bf9\u8c61\u68c0\u6d4b\u6570\u636e\u96c6\u4e00\u8d77\u8bad\u7ec3\uff0c\u4f7f\u5f97YOLO2\u5373\u4f7f\u6ca1\u6709\u5b66\u8fc7\u5f88\u591a\u5bf9\u8c61\u7684\u68c0\u6d4b\u6837\u672c\uff0c\u4e5f\u80fd\u68c0\u6d4b\u51fa\u8fd9\u4e9b\u5bf9\u8c61\u3002","title":"2.3 \u8bc6\u522b\u5bf9\u8c61\u66f4\u591a"},{"location":"objectdection/04.yolo/#3yolov3","text":"yoloV3\u4ee5V1\uff0cV2\u4e3a\u57fa\u7840\u8fdb\u884c\u7684\u6539\u8fdb\uff0c\u4e3b\u8981\u6709\uff1a\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1b\u5148\u9a8c\u6846\u66f4\u4e30\u5bcc\uff1b\u8c03\u6574\u4e86\u7f51\u7edc\u7ed3\u6784\uff1b\u5bf9\u8c61\u5206\u7c7b\u4f7f\u7528logistic\u4ee3\u66ff\u4e86softmax,\u66f4\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u3002","title":"3.yoloV3"},{"location":"objectdection/04.yolo/#31","text":"YOLOv3\u662fYOLO (You Only Look Once)\u7cfb\u5217\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u7684\u7b2c\u4e09\u7248\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u7b97\u6cd5\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u5c0f\u76ee\u6807\uff0c\u7cbe\u5ea6\u6709\u663e\u8457\u63d0\u5347\u3002 yoloV3\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u5e45\u8f93\u5165\u56fe\u50cf\uff0cYOLOv3\u4f1a\u9884\u6d4b\u4e09\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u76ee\u7684\u662f\u68c0\u6d4b\u51fa\u4e0d\u540c\u5927\u5c0f\u7684\u76ee\u6807\u3002","title":"3.1\u7b97\u6cd5\u7b80\u4ecb"},{"location":"objectdection/04.yolo/#32","text":"\u901a\u5e38\u4e00\u5e45\u56fe\u50cf\u5305\u542b\u5404\u79cd\u4e0d\u540c\u7684\u7269\u4f53\uff0c\u5e76\u4e14\u6709\u5927\u6709\u5c0f\u3002\u6bd4\u8f83\u7406\u60f3\u7684\u662f\u4e00\u6b21\u5c31\u53ef\u4ee5\u5c06\u6240\u6709\u5927\u5c0f\u7684\u7269\u4f53\u540c\u65f6\u68c0\u6d4b\u51fa\u6765\u3002\u56e0\u6b64\uff0c\u7f51\u7edc\u5fc5\u987b\u5177\u5907\u80fd\u591f\u201c\u770b\u5230\u201d\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53\u7684\u80fd\u529b\u3002\u56e0\u4e3a\u7f51\u7edc\u8d8a\u6df1\uff0c\u7279\u5f81\u56fe\u5c31\u4f1a\u8d8a\u5c0f\uff0c\u6240\u4ee5\u7f51\u7edc\u8d8a\u6df1\u5c0f\u7684\u7269\u4f53\u4e5f\u5c31\u8d8a\u96be\u68c0\u6d4b\u51fa\u6765\u3002 \u5728\u5b9e\u9645\u7684feature map\u4e2d\uff0c\u968f\u7740\u7f51\u7edc\u6df1\u5ea6\u7684\u52a0\u6df1\uff0c\u6d45\u5c42\u7684feature map\u4e2d\u4e3b\u8981\u5305\u542b\u4f4e\u7ea7\u7684\u4fe1\u606f\uff08\u7269\u4f53\u8fb9\u7f18\uff0c\u989c\u8272\uff0c\u521d\u7ea7\u4f4d\u7f6e\u4fe1\u606f\u7b49\uff09\uff0c\u6df1\u5c42\u7684feature map\u4e2d\u5305\u542b\u9ad8\u7b49\u4fe1\u606f\uff08\u4f8b\u5982\u7269\u4f53\u7684\u8bed\u4e49\u4fe1\u606f\uff1a\u72d7\uff0c\u732b\uff0c\u6c7d\u8f66\u7b49\u7b49\uff09\u3002\u56e0\u6b64\u5728\u4e0d\u540c\u7ea7\u522b\u7684feature map\u5bf9\u5e94\u4e0d\u540c\u7684scale\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u540c\u7ea7\u522b\u7684\u7279\u5f81\u56fe\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cdscale\u53d8\u6362\u7684\u7ecf\u5178\u65b9\u6cd5\u3002 (a) \u8fd9\u79cd\u65b9\u6cd5\u9996\u5148\u5efa\u7acb\u56fe\u50cf\u91d1\u5b57\u5854\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684\u91d1\u5b57\u5854\u56fe\u50cf\u88ab\u8f93\u5165\u5230\u5bf9\u5e94\u7684\u7f51\u7edc\u5f53\u4e2d\uff0c\u7528\u4e8e\u4e0d\u540cscale\u7269\u4f53\u7684\u68c0\u6d4b\u3002\u4f46\u8fd9\u6837\u505a\u7684\u7ed3\u679c\u5c31\u662f\u6bcf\u4e2a\u7ea7\u522b\u7684\u91d1\u5b57\u5854\u90fd\u9700\u8981\u8fdb\u884c\u4e00\u6b21\u5904\u7406\uff0c\u901f\u5ea6\u5f88\u6162\u3002 (b) \u68c0\u6d4b\u53ea\u5728\u6700\u540e\u4e00\u5c42feature map\u9636\u6bb5\u8fdb\u884c\uff0c\u8fd9\u4e2a\u7ed3\u6784\u65e0\u6cd5\u68c0\u6d4b\u4e0d\u540c\u5927\u5c0f\u7684\u7269\u4f53 \u00a9 \u5bf9\u4e0d\u540c\u6df1\u5ea6\u7684feature map\u5206\u522b\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002SSD\u4e2d\u91c7\u7528\u7684\u4fbf\u662f\u8fd9\u6837\u7684\u7ed3\u6784\u3002\u8fd9\u6837\u5c0f\u7684\u7269\u4f53\u4f1a\u5728\u6d45\u5c42\u7684feature map\u4e2d\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u800c\u5927\u7684\u7269\u4f53\u4f1a\u5728\u6df1\u5c42\u7684feature map\u88ab\u68c0\u6d4b\u51fa\u6765\uff0c\u4ece\u800c\u8fbe\u5230\u5bf9\u5e94\u4e0d\u540cscale\u7684\u7269\u4f53\u7684\u76ee\u7684\uff0c\u7f3a\u70b9\u662f\u6bcf\u4e00\u4e2afeature map\u83b7\u5f97\u7684\u4fe1\u606f\u4ec5\u6765\u6e90\u4e8e\u4e4b\u524d\u7684\u5c42\uff0c\u4e4b\u540e\u7684\u5c42\u7684\u7279\u5f81\u4fe1\u606f\u65e0\u6cd5\u83b7\u53d6\u5e76\u52a0\u4ee5\u5229\u7528\u3002 (d) \u4e0e\u00a9\u5f88\u63a5\u8fd1\uff0c\u4f46\u4e0d\u540c\u7684\u662f\uff0c\u5f53\u524d\u5c42\u7684feature map\u4f1a\u5bf9\u672a\u6765\u5c42\u7684feature map\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u52a0\u4ee5\u5229\u7528\u3002\u56e0\u4e3a\u6709\u4e86\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff0c\u5f53\u524d\u7684feature map\u5c31\u53ef\u4ee5\u83b7\u5f97\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u8fd9\u6837\u7684\u8bdd\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u5c31\u6709\u673a\u878d\u5408\u8d77\u6765\u4e86\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002\u5728YOLOv3\u4e2d\uff0c\u5c31\u662f\u91c7\u7528\u8fd9\u79cd\u65b9\u5f0f\u6765\u5b9e\u73b0\u76ee\u6807\u591a\u5c3a\u5ea6\u7684\u53d8\u6362\u7684\u3002","title":"3.2\u591a\u5c3a\u5ea6\u68c0\u6d4b"},{"location":"objectdection/04.yolo/#33","text":"\u5728\u57fa\u672c\u7684\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u65b9\u9762\uff0cYOLO3\u91c7\u7528\u4e86Darknet-53\u7684\u7f51\u7edc\u7ed3\u6784\uff08\u542b\u670953\u4e2a\u5377\u79ef\u5c42\uff09\uff0c\u5b83\u501f\u9274\u4e86\u6b8b\u5dee\u7f51\u7edcResNet\u7684\u505a\u6cd5\uff0c\u5728\u5c42\u4e4b\u95f4\u8bbe\u7f6e\u4e86shortcut\uff0c\u6765\u89e3\u51b3\u6df1\u5c42\u7f51\u7edc\u68af\u5ea6\u7684\u95ee\u9898\uff0cshortcut\u5982\u4e0b\u56fe\u6240\u793a\uff1a\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2ashortcut connections\u3002 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 \u4e0b\u9762\u6211\u4eec\u770b\u4e0b\u7f51\u7edc\u7ed3\u6784\uff1a \u57fa\u672c\u7ec4\u4ef6\uff1a\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206 1\u3001CBL\uff1aYolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 2\u3001Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 3\u3001ResX\uff1a\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u7ecf\u8fc75\u6b21Res\u6a21\u5757\u540e\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u662f608->304->152->76->38->19\u5927\u5c0f\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a 1\u3001Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u4f1a\u6269\u5145\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u4f8b\u598226\u00d726\u00d7256\u548c26\u00d726\u00d7512\u4e24\u4e2a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ed3\u679c\u662f26\u00d726\u00d7768\u3002 2\u3001Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u5f20\u91cf\u76f4\u63a5\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u4f8b\u5982104\u00d7104\u00d7128\u548c104\u00d7104\u00d7128\u76f8\u52a0\uff0c\u7ed3\u679c\u8fd8\u662f104\u00d7104\u00d7128\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aResX\u4e2d\u5305\u542b1+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b1+\uff081+2\u00d71\uff09+\uff081+2\u00d72\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d78\uff09+\uff081+2\u00d74\uff09=52\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2aFC\u5168\u8fde\u63a5\u5c42\uff0c\u5373\u53ef\u4ee5\u7ec4\u6210\u4e00\u4e2aDarknet53\u5206\u7c7b\u7f51\u7edc\u3002\u4e0d\u8fc7\u5728\u76ee\u6807\u68c0\u6d4bYolov3\u4e2d\uff0c\u53bb\u6389FC\u5c42\uff0c\u4ecd\u7136\u628aYolov3\u7684\u4e3b\u5e72\u7f51\u7edc\u53eb\u505aDarknet53\u7ed3\u6784\u3002","title":"3.3\u7f51\u7edc\u6a21\u578b\u7ed3\u6784"},{"location":"objectdection/04.yolo/#34","text":"yoloV3\u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 \u5728COCO\u6570\u636e\u96c6\u8fd99\u4e2a\u5148\u9a8c\u6846\u662f\uff1a(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c(116x90)\uff0c(156x198)\uff0c(373x326)\u3002\u5728\u6700\u5c0f\u7684(13x13)\u7279\u5f81\u56fe\u4e0a\uff08\u6709\u6700\u5927\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528\u8f83\u5927\u7684\u5148\u9a8c\u6846(116x90)\uff0c(156x198)\uff0c(373x326)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u5bf9\u8c61\u3002\u4e2d\u7b49\u7684(26x26)\u7279\u5f81\u56fe\u4e0a\uff08\u4e2d\u7b49\u611f\u53d7\u91ce\uff09\u5e94\u7528\u4e2d\u7b49\u7684\u5148\u9a8c\u6846(30x61)\uff0c(62x45)\uff0c(59x119)\uff0c\u9002\u5408\u68c0\u6d4b\u4e2d\u7b49\u5927\u5c0f\u7684\u5bf9\u8c61\u3002\u8f83\u5927\u7684(52x52)\u7279\u5f81\u56fe\u4e0a\uff08\u8f83\u5c0f\u7684\u611f\u53d7\u91ce\uff09\u5e94\u7528,\u5176\u4e2d\u8f83\u5c0f\u7684\u5148\u9a8c\u6846(10x13)\uff0c(16x30)\uff0c(33x23)\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u5bf9\u8c61\u3002 \u76f4\u89c2\u4e0a\u611f\u53d79\u79cd\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e0b\u56fe\u4e2d\u84dd\u8272\u6846\u4e3a\u805a\u7c7b\u5f97\u5230\u7684\u5148\u9a8c\u6846\u3002\u9ec4\u8272\u6846\u5f0fground truth\uff0c\u7ea2\u6846\u662f\u5bf9\u8c61\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u3002","title":"3.4\u5148\u9a8c\u6846"},{"location":"objectdection/04.yolo/#35-logistic","text":"\u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u88ab\u66ff\u6362\u4e3a\u4e00\u4e2a1x1\u7684\u5377\u79ef\u5c42+logistic\u6fc0\u6d3b\u51fd\u6570\u7684\u7ed3\u6784\u3002\u4f7f\u7528softmax\u5c42\u7684\u65f6\u5019\u5176\u5b9e\u5df2\u7ecf\u5047\u8bbe\u6bcf\u4e2a\u8f93\u51fa\u4ec5\u5bf9\u5e94\u67d0\u4e00\u4e2a\u5355\u4e2a\u7684class\uff0c\u4f46\u662f\u5728\u67d0\u4e9bclass\u5b58\u5728\u91cd\u53e0\u60c5\u51b5\uff08\u4f8b\u5982woman\u548cperson\uff09\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u4f7f\u7528softmax\u5c31\u4e0d\u80fd\u4f7f\u7f51\u7edc\u5bf9\u6570\u636e\u8fdb\u884c\u5f88\u597d\u7684\u9884\u6d4b\u3002","title":"3.5 logistic\u56de\u5f52"},{"location":"objectdection/04.yolo/#36-yolov3","text":"YoloV3\u7684\u8f93\u5165\u8f93\u51fa\u5f62\u5f0f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8f93\u5165416\u00d7416\u00d73\u7684\u56fe\u50cf\uff0c\u901a\u8fc7darknet\u7f51\u7edc\u5f97\u5230\u4e09\u79cd\u4e0d\u540c\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u90fd\u5bf9\u5e94N\u4e2a\u901a\u9053\uff0c\u5305\u542b\u7740\u9884\u6d4b\u7684\u4fe1\u606f\uff1b \u6bcf\u4e2a\u7f51\u683c\u6bcf\u4e2a\u5c3a\u5bf8\u7684anchors\u7684\u9884\u6d4b\u7ed3\u679c\u3002 YOLOv3\u5171\u670913\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73\u4e2a\u9884\u6d4b \u3002\u6bcf\u4e2a\u9884\u6d4b\u5bf9\u5e9485\u7ef4\uff0c\u5206\u522b\u662f4\uff08\u5750\u6807\u503c\uff09\u30011\uff08\u7f6e\u4fe1\u5ea6\u5206\u6570\uff09\u300180\uff08coco\u7c7b\u522b\u6982\u7387\uff09\u3002","title":"3.6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u4e0e\u8f93\u51fa"},{"location":"objectdection/04.yolo/#4yolov4","text":"YOLO\u4e4b\u7236\u57282020\u5e74\u521d\u5ba3\u5e03\u9000\u51faCV\u754c\uff0cYOLOv4 \u7684\u4f5c\u8005\u5e76\u4e0d\u662fYOLO\u7cfb\u5217 \u7684\u539f\u4f5c\u8005\u3002YOLO V4\u662fYOLO\u7cfb\u5217\u4e00\u4e2a\u91cd\u5927\u7684\u66f4\u65b0\uff0c\u5176\u5728COCO\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u7cbe\u5ea6(AP)\u548c\u5e27\u7387\u7cbe\u5ea6(FPS)\u5206\u522b\u63d0\u9ad8\u4e8610% \u548c12%\uff0c\u5e76\u5f97\u5230\u4e86Joseph Redmon\u7684\u5b98\u65b9\u8ba4\u53ef\uff0c\u88ab\u8ba4\u4e3a\u662f\u5f53\u524d\u6700\u5f3a\u7684\u5b9e\u65f6\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u4e4b\u4e00\u3002 yoloV4\u603b\u7ed3\u4e86\u5927\u90e8\u5206\u68c0\u6d4b\u6280\u5de7\uff0c\u7136\u540e\u7ecf\u8fc7\u7b5b\u9009\uff0c\u6392\u5217\u7ec4\u5408\uff0c\u6328\u4e2a\u5b9e\u9a8c\uff08ablation study\uff09\u54ea\u4e9b\u65b9\u6cd5\u6709\u6548\uff0c\u603b\u4f53\u6765\u8bf4\uff0cYolov4\u5e76\u6ca1\u6709\u521b\u9020\u65b0\u7684\u6539\u8fdb\uff0c\u800c\u662f\u4f7f\u7528\u4e86\u5927\u91cf\u7684\u76ee\u6807\u68c0\u6d4b\u7684\u6280\u5de7\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u7ed9\u5927\u5bb6\u770b\u4e0b\u5b83\u7684\u7f51\u7edc\u67b6\u6784\uff1a Yolov4\u7684\u7ed3\u6784\u56fe\u548cYolov3\u662f\u76f8\u4f3c\u7684\uff0c\u4e0d\u8fc7\u4f7f\u7528\u5404\u79cd\u65b0\u7684\u7b97\u6cd5\u601d\u60f3\u5bf9\u5404\u4e2a\u5b50\u7ed3\u6784\u90fd\u8fdb\u884c\u4e86\u6539\u8fdb\u3002 \u5148\u6574\u7406\u4e0bYolov4\u7684\u7ed3\u6784\u7ec4\u4ef6 \u57fa\u672c\u7ec4\u4ef6\uff1a CBM\uff1aYolov4\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Mish\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 CBL\uff1a\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\u3002 Res unit\uff1a\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1\u3002 CSPX\uff1a\u7531\u4e09\u4e2a\u5377\u79ef\u5c42\u548cX\u4e2aRes unint\u6a21\u5757Concate\u7ec4\u6210\u3002 SPP\uff1a\u91c7\u75281\u00d71\uff0c5\u00d75\uff0c9\u00d79\uff0c13\u00d713\u7684\u6700\u5927\u6c60\u5316\u7684\u65b9\u5f0f\uff0c\u8fdb\u884c\u591a\u5c3a\u5ea6\u878d\u5408\u3002 \u5176\u4ed6\u57fa\u7840\u64cd\u4f5c\uff1a Concat\uff1a\u5f20\u91cf\u62fc\u63a5\uff0c\u7ef4\u5ea6\u4f1a\u6269\u5145\uff0c\u548cYolov3\u4e2d\u7684\u89e3\u91ca\u4e00\u6837\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684route\u64cd\u4f5c\u3002 Add\uff1a\u5f20\u91cf\u76f8\u52a0\uff0c\u4e0d\u4f1a\u6269\u5145\u7ef4\u5ea6\uff0c\u5bf9\u5e94\u4e8ecfg\u6587\u4ef6\u4e2d\u7684shortcut\u64cd\u4f5c\u3002 Backbone\u4e2d\u5377\u79ef\u5c42\u7684\u6570\u91cf\uff1a \u6bcf\u4e2aCSPX\u4e2d\u5305\u542b3+2\u00d7X\u4e2a\u5377\u79ef\u5c42\uff0c\u56e0\u6b64\u6574\u4e2a\u4e3b\u5e72\u7f51\u7edcBackbone\u4e2d\u4e00\u5171\u5305\u542b2+\uff083+2\u00d71\uff09+2+\uff083+2\u00d72\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d78\uff09+2+\uff083+2\u00d74\uff09+1=72\u3002 \u6ce8\u610f\uff1a \u7f51\u7edc\u7684\u8f93\u5165\u5927\u5c0f\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u5728yoloV3\u4e2d\u8f93\u5165\u9ed8\u8ba4\u662f416\u00d7416\uff0c\u5728yoloV4\u4e2d\u9ed8\u8ba4\u662f608\u00d7608\uff0c\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u4e5f\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4fee\u6539\uff0c\u6bd4\u5982320\u00d7320\uff0c\u4e00\u822c\u662f32\u7684\u500d\u6570\u3002 \u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u548c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u4e5f\u662f\u5bf9\u5e94\u7684\uff0c\u6bd4\u5982416\u00d7416\u7684\u8f93\u5165\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u662f13\u00d713\uff0c26\u00d726\uff0c52\u00d752\uff0c \u5982\u679c\u662f608\u00d7608\uff0c\u6700\u540e\u7684\u4e09\u4e2a\u7279\u5f81\u56fe\u5927\u5c0f\u5219\u662f19\u00d719\uff0c38\u00d738\uff0c76\u00d776\u3002 \u603b\u7ed3 \u77e5\u9053yolo\u7f51\u7edc\u67b6\u6784\uff0c\u7406\u89e3\u5176\u8f93\u5165\u8f93\u51fa YOLO\u7684\u6574\u4e2a\u7ed3\u6784\u5c31\u662f\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u6362\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7684\u5f20\u91cf \u77e5\u9053yolo\u6a21\u578b\u7684\u8bad\u7ec3\u6837\u672c\u6784\u5efa\u7684\u65b9\u6cd5 \u5bf9\u4e8e\u539f\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e00\u4e2a\u7f51\u683cgrid\u90fd\u9700\u8981\u6784\u5efa\u4e00\u4e2a30\u7ef4\u7684\u5411\u91cf\uff1a\u5206\u7c7b\uff0c\u7f6e\u4fe1\u5ea6\uff0c\u56de\u5f52\u7684\u76ee\u6807\u503c \u7406\u89e3yolo\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570 \u635f\u5931\u51fd\u6570\u5206\u4e3a3\u90e8\u5206\uff1a\u5206\u7c7b\u635f\u5931\uff0c\u56de\u5f52\u635f\u5931\uff0c\u7f6e\u4fe1\u5ea6\u635f\u5931 \u77e5\u9053yoloV2\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5 \u4f7f\u7528\u4e86BN\u5c42\uff0c\u9ad8\u5206\u8fa8\u7387\u8bad\u7ec3\uff0c\u91c7\u7528Anchorbox\uff0c\u805a\u7c7b\u5f97\u5230anchorbox\u7684\u5c3a\u5bf8\uff0c\u6539\u8fdb\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u7279\u5f81\u878d\u5408\uff0c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u7f51\u7edc\u6a21\u578b\u4f7f\u7528darknet19\uff0c\u5229\u7528imagenet\u6570\u636e\u96c6\u8bc6\u522b\u66f4\u591a\u7684\u76ee\u6807 yoloV3\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5 \u5728YOLOv3\u4e2d\u91c7\u7528FPN\u7ed3\u6784\u6765\u63d0\u9ad8\u5bf9\u5e94\u591a\u5c3a\u5ea6\u76ee\u6807\u68c0\u6d4b\u7684\u7cbe\u5ea6\uff0c\u5f53\u524d\u7684feature map\u5229\u7528\u201c\u672a\u6765\u201d\u5c42\u7684\u4fe1\u606f\uff0c\u5c06\u4f4e\u9636\u7279\u5f81\u4e0e\u9ad8\u9636\u7279\u5f81\u8fdb\u884c\u878d\u5408\uff0c\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002 yoloV3\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784 \u4ee5darknet-53\u4e3a\u57fa\u7840\uff0c\u501f\u9274resnet\u7684\u601d\u60f3\uff0c\u5728\u7f51\u7edc\u4e2d\u52a0\u5165\u4e86\u6b8b\u5dee\u6a21\u5757\uff0c\u5229\u4e8e\u89e3\u51b3\u6df1\u5c42\u6b21\u7f51\u7edc\u7684\u68af\u5ea6\u95ee\u9898 \u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u53ea\u6709\u5377\u79ef\u5c42 \u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684 yoloV3\u6a21\u578b\u5148\u9a8c\u6846\u8bbe\u8ba1\u7684\u65b9\u6cd5 \u91c7\u7528K-means\u805a\u7c7b\u5f97\u5230\u5148\u9a8c\u6846\u7684\u5c3a\u5bf8\uff0c\u4e3a\u6bcf\u79cd\u5c3a\u5ea6\u8bbe\u5b9a3\u79cd\u5148\u9a8c\u6846\uff0c\u603b\u5171\u805a\u7c7b\u51fa9\u79cd\u5c3a\u5bf8\u7684\u5148\u9a8c\u6846\u3002 yoloV3\u6a21\u578b\u4e3a\u4ec0\u4e48\u9002\u7528\u4e8e\u591a\u6807\u7b7e\u7684\u76ee\u6807\u5206\u7c7b \u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u65f6\u4e0d\u4f7f\u7528softmax\uff0c\u800c\u662f\u4f7f\u7528logistic\u7684\u8f93\u51fa\u8fdb\u884c\u9884\u6d4b yoloV3\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa \u5bf9\u4e8e416\u00d7416\u00d73\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u7684\u6bcf\u4e2a\u7f51\u683c\u8bbe\u7f6e3\u4e2a\u5148\u9a8c\u6846\uff0c\u603b\u5171\u6709 13\u00d713\u00d73 + 26\u00d726\u00d73 + 52\u00d752\u00d73 = 10647 \u4e2a\u9884\u6d4b\u3002\u6bcf\u4e00\u4e2a\u9884\u6d4b\u662f\u4e00\u4e2a(4+1+80)=85\u7ef4\u5411\u91cf\uff0c\u8fd9\u4e2a85\u7ef4\u5411\u91cf\u5305\u542b\u8fb9\u6846\u5750\u6807\uff084\u4e2a\u6570\u503c\uff09\uff0c\u8fb9\u6846\u7f6e\u4fe1\u5ea6\uff081\u4e2a\u6570\u503c\uff09\uff0c\u5bf9\u8c61\u7c7b\u522b\u7684\u6982\u7387\uff08\u5bf9\u4e8eCOCO\u6570\u636e\u96c6\uff0c\u670980\u79cd\u5bf9\u8c61\uff09\u3002","title":"4.yoloV4[\u4e86\u89e3]"},{"location":"objectdection/05.yolo-demo/","text":"4.5 YoloV3 \u6848\u4f8b \u00b6 \u5b66\u4e60\u76ee\u6807 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b 1.TFrecord\u6587\u4ef6 \u00b6 \u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f9d\u7136\u4f7f\u7528VOC\u6570\u636e\u96c6\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e0d\u540c\u7684\u662f\u6211\u4eec\u8981\u5229\u7528tfrecord\u6587\u4ef6\u6765\u5b58\u50a8\u548c\u8bfb\u53d6\u6570\u636e\uff0c\u9996\u5148\u6765\u770b\u4e00\u4e0btfrecord\u6587\u4ef6\u7684\u76f8\u5173\u5185\u5bb9\u3002 \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528tfrecord\u6587\u4ef6\uff1f TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002 TFRecord\u89c4\u8303\u4e86\u6570\u636e\u7684\u8bfb\u5199\u65b9\u5f0f\uff0c\u6570\u636e\u8bfb\u53d6\u548c\u5904\u7406\u7684\u6548\u7387\u90fd\u4f1a\u5f97\u5230\u663e\u8457\u7684\u63d0\u9ad8\u3002 1.1 \u4ec0\u4e48\u662fTFrecord\u6587\u4ef6 \u00b6 TFRecord \u662fGoogle\u5b98\u65b9\u63a8\u8350\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u662fGoogle\u4e13\u95e8\u4e3aTensorFlow\u8bbe\u8ba1\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5229\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u6570\u636e\u53ef\u4ee5\u4f7f\u5176\u4e0e\u7f51\u7edc\u67b6\u6784\u66f4\u9002\u914d\u3002TFRecord\u662f\u4e00\u79cd\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5176\u80fd\u66f4\u597d\u7684\u5229\u7528\u5185\u5b58\uff0c\u4e0ecsv,hdf5\u6587\u4ef6\u662f\u7c7b\u4f3c\u7684\u3002 TFRecord\u7684\u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b\u56fe\u6240\u793a\uff1a TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\uff0c\u5176\u4e2d\uff0ckey \u662fstring\u7c7b\u578b\uff0c\u800cvalue \u7684\u53d6\u503c\u6709\u4e09\u79cd\uff1a tf.train.bytes_list: \u53ef\u4ee5\u5b58\u50a8string \u548cbyte\u4e24\u79cd\u6570\u636e\u7c7b\u578b\u3002\u56fe\u50cf\u6570\u636e\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u5373\u53ef\u3002 tf.train.float_list: \u53ef\u4ee5\u5b58\u50a8float(float32)\u4e0edouble(float64) \u4e24\u79cd\u6570\u636e\u7c7b\u578b \u3002 tf.train.int64_list: \u53ef\u4ee5\u5b58\u50a8\uff1abool, enum, int32, uint32, int64, uint64 \u3002 TFRecord \u5e76\u975e\u662fTensorFlow\u552f\u4e00\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528CSV\u6216\u6587\u672c\u7b49\u5176\u4ed6\u683c\u5f0f\uff0c\u4f46\u662f\u5bf9\u4e8eTensorFlow\u6765\u8bf4\uff0cTFRecord \u662f\u6700\u53cb\u597d\u7684\uff0c\u6700\u65b9\u4fbf\u7684\uff0c\u800c\u4e14tensorflow\u4e5f\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684API\u5e2e\u52a9\u6211\u4eec\u8f7b\u677e\u7684\u521b\u5efa\u548c\u83b7\u53d6TFRecord\u6587\u4ef6\u3002 1.2 \u5c06\u6570\u636e\u8f6c\u6362\u4e3aTFRecord\u6587\u4ef6 \u00b6 \u5bf9\u4e8e\u4e2d\u5927\u6570\u636e\u96c6\u6765\u8bf4\uff0cGoogle\u5b98\u65b9\u63a8\u8350\u5148\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aTFRecord\u6570\u636e, \u8fd9\u6837\u53ef\u52a0\u5feb\u5728\u6570\u636e\u8bfb\u53d6, \u9884\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5c06VOC\u6570\u636e\u96c6\u8f6c\u6362\u4e3aRecords\u683c\u5f0f\uff0c\u5728\u8fd9\u91cc\u9996\u5148\u8bfb\u53d6\u6807\u6ce8XML\u6587\u4ef6\uff0c\u5e76\u627e\u5230\u5bf9\u5e94\u7684\u56fe\u50cf\u6570\u636e\uff0c\u6700\u540e\u5c06\u6570\u636e\u5199\u5165TFRecords\u6587\u4ef6\u4e2d\u3002 1.2.1 \u8bfb\u53d6\u6807\u6ce8\u4fe1\u606f \u00b6 VOC\u6570\u636e\u96c6\u7684\u6807\u6ce8\u4fe1\u606f\u5b58\u50a8\u5728xml\u6587\u4ef6\u4e2d\uff0c\u5728VOC2007\u7684\u6570\u636e\u4e2d\u4e3b\u8981\u83b7\u53d6fIlename\uff0cwidth\uff0cheight\uff0c\u548cobject\uff08\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff09\u4e0b\u7684name\uff08\u76ee\u6807\u540d\u79f0\uff09\u548cbndbox\uff08\u6846\u7684\u4f4d\u7f6e\uff09\u3002\u5177\u4f53\u5927\u5bb6\u53ef\u4ee5\u770b\u4e0b\u5728FasterRCNN\u4e2d\u7684\u4ecb\u7ecd\uff0c\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a import xml.dom.minidom as xdom # VOC\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f voc_classes = { 'none' : 0 , 'aeroplane' : 1 , 'bicycle' : 2 , 'bird' : 3 , 'boat' : 4 , 'bottle' : 5 , 'bus' : 6 , 'car' : 7 , 'cat' : 8 , 'chair' : 9 , 'cow' : 10 , 'diningtable' : 11 , 'dog' : 12 , 'horse' : 13 , 'motorbike' : 14 , 'person' : 15 , 'pottedplant' : 16 , 'sheep' : 17 , 'sofa' : 18 , 'train' : 19 , 'tvmonitor' : 20 , } # \u8bfb\u53d6XML\u6587\u4ef6\u4e2d\u7684\u4fe1\u606f def Prase_Singel_xml ( xml_path ): DOMTree = xdom . parse ( xml_path ) RootNode = DOMTree . documentElement #\u83b7\u53d6XML\u6587\u4ef6\u5bf9\u5e94\u7684\u56fe\u50cf image_name = RootNode . getElementsByTagName ( \"filename\" )[ 0 ] . childNodes [ 0 ] . data #\u83b7\u53d6\u56fe\u50cf\u5bbd\u548c\u9ad8 size = RootNode . getElementsByTagName ( \"size\" ) image_height = int ( size [ 0 ] . getElementsByTagName ( \"height\" )[ 0 ] . childNodes [ 0 ] . data ) image_width = int ( size [ 0 ] . getElementsByTagName ( \"width\" )[ 0 ] . childNodes [ 0 ] . data ) #\u83b7\u53d6\u56fe\u50cf\u4e2d\u76ee\u6807\u5bf9\u8c61 all_obj = RootNode . getElementsByTagName ( \"object\" ) bndbox_lable_dic = [] # \u904d\u5386\u6240\u6709\u7684\u5bf9\u8c61 for one_obj in all_obj : # \u83b7\u53d6\u76ee\u6807\u7684\u6807\u6ce8\u4fe1\u606f obj_name = one_obj . getElementsByTagName ( \"name\" )[ 0 ] . childNodes [ 0 ] . data # \u83b7\u53d6\u5bf9\u5e94\u7684label\u503c obj_label = voc_classes [ obj_name ] # \u83b7\u53d6bbox bndbox = one_obj . getElementsByTagName ( \"bndbox\" ) # \u83b7\u53d6\u76ee\u6807\u7684\u5de6\u4e0a\u53f3\u4e0b\u7684\u4f4d\u7f6e xmin = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmin\" )[ 0 ] . childNodes [ 0 ] . data ) ymin = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymin\" )[ 0 ] . childNodes [ 0 ] . data ) xmax = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmax\" )[ 0 ] . childNodes [ 0 ] . data ) ymax = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymax\" )[ 0 ] . childNodes [ 0 ] . data ) # \u5c06\u76ee\u6807\u6846\u548c\u7c7b\u522b\u7ec4\u5408\u5728\u4e00\u8d77 bndbox_lable_dic . append ([ xmin , ymin , xmax , ymax , obj_label ]) # \u8fd4\u56de\u76f8\u5e94\u7684\u4fe1\u606f return image_name , image_width , image_height , bndbox_lable_dic \u63a5\u4e0b\u6765\u6211\u4eec\u8bfb\u53d6\u4e00\u4e2aXML\u6587\u4ef6\u770b\u4e0b\u6548\u679c\uff1a # \u5c55\u793a\u6548\u679c print ( Prase_Singel_xml ( 'VOCdevkit/VOC2007/Annotations/000007.xml' )) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a ( '000007.jpg' , 500 , 333 , [[ 141 , 50 , 500 , 330 , 7 ]]) \u4ece\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u5e94\u7684\u56fe\u50cf\u662f000007.jpg\uff0c\u56fe\u50cf\u7684\u5bbd\u9ad8\u662f500, 333\uff0c\u56fe\u50cf\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff0c\u4f4d\u7f6e\u662f141, 50, 500, 330\uff0c\u7c7b\u522b\u662f7 car. 1.2.2 \u5c06\u6570\u636e\u5199\u5165TFRecord\u6587\u4ef6\u4e2d \u00b6 \u5728\u5c06\u6570\u636e\u5199\u5165\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528tf.io.TFRecordWriter\u6765\u5b8c\u6210\uff0c\u4e3b\u8981\u6b65\u9aa4\u662f\uff1a 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 7\u3001\u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 import tensorflow as tf import glob import os # \u6307\u660exml\u6587\u4ef6\uff0ctfrecord\u6587\u4ef6\u548c\u56fe\u50cf\u7684\u4f4d\u7f6e def write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ): # 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 writer = tf . io . TFRecordWriter ( tfrecord_path ) # \u904d\u5386\u6240\u6709\u7684XML\u6587\u4ef6 for i , single_xml_path in enumerate ( all_xml_path ): # \u8bfb\u53d6xml\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9 image_name , image_width , image_height , bndbox_lable_dic = Prase_Singel_xml ( single_xml_path ) # \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 sigle_img_path = os . path . join ( voc_img_path , image_name ) # \u8bfb\u53d6\u56fe\u50cf image_data = open ( sigle_img_path , 'rb' ) . read () xmin = [] ymin = [] xmax = [] ymax = [] obj_label = [] # \u904d\u5386box\u548clabel\u4fe1\u606f\uff0c\u5e76\u8bb0\u5f55\u4e0b\u6765 for j in range ( len ( bndbox_lable_dic )): xmin . append ( bndbox_lable_dic [ j ][ 0 ]) ymin . append ( bndbox_lable_dic [ j ][ 1 ]) xmax . append ( bndbox_lable_dic [ j ][ 2 ]) ymax . append ( bndbox_lable_dic [ j ][ 3 ]) obj_label . append ( bndbox_lable_dic [ j ][ 4 ]) # \u521b\u5efa\u7279\u5f81\uff1a\u56fe\u50cf\uff0csize,box\u548clabel # 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 # 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d feature = { 'image' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ image_data ])), 'width' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_width ])), 'height' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_height ])), 'xmin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmin )), 'ymin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymin )), 'xmax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmax )), 'ymax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymax )), 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = obj_label )) } # 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d example = tf . train . Example ( features = tf . train . Features ( feature = feature )) # \u5c06example\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d # 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 # 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 writer . write ( example . SerializeToString ()) # \u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 writer . close () print ( '\u7b2c{}\u5f20\u56fe\u7247\u5199\u5165\u5b8c\u6bd5' . format ( i )) \u63a5\u4e0b\u6765\u8c03\u7528\u4e0a\u8ff0\u65b9\u6cd5\u5c06VOC\u6570\u636e\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\uff1a # \u83b7\u53d6\u6240\u6709\u7684xml\u6587\u4ef6 all_xml_path = glob . glob ( 'VOCdevkit/VOC2007/Annotations/*.xml' ) # \u6307\u5b9atfrecords\u6587\u4ef6\u7684\u8def\u5f84 tfrecord_path = 'voc_2007.tfrecords' # \u6307\u5b9a\u56fe\u50cf\u6240\u5728\u7684\u8def\u5f84 voc_img_path = 'VOCdevkit/VOC2007/JPEGImages' # \u5c06\u4fe1\u606f\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a 1.3 \u8bfb\u53d6TFRecord\u6587\u4ef6 \u00b6 VOC\u6570\u636e\u96c6\u5df2\u7ecf\u88ab\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\u4e86\uff0c\u90a3\u6211\u4eec\u5c31\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u5c06\u6570\u636e\u8bfb\u53d6\u51fa\u6765\u3002\u53ea\u9700\u8981\u7b80\u5355\u7684\u4f7f\u7528 tf.data.TFRecordDataset \u5c31\u80fd\u591f\u8f7b\u677e\u7684\u8bfb\u53d6\u6570\u636e\u3002 \u4f7f\u7528tf.data.TFRecordDataset\u6765\u83b7\u53d6TFRecord\u6587\u4ef6\u4e2d\u7684\u6570\u636e \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff0c\u4e0e\u5199\u5165\u65f6\u662f\u5bf9\u5e94\u7684 \u4f7f\u7528tf.io.parse_single_example\u5c06\u4e00\u4e2aexample\u8f6c\u6362\u4e3a\u539f\u59cb\u6570\u636e \u4f7f\u7528\u529f\u80fdmap\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c\uff08map\u65b9\u6cd5\u7a0d\u540e\u4ecb\u7ecd\uff09 import tensorflow as tf import os import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # \u83b7\u53d6tfreocrd\u4e2d\u7684\u6240\u6709\u6570\u636e raw_datasets = tf . data . TFRecordDataset ( 'voc_2007.tfrecords' ) # \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff1a\u56fe\u50cf\uff0cbox\u548clabel,\u6ce8\u610f\uff1a\u8981\u548c\u5199\u5165\u65f6\u662f\u4e00\u4e00\u5bf9\u5e94\u7684 feature_description = { 'image' : tf . io . FixedLenFeature ([], tf . string ), 'width' : tf . io . FixedLenFeature ([], tf . float32 ), 'height' : tf . io . FixedLenFeature ([], tf . float32 ), 'xmin' : tf . io . VarLenFeature ( tf . float32 ), 'ymin' : tf . io . VarLenFeature ( tf . float32 ), 'xmax' : tf . io . VarLenFeature ( tf . float32 ), 'ymax' : tf . io . VarLenFeature ( tf . float32 ), 'label' : tf . io . VarLenFeature ( tf . int64 ), } # \u5c06tfrecord\u4e2d\u7684\u6570\u636e\u8f6c\u6362\u4e3a\u539f\u59cb\u56fe\u50cf\u548c\u6807\u6ce8\u4fe1\u606f\uff08\u53ea\u80fd\u5bf9\u4e00\u4e2a\u6570\u636e\u8fdb\u884c\u5904\u7406\uff09 def parse_example ( example_string ): # \u5c06tfreocord\u6587\u4ef6\u4e2d\u7684\u4e00\u4e2aexample\u6620\u5c04\u56de\u539f\u59cb\u6570\u636e feature_dict = tf . io . parse_single_example ( example_string , feature_description ) # \u83b7\u53d6\u56fe\u50cf\u6570\u636e image_data = tf . io . decode_jpeg ( feature_dict [ 'image' ]) # \u83b7\u53d6box boxes = tf . stack ([ tf . sparse . to_dense ( feature_dict [ 'xmin' ]), tf . sparse . to_dense ( feature_dict [ 'ymin' ]), tf . sparse . to_dense ( feature_dict [ 'xmax' ]), tf . sparse . to_dense ( feature_dict [ 'ymax' ])], axis = 1 ) # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f boxes_category = tf . sparse . to_dense ( feature_dict [ 'label' ]) # \u8fd4\u56de\u7ed3\u679c return image_data , feature_dict [ 'width' ], feature_dict [ 'height' ], boxes , boxes_category # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u6211\u4eec\u5c06\u4eceTFRecord\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) # \u521d\u59cb\u5316\uff1a\u7b2c\u51e0\u4e2a\u56fe\u50cf i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image ) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u7ed3\u679c\u4e3a\uff1a 1.4 \u6570\u636e\u5904\u7406\u7684Pipeline \u00b6 \u4f7f\u7528\u6570\u636e\u5904\u7406\u7684tf.data.Dataset\u6a21\u5757\u4e2dpipline\u673a\u5236\uff0c\u53ef\u5b9e\u73b0CPU\u591a\u7ebf\u7a0b\u5904\u7406\u8f93\u5165\u7684\u6570\u636e\uff0c\u5982\u8bfb\u53d6\u56fe\u7247\u548c\u56fe\u7247\u7684\u4e00\u4e9b\u7684\u9884\u5904\u7406\uff0c\u8fd9\u6837GPU\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u800cCPU\u53bb\u51c6\u5907\u6570\u636e\u3002 Dataset\u652f\u6301\u4e00\u7c7b\u7279\u6b8a\u7684\u64cd\u4f5c\uff1aTransformation\u3002\u4e00\u4e2aDataset\u901a\u8fc7Transformation\u53d8\u6210\u4e00\u4e2a\u65b0\u7684Dataset\u3002\u901a\u5e38\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Transformation\u5b8c\u6210\u6570\u636e\u53d8\u6362\uff0c\u6253\u4e71\uff0c\u7ec4\u6210batch\uff0c\u751f\u6210epoch\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c\u3002\u5e38\u7528\u7684Transformation\u6709\uff1amap\u3001batch\u3001shuffle\u548crepeat\u3002\u89e3\u6790tfrecord\u6587\u4ef6\u5f97\u5230\u7684\u6570\u636e\u90fd\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u4f8b\u5982\u6211\u4eec\u524d\u9762\u4f7f\u7528\u7684\uff1a # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u4e0b\u9762\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\uff1a 1.4.1 map \u00b6 \u4f7f\u7528 tf.data.Dataset.map\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u5bf9\u6570\u636e\u96c6\u4e2d\u7684\u5404\u4e2a\u5143\u7d20\u8fdb\u884c\u9884\u5904\u7406\u3002\u56e0\u4e3a\u8f93\u5165\u5143\u7d20\u4e4b\u95f4\u65f6\u72ec\u7acb\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u5728\u591a\u4e2a CPU \u6838\u5fc3\u4e0a\u5e76\u884c\u5730\u8fdb\u884c\u9884\u5904\u7406\u3002map \u53d8\u6362\u63d0\u4f9b\u4e86\u4e00\u4e2a num_parallel_calls\u53c2\u6570\u53bb\u6307\u5b9a\u5e76\u884c\u7684\u7ea7\u522b\u3002 dataset = dataset . map ( map_func = parse_fn , num_parallel_calls = FLAGS . num_parallel_calls ) 1.4.2 repeat \u00b6 repeat\u7684\u529f\u80fd\u5c31\u662f\u5c06\u6574\u4e2a\u5e8f\u5217\u91cd\u590d\u591a\u6b21\uff0c\u4e3b\u8981\u7528\u6765\u5904\u7406\u673a\u5668\u5b66\u4e60\u4e2d\u7684epoch\uff0c\u5047\u8bbe\u539f\u5148\u7684\u6570\u636e\u662f\u4e00\u4e2aepoch\uff0c\u4f7f\u7528repeat(5)\u5c31\u53ef\u4ee5\u5c06\u4e4b\u53d8\u62105\u4e2aepoch\u7684\u6570\u636e\u3002 1.4.3 prefetch \u00b6 tf.data.Dataset.prefetch \u63d0\u4f9b\u89e3\u8026\u4e86 \u6570\u636e\u4ea7\u751f\u7684\u65f6\u95f4 \u548c \u6570\u636e\u6d88\u8017\u7684\u65f6\u95f4\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u6570\u636e\u88ab\u8bf7\u6c42\u524d\uff0c\u5c31\u4ece dataset \u4e2d\u9884\u52a0\u8f7d\u4e00\u4e9b\u6570\u636e\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002prefech(n) \u4e00\u822c\u4f5c\u4e3a\u6700\u540e\u4e00\u4e2a transformation\uff0c\u5176\u4e2d n \u4e3a batch_size\u3002 prefetch \u7684\u4f7f\u7528\u65b9\u6cd5\u5982\u4e0b\uff1a # \u6700\u540e\u4e00\u4e2a\u53d8\u6362 dataset = dataset . prefetch ( buffer_size = FLAGS . prefetch_buffer_size ) return dataset \u53e6\u5916\u8fd8\u53ef\u4f7f\u7528bacth\u65b9\u6cd5\u7ec4\u6210\u6279\u6b21\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\uff0c\u4e5f\u53ef\u4f7f\u7528shuffle\u65b9\u6cd5\u5bf9\u6570\u636e\u6253\u4e71\u3002 1.5. \u6570\u636e\u5904\u7406 \u00b6 yoloV3\u6a21\u578b\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u662f32\u7684\u500d\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u56fe\u50cf\u7684\u5c3a\u5ea6\u8c03\u6574\u4e3a416x416\u7684\u5927\u5c0f\uff0c\u4e3a\u4e86\u4fdd\u6301\u957f\u5bbd\u6bd4\uff0c\u6211\u5c06\u56db\u5468\u4e3a0\u7684\u50cf\u7d20\u4ee5\u7070\u5ea6\u503c128\u8fdb\u884c\u586b\u5145\u3002 def preprocess ( image , bbox , input_shape = ( 416 , 416 )): # \u589e\u52a0batch\u7ef4 image = tf . expand_dims ( image , axis = 0 ) # \u83b7\u53d6\u56fe\u50cf\u7684\u9ad8\u5bbd[height, width] img_shape = image . shape [ 1 : 3 ] # \u5c06\u56fe\u50cf\u8fdb\u884c\u8c03\u6574\uff0c\u63d2\u503c\u65b9\u6cd5\u662f\u53cc\u4e09\u6b21\u63d2\u503c\uff0c\u4fdd\u7559\u957f\u5bbd\u6bd4 resize_image = tf . image . resize ( image , input_shape , method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u83b7\u53d6\u56fe\u50cf\u7684\u5bbd\u9ad8[height,width] resize_shape = resize_image . shape [ 1 : 3 ] # \u56fe\u50cf\u4e0a\u65b9\u7684\u586b\u5145\u5927\u5c0f top_pad = ( input_shape [ 0 ] - resize_shape [ 0 ]) // 2 # \u56fe\u50cf\u4e0b\u65b9\u7684\u586b\u5145\u5927\u5c0f bottom_pad = input_shape [ 0 ] - resize_shape [ 0 ] - top_pad # \u56fe\u50cf\u5de6\u65b9\u7684\u586b\u5145\u5927\u5c0f left_pad = ( input_shape [ 1 ] - resize_shape [ 1 ]) // 2 # \u56fe\u50cf\u53f3\u65b9\u7684\u586b\u5145\u5927\u5c0f right_pad = input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u5c06\u56fe\u50cf\u5468\u56f4\u586b\u5145128 resize_image = tf . pad ( resize_image , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u7c7b\u578b\u8f6c\u5316 image_data = tf . cast ( resize_image , tf . float32 ) / 255. # \u5bf9\u6807\u6ce8\u6846\u8fdb\u884c\u8c03\u6574\uff1a\u8fdb\u884c\u5c3a\u5ea6\u548c\u5e73\u79fb\u8c03\u6574 # \u5c3a\u5ea6\u53d8\u6362 bbox = bbox * tf . convert_to_tensor ( [ resize_shape [ 1 ], resize_shape [ 0 ], resize_shape [ 1 ], resize_shape [ 0 ]], dtype = tf . float32 ) # \u9664\u4ee5\u539f\u56fe\u50cf\u5927\u5c0f bbox = bbox / tf . convert_to_tensor ( [ img_shape [ 1 ], img_shape [ 0 ], img_shape [ 1 ], img_shape [ 0 ]], dtype = tf . float32 ) # \u5e73\u79fb,\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c bbox = bbox + tf . convert_to_tensor ( [ left_pad , top_pad , left_pad , top_pad ], dtype = tf . float32 ) # \u8fd4\u56de return image_data , bbox \u7ecf\u8fc7\u56fe\u50cf\u5904\u7406\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u7ed3\u679c\u4e3a: # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u56fe\u50cf\u5904\u7406 image , boxes = preprocess ( image , boxes ) # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image [ 0 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a: 2.\u6a21\u578b\u6784\u5efa \u00b6 yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002 2.1 \u57fa\u672c\u7ec4\u4ef6 \u00b6 \u57fa\u672c\u7ec4\u4ef6\u6307\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206\uff1a 2.1.1 CBL \u00b6 Yolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\uff0c \u6e90\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a def ConvBlock ( input_shape , filters , kernel_size , strides = ( 1 , 1 ), padding = None ): # padding\u6839\u636e\u6b65\u957f\u7684\u5927\u5c0f\u8fdb\u884c\u4fee\u6539 padding = 'valid' if strides == ( 2 , 2 ) else 'same' # \u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u5c42\uff1a\u52a0\u5165L2\u6b63\u5219\u5316\u7684\u5377\u79ef\u5c42 conv = tf . keras . layers . Conv2D ( filters , kernel_size = kernel_size , strides = strides , padding = padding , kernel_regularizer = tf . keras . regularizers . l2 ( l = 5e-4 ))( inputs ) # BN \u5c42 bn = tf . keras . layers . BatchNormalization ()( conv ) # \u6fc0\u6d3b\u51fd\u6570 relu = tf . keras . layers . LeakyReLU ( alpha = 0.1 )( bn ) # \u6a21\u578b\u6784\u5efa return tf . keras . Model ( inputs = inputs , outputs = relu ) 2.1.2 ResX \u00b6 \u6b8b\u5dee\u7ec4\u4ef6\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1,ResX\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\u3002 def ResBlock ( input_shape , filters , blocks ): # \u6307\u5b9a\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5bf9\u8f93\u5165\u8fdb\u884cpad pad = tf . keras . layers . ZeroPadding2D ( padding = (( 1 , 0 ), ( 1 , 0 )))( inputs ) # \u5377\u79ef\u6b65\u957f\u4e3a2 results = ConvBlock ( pad . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ), strides = ( 2 , 2 ))( pad ) # \u6784\u5efa\u6b8b\u5dee\u5355\u5143 for i in range ( blocks ): # \u5377\u79ef results_conv = ConvBlock ( results . shape [ 1 :], filters = filters // 2 , kernel_size = ( 1 , 1 ))( results ) # \u5377\u79ef results_conv = ConvBlock ( results_conv . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ))( results_conv ) # \u878d\u548c results = tf . keras . layers . Add ()([ results_conv , results ]) # \u8fd4\u56de\u6a21\u578b return tf . keras . Model ( inputs = inputs , outputs = results ) 2.2 BackBone \u00b6 BackBone\u662fDarkNet53\u6784\u6210,\u7528\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e3b\u8981\u662fResX\u6a21\u5757\u3002 def Body ( input_shape ): # \u6a21\u578b\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u7ed3\u679c(batch, 416, 416, 32) cb = ConvBlock ( inputs . shape [ 1 :], filters = 32 , kernel_size = ( 3 , 3 ))( inputs ) # \u6b8b\u5dee\u6a21\u5757 (batch, 208, 208, 64) rb1 = ResBlock ( cb . shape [ 1 :], filters = 64 , blocks = 1 )( cb ) # (batch, 104, 104, 128) rb2 = ResBlock ( rb1 . shape [ 1 :], filters = 128 , blocks = 2 )( rb1 ) # (batch, 52, 52, 256) rb3 = ResBlock ( rb2 . shape [ 1 :], filters = 256 , blocks = 8 )( rb2 ) # (batch, 26, 26, 512) rb4 = ResBlock ( rb3 . shape [ 1 :], filters = 512 , blocks = 8 )( rb3 ) # (batch, 13, 13, 1024) rb5 = ResBlock ( rb4 . shape [ 1 :], filters = 1024 , blocks = 4 )( rb4 ) return tf . keras . Model ( inputs = inputs , outputs = ( rb5 , rb4 , rb3 )) 2.3 \u8f93\u51fa\u90e8\u5206 \u00b6 \u8f93\u51fa\u662f3\u4e2a\u5c3a\u5ea6\u8f93\u51fa\u7684CBL\u4e32\u8054\u7ed3\u6784\uff1a def Output ( input_shape , input_filters , output_filters ): # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u8f93\u51fa\u8fde\u7eed\u7684\u516d\u4e2a\u6a21\u5757 cb1 = ConvBlock ( inputs . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( inputs ) cb2 = ConvBlock ( cb1 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb1 ) cb3 = ConvBlock ( cb2 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb2 ) cb4 = ConvBlock ( cb3 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb3 ) cb5 = ConvBlock ( cb4 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb4 ) cb6 = ConvBlock ( cb5 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb5 ) # \u6700\u540e\u7684\u7b2c\u4e03\u4e2a\u5377\u79ef\u5757 cb7 = ConvBlock ( cb6 . shape [ 1 :], filters = output_filters , kernel_size = ( 1 , 1 ))( cb6 ) return tf . keras . Model ( inputs = inputs , outputs = ( cb5 , cb7 )) 2.4 V3\u6a21\u578b\u6784\u5efa \u00b6 \u5c06\u6a21\u578b\u7684backbone\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u878d\u5408\u540e\u9001\u5165\u5230output\u6a21\u5757\uff0c\u6784\u5efa\u6574\u4e2ayoloV3\u6a21\u578b\u3002 def YOLOv3 ( input_shape , class_num = 80 ): # anchor\u6570\u76ee anchor_num = 3 # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u83b7\u53d6backbone\u8f93\u51fa\u76843\u4e2a\u7279\u5f81\u56fe large , middle , small = Body ( inputs . shape [ 1 :])( inputs ) # \u8f83\u5927\u76ee\u6807\u7684\u68c0\u6d4b x1 , y1 = Output ( large . shape [ 1 :], 512 , anchor_num * ( class_num + 5 ))( large ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y1 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 32 , input_shape [ 1 ] // 32 , 3 , 5 + class_num ))( y1 ) # \u4e2d\u7b49\u76ee\u6807\u7684\u68c0\u6d4b cb1 = ConvBlock ( x1 . shape [ 1 :], filters = 256 , kernel_size = ( 1 , 1 ))( x1 ) # \u4e0a\u91c7\u6837 us1 = tf . keras . layers . UpSampling2D ( 2 )( cb1 ) # \u62fc\u63a5 cat1 = tf . keras . layers . Concatenate ()([ us1 , middle ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x2 , y2 = Output ( cat1 . shape [ 1 :], 256 , anchor_num * ( class_num + 5 ))( cat1 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y2 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 16 , input_shape [ 1 ] // 16 , 3 , 5 + class_num ))( y2 ) # \u8f83\u5c0f\u76ee\u6807\u68c0\u6d4b cb2 = ConvBlock ( x2 . shape [ 1 :], filters = 128 , kernel_size = ( 1 , 1 ))( x2 ) # \u4e0a\u91c7\u6837 us2 = tf . keras . layers . UpSampling2D ( 2 )( cb2 ) # \u62fc\u63a5 cat2 = tf . keras . layers . Concatenate ()([ us2 , small ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x3 , y3 = Output ( cat2 . shape [ 1 :], 128 , anchor_num * ( class_num + 5 ))( cat2 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y3 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 8 , input_shape [ 1 ] // 8 , 3 , 5 + class_num ))( y3 ) # \u8fd4\u56de\u7ed3\u679c return tf . keras . Model ( inputs = inputs , outputs = ( y1 , y2 , y3 )) 2.5 \u8f93\u51fa\u7ed3\u679c\u5904\u7406 \u00b6 \u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u662f\uff1a \u5750\u6807\u662f\u5bf9anchor\u7684\u4fee\u6b63\uff0c\u5c06\u5176\u8f6c\u6362\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u7684\u5f62\u5f0f\uff0c\u5728\u9884\u6d4b\u8fc7\u7a0b\u548c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u4f7f\u7528\u3002 V3\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a$ t_x,t_y,t_w,t_h$ \u4e0e\u8fb9\u6846\u8868\u793a b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002\u6839\u636e\u4e0a\u8ff0\u5173\u7cfb\u5bf9\u7f51\u7edc\u7684\u8f93\u51fa\u8fdb\u884c\u4fee\u6b63\u3002 \u53e6\u5916\u5bf9\u4e8e\u5206\u7c7b\u7684\u8f93\u51fa\u7ed3\u679c\u5e94\u9001\u5165\u5230Sigmoid\u6fc0\u6d3b\u51fd\u6570\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u5e38\u89c1\u7684\u65b9\u6cd5\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u628a\u4efb\u610f\u7684\u8868\u8fbe\u5f0ffunction\u4f5c\u4e3a\u4e00\u4e2a\u201cLayer\u201d\u5bf9\u8c61: keras . layers . Lambda ( function , output_shape = None , mask = None , arguments = None ) \u53c2\u6570\uff1a function\uff1a\u9700\u8981\u5c01\u88c5\u7684\u51fd\u6570\u3002 output_shape: \u9884\u671f\u7684\u51fd\u6570\u8f93\u51fa\u5c3a\u5bf8\u3002 arguments: \u53ef\u9009\u7684\u9700\u8981\u4f20\u9012\u7ed9\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570 \u8f6c\u6362\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8f6c\u6362\u4e3abbox\u7684\u5750\u6807\u53ca\u5bbd\u9ad8 def OutputParser ( input_shape , img_shape , anchors ): # feats/input_shape\u7684\u610f\u4e49\uff1a[batch,height,width,anchor_num,(1(delta x) + 1(delta y) + 1(width scale) + 1(height scale) + 1(object mask) + class_num(class probability))] feats = tf . keras . Input ( input_shape ) # \u83b7\u53d6\u7f51\u683cgrid\u7684\u5de6\u4e0a\u89d2x,y\u5750\u6807\uff0c\u5bf9\u5e94\u7740cx,cy # \u83b7\u53d6\u884cy\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u9ad8 # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(height,1,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u5217\u6570x\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_y = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 1 ], dtype = tf . float32 ), dtype = tf . float32 ), ( - 1 , 1 , 1 , 1 )), ( 1 , tf . shape ( x )[ 2 ], 1 , 1 )))( feats ) # \u83b7\u53d6\u5217x\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u5bbd # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(1,width,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u884c\u6570y\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_x = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 2 ], dtype = tf . float32 ), dtype = tf . float32 ), ( 1 , - 1 , 1 , 1 )), ( tf . shape ( x )[ 1 ], 1 , 1 , 1 )))( feats ) # \u6784\u5efagrid\u7684\u7f51\u683c\u8868\u793a # grid.shape = (grid h, grid w, 1, 2) grid = tf . keras . layers . Concatenate ( axis =- 1 )([ grid_x , grid_y ]) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u7ed3\u679c\u4e2d\u5fc3\u70b9\u5750\u6807:\u5c06\u9884\u6d4b\u7ed3\u679c\u8f6c\u6362\u4e3a\u4e2d\u5fc3\u70b9\u5750\u6807 # box_xy = (delta x, delta y) + (priorbox upper left x,priorbox upper left y) / (feature map.width, feature map.height) # box_xy.shape = (batch, grid h, grid w, anchor_num, 2) box_xy = tf . keras . layers . Lambda ( lambda x : ( tf . math . sigmoid ( x [ 0 ][ ... , 0 : 2 ]) + x [ 1 ]) / tf . cast ( [ tf . shape ( x [ 1 ])[ 1 ], tf . shape ( x [ 1 ])[ 0 ]], dtype = tf . float32 ))([ feats , grid ]) # box_wh.shape = (batch, grid h, grid w, anchor_num, 2) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c\u7684\u5bbd\u9ad8 # box_wh = (width scale, height scale) * (anchor width, anchor height) / (image.width, image.height) box_wh = tf . keras . layers . Lambda ( lambda x , y , z : tf . math . exp ( x [ ... , 2 : 4 ]) * y / tf . cast ( [ z [ 1 ], z [ 0 ]], dtype = tf . float32 ), arguments = { 'y' : anchors , 'z' : img_shape })( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u4e2d\u5305\u542b\u76ee\u6807\u7684\u6982\u7387 box_confidence = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 4 ]))( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u6982\u7387 box_class_probs = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 5 :]))( feats ) # \u8fd4\u56de\u8f93\u51fa\u7ed3\u679c return tf . keras . Model ( inputs = feats , outputs = ( box_xy , box_wh , box_confidence , box_class_probs )) 3.\u6a21\u578b\u8bad\u7ec3 \u00b6 3.1\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97 \u00b6 YoloV3\u7684\u635f\u5931\u51fd\u6570\u5206\u4e3a\u4e09\u90e8\u5206\uff1a box\u7684\u635f\u5931\uff1a \u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u7684gridcell\u4e2d\u7684anchor\u624d\u4f1a\u8ba1\u5165\u635f\u5931,\u5bf9x,y,w,h\u5206\u522b\u6c42\u5747\u65b9\u8bef\u5dee \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931 \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u6709\u7684box\u90fd\u8ba1\u5165\u635f\u5931\u8ba1\u7b97 \u5206\u7c7b\u7684\u635f\u5931\uff1a \u5206\u7c7b\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u76ee\u6807\u7684\u624d\u8ba1\u7b97\u635f\u5931 def Loss ( img_shape , class_num = 80 ): # anchor\u7684\u5c3a\u5ea6\uff1a\u5206\u522b\u68c0\u6d4b\u5c0f\uff0c\u4e2d\uff0c\u5927\u7684\u76ee\u6807 anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]} # \u6784\u5efa\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u6570\u7ec4 input_shapes = [ ( img_shape [ 0 ] // 32 , img_shape [ 1 ] // 32 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 16 , img_shape [ 1 ] // 16 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 8 , img_shape [ 1 ] // 8 , 3 , 5 + class_num ) ] # \u7f51\u7edc\u7684\u8f93\u51fa\u503c inputs = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] # \u76ee\u6807\u503c labels = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] losses = list () # \u904d\u5386\u4e09\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa for l in range ( 3 ): # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684\u5f62\u72b6 input_shape_of_this_layer = input_shapes [ l ] # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684anchor anchors_of_this_layer = anchors [ l ] # \u83b7\u53d6\u7f51\u7edc\u8f93\u51fa input_of_this_layer = inputs [ l ] # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label_of_this_layer = labels [ l ] # YOLOV3\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff1a\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5bbd\u9ad8\uff0c\u7f6e\u4fe1\u5ea6 pred_xy , pred_wh , pred_box_confidence , pred_class = OutputParser ( input_shape_of_this_layer , img_shape , anchors_of_this_layer )( input_of_this_layer ) # \u9884\u6d4b\u6846 pred_box = tf . keras . layers . Concatenate ()([ pred_xy , pred_wh ]) # \u771f\u5b9e\u503c true_box = tf . keras . layers . Lambda ( lambda x : x [ ... , 0 : 4 ])( label_of_this_layer ) true_box_confidence = tf . keras . layers . Lambda ( lambda x : x [ ... , 4 ])( label_of_this_layer ) true_class = tf . keras . layers . Lambda ( lambda x : x [ ... , 5 :])( label_of_this_layer ) # \u83b7\u53d6box\u7684\u7f6e\u4fe1\u5ea6 object_mask = tf . keras . layers . Lambda ( lambda x : tf . cast ( x , dtype = tf . bool ))( true_box_confidence ) # \u8ba1\u7b97MSE\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97 pos_loss = tf . keras . layers . Lambda ( lambda x : tf . math . reduce_sum ( tf . keras . losses . MSE ( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) )) )([ true_box , pred_box , object_mask ]) # \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\uff1a\u4ea4\u53c9\u71b5\u635f\u5931 confidence_loss = tf . keras . layers . Lambda ( lambda x : # \u6b63\u6837\u672c\u7684\u635f\u5931 tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) + # \u8d1f\u6837\u672c\u7684\u635f\u5931 100 * tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], tf . math . logical_not ( x [ 2 ])), tf . boolean_mask ( x [ 1 ], tf . math . logical_not ( x [ 2 ])) ) )([ true_box_confidence , pred_box_confidence , object_mask ]) # \u5206\u7c7b\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u8ba1\u7b97\u635f\u5931 class_loss = tf . keras . layers . Lambda ( lambda x : tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) )([ true_class , pred_class , object_mask ]) # \u635f\u5931\u7ed3\u679c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( [ pos_loss , confidence_loss , class_loss ]) losses . append ( loss ) # \u8ba1\u7b97\u635f\u5931\u503c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( losses ) return tf . keras . Model ( inputs = ( * inputs , * labels ), outputs = loss ) 3.2 \u6b63\u8d1f\u6837\u672c\u7684\u8bbe\u5b9a \u00b6 \u5728\u4e0a\u8ff0\u7684loss\u8ba1\u7b97\u4e2d\uff0c\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684anchor\u5c31\u662f\u6b63\u6837\u672c\uff0c\u800c\u4e0d\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u4e5f\u5c31\u662f\u80cc\u666f\uff0c\u90a3\u5728\u8fd9\u91cc\u6211\u4eec\u662f\u5982\u4f55\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b63\u6837\u672c \uff1a\u9996\u5148\u8ba1\u7b97\u76ee\u6807\u4e2d\u5fc3\u70b9\u843d\u5728\u54ea\u4e2agrid\u4e0a\uff0c\u7136\u540e\u8ba1\u7b97\u8fd9\u4e2agrid\u5bf9\u5e94\u76843\u4e2a\u5148\u9a8c\u6846\uff08anchor\uff09\u548c\u76ee\u6807\u771f\u5b9e\u4f4d\u7f6e\u7684IOU\u503c\uff0c\u53d6IOU\u503c\u6700\u5927\u7684\u5148\u9a8c\u6846\u548c\u76ee\u6807\u5339\u914d\u3002\u90a3\u4e48\u8be5anchor \u5c31\u8d1f\u8d23\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807\uff0c\u90a3\u8fd9\u4e2aanchor\u5c31\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1\uff0c\u5176\u4ed6\u7684\u76ee\u6807\u503c\u6839\u636e\u6807\u6ce8\u4fe1\u606f\u8bbe\u7f6e\u3002 \u8d1f\u6837\u672c \uff1a\u6240\u6709\u4e0d\u662f\u6b63\u6837\u672c\u7684anchor\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a0\uff0c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5176\u5b83\u7684\u503c\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u9ed8\u8ba4\u4e3a0\u3002 \u5728\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u505a\u4e86\u4f18\u5316\uff0c\u5728\u8ba1\u7b97\u662f\u5426\u4e3a\u6b63\u6837\u672c\u65f6\uff0c\u6211\u4eec\u8ba4\u4e3aanchor\u548c\u76ee\u6807\u7684\u4e2d\u5fc3\u70b9\u662f\u76f8\u540c\u7684\uff0c\u76f4\u63a5\u5229\u7528anchor\u548c\u76ee\u6807box\u7684\u5bbd\u9ad8\u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff0c\u786e\u5b9a\u6b63\u6837\u672c\u3002\u5b9e\u73b0\u5982\u4e0b\uff1a \u5b9a\u4e49anchor: YOLOv3_anchors = np . array ([[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ], [ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ], [ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]], dtype = np . int32 ) \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97anchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u786e\u5b9a\u6b63\u8d1f\u6837\u672c\uff1a def bbox_to_tensor ( bbox , label , input_shape = ( 416 , 416 ), anchors = YOLOv3_anchors , num_classes = 80 ): # bbox\uff1a\u771f\u5b9e\u503c\u5750\u6807\u8868\u793a\u4e3a(xmin,ymin,xmax,ymax)\uff0c\u662f\u76f8\u5bf9\u5750\u6807 # label\uff1a \u6bcf\u4e2abbox\u7684\u7c7b\u522b # anchors = (9,2) # \u8fd4\u56de\uff1aanchor\u5bf9\u5e94\u7684\u771f\u5b9e\u503c,\u5373\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\u7ed3\u679c \u83b7\u53d6\u5c3a\u5ea6\u4e2a\u6570\u548cbox\u7684\u7edd\u5bf9\u5750\u6807 # \u83b7\u53d6\u6709\u51e0\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u5bf9\u5e943\u4e2aanchor:3 num_layers = anchors . shape [ 0 ] // 3 # anchor\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u63a9\u7801\uff1a\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u5bf9\u5e94\u7b2c6\uff0c7\uff0c8\u4e2aanchor... anchor_mask = tf . cond ( tf . equal ( num_layers , 3 ), lambda : tf . constant ( [[ 6 , 7 , 8 ], [ 3 , 4 , 5 ], [ 0 , 1 , 2 ]]), lambda : tf . constant ([[ 3 , 4 , 5 ], [ 1 , 2 , 3 ]])) # bbox\u7684\u76f8\u5bf9\u4e2d\u5fc3\u70b9\u5750\u6807 true_boxes_xy = ( bbox [ ... , 0 : 2 ] + bbox [ ... , 2 : 4 ]) / 2. # bbox\u7684\u76f8\u5bf9\u5bbd\u9ad8 true_boxes_wh = tf . math . abs ( bbox [ ... , 2 : 4 ] - bbox [ ... , 0 : 2 ]) # bbox\u7684\u7ed3\u679c:\u5c06\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u62fc\u63a5\u5728\u4e00\u8d77 true_boxes = tf . concat ([ true_boxes_xy , true_boxes_wh ], axis =- 1 ) # bbox\u7684\u7edd\u5bf9\u5750\u6807\u548c\u7edd\u5bf9\u5bbd\u9ad8 boxes_xy = true_boxes [ ... , 0 : 2 ] * input_shape boxes_wh = true_boxes [ ... , 2 : 4 ] * input_shape \u521b\u5efa\u4e00\u4e2a\u4e0e\u7f51\u7edc\u8f93\u51fa\u5927\u5c0f\u76f8\u540c\u7684\u5168\u96f6\u6570\u7ec4\uff0c\u7528\u6765\u8bbe\u7f6e\u771f\u5b9e\u503c # \u751f\u6210\u4e0eyoloV3\u8f93\u51fa\u7ed3\u679c\u76f8\u540c\u5927\u5c0f\u7684\u51680\u6570\u7ec4\uff1ay_true.shape[layer] = (height, width, anchor num, 5 + class num) y_true = tuple (( np . zeros ( shape = ( input_shape [ 0 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], input_shape [ 1 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], tf . shape ( anchor_mask [ l , ... ])[ 0 ], 5 + num_classes ), dtype = np . float32 ) for l in range ( num_layers ))) \u8ba1\u7b97anchor\u7684\u4f4d\u7f6e\u4fe1\u606f # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653eanchor\u7684\u7d22\u5f15 anchors = tf . expand_dims ( tf . convert_to_tensor ( anchors , dtype = tf . float32 ), 0 ) # \u7528\u4e8e\u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807 anchor_maxes = anchors / 2. # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807 anchor_mins = - anchor_maxes \u5bf9\u76ee\u6807\u8fdb\u884c\u7b5b\u9009\uff0c\u53ea\u6709\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u6b63\u7684\u76ee\u6807 # \u521b\u5efa\u4e00\u4e2amask,\u6307\u660e\u76ee\u6807\u662f\u5426\u5b58\u5728\uff0c\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u5b9e\u7684\u76ee\u6807 valid_mask = tf . greater ( boxes_wh [ ... , 0 ], 0 \uff09 # \u83b7\u53d6\u771f\u5b9e\u7684\u76ee\u6807\u7684\u5bbd\u9ad8 wh = tf . boolean_mask ( boxes_wh , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684box\uff1avalid_true_boxes.shape = (valid box num, 4) valid_true_boxes = tf . boolean_mask ( boxes , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684\u6807\u7b7e\u503c\uff1avalid_label.shape = (valid box num) valid_label = tf . boolean_mask ( label , valid_mask ) \u83b7\u53d6\u4e0e\u76ee\u6807\u4ea4\u5e76\u6700\u5927\u7684anchor,\u90a3\u8fd9\u4e9banchor\u5373\u4e3a\u6b63\u6837\u672c # \u5f53\u56fe\u50cf\u4e2d\u5b58\u5728\u76ee\u6807\u65f6\uff0c\u8ba1\u7b97\u4e0e\u76ee\u6807\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5e76\u8bbe\u7f6e\u6807\u8bb0\u7ed3\u679c if wh . shape [ 0 ] > 0 : # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653e\u5bf9\u5e94\u7684anchor\uff1awh.shape = (valid box num, 1, 2) wh = tf . expand_dims ( wh , - 2 ) # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807\uff1amax of width, height, box_maxes.shape = (valid box num, 1, 2) box_maxes = wh / 2 # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807\uff1amin of width, height, box_mins.shape = (valid box num, 1, 2) box_mins = - box_maxes # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807\uff1aintersect_mins.shape = (valid box num, anchor num(9), 2) intersect_mins = tf . math . maximum ( box_mins , anchor_mins ) # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807\uff1aintersect_maxes.shape = (valid box num, anchor num(9), 2) intersect_maxes = tf . math . minimum ( box_maxes , anchor_maxes ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u5bbd\u9ad8\uff1aintersect_wh.shape = (valid box num, anchor num(9), 2) intersect_wh = tf . math . maximum ( intersect_maxes - intersect_mins , 0. ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u9762\u79ef\uff1aintersect_area.shape = (valid box num, anchor num(9)) intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97box\u7684\u9762\u79ef\uff1abox_area.shape = (valid box_num, 1) box_area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u8ba1\u7b97anchor\u7684\u9762\u79ef\uff1aanchor_area.shape = (1, anchor num(9)) anchor_area = anchors [ ... , 0 ] * anchors [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff1aiou.shape = (valid box num, anchor num(9)) iou = intersect_area / ( box_area + anchor_area - intersect_area ) # \u8ba1\u7b97\u4e0ebox\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor,\u5c06\u5176\u4f5c\u4e3a\u6b63\u6837\u672c\uff1abest_anchor.shape = (valid box num) best_anchor = tf . math . argmax ( iou , axis =- 1 , output_type = tf . int32 ) \u904d\u5386\u5339\u914d\u6210\u529f\u7684anchor(\u6b63\u6837\u672c)\uff0c\u8bbe\u7f6e\u76ee\u6807\u503c # \u904d\u5386\u4e0ebox\u5339\u914d\u6210\u529f\u7684anchor for t in range ( tf . shape ( best_anchor )[ 0 ]): # \u83b7\u53d6\u7b2ct\u4e2aanchor n = best_anchor [ t ] # \u83b7\u53d6anchor\u7684\u4f4d\u7f6e pos = tf . where ( tf . equal ( anchor_mask , n )) # \u83b7\u53d6\u5c3a\u5ea6\u503c\uff1a0\uff0c1\uff0c2 l = pos [ 0 ][ 0 ] # \u83b7\u53d6\u5bf9\u5e94\u7684anchor\u7d22\u5f15 k = pos [ 0 ][ 1 ] # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u5217\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 i = int ( tf . clip_by_value ( valid_true_boxes [ t , 1 ] * y_true [ l ] . shape [ 0 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 0 ] - 1 )) # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u884c\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 j = int ( tf . clip_by_value ( valid_true_boxes [ t , 0 ] * y_true [ l ] . shape [ 1 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 1 ] - 1 )) # \u83b7\u53d6anchor\u7684\u7c7b\u522b c = valid_label [ t ] # box\u7684\u4f4d\u7f6e:(x,y,width,height) y_true [ l ][ i , j , k , 0 : 4 ] = valid_true_boxes [ t , 0 : 4 ] # \u5339\u914d\u4e0a\u7684\u90fd\u5305\u542b\u76ee\u6807\uff0c\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1 y_true [ l ][ i , j , k , 4 ] = 1 # \u7c7b\u522b\u4fe1\u606f y_true [ l ][ i , j , k , 5 + c ] = 1 \u8fd4\u56de\u7ed3\u679c # \u8fd4\u56de3\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u771f\u5b9e\u503c return ( tf . convert_to_tensor ( y_true [ 0 ]), tf . convert_to_tensor ( y_true [ 1 ]), tf . convert_to_tensor ( y_true [ 2 ])) 3.3 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a 3.3.1 \u83b7\u53d6\u6570\u636e\u96c6 \u00b6 \u9996\u5148\u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u6570\u636e\u5904\u7406\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u8fd9\u4e9b\u901a\u8fc7map\u65b9\u6cd5\u6765\u5b9e\u73b0 1.\u5b9a\u4e49\u65b9\u6cd5\u8fdb\u884c\u6570\u636e\u5904\u7406\u548c\u83b7\u53d6\u76ee\u6807\u503c def map_function_impl ( image , bbox , label ): # \u56fe\u50cf\u5c3a\u5ea6\u8c03\u6574 image , bbox = preprocess ( image , bbox , random = True ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label1 , label2 , label3 = bbox_to_tensor ( bbox , label ) # \u8fd4\u56de\u7ed3\u679c return image , label1 , label2 , label3 2.\u4f7f\u7528py_function\u6765\u63d0\u9ad8\u6027\u80fd def map_function ( image , width , height , boxes , boxes_category ): # \u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u83b7\u53d6\u56fe\u50cf\u53ca\u76ee\u6807\u503c\uff1a\u63d0\u5347\u6027\u80fd image , label1 , label2 , label3 = tf . py_function ( map_function_impl , inp = [ image , boxes , boxes_category ], Tout = [ tf . float32 , tf . float32 , tf . float32 , tf . float32 ]) # \u5bf9\u56fe\u50cf\u548c\u76ee\u6807\u503c\u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574 image = tf . reshape ( image , ( 416 , 416 , 3 )) label1 = tf . reshape ( label1 , ( 13 , 13 , 3 , 85 )) label2 = tf . reshape ( label2 , ( 26 , 26 , 3 , 85 )) label3 = tf . reshape ( label3 , ( 52 , 52 , 3 , 85 )) # \u8fd4\u56de\u7ed3\u679c return image , ( label1 , label2 , label3 ) 3.\u4f7f\u7528map\u65b9\u6cd5\u5bf9\u4eceTFRcords\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u8fdb\u884c\u5904\u7406 # \u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5904\u7406 batch_size = 10 trainset = raw_datasets . map ( map_function ) . shuffle ( batch_size ) . batch ( batch_size ) . prefetch ( tf . data . experimental . AUTOTUNE ) 3.3.2 \u6a21\u578b\u8bad\u7ec3 \u00b6 \u6a21\u578b\u521d\u59cb\u5316\uff1a yolov3 = YOLOv3 (( 416 , 416 , 3 ,), 20 ) yolov3_loss = Loss (( 416 , 416 , 3 ), 20 ) \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5\uff1a # \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5 optimizer = tf . keras . optimizers . Adam ( 1e-4 ) \u63a5\u4e0b\u6765\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\uff0c\u8fd9\u91cc\u4f7f\u7528\uff1a 1.\u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c 2.\u4f7f\u7528 tape.gradient(ys, xs)\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 3.\u4f7f\u7528 optimizer.apply_gradients(grads_and_vars)\u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u8bad\u7ec3\uff0c\u5e76\u4fdd\u5b58\u8bad\u7ec3\u7ed3\u679c # \u904d\u5386\u56fe\u50cf\u548c\u76ee\u6807\u503c\uff0c\u8fdb\u884c\u66f4\u65b0 for images , labels in trainset : # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d outputs = yolov3 ( images ) # \u8ba1\u7b97\u635f\u5931\u51fd\u6570 loss = yolov3_loss ([ * outputs , * labels ]) # \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , yolov3 . trainable_variables ) try : # \u8fdb\u884c\u68af\u5ea6\u68c0\u67e5 grads_check = [ tf . debugging . check_numerics ( grad , 'the grad is not correct! cancel gradient apply!' ) for grad in grads ] with tf . control_dependencies ( grads_check ): # \u68af\u5ea6\u66f4\u65b0 optimizer . apply_gradients ( zip ( grads , yolov3 . trainable_variables )) except BaseException as e : print ( e . message ) # \u4fdd\u5b58\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c yolov3 . save ( 'yolov3.h5' ) 4.\u6a21\u578b\u9884\u6d4b \u00b6 \u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b,\u5728\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7yoloV3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u9884\u6d4b\u4e4b\u540e\u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\u540e\uff0c\u83b7\u53d6\u591a\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u4f7f\u7528NMS\u8fdb\u884c\u68c0\u6d4b\u6846\u7684\u7b5b\u9009\u3002 \u9996\u5148\u5b9a\u4e49\u9884\u6d4b\u7c7b\uff1a # \u5b9a\u4e49\u9884\u6d4b\u7c7b class Predictor ( object ): \u6307\u660eanchor\u7684\u5927\u5c0f\uff1a # anchorbox\u7684\u5927\u5c0f anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]} 4.1 \u521d\u59cb\u5316 \u00b6 \u8fdb\u884c\u6a21\u578b\u521d\u59cb\u5316 # \u521d\u59cb\u5316 def __init__ ( self , input_shape = ( 416 , 416 , 3 ), class_num = 80 , yolov3 = None ): # \u8f93\u5165\u5927\u5c0f self . input_shape = input_shape # \u6a21\u578b\u521d\u59cb\u5316 self . yolov3 = tf . keras . models . load_model ( 'yolov3.h5' , compile = False ) # \u5c06\u7ed3\u679c\u8f6c\u6362\u4e3a\u5750\u6807\u503c self . parsers = [ OutputParser ( tuple ( self . yolov3 . outputs [ l ] . shape [ 1 :]), self . input_shape , self . anchors [ l ]) for l in range ( 3 )] 4.2 \u9884\u6d4b\u65b9\u6cd5\u5b9e\u73b0 \u00b6 \u5728\u8fd9\u91cc\u52a0\u5165NMS\u65b9\u6cd5\uff1a 4.2.1 \u83b7\u53d6\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c \u00b6 def predict ( self , image , conf_thres = 0.5 , nms_thres = 0.5 ): # conf_thres\uff1a\u7f6e\u4fe1\u5ea6\u7684\u9608\u503c\uff0cNMS\u4e2d\u4ea4\u5e76\u6bd4\u7684\u9608\u503c # \u589e\u52a0\u4e00\u7ef4batch images = tf . expand_dims ( image , axis = 0 ) # \u56fe\u50cf\u53d8\u5f62 resize_images = tf . image . resize ( images , self . input_shape [: 2 ], method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u56fe\u50cf\u53d8\u5f62\u540e\u7684\u5927\u5c0f resize_shape = resize_images . shape [ 1 : 3 ] # \u56fe\u50cf\u5728\u4e0a\u4e0b\u5de6\u53f3\u586b\u5145\u7684\u5927\u5c0f top_pad = ( self . input_shape [ 0 ] - resize_shape [ 0 ]) // 2 bottom_pad = self . input_shape [ 0 ] - resize_shape [ 0 ] - top_pad left_pad = ( self . input_shape [ 1 ] - resize_shape [ 1 ]) // 2 right_pad = self . input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u586b\u5145\u4e3a128 resize_images = tf . pad ( resize_images , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u6807\u51c6\u5dee deviation = tf . constant ([ left_pad / self . input_shape [ 1 ], top_pad / self . input_shape [ 0 ], 0 , 0 ], dtype = tf . float32 ) # \u5c3a\u5ea6\u7684\u53d8\u6362 scale = tf . constant ([ self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ], self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ] ], dtype = tf . float32 ) # \u7c7b\u578b\u8f6c\u6362 images_data = tf . cast ( resize_images , tf . float32 ) / 255. # \u8f93\u51fa\u7ed3\u679c outputs = self . yolov3 ( images_data ) 4.2.2 \u7ed3\u679c\u7ec4\u5408 \u00b6 \u904d\u5386\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\uff0c\u8fdb\u884c\u62fc\u63a5 # \u76ee\u6807\u503c whole_targets = tf . zeros (( 0 , 6 ), dtype = tf . float32 ) # \u904d\u5386\u6bcf\u4e00\u4e2a\u5c3a\u5ea6 for i in range ( 3 ): # \u83b7\u53d6\u9884\u6d4b\u7684\u4f4d\u7f6e\u3001\u7f6e\u4fe1\u5ea6\u548c\u5206\u7c7b\u7ed3\u679c pred_xy , pred_wh , pred_box_confidence , pred_class = self . parsers [ i ]( outputs [ i ]) # \u83b7\u53d6\u76ee\u6807\u6846\u7684\u4f4d\u7f6e pred_box = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_xy , pred_wh ]) #\u76ee\u6807\u6846\u7684\u7f6e\u4fe1\u5ea6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\uff1atarget_mask.shape = (h, w, anchor num) target_mask = tf . greater ( pred_box_confidence , conf_thres ) # \u83b7\u53d6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\u7684\u7f6e\u4fe1\u5ea6\uff1apred_box_confidence = (pred target num, 1) pred_box_confidence = tf . boolean_mask ( pred_box_confidence , target_mask ) # \u5728\u6700\u540e\u589e\u52a0\u4e00\u7ef4 pred_box_confidence = tf . expand_dims ( pred_box_confidence , axis =- 1 ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u6846\u68c0\u6d4b\u7ed3\u679c pred_box.shape = (pred target num, 4) pred_box = tf . boolean_mask ( pred_box , target_mask ) # \u5f52\u4e00\u5316\u5904\u7406 pred_box = ( pred_box - deviation ) * scale * \\ [ image . shape [ 1 ], image . shape [ 0 ], image . shape [ 1 ], image . shape [ 0 ]] # \u5206\u7c7b\u7ed3\u679c\uff1apred_class.shape = (pred target num, 1) pred_class = tf . boolean_mask ( pred_class , target_mask ) # \u83b7\u53d6\u6bcf\u4e2a\u7c7b\u522b\u6700\u5927\u7684\u7d22\u5f15 pred_class = tf . math . argmax ( pred_class , axis =- 1 ) # \u7c7b\u578b\u8f6c\u6362 pred_class = tf . cast ( tf . expand_dims ( pred_class , axis =- 1 ), dtype = tf . float32 ) # \u5c06\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 targets,sgaoe = (pred target num, 6) targets = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_box , pred_box_confidence , pred_class ]) # \u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 whole_targets = tf . keras . layers . Concatenate ( axis = 0 )([ whole_targets , targets ]) 4.2.3 NMS \u00b6 \u8fdb\u884cNMS\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c # \u8fdb\u884cNMS,\u6392\u5e8f\u4ee5\u7f6e\u4fe1\u5ea6\u6392\u5e8f,\u4ece\u5927\u5230\u5c0f\u6392\u5e8f descend_idx = tf . argsort ( whole_targets [ ... , 4 ], direction = 'DESCENDING' ) i = 0 # \u904d\u5386 while i < descend_idx . shape [ 0 ]: # \u83b7\u53d6\u7d22\u5f15\u503c idx = descend_idx [ i ] # \u5de6\u4e0a\u89d2\u5750\u6807 cur_upper_left = whole_targets [ idx , 0 : 2 ] - whole_targets [ idx , 2 : 4 ] / 2 # \u53f3\u4e0b\u89d2\u5750\u6807 cur_down_right = cur_upper_left + whole_targets [ idx , 2 : 4 ] # \u5bbd\u9ad8 wh = whole_targets [ idx , 2 : 4 ] # \u83b7\u53d6\u9762\u79ef area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u7d22\u5f15 following_idx = descend_idx [ i + 1 :] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846 following_targets = tf . gather ( whole_targets , following_idx ) # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5de6\u4e0a\u89d2\u5750\u6807 following_upper_left = following_targets [ ... , 0 : 2 ] - following_targets [ ... , 2 : 4 ] / 2 # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u53f3\u4e0b\u89d2\u5750\u6807 following_down_right = following_upper_left + following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5bbd\u9ad8 following_wh = following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u9762\u79ef following_area = following_wh [ ... , 0 ] * following_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u8ba1\u7b97\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807 max_upper_left = tf . math . maximum ( cur_upper_left , following_upper_left ) # \u8ba1\u7b97\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807 min_down_right = tf . math . minimum ( cur_down_right , following_down_right ) # \u4ea4\u7684\u5bbd\u9ad8 intersect_wh = min_down_right - max_upper_left # \u5c06\u5bbd\u9ad8\u5927\u4e8e0\uff0c\u4fdd\u6301\u4e0d\u53d8\uff0c\u5c0f\u4e8e0\u7684\u7f6e\u4e3a0 intersect_wh = tf . where ( tf . math . greater ( intersect_wh , 0 ), intersect_wh , tf . zeros_like ( intersect_wh )) # \u8ba1\u7b97\u4ea4\u7684\u9762\u79ef intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 overlap = intersect_area / ( area + following_area - intersect_area ) # \u83b7\u53d6\u5c0f\u4e8eNMS\u9608\u503c\u7684\u4fdd\u7559\uff0c\u5176\u4ed6\u7684\u820d\u5f03 indices = tf . where ( tf . less ( overlap , nms_thres )) # \u8fdb\u884c\u5207\u7247\uff0c\u4fdd\u7559\u7ed3\u679c following_idx = tf . gather_nd ( following_idx , indices ) # \u5c06\u5176\u6dfb\u52a0\u5230descend\u4e2d\u5373\u53ef descend_idx = tf . concat ([ descend_idx [: i + 1 ], following_idx ], axis = 0 ) i += 1 # \u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c whole_targets = tf . gather ( whole_targets , descend_idx ) # \u5de6\u4e0a\u89d2\u5750\u6807 upper_left = ( whole_targets [ ... , 0 : 2 ] - whole_targets [ ... , 2 : 4 ] / 2 ) # \u53f3\u4e0b\u89d2\u5750\u6807 down_right = ( upper_left + whole_targets [ ... , 2 : 4 ]) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c boundings = tf . keras . layers . Concatenate ( axis =- 1 )([ upper_left , down_right , whole_targets [ ... , 4 :]]) return boundings 4.3 \u9884\u6d4b\u7ed3\u679c \u00b6 \u6a21\u578b\u7684\u9884\u6d4b\u6548\u679c\uff1a import cv2 import numpy as np import matplotlib.pyplot as plt # \u56fe\u50cf\u8bfb\u53d6 img = cv2 . imread ( \"image.jpg\" ) # \u5b9e\u4f8b\u5316 predictor = Predictor () # \u83b7\u53d6\u7ed3\u679c boundings = predictor . predict ( img ) # \u663e\u793a\u56fe\u50cf plt . imshow ( img [:, :, :: - 1 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] for bounding in boundings : # \u7ed8\u5236\u6846 rect = Rectangle (( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy ()), bounding [ 2 ] . numpy ( ) - bounding [ 0 ] . numpy (), bounding [ 3 ] . numpy () - bounding [ 1 ] . numpy (), color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u7c7b\u522b\u4fe1\u606f # \u83b7\u53d6\u7c7b\u522b\u4fe1\u606f\u7684id label_id = bounding [ 5 ] . numpy () . astype ( 'int32' ) # \u83b7\u53d6\u7c7b\u522b label = classes [ label_id ] # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy () + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c # \u663e\u793a\u56fe\u50cf plt . show () \u9884\u6d4b\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u603b\u7ed3 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\u3002 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u57fa\u672c\u7ec4\u4ef6\u7684\u6784\u5efa\uff0cbackbone\uff0coutput, yoloV3, \u8f93\u51fa\u503c\u7684\u8f6c\u6362 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u77e5\u9053\u5bf9\u56fe\u50cf\u8fdb\u884cresize,\u4fdd\u6301\u5bbd\u9ad8\u6bd4\uff0c\u8fdb\u884cpad\u7684\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b \u77e5\u9053\u635f\u5931\u51fd\u6570\uff0c\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\uff0c\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002","title":"YOLOV3\u6848\u4f8b"},{"location":"objectdection/05.yolo-demo/#45-yolov3","text":"\u5b66\u4e60\u76ee\u6807 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b","title":"4.5 YoloV3 \u6848\u4f8b"},{"location":"objectdection/05.yolo-demo/#1tfrecord","text":"\u8be5\u6848\u4f8b\u4e2d\u6211\u4eec\u4f9d\u7136\u4f7f\u7528VOC\u6570\u636e\u96c6\u6765\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u4e0d\u540c\u7684\u662f\u6211\u4eec\u8981\u5229\u7528tfrecord\u6587\u4ef6\u6765\u5b58\u50a8\u548c\u8bfb\u53d6\u6570\u636e\uff0c\u9996\u5148\u6765\u770b\u4e00\u4e0btfrecord\u6587\u4ef6\u7684\u76f8\u5173\u5185\u5bb9\u3002 \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528tfrecord\u6587\u4ef6\uff1f TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002 TFRecord\u89c4\u8303\u4e86\u6570\u636e\u7684\u8bfb\u5199\u65b9\u5f0f\uff0c\u6570\u636e\u8bfb\u53d6\u548c\u5904\u7406\u7684\u6548\u7387\u90fd\u4f1a\u5f97\u5230\u663e\u8457\u7684\u63d0\u9ad8\u3002","title":"1.TFrecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#11-tfrecord","text":"TFRecord \u662fGoogle\u5b98\u65b9\u63a8\u8350\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u662fGoogle\u4e13\u95e8\u4e3aTensorFlow\u8bbe\u8ba1\u7684\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5229\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u6570\u636e\u53ef\u4ee5\u4f7f\u5176\u4e0e\u7f51\u7edc\u67b6\u6784\u66f4\u9002\u914d\u3002TFRecord\u662f\u4e00\u79cd\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5176\u80fd\u66f4\u597d\u7684\u5229\u7528\u5185\u5b58\uff0c\u4e0ecsv,hdf5\u6587\u4ef6\u662f\u7c7b\u4f3c\u7684\u3002 TFRecord\u7684\u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b\u56fe\u6240\u793a\uff1a TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\uff0c\u5176\u4e2d\uff0ckey \u662fstring\u7c7b\u578b\uff0c\u800cvalue \u7684\u53d6\u503c\u6709\u4e09\u79cd\uff1a tf.train.bytes_list: \u53ef\u4ee5\u5b58\u50a8string \u548cbyte\u4e24\u79cd\u6570\u636e\u7c7b\u578b\u3002\u56fe\u50cf\u6570\u636e\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u5373\u53ef\u3002 tf.train.float_list: \u53ef\u4ee5\u5b58\u50a8float(float32)\u4e0edouble(float64) \u4e24\u79cd\u6570\u636e\u7c7b\u578b \u3002 tf.train.int64_list: \u53ef\u4ee5\u5b58\u50a8\uff1abool, enum, int32, uint32, int64, uint64 \u3002 TFRecord \u5e76\u975e\u662fTensorFlow\u552f\u4e00\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528CSV\u6216\u6587\u672c\u7b49\u5176\u4ed6\u683c\u5f0f\uff0c\u4f46\u662f\u5bf9\u4e8eTensorFlow\u6765\u8bf4\uff0cTFRecord \u662f\u6700\u53cb\u597d\u7684\uff0c\u6700\u65b9\u4fbf\u7684\uff0c\u800c\u4e14tensorflow\u4e5f\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684API\u5e2e\u52a9\u6211\u4eec\u8f7b\u677e\u7684\u521b\u5efa\u548c\u83b7\u53d6TFRecord\u6587\u4ef6\u3002","title":"1.1 \u4ec0\u4e48\u662fTFrecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#12-tfrecord","text":"\u5bf9\u4e8e\u4e2d\u5927\u6570\u636e\u96c6\u6765\u8bf4\uff0cGoogle\u5b98\u65b9\u63a8\u8350\u5148\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3aTFRecord\u6570\u636e, \u8fd9\u6837\u53ef\u52a0\u5feb\u5728\u6570\u636e\u8bfb\u53d6, \u9884\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c31\u5c06VOC\u6570\u636e\u96c6\u8f6c\u6362\u4e3aRecords\u683c\u5f0f\uff0c\u5728\u8fd9\u91cc\u9996\u5148\u8bfb\u53d6\u6807\u6ce8XML\u6587\u4ef6\uff0c\u5e76\u627e\u5230\u5bf9\u5e94\u7684\u56fe\u50cf\u6570\u636e\uff0c\u6700\u540e\u5c06\u6570\u636e\u5199\u5165TFRecords\u6587\u4ef6\u4e2d\u3002","title":"1.2 \u5c06\u6570\u636e\u8f6c\u6362\u4e3aTFRecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#121","text":"VOC\u6570\u636e\u96c6\u7684\u6807\u6ce8\u4fe1\u606f\u5b58\u50a8\u5728xml\u6587\u4ef6\u4e2d\uff0c\u5728VOC2007\u7684\u6570\u636e\u4e2d\u4e3b\u8981\u83b7\u53d6fIlename\uff0cwidth\uff0cheight\uff0c\u548cobject\uff08\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff09\u4e0b\u7684name\uff08\u76ee\u6807\u540d\u79f0\uff09\u548cbndbox\uff08\u6846\u7684\u4f4d\u7f6e\uff09\u3002\u5177\u4f53\u5927\u5bb6\u53ef\u4ee5\u770b\u4e0b\u5728FasterRCNN\u4e2d\u7684\u4ecb\u7ecd\uff0c\u4ee3\u7801\u5982\u4e0b\u6240\u793a\uff1a import xml.dom.minidom as xdom # VOC\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f voc_classes = { 'none' : 0 , 'aeroplane' : 1 , 'bicycle' : 2 , 'bird' : 3 , 'boat' : 4 , 'bottle' : 5 , 'bus' : 6 , 'car' : 7 , 'cat' : 8 , 'chair' : 9 , 'cow' : 10 , 'diningtable' : 11 , 'dog' : 12 , 'horse' : 13 , 'motorbike' : 14 , 'person' : 15 , 'pottedplant' : 16 , 'sheep' : 17 , 'sofa' : 18 , 'train' : 19 , 'tvmonitor' : 20 , } # \u8bfb\u53d6XML\u6587\u4ef6\u4e2d\u7684\u4fe1\u606f def Prase_Singel_xml ( xml_path ): DOMTree = xdom . parse ( xml_path ) RootNode = DOMTree . documentElement #\u83b7\u53d6XML\u6587\u4ef6\u5bf9\u5e94\u7684\u56fe\u50cf image_name = RootNode . getElementsByTagName ( \"filename\" )[ 0 ] . childNodes [ 0 ] . data #\u83b7\u53d6\u56fe\u50cf\u5bbd\u548c\u9ad8 size = RootNode . getElementsByTagName ( \"size\" ) image_height = int ( size [ 0 ] . getElementsByTagName ( \"height\" )[ 0 ] . childNodes [ 0 ] . data ) image_width = int ( size [ 0 ] . getElementsByTagName ( \"width\" )[ 0 ] . childNodes [ 0 ] . data ) #\u83b7\u53d6\u56fe\u50cf\u4e2d\u76ee\u6807\u5bf9\u8c61 all_obj = RootNode . getElementsByTagName ( \"object\" ) bndbox_lable_dic = [] # \u904d\u5386\u6240\u6709\u7684\u5bf9\u8c61 for one_obj in all_obj : # \u83b7\u53d6\u76ee\u6807\u7684\u6807\u6ce8\u4fe1\u606f obj_name = one_obj . getElementsByTagName ( \"name\" )[ 0 ] . childNodes [ 0 ] . data # \u83b7\u53d6\u5bf9\u5e94\u7684label\u503c obj_label = voc_classes [ obj_name ] # \u83b7\u53d6bbox bndbox = one_obj . getElementsByTagName ( \"bndbox\" ) # \u83b7\u53d6\u76ee\u6807\u7684\u5de6\u4e0a\u53f3\u4e0b\u7684\u4f4d\u7f6e xmin = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmin\" )[ 0 ] . childNodes [ 0 ] . data ) ymin = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymin\" )[ 0 ] . childNodes [ 0 ] . data ) xmax = int ( bndbox [ 0 ] . getElementsByTagName ( \"xmax\" )[ 0 ] . childNodes [ 0 ] . data ) ymax = int ( bndbox [ 0 ] . getElementsByTagName ( \"ymax\" )[ 0 ] . childNodes [ 0 ] . data ) # \u5c06\u76ee\u6807\u6846\u548c\u7c7b\u522b\u7ec4\u5408\u5728\u4e00\u8d77 bndbox_lable_dic . append ([ xmin , ymin , xmax , ymax , obj_label ]) # \u8fd4\u56de\u76f8\u5e94\u7684\u4fe1\u606f return image_name , image_width , image_height , bndbox_lable_dic \u63a5\u4e0b\u6765\u6211\u4eec\u8bfb\u53d6\u4e00\u4e2aXML\u6587\u4ef6\u770b\u4e0b\u6548\u679c\uff1a # \u5c55\u793a\u6548\u679c print ( Prase_Singel_xml ( 'VOCdevkit/VOC2007/Annotations/000007.xml' )) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a ( '000007.jpg' , 500 , 333 , [[ 141 , 50 , 500 , 330 , 7 ]]) \u4ece\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u5e94\u7684\u56fe\u50cf\u662f000007.jpg\uff0c\u56fe\u50cf\u7684\u5bbd\u9ad8\u662f500, 333\uff0c\u56fe\u50cf\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff0c\u4f4d\u7f6e\u662f141, 50, 500, 330\uff0c\u7c7b\u522b\u662f7 car.","title":"1.2.1 \u8bfb\u53d6\u6807\u6ce8\u4fe1\u606f"},{"location":"objectdection/05.yolo-demo/#122-tfrecord","text":"\u5728\u5c06\u6570\u636e\u5199\u5165\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528tf.io.TFRecordWriter\u6765\u5b8c\u6210\uff0c\u4e3b\u8981\u6b65\u9aa4\u662f\uff1a 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 7\u3001\u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 import tensorflow as tf import glob import os # \u6307\u660exml\u6587\u4ef6\uff0ctfrecord\u6587\u4ef6\u548c\u56fe\u50cf\u7684\u4f4d\u7f6e def write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ): # 1\u3001\u4f7f\u7528tf.io.TFRecordWriter\u6253\u5f00TFRecords\u6587\u4ef6 writer = tf . io . TFRecordWriter ( tfrecord_path ) # \u904d\u5386\u6240\u6709\u7684XML\u6587\u4ef6 for i , single_xml_path in enumerate ( all_xml_path ): # \u8bfb\u53d6xml\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9 image_name , image_width , image_height , bndbox_lable_dic = Prase_Singel_xml ( single_xml_path ) # \u83b7\u53d6\u56fe\u50cf\u7684\u8def\u5f84 sigle_img_path = os . path . join ( voc_img_path , image_name ) # \u8bfb\u53d6\u56fe\u50cf image_data = open ( sigle_img_path , 'rb' ) . read () xmin = [] ymin = [] xmax = [] ymax = [] obj_label = [] # \u904d\u5386box\u548clabel\u4fe1\u606f\uff0c\u5e76\u8bb0\u5f55\u4e0b\u6765 for j in range ( len ( bndbox_lable_dic )): xmin . append ( bndbox_lable_dic [ j ][ 0 ]) ymin . append ( bndbox_lable_dic [ j ][ 1 ]) xmax . append ( bndbox_lable_dic [ j ][ 2 ]) ymax . append ( bndbox_lable_dic [ j ][ 3 ]) obj_label . append ( bndbox_lable_dic [ j ][ 4 ]) # \u521b\u5efa\u7279\u5f81\uff1a\u56fe\u50cf\uff0csize,box\u548clabel # 2\u3001\u4f7f\u7528tf.train.Int64List\uff0ctf.train.BytesList\u6216tf.train.FloatList\u5bf9\u6570\u636e\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362 # 3\u3001\u5c06\u7c7b\u578b\u8f6c\u6362\u540e\u7684\u6570\u636e\u4f20\u5165tf.train.Feature\u521b\u5efa\u7684\u7279\u5f81\u4e2d feature = { 'image' : tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ image_data ])), 'width' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_width ])), 'height' : tf . train . Feature ( float_list = tf . train . FloatList ( value = [ image_height ])), 'xmin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmin )), 'ymin' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymin )), 'xmax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = xmax )), 'ymax' : tf . train . Feature ( float_list = tf . train . FloatList ( value = ymax )), 'label' : tf . train . Feature ( int64_list = tf . train . Int64List ( value = obj_label )) } # 4\u3001\u5c06\u7279\u5f81\u4f20\u5165tf.train.Example\u521b\u5efa\u7684example\u4e2d example = tf . train . Example ( features = tf . train . Features ( feature = feature )) # \u5c06example\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d # 5\u3001\u4f7f\u7528example.SerializeToString()\u5c06example\u5e8f\u5217\u5316\u4e3a\u5b57\u7b26\u4e32 # 6\u3001\u4f7f\u7528writer.write\u5c06\u5e8f\u5217\u5316\u540e\u7684example\u5199\u5165TFRecords\u6587\u4ef6 writer . write ( example . SerializeToString ()) # \u6700\u540e\u4f7f\u7528writer.close\uff08\uff09\u5173\u95ed\u6587\u4ef6 writer . close () print ( '\u7b2c{}\u5f20\u56fe\u7247\u5199\u5165\u5b8c\u6bd5' . format ( i )) \u63a5\u4e0b\u6765\u8c03\u7528\u4e0a\u8ff0\u65b9\u6cd5\u5c06VOC\u6570\u636e\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\uff1a # \u83b7\u53d6\u6240\u6709\u7684xml\u6587\u4ef6 all_xml_path = glob . glob ( 'VOCdevkit/VOC2007/Annotations/*.xml' ) # \u6307\u5b9atfrecords\u6587\u4ef6\u7684\u8def\u5f84 tfrecord_path = 'voc_2007.tfrecords' # \u6307\u5b9a\u56fe\u50cf\u6240\u5728\u7684\u8def\u5f84 voc_img_path = 'VOCdevkit/VOC2007/JPEGImages' # \u5c06\u4fe1\u606f\u5199\u5165\u5230tfrecord\u6587\u4ef6\u4e2d write_to_tfrecord ( all_xml_path , tfrecord_path , voc_img_path ) \u7ed3\u679c\u5982\u4e0b\u6240\u793a\uff1a","title":"1.2.2 \u5c06\u6570\u636e\u5199\u5165TFRecord\u6587\u4ef6\u4e2d"},{"location":"objectdection/05.yolo-demo/#13-tfrecord","text":"VOC\u6570\u636e\u96c6\u5df2\u7ecf\u88ab\u5199\u5165\u5230TFRecord\u6587\u4ef6\u4e2d\u4e86\uff0c\u90a3\u6211\u4eec\u5c31\u8981\u4eceTFrecord\u6587\u4ef6\u4e2d\u5c06\u6570\u636e\u8bfb\u53d6\u51fa\u6765\u3002\u53ea\u9700\u8981\u7b80\u5355\u7684\u4f7f\u7528 tf.data.TFRecordDataset \u5c31\u80fd\u591f\u8f7b\u677e\u7684\u8bfb\u53d6\u6570\u636e\u3002 \u4f7f\u7528tf.data.TFRecordDataset\u6765\u83b7\u53d6TFRecord\u6587\u4ef6\u4e2d\u7684\u6570\u636e \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff0c\u4e0e\u5199\u5165\u65f6\u662f\u5bf9\u5e94\u7684 \u4f7f\u7528tf.io.parse_single_example\u5c06\u4e00\u4e2aexample\u8f6c\u6362\u4e3a\u539f\u59cb\u6570\u636e \u4f7f\u7528\u529f\u80fdmap\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c\uff08map\u65b9\u6cd5\u7a0d\u540e\u4ecb\u7ecd\uff09 import tensorflow as tf import os import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import Rectangle # \u83b7\u53d6tfreocrd\u4e2d\u7684\u6240\u6709\u6570\u636e raw_datasets = tf . data . TFRecordDataset ( 'voc_2007.tfrecords' ) # \u5b9a\u4e49\u7279\u5f81\u7684\u63cf\u8ff0\u65b9\u6cd5\uff1a\u56fe\u50cf\uff0cbox\u548clabel,\u6ce8\u610f\uff1a\u8981\u548c\u5199\u5165\u65f6\u662f\u4e00\u4e00\u5bf9\u5e94\u7684 feature_description = { 'image' : tf . io . FixedLenFeature ([], tf . string ), 'width' : tf . io . FixedLenFeature ([], tf . float32 ), 'height' : tf . io . FixedLenFeature ([], tf . float32 ), 'xmin' : tf . io . VarLenFeature ( tf . float32 ), 'ymin' : tf . io . VarLenFeature ( tf . float32 ), 'xmax' : tf . io . VarLenFeature ( tf . float32 ), 'ymax' : tf . io . VarLenFeature ( tf . float32 ), 'label' : tf . io . VarLenFeature ( tf . int64 ), } # \u5c06tfrecord\u4e2d\u7684\u6570\u636e\u8f6c\u6362\u4e3a\u539f\u59cb\u56fe\u50cf\u548c\u6807\u6ce8\u4fe1\u606f\uff08\u53ea\u80fd\u5bf9\u4e00\u4e2a\u6570\u636e\u8fdb\u884c\u5904\u7406\uff09 def parse_example ( example_string ): # \u5c06tfreocord\u6587\u4ef6\u4e2d\u7684\u4e00\u4e2aexample\u6620\u5c04\u56de\u539f\u59cb\u6570\u636e feature_dict = tf . io . parse_single_example ( example_string , feature_description ) # \u83b7\u53d6\u56fe\u50cf\u6570\u636e image_data = tf . io . decode_jpeg ( feature_dict [ 'image' ]) # \u83b7\u53d6box boxes = tf . stack ([ tf . sparse . to_dense ( feature_dict [ 'xmin' ]), tf . sparse . to_dense ( feature_dict [ 'ymin' ]), tf . sparse . to_dense ( feature_dict [ 'xmax' ]), tf . sparse . to_dense ( feature_dict [ 'ymax' ])], axis = 1 ) # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f boxes_category = tf . sparse . to_dense ( feature_dict [ 'label' ]) # \u8fd4\u56de\u7ed3\u679c return image_data , feature_dict [ 'width' ], feature_dict [ 'height' ], boxes , boxes_category # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u6211\u4eec\u5c06\u4eceTFRecord\u6587\u4ef6\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u5c55\u793a\u51fa\u6765\uff1a # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) # \u521d\u59cb\u5316\uff1a\u7b2c\u51e0\u4e2a\u56fe\u50cf i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image ) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u7ed3\u679c\u4e3a\uff1a","title":"1.3 \u8bfb\u53d6TFRecord\u6587\u4ef6"},{"location":"objectdection/05.yolo-demo/#14-pipeline","text":"\u4f7f\u7528\u6570\u636e\u5904\u7406\u7684tf.data.Dataset\u6a21\u5757\u4e2dpipline\u673a\u5236\uff0c\u53ef\u5b9e\u73b0CPU\u591a\u7ebf\u7a0b\u5904\u7406\u8f93\u5165\u7684\u6570\u636e\uff0c\u5982\u8bfb\u53d6\u56fe\u7247\u548c\u56fe\u7247\u7684\u4e00\u4e9b\u7684\u9884\u5904\u7406\uff0c\u8fd9\u6837GPU\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u800cCPU\u53bb\u51c6\u5907\u6570\u636e\u3002 Dataset\u652f\u6301\u4e00\u7c7b\u7279\u6b8a\u7684\u64cd\u4f5c\uff1aTransformation\u3002\u4e00\u4e2aDataset\u901a\u8fc7Transformation\u53d8\u6210\u4e00\u4e2a\u65b0\u7684Dataset\u3002\u901a\u5e38\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7Transformation\u5b8c\u6210\u6570\u636e\u53d8\u6362\uff0c\u6253\u4e71\uff0c\u7ec4\u6210batch\uff0c\u751f\u6210epoch\u7b49\u4e00\u7cfb\u5217\u64cd\u4f5c\u3002\u5e38\u7528\u7684Transformation\u6709\uff1amap\u3001batch\u3001shuffle\u548crepeat\u3002\u89e3\u6790tfrecord\u6587\u4ef6\u5f97\u5230\u7684\u6570\u636e\u90fd\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u4f8b\u5982\u6211\u4eec\u524d\u9762\u4f7f\u7528\u7684\uff1a # \u5229\u7528map\u65b9\u6cd5\u8c03\u7528parse_example\u65b9\u6cd5\u5bf9\u6240\u6709\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7ecf\u8fc7 raw_datasets = raw_datasets . map ( parse_example ) \u4e0b\u9762\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\uff1a","title":"1.4 \u6570\u636e\u5904\u7406\u7684Pipeline"},{"location":"objectdection/05.yolo-demo/#141-map","text":"\u4f7f\u7528 tf.data.Dataset.map\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u5bf9\u6570\u636e\u96c6\u4e2d\u7684\u5404\u4e2a\u5143\u7d20\u8fdb\u884c\u9884\u5904\u7406\u3002\u56e0\u4e3a\u8f93\u5165\u5143\u7d20\u4e4b\u95f4\u65f6\u72ec\u7acb\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u5728\u591a\u4e2a CPU \u6838\u5fc3\u4e0a\u5e76\u884c\u5730\u8fdb\u884c\u9884\u5904\u7406\u3002map \u53d8\u6362\u63d0\u4f9b\u4e86\u4e00\u4e2a num_parallel_calls\u53c2\u6570\u53bb\u6307\u5b9a\u5e76\u884c\u7684\u7ea7\u522b\u3002 dataset = dataset . map ( map_func = parse_fn , num_parallel_calls = FLAGS . num_parallel_calls )","title":"1.4.1 map"},{"location":"objectdection/05.yolo-demo/#142-repeat","text":"repeat\u7684\u529f\u80fd\u5c31\u662f\u5c06\u6574\u4e2a\u5e8f\u5217\u91cd\u590d\u591a\u6b21\uff0c\u4e3b\u8981\u7528\u6765\u5904\u7406\u673a\u5668\u5b66\u4e60\u4e2d\u7684epoch\uff0c\u5047\u8bbe\u539f\u5148\u7684\u6570\u636e\u662f\u4e00\u4e2aepoch\uff0c\u4f7f\u7528repeat(5)\u5c31\u53ef\u4ee5\u5c06\u4e4b\u53d8\u62105\u4e2aepoch\u7684\u6570\u636e\u3002","title":"1.4.2 repeat"},{"location":"objectdection/05.yolo-demo/#143-prefetch","text":"tf.data.Dataset.prefetch \u63d0\u4f9b\u89e3\u8026\u4e86 \u6570\u636e\u4ea7\u751f\u7684\u65f6\u95f4 \u548c \u6570\u636e\u6d88\u8017\u7684\u65f6\u95f4\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u6570\u636e\u88ab\u8bf7\u6c42\u524d\uff0c\u5c31\u4ece dataset \u4e2d\u9884\u52a0\u8f7d\u4e00\u4e9b\u6570\u636e\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002prefech(n) \u4e00\u822c\u4f5c\u4e3a\u6700\u540e\u4e00\u4e2a transformation\uff0c\u5176\u4e2d n \u4e3a batch_size\u3002 prefetch \u7684\u4f7f\u7528\u65b9\u6cd5\u5982\u4e0b\uff1a # \u6700\u540e\u4e00\u4e2a\u53d8\u6362 dataset = dataset . prefetch ( buffer_size = FLAGS . prefetch_buffer_size ) return dataset \u53e6\u5916\u8fd8\u53ef\u4f7f\u7528bacth\u65b9\u6cd5\u7ec4\u6210\u6279\u6b21\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\uff0c\u4e5f\u53ef\u4f7f\u7528shuffle\u65b9\u6cd5\u5bf9\u6570\u636e\u6253\u4e71\u3002","title":"1.4.3 prefetch"},{"location":"objectdection/05.yolo-demo/#15","text":"yoloV3\u6a21\u578b\u7684\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u662f32\u7684\u500d\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u5904\u7406\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u56fe\u50cf\u7684\u5c3a\u5ea6\u8c03\u6574\u4e3a416x416\u7684\u5927\u5c0f\uff0c\u4e3a\u4e86\u4fdd\u6301\u957f\u5bbd\u6bd4\uff0c\u6211\u5c06\u56db\u5468\u4e3a0\u7684\u50cf\u7d20\u4ee5\u7070\u5ea6\u503c128\u8fdb\u884c\u586b\u5145\u3002 def preprocess ( image , bbox , input_shape = ( 416 , 416 )): # \u589e\u52a0batch\u7ef4 image = tf . expand_dims ( image , axis = 0 ) # \u83b7\u53d6\u56fe\u50cf\u7684\u9ad8\u5bbd[height, width] img_shape = image . shape [ 1 : 3 ] # \u5c06\u56fe\u50cf\u8fdb\u884c\u8c03\u6574\uff0c\u63d2\u503c\u65b9\u6cd5\u662f\u53cc\u4e09\u6b21\u63d2\u503c\uff0c\u4fdd\u7559\u957f\u5bbd\u6bd4 resize_image = tf . image . resize ( image , input_shape , method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u83b7\u53d6\u56fe\u50cf\u7684\u5bbd\u9ad8[height,width] resize_shape = resize_image . shape [ 1 : 3 ] # \u56fe\u50cf\u4e0a\u65b9\u7684\u586b\u5145\u5927\u5c0f top_pad = ( input_shape [ 0 ] - resize_shape [ 0 ]) // 2 # \u56fe\u50cf\u4e0b\u65b9\u7684\u586b\u5145\u5927\u5c0f bottom_pad = input_shape [ 0 ] - resize_shape [ 0 ] - top_pad # \u56fe\u50cf\u5de6\u65b9\u7684\u586b\u5145\u5927\u5c0f left_pad = ( input_shape [ 1 ] - resize_shape [ 1 ]) // 2 # \u56fe\u50cf\u53f3\u65b9\u7684\u586b\u5145\u5927\u5c0f right_pad = input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u5c06\u56fe\u50cf\u5468\u56f4\u586b\u5145128 resize_image = tf . pad ( resize_image , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u7c7b\u578b\u8f6c\u5316 image_data = tf . cast ( resize_image , tf . float32 ) / 255. # \u5bf9\u6807\u6ce8\u6846\u8fdb\u884c\u8c03\u6574\uff1a\u8fdb\u884c\u5c3a\u5ea6\u548c\u5e73\u79fb\u8c03\u6574 # \u5c3a\u5ea6\u53d8\u6362 bbox = bbox * tf . convert_to_tensor ( [ resize_shape [ 1 ], resize_shape [ 0 ], resize_shape [ 1 ], resize_shape [ 0 ]], dtype = tf . float32 ) # \u9664\u4ee5\u539f\u56fe\u50cf\u5927\u5c0f bbox = bbox / tf . convert_to_tensor ( [ img_shape [ 1 ], img_shape [ 0 ], img_shape [ 1 ], img_shape [ 0 ]], dtype = tf . float32 ) # \u5e73\u79fb,\u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c bbox = bbox + tf . convert_to_tensor ( [ left_pad , top_pad , left_pad , top_pad ], dtype = tf . float32 ) # \u8fd4\u56de return image_data , bbox \u7ecf\u8fc7\u56fe\u50cf\u5904\u7406\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u56fe\u50cf\u7ed3\u679c\u4e3a: # \u5c06VOC_class\u5b57\u5178\u7684key\u548cvalue\u8fdb\u884c\u7ffb\u8f6c new_voc_class = { v : k for k , v in voc_classes . items ()} # \u5c06tfrecord\u4e2d\u7684\u56fe\u50cf\u8fdb\u884c\u5c55\u793a plt . figure ( figsize = ( 15 , 10 )) i = 0 # \u4eceraw_datasets\u4e2d\u9009\u53d63\u4e2a\u6837\u672c\uff0c\u83b7\u53d6\u56fe\u50cf\uff0c\u5927\u5c0f\uff0c\u6846\u7684\u6807\u6ce8\u4fe1\u606f\u548c\u7c7b\u522b\u4fe1\u606f for image , width , height , boxes , boxes_category in raw_datasets . take ( 3 ): # \u56fe\u50cf\u5904\u7406 image , boxes = preprocess ( image , boxes ) # \u8fdb\u884c\u7ed8\u56fe plt . subplot ( 1 , 3 , i + 1 ) # \u7ed8\u5236\u56fe\u50cf plt . imshow ( image [ 0 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u904d\u5386\u6240\u6709\u7684\u6846 for j in range ( boxes . shape [ 0 ]): # \u7ed8\u5236\u6846 rect = Rectangle (( boxes [ j , 0 ], boxes [ j , 1 ]), boxes [ j , 2 ] - boxes [ j , 0 ], boxes [ j , 3 ] - boxes [ j , 1 ], color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u6807\u6ce8\u4fe1\u606f # \u83b7\u53d6\u6807\u6ce8\u4fe1\u606f\u7684id label_id = boxes_category [ j ] # \u83b7\u53d6\u6807\u51c6\u4fe1\u606f label = new_voc_class . get ( label_id . numpy ()) # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( boxes [ j , 0 ], boxes [ j , 1 ] + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c i += 1 # \u663e\u793a\u56fe\u50cf plt . show () \u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a:","title":"1.5. \u6570\u636e\u5904\u7406"},{"location":"objectdection/05.yolo-demo/#2","text":"yoloV3\u7684\u6a21\u578b\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a\u6574\u4e2av3\u7ed3\u6784\u91cc\u9762\uff0c\u6ca1\u6709\u6c60\u5316\u5c42\u548c\u5168\u8fde\u63a5\u5c42\uff0c\u7f51\u7edc\u7684\u4e0b\u91c7\u6837\u662f\u901a\u8fc7\u8bbe\u7f6e\u5377\u79ef\u7684stride\u4e3a2\u6765\u8fbe\u5230\u7684\uff0c\u6bcf\u5f53\u901a\u8fc7\u8fd9\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\u56fe\u50cf\u7684\u5c3a\u5bf8\u5c31\u4f1a\u51cf\u5c0f\u5230\u4e00\u534a\u3002","title":"2.\u6a21\u578b\u6784\u5efa"},{"location":"objectdection/05.yolo-demo/#21","text":"\u57fa\u672c\u7ec4\u4ef6\u6307\u84dd\u8272\u65b9\u6846\u5185\u90e8\u5206\uff1a","title":"2.1 \u57fa\u672c\u7ec4\u4ef6"},{"location":"objectdection/05.yolo-demo/#211-cbl","text":"Yolov3\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u6700\u5c0f\u7ec4\u4ef6\uff0c\u7531Conv+Bn+Leaky_relu\u6fc0\u6d3b\u51fd\u6570\u4e09\u8005\u7ec4\u6210\uff0c \u6e90\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a def ConvBlock ( input_shape , filters , kernel_size , strides = ( 1 , 1 ), padding = None ): # padding\u6839\u636e\u6b65\u957f\u7684\u5927\u5c0f\u8fdb\u884c\u4fee\u6539 padding = 'valid' if strides == ( 2 , 2 ) else 'same' # \u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u5c42\uff1a\u52a0\u5165L2\u6b63\u5219\u5316\u7684\u5377\u79ef\u5c42 conv = tf . keras . layers . Conv2D ( filters , kernel_size = kernel_size , strides = strides , padding = padding , kernel_regularizer = tf . keras . regularizers . l2 ( l = 5e-4 ))( inputs ) # BN \u5c42 bn = tf . keras . layers . BatchNormalization ()( conv ) # \u6fc0\u6d3b\u51fd\u6570 relu = tf . keras . layers . LeakyReLU ( alpha = 0.1 )( bn ) # \u6a21\u578b\u6784\u5efa return tf . keras . Model ( inputs = inputs , outputs = relu )","title":"2.1.1 CBL"},{"location":"objectdection/05.yolo-demo/#212-resx","text":"\u6b8b\u5dee\u7ec4\u4ef6\u501f\u9274Resnet\u7f51\u7edc\u4e2d\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u8ba9\u7f51\u7edc\u53ef\u4ee5\u6784\u5efa\u7684\u66f4\u6df1,ResX\u7531\u4e00\u4e2aCBL\u548cX\u4e2a\u6b8b\u5dee\u7ec4\u4ef6\u6784\u6210\uff0c\u662fYolov3\u4e2d\u7684\u5927\u7ec4\u4ef6\u3002\u6bcf\u4e2aRes\u6a21\u5757\u524d\u9762\u7684CBL\u90fd\u8d77\u5230\u4e0b\u91c7\u6837\u7684\u4f5c\u7528\u3002 def ResBlock ( input_shape , filters , blocks ): # \u6307\u5b9a\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5bf9\u8f93\u5165\u8fdb\u884cpad pad = tf . keras . layers . ZeroPadding2D ( padding = (( 1 , 0 ), ( 1 , 0 )))( inputs ) # \u5377\u79ef\u6b65\u957f\u4e3a2 results = ConvBlock ( pad . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ), strides = ( 2 , 2 ))( pad ) # \u6784\u5efa\u6b8b\u5dee\u5355\u5143 for i in range ( blocks ): # \u5377\u79ef results_conv = ConvBlock ( results . shape [ 1 :], filters = filters // 2 , kernel_size = ( 1 , 1 ))( results ) # \u5377\u79ef results_conv = ConvBlock ( results_conv . shape [ 1 :], filters = filters , kernel_size = ( 3 , 3 ))( results_conv ) # \u878d\u548c results = tf . keras . layers . Add ()([ results_conv , results ]) # \u8fd4\u56de\u6a21\u578b return tf . keras . Model ( inputs = inputs , outputs = results )","title":"2.1.2 ResX"},{"location":"objectdection/05.yolo-demo/#22-backbone","text":"BackBone\u662fDarkNet53\u6784\u6210,\u7528\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4e3b\u8981\u662fResX\u6a21\u5757\u3002 def Body ( input_shape ): # \u6a21\u578b\u8f93\u5165 inputs = tf . keras . Input ( shape = input_shape ) # \u5377\u79ef\u7ed3\u679c(batch, 416, 416, 32) cb = ConvBlock ( inputs . shape [ 1 :], filters = 32 , kernel_size = ( 3 , 3 ))( inputs ) # \u6b8b\u5dee\u6a21\u5757 (batch, 208, 208, 64) rb1 = ResBlock ( cb . shape [ 1 :], filters = 64 , blocks = 1 )( cb ) # (batch, 104, 104, 128) rb2 = ResBlock ( rb1 . shape [ 1 :], filters = 128 , blocks = 2 )( rb1 ) # (batch, 52, 52, 256) rb3 = ResBlock ( rb2 . shape [ 1 :], filters = 256 , blocks = 8 )( rb2 ) # (batch, 26, 26, 512) rb4 = ResBlock ( rb3 . shape [ 1 :], filters = 512 , blocks = 8 )( rb3 ) # (batch, 13, 13, 1024) rb5 = ResBlock ( rb4 . shape [ 1 :], filters = 1024 , blocks = 4 )( rb4 ) return tf . keras . Model ( inputs = inputs , outputs = ( rb5 , rb4 , rb3 ))","title":"2.2 BackBone"},{"location":"objectdection/05.yolo-demo/#23","text":"\u8f93\u51fa\u662f3\u4e2a\u5c3a\u5ea6\u8f93\u51fa\u7684CBL\u4e32\u8054\u7ed3\u6784\uff1a def Output ( input_shape , input_filters , output_filters ): # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u8f93\u51fa\u8fde\u7eed\u7684\u516d\u4e2a\u6a21\u5757 cb1 = ConvBlock ( inputs . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( inputs ) cb2 = ConvBlock ( cb1 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb1 ) cb3 = ConvBlock ( cb2 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb2 ) cb4 = ConvBlock ( cb3 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb3 ) cb5 = ConvBlock ( cb4 . shape [ 1 :], filters = input_filters , kernel_size = ( 1 , 1 ))( cb4 ) cb6 = ConvBlock ( cb5 . shape [ 1 :], filters = input_filters * 2 , kernel_size = ( 3 , 3 ))( cb5 ) # \u6700\u540e\u7684\u7b2c\u4e03\u4e2a\u5377\u79ef\u5757 cb7 = ConvBlock ( cb6 . shape [ 1 :], filters = output_filters , kernel_size = ( 1 , 1 ))( cb6 ) return tf . keras . Model ( inputs = inputs , outputs = ( cb5 , cb7 ))","title":"2.3 \u8f93\u51fa\u90e8\u5206"},{"location":"objectdection/05.yolo-demo/#24-v3","text":"\u5c06\u6a21\u578b\u7684backbone\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u878d\u5408\u540e\u9001\u5165\u5230output\u6a21\u5757\uff0c\u6784\u5efa\u6574\u4e2ayoloV3\u6a21\u578b\u3002 def YOLOv3 ( input_shape , class_num = 80 ): # anchor\u6570\u76ee anchor_num = 3 # \u8f93\u5165\u6570\u636e inputs = tf . keras . Input ( shape = input_shape ) # \u83b7\u53d6backbone\u8f93\u51fa\u76843\u4e2a\u7279\u5f81\u56fe large , middle , small = Body ( inputs . shape [ 1 :])( inputs ) # \u8f83\u5927\u76ee\u6807\u7684\u68c0\u6d4b x1 , y1 = Output ( large . shape [ 1 :], 512 , anchor_num * ( class_num + 5 ))( large ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y1 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 32 , input_shape [ 1 ] // 32 , 3 , 5 + class_num ))( y1 ) # \u4e2d\u7b49\u76ee\u6807\u7684\u68c0\u6d4b cb1 = ConvBlock ( x1 . shape [ 1 :], filters = 256 , kernel_size = ( 1 , 1 ))( x1 ) # \u4e0a\u91c7\u6837 us1 = tf . keras . layers . UpSampling2D ( 2 )( cb1 ) # \u62fc\u63a5 cat1 = tf . keras . layers . Concatenate ()([ us1 , middle ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x2 , y2 = Output ( cat1 . shape [ 1 :], 256 , anchor_num * ( class_num + 5 ))( cat1 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y2 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 16 , input_shape [ 1 ] // 16 , 3 , 5 + class_num ))( y2 ) # \u8f83\u5c0f\u76ee\u6807\u68c0\u6d4b cb2 = ConvBlock ( x2 . shape [ 1 :], filters = 128 , kernel_size = ( 1 , 1 ))( x2 ) # \u4e0a\u91c7\u6837 us2 = tf . keras . layers . UpSampling2D ( 2 )( cb2 ) # \u62fc\u63a5 cat2 = tf . keras . layers . Concatenate ()([ us2 , small ]) # \u8ba1\u7b97\u8f93\u51fa\u7ed3\u679c x3 , y3 = Output ( cat2 . shape [ 1 :], 128 , anchor_num * ( class_num + 5 ))( cat2 ) # reshape\u6210\u6700\u7ec8\u7684\u6570\u636e\u7ed3\u679c y3 = tf . keras . layers . Reshape ( ( input_shape [ 0 ] // 8 , input_shape [ 1 ] // 8 , 3 , 5 + class_num ))( y3 ) # \u8fd4\u56de\u7ed3\u679c return tf . keras . Model ( inputs = inputs , outputs = ( y1 , y2 , y3 ))","title":"2.4 V3\u6a21\u578b\u6784\u5efa"},{"location":"objectdection/05.yolo-demo/#25","text":"\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u662f\uff1a \u5750\u6807\u662f\u5bf9anchor\u7684\u4fee\u6b63\uff0c\u5c06\u5176\u8f6c\u6362\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u7684\u5f62\u5f0f\uff0c\u5728\u9884\u6d4b\u8fc7\u7a0b\u548c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u4f7f\u7528\u3002 V3\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a$ t_x,t_y,t_w,t_h$ \u4e0e\u8fb9\u6846\u8868\u793a b_x,b_y,b_w,b_h b_x,b_y,b_w,b_h \u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a c_x,c_y c_x,c_y \u662f\u5f53\u524d\u7f51\u683c\u5de6\u4e0a\u89d2\u5230\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u8ddd\u79bb\uff0c p_w,p_h p_w,p_h \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u548c\u9ad8\u3002\u6839\u636e\u4e0a\u8ff0\u5173\u7cfb\u5bf9\u7f51\u7edc\u7684\u8f93\u51fa\u8fdb\u884c\u4fee\u6b63\u3002 \u53e6\u5916\u5bf9\u4e8e\u5206\u7c7b\u7684\u8f93\u51fa\u7ed3\u679c\u5e94\u9001\u5165\u5230Sigmoid\u6fc0\u6d3b\u51fd\u6570\u4e2d\u8fdb\u884c\u5904\u7406\u3002 \u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u5e38\u89c1\u7684\u65b9\u6cd5\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u628a\u4efb\u610f\u7684\u8868\u8fbe\u5f0ffunction\u4f5c\u4e3a\u4e00\u4e2a\u201cLayer\u201d\u5bf9\u8c61: keras . layers . Lambda ( function , output_shape = None , mask = None , arguments = None ) \u53c2\u6570\uff1a function\uff1a\u9700\u8981\u5c01\u88c5\u7684\u51fd\u6570\u3002 output_shape: \u9884\u671f\u7684\u51fd\u6570\u8f93\u51fa\u5c3a\u5bf8\u3002 arguments: \u53ef\u9009\u7684\u9700\u8981\u4f20\u9012\u7ed9\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570 \u8f6c\u6362\u8fc7\u7a0b\u5982\u4e0b\uff1a # \u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u7ed3\u679c\u8f6c\u6362\u4e3abbox\u7684\u5750\u6807\u53ca\u5bbd\u9ad8 def OutputParser ( input_shape , img_shape , anchors ): # feats/input_shape\u7684\u610f\u4e49\uff1a[batch,height,width,anchor_num,(1(delta x) + 1(delta y) + 1(width scale) + 1(height scale) + 1(object mask) + class_num(class probability))] feats = tf . keras . Input ( input_shape ) # \u83b7\u53d6\u7f51\u683cgrid\u7684\u5de6\u4e0a\u89d2x,y\u5750\u6807\uff0c\u5bf9\u5e94\u7740cx,cy # \u83b7\u53d6\u884cy\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u9ad8 # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(height,1,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u5217\u6570x\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_y = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 1 ], dtype = tf . float32 ), dtype = tf . float32 ), ( - 1 , 1 , 1 , 1 )), ( 1 , tf . shape ( x )[ 2 ], 1 , 1 )))( feats ) # \u83b7\u53d6\u5217x\u7684\u5750\u6807 # 1.\u4f7f\u7528tf.shape\u83b7\u53d6feats\u7684\u5bbd # 2.\u4f7f\u7528tf.cast\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362\uff0c\u8f6c\u6362\u4e3afloat32\u7c7b\u578b # 3.\u4f7f\u7528tf.range\u521b\u5efa\u6570\u5b57\u5e8f\u5217 # 4.\u4f7f\u7528tf.reshape\u8fdb\u884c\u5f62\u72b6\u8f6c\u6362\u4e3a(1,width,1,1) # 5.\u4f7f\u7528tf.tile\u5bf9\u4e0a\u8ff0\u7ed3\u679c\u6309\u7167\u884c\u6570y\u8fdb\u884c\u5e73\u94fa # 6.\u4f7f\u7528tf.keras.layers.Lambda\u8f6c\u6362\u6210\u5c42 grid_x = tf . keras . layers . Lambda ( lambda x : tf . tile ( tf . reshape ( tf . range ( tf . cast ( tf . shape ( x )[ 2 ], dtype = tf . float32 ), dtype = tf . float32 ), ( 1 , - 1 , 1 , 1 )), ( tf . shape ( x )[ 1 ], 1 , 1 , 1 )))( feats ) # \u6784\u5efagrid\u7684\u7f51\u683c\u8868\u793a # grid.shape = (grid h, grid w, 1, 2) grid = tf . keras . layers . Concatenate ( axis =- 1 )([ grid_x , grid_y ]) # \u83b7\u53d6\u6bcf\u4e00\u4e2a\u68c0\u6d4b\u7ed3\u679c\u4e2d\u5fc3\u70b9\u5750\u6807:\u5c06\u9884\u6d4b\u7ed3\u679c\u8f6c\u6362\u4e3a\u4e2d\u5fc3\u70b9\u5750\u6807 # box_xy = (delta x, delta y) + (priorbox upper left x,priorbox upper left y) / (feature map.width, feature map.height) # box_xy.shape = (batch, grid h, grid w, anchor_num, 2) box_xy = tf . keras . layers . Lambda ( lambda x : ( tf . math . sigmoid ( x [ 0 ][ ... , 0 : 2 ]) + x [ 1 ]) / tf . cast ( [ tf . shape ( x [ 1 ])[ 1 ], tf . shape ( x [ 1 ])[ 0 ]], dtype = tf . float32 ))([ feats , grid ]) # box_wh.shape = (batch, grid h, grid w, anchor_num, 2) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c\u7684\u5bbd\u9ad8 # box_wh = (width scale, height scale) * (anchor width, anchor height) / (image.width, image.height) box_wh = tf . keras . layers . Lambda ( lambda x , y , z : tf . math . exp ( x [ ... , 2 : 4 ]) * y / tf . cast ( [ z [ 1 ], z [ 0 ]], dtype = tf . float32 ), arguments = { 'y' : anchors , 'z' : img_shape })( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u4e2d\u5305\u542b\u76ee\u6807\u7684\u6982\u7387 box_confidence = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 4 ]))( feats ) # \u83b7\u53d6\u67d0\u4e00\u4e2aanchor\u5c5e\u4e8e\u67d0\u4e00\u4e2a\u7c7b\u522b\u7684\u6982\u7387 box_class_probs = tf . keras . layers . Lambda ( lambda x : tf . math . sigmoid ( x [ ... , 5 :]))( feats ) # \u8fd4\u56de\u8f93\u51fa\u7ed3\u679c return tf . keras . Model ( inputs = feats , outputs = ( box_xy , box_wh , box_confidence , box_class_probs ))","title":"2.5 \u8f93\u51fa\u7ed3\u679c\u5904\u7406"},{"location":"objectdection/05.yolo-demo/#3","text":"","title":"3.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yolo-demo/#31","text":"YoloV3\u7684\u635f\u5931\u51fd\u6570\u5206\u4e3a\u4e09\u90e8\u5206\uff1a box\u7684\u635f\u5931\uff1a \u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u7684gridcell\u4e2d\u7684anchor\u624d\u4f1a\u8ba1\u5165\u635f\u5931,\u5bf9x,y,w,h\u5206\u522b\u6c42\u5747\u65b9\u8bef\u5dee \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931 \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u6240\u6709\u7684box\u90fd\u8ba1\u5165\u635f\u5931\u8ba1\u7b97 \u5206\u7c7b\u7684\u635f\u5931\uff1a \u5206\u7c7b\u7684\u635f\u5931\u662f\u4e8c\u5206\u7c7b\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ea\u6709\u8d1f\u8d23\u68c0\u6d4b\u76ee\u6807\u7684\u624d\u8ba1\u7b97\u635f\u5931 def Loss ( img_shape , class_num = 80 ): # anchor\u7684\u5c3a\u5ea6\uff1a\u5206\u522b\u68c0\u6d4b\u5c0f\uff0c\u4e2d\uff0c\u5927\u7684\u76ee\u6807 anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]} # \u6784\u5efa\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u6570\u7ec4 input_shapes = [ ( img_shape [ 0 ] // 32 , img_shape [ 1 ] // 32 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 16 , img_shape [ 1 ] // 16 , 3 , 5 + class_num ), ( img_shape [ 0 ] // 8 , img_shape [ 1 ] // 8 , 3 , 5 + class_num ) ] # \u7f51\u7edc\u7684\u8f93\u51fa\u503c inputs = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] # \u76ee\u6807\u503c labels = [ tf . keras . Input ( input_shape ) for input_shape in input_shapes ] losses = list () # \u904d\u5386\u4e09\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa for l in range ( 3 ): # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684\u5f62\u72b6 input_shape_of_this_layer = input_shapes [ l ] # \u83b7\u53d6\u5f53\u524d\u5c3a\u5ea6\u7684anchor anchors_of_this_layer = anchors [ l ] # \u83b7\u53d6\u7f51\u7edc\u8f93\u51fa input_of_this_layer = inputs [ l ] # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label_of_this_layer = labels [ l ] # YOLOV3\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff1a\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u5bbd\u9ad8\uff0c\u7f6e\u4fe1\u5ea6 pred_xy , pred_wh , pred_box_confidence , pred_class = OutputParser ( input_shape_of_this_layer , img_shape , anchors_of_this_layer )( input_of_this_layer ) # \u9884\u6d4b\u6846 pred_box = tf . keras . layers . Concatenate ()([ pred_xy , pred_wh ]) # \u771f\u5b9e\u503c true_box = tf . keras . layers . Lambda ( lambda x : x [ ... , 0 : 4 ])( label_of_this_layer ) true_box_confidence = tf . keras . layers . Lambda ( lambda x : x [ ... , 4 ])( label_of_this_layer ) true_class = tf . keras . layers . Lambda ( lambda x : x [ ... , 5 :])( label_of_this_layer ) # \u83b7\u53d6box\u7684\u7f6e\u4fe1\u5ea6 object_mask = tf . keras . layers . Lambda ( lambda x : tf . cast ( x , dtype = tf . bool ))( true_box_confidence ) # \u8ba1\u7b97MSE\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97 pos_loss = tf . keras . layers . Lambda ( lambda x : tf . math . reduce_sum ( tf . keras . losses . MSE ( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) )) )([ true_box , pred_box , object_mask ]) # \u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\uff1a\u4ea4\u53c9\u71b5\u635f\u5931 confidence_loss = tf . keras . layers . Lambda ( lambda x : # \u6b63\u6837\u672c\u7684\u635f\u5931 tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) + # \u8d1f\u6837\u672c\u7684\u635f\u5931 100 * tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], tf . math . logical_not ( x [ 2 ])), tf . boolean_mask ( x [ 1 ], tf . math . logical_not ( x [ 2 ])) ) )([ true_box_confidence , pred_box_confidence , object_mask ]) # \u5206\u7c7b\u635f\u5931\uff1a\u53ea\u6709\u6b63\u6837\u672c\u8ba1\u7b97\u635f\u5931 class_loss = tf . keras . layers . Lambda ( lambda x : tf . keras . losses . BinaryCrossentropy ( from_logits = False )( tf . boolean_mask ( x [ 0 ], x [ 2 ]), tf . boolean_mask ( x [ 1 ], x [ 2 ]) ) )([ true_class , pred_class , object_mask ]) # \u635f\u5931\u7ed3\u679c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( [ pos_loss , confidence_loss , class_loss ]) losses . append ( loss ) # \u8ba1\u7b97\u635f\u5931\u503c loss = tf . keras . layers . Lambda ( lambda x : tf . math . add_n ( x ))( losses ) return tf . keras . Model ( inputs = ( * inputs , * labels ), outputs = loss )","title":"3.1\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97"},{"location":"objectdection/05.yolo-demo/#32","text":"\u5728\u4e0a\u8ff0\u7684loss\u8ba1\u7b97\u4e2d\uff0c\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684anchor\u5c31\u662f\u6b63\u6837\u672c\uff0c\u800c\u4e0d\u8d1f\u8d23\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u7684\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u4e5f\u5c31\u662f\u80cc\u666f\uff0c\u90a3\u5728\u8fd9\u91cc\u6211\u4eec\u662f\u5982\u4f55\u8bbe\u7f6e\u6b63\u8d1f\u6837\u672c\u7684\u5462\uff1f\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b63\u6837\u672c \uff1a\u9996\u5148\u8ba1\u7b97\u76ee\u6807\u4e2d\u5fc3\u70b9\u843d\u5728\u54ea\u4e2agrid\u4e0a\uff0c\u7136\u540e\u8ba1\u7b97\u8fd9\u4e2agrid\u5bf9\u5e94\u76843\u4e2a\u5148\u9a8c\u6846\uff08anchor\uff09\u548c\u76ee\u6807\u771f\u5b9e\u4f4d\u7f6e\u7684IOU\u503c\uff0c\u53d6IOU\u503c\u6700\u5927\u7684\u5148\u9a8c\u6846\u548c\u76ee\u6807\u5339\u914d\u3002\u90a3\u4e48\u8be5anchor \u5c31\u8d1f\u8d23\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807\uff0c\u90a3\u8fd9\u4e2aanchor\u5c31\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1\uff0c\u5176\u4ed6\u7684\u76ee\u6807\u503c\u6839\u636e\u6807\u6ce8\u4fe1\u606f\u8bbe\u7f6e\u3002 \u8d1f\u6837\u672c \uff1a\u6240\u6709\u4e0d\u662f\u6b63\u6837\u672c\u7684anchor\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5c06\u5176\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a0\uff0c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u5176\u5b83\u7684\u503c\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u9ed8\u8ba4\u4e3a0\u3002 \u5728\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u505a\u4e86\u4f18\u5316\uff0c\u5728\u8ba1\u7b97\u662f\u5426\u4e3a\u6b63\u6837\u672c\u65f6\uff0c\u6211\u4eec\u8ba4\u4e3aanchor\u548c\u76ee\u6807\u7684\u4e2d\u5fc3\u70b9\u662f\u76f8\u540c\u7684\uff0c\u76f4\u63a5\u5229\u7528anchor\u548c\u76ee\u6807box\u7684\u5bbd\u9ad8\u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff0c\u786e\u5b9a\u6b63\u6837\u672c\u3002\u5b9e\u73b0\u5982\u4e0b\uff1a \u5b9a\u4e49anchor: YOLOv3_anchors = np . array ([[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ], [ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ], [ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]], dtype = np . int32 ) \u5b9a\u4e49\u65b9\u6cd5\u8ba1\u7b97anchor\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u786e\u5b9a\u6b63\u8d1f\u6837\u672c\uff1a def bbox_to_tensor ( bbox , label , input_shape = ( 416 , 416 ), anchors = YOLOv3_anchors , num_classes = 80 ): # bbox\uff1a\u771f\u5b9e\u503c\u5750\u6807\u8868\u793a\u4e3a(xmin,ymin,xmax,ymax)\uff0c\u662f\u76f8\u5bf9\u5750\u6807 # label\uff1a \u6bcf\u4e2abbox\u7684\u7c7b\u522b # anchors = (9,2) # \u8fd4\u56de\uff1aanchor\u5bf9\u5e94\u7684\u771f\u5b9e\u503c,\u5373\u6b63\u8d1f\u6837\u672c\u7684\u6807\u8bb0\u7ed3\u679c \u83b7\u53d6\u5c3a\u5ea6\u4e2a\u6570\u548cbox\u7684\u7edd\u5bf9\u5750\u6807 # \u83b7\u53d6\u6709\u51e0\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u5bf9\u5e943\u4e2aanchor:3 num_layers = anchors . shape [ 0 ] // 3 # anchor\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u63a9\u7801\uff1a\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u5bf9\u5e94\u7b2c6\uff0c7\uff0c8\u4e2aanchor... anchor_mask = tf . cond ( tf . equal ( num_layers , 3 ), lambda : tf . constant ( [[ 6 , 7 , 8 ], [ 3 , 4 , 5 ], [ 0 , 1 , 2 ]]), lambda : tf . constant ([[ 3 , 4 , 5 ], [ 1 , 2 , 3 ]])) # bbox\u7684\u76f8\u5bf9\u4e2d\u5fc3\u70b9\u5750\u6807 true_boxes_xy = ( bbox [ ... , 0 : 2 ] + bbox [ ... , 2 : 4 ]) / 2. # bbox\u7684\u76f8\u5bf9\u5bbd\u9ad8 true_boxes_wh = tf . math . abs ( bbox [ ... , 2 : 4 ] - bbox [ ... , 0 : 2 ]) # bbox\u7684\u7ed3\u679c:\u5c06\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u62fc\u63a5\u5728\u4e00\u8d77 true_boxes = tf . concat ([ true_boxes_xy , true_boxes_wh ], axis =- 1 ) # bbox\u7684\u7edd\u5bf9\u5750\u6807\u548c\u7edd\u5bf9\u5bbd\u9ad8 boxes_xy = true_boxes [ ... , 0 : 2 ] * input_shape boxes_wh = true_boxes [ ... , 2 : 4 ] * input_shape \u521b\u5efa\u4e00\u4e2a\u4e0e\u7f51\u7edc\u8f93\u51fa\u5927\u5c0f\u76f8\u540c\u7684\u5168\u96f6\u6570\u7ec4\uff0c\u7528\u6765\u8bbe\u7f6e\u771f\u5b9e\u503c # \u751f\u6210\u4e0eyoloV3\u8f93\u51fa\u7ed3\u679c\u76f8\u540c\u5927\u5c0f\u7684\u51680\u6570\u7ec4\uff1ay_true.shape[layer] = (height, width, anchor num, 5 + class num) y_true = tuple (( np . zeros ( shape = ( input_shape [ 0 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], input_shape [ 1 ] // { 0 : 32 , 1 : 16 , 2 : 8 }[ l ], tf . shape ( anchor_mask [ l , ... ])[ 0 ], 5 + num_classes ), dtype = np . float32 ) for l in range ( num_layers ))) \u8ba1\u7b97anchor\u7684\u4f4d\u7f6e\u4fe1\u606f # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653eanchor\u7684\u7d22\u5f15 anchors = tf . expand_dims ( tf . convert_to_tensor ( anchors , dtype = tf . float32 ), 0 ) # \u7528\u4e8e\u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807 anchor_maxes = anchors / 2. # \u4ee5anchor\u4e2d\u5fc3\u4e3a\u539f\u70b9\uff0c\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807 anchor_mins = - anchor_maxes \u5bf9\u76ee\u6807\u8fdb\u884c\u7b5b\u9009\uff0c\u53ea\u6709\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u6b63\u7684\u76ee\u6807 # \u521b\u5efa\u4e00\u4e2amask,\u6307\u660e\u76ee\u6807\u662f\u5426\u5b58\u5728\uff0c\u5bbd\u5ea6\u5927\u4e8e0\u7684\u8ba4\u4e3a\u662f\u771f\u5b9e\u7684\u76ee\u6807 valid_mask = tf . greater ( boxes_wh [ ... , 0 ], 0 \uff09 # \u83b7\u53d6\u771f\u5b9e\u7684\u76ee\u6807\u7684\u5bbd\u9ad8 wh = tf . boolean_mask ( boxes_wh , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684box\uff1avalid_true_boxes.shape = (valid box num, 4) valid_true_boxes = tf . boolean_mask ( boxes , valid_mask ) # \u83b7\u53d6\u771f\u5b9e\u76ee\u6807\u7684\u6807\u7b7e\u503c\uff1avalid_label.shape = (valid box num) valid_label = tf . boolean_mask ( label , valid_mask ) \u83b7\u53d6\u4e0e\u76ee\u6807\u4ea4\u5e76\u6700\u5927\u7684anchor,\u90a3\u8fd9\u4e9banchor\u5373\u4e3a\u6b63\u6837\u672c # \u5f53\u56fe\u50cf\u4e2d\u5b58\u5728\u76ee\u6807\u65f6\uff0c\u8ba1\u7b97\u4e0e\u76ee\u6807\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u5e76\u8bbe\u7f6e\u6807\u8bb0\u7ed3\u679c if wh . shape [ 0 ] > 0 : # \u6269\u5c55\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7528\u6765\u5b58\u653e\u5bf9\u5e94\u7684anchor\uff1awh.shape = (valid box num, 1, 2) wh = tf . expand_dims ( wh , - 2 ) # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u53f3\u4e0b\u89d2\u5750\u6807\uff1amax of width, height, box_maxes.shape = (valid box num, 1, 2) box_maxes = wh / 2 # \u4ee5box\u7684\u4e2d\u5fc3\u70b9\u4e3a\u539f\u70b9\uff1a\u8ba1\u7b97\u5de6\u4e0a\u89d2\u5750\u6807\uff1amin of width, height, box_mins.shape = (valid box num, 1, 2) box_mins = - box_maxes # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807\uff1aintersect_mins.shape = (valid box num, anchor num(9), 2) intersect_mins = tf . math . maximum ( box_mins , anchor_mins ) # \u8ba1\u7b97box\u4e0eanchor\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807\uff1aintersect_maxes.shape = (valid box num, anchor num(9), 2) intersect_maxes = tf . math . minimum ( box_maxes , anchor_maxes ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u5bbd\u9ad8\uff1aintersect_wh.shape = (valid box num, anchor num(9), 2) intersect_wh = tf . math . maximum ( intersect_maxes - intersect_mins , 0. ) # \u8ba1\u7b97\u4ea4\u96c6\u7684\u9762\u79ef\uff1aintersect_area.shape = (valid box num, anchor num(9)) intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97box\u7684\u9762\u79ef\uff1abox_area.shape = (valid box_num, 1) box_area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u8ba1\u7b97anchor\u7684\u9762\u79ef\uff1aanchor_area.shape = (1, anchor num(9)) anchor_area = anchors [ ... , 0 ] * anchors [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4\uff1aiou.shape = (valid box num, anchor num(9)) iou = intersect_area / ( box_area + anchor_area - intersect_area ) # \u8ba1\u7b97\u4e0ebox\u4ea4\u5e76\u6bd4\u6700\u5927\u7684anchor,\u5c06\u5176\u4f5c\u4e3a\u6b63\u6837\u672c\uff1abest_anchor.shape = (valid box num) best_anchor = tf . math . argmax ( iou , axis =- 1 , output_type = tf . int32 ) \u904d\u5386\u5339\u914d\u6210\u529f\u7684anchor(\u6b63\u6837\u672c)\uff0c\u8bbe\u7f6e\u76ee\u6807\u503c # \u904d\u5386\u4e0ebox\u5339\u914d\u6210\u529f\u7684anchor for t in range ( tf . shape ( best_anchor )[ 0 ]): # \u83b7\u53d6\u7b2ct\u4e2aanchor n = best_anchor [ t ] # \u83b7\u53d6anchor\u7684\u4f4d\u7f6e pos = tf . where ( tf . equal ( anchor_mask , n )) # \u83b7\u53d6\u5c3a\u5ea6\u503c\uff1a0\uff0c1\uff0c2 l = pos [ 0 ][ 0 ] # \u83b7\u53d6\u5bf9\u5e94\u7684anchor\u7d22\u5f15 k = pos [ 0 ][ 1 ] # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u5217\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 i = int ( tf . clip_by_value ( valid_true_boxes [ t , 1 ] * y_true [ l ] . shape [ 0 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 0 ] - 1 )) # \u83b7\u53d6anchor\u5bf9\u5e94\u7684grid cell\u7684\u884c\u6570\uff0c\u9650\u5236\u57280\u5230\u6700\u5927\u503c\u4e4b\u95f4 j = int ( tf . clip_by_value ( valid_true_boxes [ t , 0 ] * y_true [ l ] . shape [ 1 ], clip_value_min = 0 , clip_value_max = y_true [ l ] . shape [ 1 ] - 1 )) # \u83b7\u53d6anchor\u7684\u7c7b\u522b c = valid_label [ t ] # box\u7684\u4f4d\u7f6e:(x,y,width,height) y_true [ l ][ i , j , k , 0 : 4 ] = valid_true_boxes [ t , 0 : 4 ] # \u5339\u914d\u4e0a\u7684\u90fd\u5305\u542b\u76ee\u6807\uff0c\u7f6e\u4fe1\u5ea6\u8bbe\u4e3a1 y_true [ l ][ i , j , k , 4 ] = 1 # \u7c7b\u522b\u4fe1\u606f y_true [ l ][ i , j , k , 5 + c ] = 1 \u8fd4\u56de\u7ed3\u679c # \u8fd4\u56de3\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u771f\u5b9e\u503c return ( tf . convert_to_tensor ( y_true [ 0 ]), tf . convert_to_tensor ( y_true [ 1 ]), tf . convert_to_tensor ( y_true [ 2 ]))","title":"3.2 \u6b63\u8d1f\u6837\u672c\u7684\u8bbe\u5b9a"},{"location":"objectdection/05.yolo-demo/#33","text":"\u63a5\u4e0b\u6765\u6211\u4eec\u5229\u7528\u5df2\u642d\u5efa\u597d\u7684\u7f51\u7edc\u548c\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff1a","title":"3.3 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yolo-demo/#331","text":"\u9996\u5148\u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u6570\u636e\u5904\u7406\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u76ee\u6807\u503c\uff0c\u8fd9\u4e9b\u901a\u8fc7map\u65b9\u6cd5\u6765\u5b9e\u73b0 1.\u5b9a\u4e49\u65b9\u6cd5\u8fdb\u884c\u6570\u636e\u5904\u7406\u548c\u83b7\u53d6\u76ee\u6807\u503c def map_function_impl ( image , bbox , label ): # \u56fe\u50cf\u5c3a\u5ea6\u8c03\u6574 image , bbox = preprocess ( image , bbox , random = True ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u503c label1 , label2 , label3 = bbox_to_tensor ( bbox , label ) # \u8fd4\u56de\u7ed3\u679c return image , label1 , label2 , label3 2.\u4f7f\u7528py_function\u6765\u63d0\u9ad8\u6027\u80fd def map_function ( image , width , height , boxes , boxes_category ): # \u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u83b7\u53d6\u56fe\u50cf\u53ca\u76ee\u6807\u503c\uff1a\u63d0\u5347\u6027\u80fd image , label1 , label2 , label3 = tf . py_function ( map_function_impl , inp = [ image , boxes , boxes_category ], Tout = [ tf . float32 , tf . float32 , tf . float32 , tf . float32 ]) # \u5bf9\u56fe\u50cf\u548c\u76ee\u6807\u503c\u8fdb\u884c\u5c3a\u5ea6\u8c03\u6574 image = tf . reshape ( image , ( 416 , 416 , 3 )) label1 = tf . reshape ( label1 , ( 13 , 13 , 3 , 85 )) label2 = tf . reshape ( label2 , ( 26 , 26 , 3 , 85 )) label3 = tf . reshape ( label3 , ( 52 , 52 , 3 , 85 )) # \u8fd4\u56de\u7ed3\u679c return image , ( label1 , label2 , label3 ) 3.\u4f7f\u7528map\u65b9\u6cd5\u5bf9\u4eceTFRcords\u4e2d\u8bfb\u53d6\u7684\u6570\u636e\u8fdb\u884c\u5904\u7406 # \u4eceTFRecord\u6587\u4ef6\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5904\u7406 batch_size = 10 trainset = raw_datasets . map ( map_function ) . shuffle ( batch_size ) . batch ( batch_size ) . prefetch ( tf . data . experimental . AUTOTUNE )","title":"3.3.1 \u83b7\u53d6\u6570\u636e\u96c6"},{"location":"objectdection/05.yolo-demo/#332","text":"\u6a21\u578b\u521d\u59cb\u5316\uff1a yolov3 = YOLOv3 (( 416 , 416 , 3 ,), 20 ) yolov3_loss = Loss (( 416 , 416 , 3 ), 20 ) \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5\uff1a # \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5 optimizer = tf . keras . optimizers . Adam ( 1e-4 ) \u63a5\u4e0b\u6765\u8fdb\u884c\u7f51\u7edc\u8bad\u7ec3\uff0c\u8fd9\u91cc\u4f7f\u7528\uff1a 1.\u5b9a\u4e49tf.GradientTape\u7684\u4f5c\u7528\u57df\uff0c\u8ba1\u7b97\u635f\u5931\u503c 2.\u4f7f\u7528 tape.gradient(ys, xs)\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6 3.\u4f7f\u7528 optimizer.apply_gradients(grads_and_vars)\u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570 \u5b8c\u6210\u7f51\u7edc\u8bad\u7ec3\uff0c\u5e76\u4fdd\u5b58\u8bad\u7ec3\u7ed3\u679c # \u904d\u5386\u56fe\u50cf\u548c\u76ee\u6807\u503c\uff0c\u8fdb\u884c\u66f4\u65b0 for images , labels in trainset : # \u5b9a\u4e49\u4f5c\u7528\u57df with tf . GradientTape () as tape : # \u5c06\u56fe\u50cf\u9001\u5165\u7f51\u7edc\u4e2d outputs = yolov3 ( images ) # \u8ba1\u7b97\u635f\u5931\u51fd\u6570 loss = yolov3_loss ([ * outputs , * labels ]) # \u8ba1\u7b97\u68af\u5ea6 grads = tape . gradient ( loss , yolov3 . trainable_variables ) try : # \u8fdb\u884c\u68af\u5ea6\u68c0\u67e5 grads_check = [ tf . debugging . check_numerics ( grad , 'the grad is not correct! cancel gradient apply!' ) for grad in grads ] with tf . control_dependencies ( grads_check ): # \u68af\u5ea6\u66f4\u65b0 optimizer . apply_gradients ( zip ( grads , yolov3 . trainable_variables )) except BaseException as e : print ( e . message ) # \u4fdd\u5b58\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c yolov3 . save ( 'yolov3.h5' )","title":"3.3.2 \u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/05.yolo-demo/#4","text":"\u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b,\u5728\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7yoloV3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u9884\u6d4b\u4e4b\u540e\u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\u540e\uff0c\u83b7\u53d6\u591a\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u4f7f\u7528NMS\u8fdb\u884c\u68c0\u6d4b\u6846\u7684\u7b5b\u9009\u3002 \u9996\u5148\u5b9a\u4e49\u9884\u6d4b\u7c7b\uff1a # \u5b9a\u4e49\u9884\u6d4b\u7c7b class Predictor ( object ): \u6307\u660eanchor\u7684\u5927\u5c0f\uff1a # anchorbox\u7684\u5927\u5c0f anchors = { 2 : [[ 10 , 13 ], [ 16 , 30 ], [ 33 , 23 ]], 1 : [[ 30 , 61 ], [ 62 , 45 ], [ 59 , 119 ]], 0 : [[ 116 , 90 ], [ 156 , 198 ], [ 373 , 326 ]]}","title":"4.\u6a21\u578b\u9884\u6d4b"},{"location":"objectdection/05.yolo-demo/#41","text":"\u8fdb\u884c\u6a21\u578b\u521d\u59cb\u5316 # \u521d\u59cb\u5316 def __init__ ( self , input_shape = ( 416 , 416 , 3 ), class_num = 80 , yolov3 = None ): # \u8f93\u5165\u5927\u5c0f self . input_shape = input_shape # \u6a21\u578b\u521d\u59cb\u5316 self . yolov3 = tf . keras . models . load_model ( 'yolov3.h5' , compile = False ) # \u5c06\u7ed3\u679c\u8f6c\u6362\u4e3a\u5750\u6807\u503c self . parsers = [ OutputParser ( tuple ( self . yolov3 . outputs [ l ] . shape [ 1 :]), self . input_shape , self . anchors [ l ]) for l in range ( 3 )]","title":"4.1 \u521d\u59cb\u5316"},{"location":"objectdection/05.yolo-demo/#42","text":"\u5728\u8fd9\u91cc\u52a0\u5165NMS\u65b9\u6cd5\uff1a","title":"4.2 \u9884\u6d4b\u65b9\u6cd5\u5b9e\u73b0"},{"location":"objectdection/05.yolo-demo/#421","text":"def predict ( self , image , conf_thres = 0.5 , nms_thres = 0.5 ): # conf_thres\uff1a\u7f6e\u4fe1\u5ea6\u7684\u9608\u503c\uff0cNMS\u4e2d\u4ea4\u5e76\u6bd4\u7684\u9608\u503c # \u589e\u52a0\u4e00\u7ef4batch images = tf . expand_dims ( image , axis = 0 ) # \u56fe\u50cf\u53d8\u5f62 resize_images = tf . image . resize ( images , self . input_shape [: 2 ], method = tf . image . ResizeMethod . BICUBIC , preserve_aspect_ratio = True ) # \u56fe\u50cf\u53d8\u5f62\u540e\u7684\u5927\u5c0f resize_shape = resize_images . shape [ 1 : 3 ] # \u56fe\u50cf\u5728\u4e0a\u4e0b\u5de6\u53f3\u586b\u5145\u7684\u5927\u5c0f top_pad = ( self . input_shape [ 0 ] - resize_shape [ 0 ]) // 2 bottom_pad = self . input_shape [ 0 ] - resize_shape [ 0 ] - top_pad left_pad = ( self . input_shape [ 1 ] - resize_shape [ 1 ]) // 2 right_pad = self . input_shape [ 1 ] - resize_shape [ 1 ] - left_pad # \u586b\u5145\u4e3a128 resize_images = tf . pad ( resize_images , [[ 0 , 0 ], [ top_pad , bottom_pad ], [ left_pad , right_pad ], [ 0 , 0 ]], constant_values = 128 ) # \u6807\u51c6\u5dee deviation = tf . constant ([ left_pad / self . input_shape [ 1 ], top_pad / self . input_shape [ 0 ], 0 , 0 ], dtype = tf . float32 ) # \u5c3a\u5ea6\u7684\u53d8\u6362 scale = tf . constant ([ self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ], self . input_shape [ 1 ] / resize_shape [ 1 ], self . input_shape [ 0 ] / resize_shape [ 0 ] ], dtype = tf . float32 ) # \u7c7b\u578b\u8f6c\u6362 images_data = tf . cast ( resize_images , tf . float32 ) / 255. # \u8f93\u51fa\u7ed3\u679c outputs = self . yolov3 ( images_data )","title":"4.2.1 \u83b7\u53d6\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/05.yolo-demo/#422","text":"\u904d\u5386\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\uff0c\u8fdb\u884c\u62fc\u63a5 # \u76ee\u6807\u503c whole_targets = tf . zeros (( 0 , 6 ), dtype = tf . float32 ) # \u904d\u5386\u6bcf\u4e00\u4e2a\u5c3a\u5ea6 for i in range ( 3 ): # \u83b7\u53d6\u9884\u6d4b\u7684\u4f4d\u7f6e\u3001\u7f6e\u4fe1\u5ea6\u548c\u5206\u7c7b\u7ed3\u679c pred_xy , pred_wh , pred_box_confidence , pred_class = self . parsers [ i ]( outputs [ i ]) # \u83b7\u53d6\u76ee\u6807\u6846\u7684\u4f4d\u7f6e pred_box = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_xy , pred_wh ]) #\u76ee\u6807\u6846\u7684\u7f6e\u4fe1\u5ea6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\uff1atarget_mask.shape = (h, w, anchor num) target_mask = tf . greater ( pred_box_confidence , conf_thres ) # \u83b7\u53d6\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\u7684\u7f6e\u4fe1\u5ea6\uff1apred_box_confidence = (pred target num, 1) pred_box_confidence = tf . boolean_mask ( pred_box_confidence , target_mask ) # \u5728\u6700\u540e\u589e\u52a0\u4e00\u7ef4 pred_box_confidence = tf . expand_dims ( pred_box_confidence , axis =- 1 ) # \u83b7\u53d6\u5bf9\u5e94\u7684\u76ee\u6807\u6846\u68c0\u6d4b\u7ed3\u679c pred_box.shape = (pred target num, 4) pred_box = tf . boolean_mask ( pred_box , target_mask ) # \u5f52\u4e00\u5316\u5904\u7406 pred_box = ( pred_box - deviation ) * scale * \\ [ image . shape [ 1 ], image . shape [ 0 ], image . shape [ 1 ], image . shape [ 0 ]] # \u5206\u7c7b\u7ed3\u679c\uff1apred_class.shape = (pred target num, 1) pred_class = tf . boolean_mask ( pred_class , target_mask ) # \u83b7\u53d6\u6bcf\u4e2a\u7c7b\u522b\u6700\u5927\u7684\u7d22\u5f15 pred_class = tf . math . argmax ( pred_class , axis =- 1 ) # \u7c7b\u578b\u8f6c\u6362 pred_class = tf . cast ( tf . expand_dims ( pred_class , axis =- 1 ), dtype = tf . float32 ) # \u5c06\u9884\u6d4b\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 targets,sgaoe = (pred target num, 6) targets = tf . keras . layers . Concatenate ( axis =- 1 )([ pred_box , pred_box_confidence , pred_class ]) # \u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77 whole_targets = tf . keras . layers . Concatenate ( axis = 0 )([ whole_targets , targets ])","title":"4.2.2 \u7ed3\u679c\u7ec4\u5408"},{"location":"objectdection/05.yolo-demo/#423-nms","text":"\u8fdb\u884cNMS\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c # \u8fdb\u884cNMS,\u6392\u5e8f\u4ee5\u7f6e\u4fe1\u5ea6\u6392\u5e8f,\u4ece\u5927\u5230\u5c0f\u6392\u5e8f descend_idx = tf . argsort ( whole_targets [ ... , 4 ], direction = 'DESCENDING' ) i = 0 # \u904d\u5386 while i < descend_idx . shape [ 0 ]: # \u83b7\u53d6\u7d22\u5f15\u503c idx = descend_idx [ i ] # \u5de6\u4e0a\u89d2\u5750\u6807 cur_upper_left = whole_targets [ idx , 0 : 2 ] - whole_targets [ idx , 2 : 4 ] / 2 # \u53f3\u4e0b\u89d2\u5750\u6807 cur_down_right = cur_upper_left + whole_targets [ idx , 2 : 4 ] # \u5bbd\u9ad8 wh = whole_targets [ idx , 2 : 4 ] # \u83b7\u53d6\u9762\u79ef area = wh [ ... , 0 ] * wh [ ... , 1 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u7d22\u5f15 following_idx = descend_idx [ i + 1 :] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846 following_targets = tf . gather ( whole_targets , following_idx ) # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5de6\u4e0a\u89d2\u5750\u6807 following_upper_left = following_targets [ ... , 0 : 2 ] - following_targets [ ... , 2 : 4 ] / 2 # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u53f3\u4e0b\u89d2\u5750\u6807 following_down_right = following_upper_left + following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u5bbd\u9ad8 following_wh = following_targets [ ... , 2 : 4 ] # \u4e0b\u4e00\u4e2a\u68c0\u6d4b\u6846\u7684\u9762\u79ef following_area = following_wh [ ... , 0 ] * following_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 # \u8ba1\u7b97\u4ea4\u7684\u5de6\u4e0a\u89d2\u5750\u6807 max_upper_left = tf . math . maximum ( cur_upper_left , following_upper_left ) # \u8ba1\u7b97\u4ea4\u7684\u53f3\u4e0b\u89d2\u5750\u6807 min_down_right = tf . math . minimum ( cur_down_right , following_down_right ) # \u4ea4\u7684\u5bbd\u9ad8 intersect_wh = min_down_right - max_upper_left # \u5c06\u5bbd\u9ad8\u5927\u4e8e0\uff0c\u4fdd\u6301\u4e0d\u53d8\uff0c\u5c0f\u4e8e0\u7684\u7f6e\u4e3a0 intersect_wh = tf . where ( tf . math . greater ( intersect_wh , 0 ), intersect_wh , tf . zeros_like ( intersect_wh )) # \u8ba1\u7b97\u4ea4\u7684\u9762\u79ef intersect_area = intersect_wh [ ... , 0 ] * intersect_wh [ ... , 1 ] # \u8ba1\u7b97\u4ea4\u5e76\u6bd4 overlap = intersect_area / ( area + following_area - intersect_area ) # \u83b7\u53d6\u5c0f\u4e8eNMS\u9608\u503c\u7684\u4fdd\u7559\uff0c\u5176\u4ed6\u7684\u820d\u5f03 indices = tf . where ( tf . less ( overlap , nms_thres )) # \u8fdb\u884c\u5207\u7247\uff0c\u4fdd\u7559\u7ed3\u679c following_idx = tf . gather_nd ( following_idx , indices ) # \u5c06\u5176\u6dfb\u52a0\u5230descend\u4e2d\u5373\u53ef descend_idx = tf . concat ([ descend_idx [: i + 1 ], following_idx ], axis = 0 ) i += 1 # \u83b7\u53d6\u6700\u7ec8\u7684\u7ed3\u679c whole_targets = tf . gather ( whole_targets , descend_idx ) # \u5de6\u4e0a\u89d2\u5750\u6807 upper_left = ( whole_targets [ ... , 0 : 2 ] - whole_targets [ ... , 2 : 4 ] / 2 ) # \u53f3\u4e0b\u89d2\u5750\u6807 down_right = ( upper_left + whole_targets [ ... , 2 : 4 ]) # \u83b7\u53d6\u68c0\u6d4b\u7ed3\u679c boundings = tf . keras . layers . Concatenate ( axis =- 1 )([ upper_left , down_right , whole_targets [ ... , 4 :]]) return boundings","title":"4.2.3 NMS"},{"location":"objectdection/05.yolo-demo/#43","text":"\u6a21\u578b\u7684\u9884\u6d4b\u6548\u679c\uff1a import cv2 import numpy as np import matplotlib.pyplot as plt # \u56fe\u50cf\u8bfb\u53d6 img = cv2 . imread ( \"image.jpg\" ) # \u5b9e\u4f8b\u5316 predictor = Predictor () # \u83b7\u53d6\u7ed3\u679c boundings = predictor . predict ( img ) # \u663e\u793a\u56fe\u50cf plt . imshow ( img [:, :, :: - 1 ]) # \u83b7\u53d6\u5750\u6807\u533a\u57df ax = plt . gca () # \u52a0\u8f7d\u6a21\u578b\uff1a\u6a21\u578b\u8bad\u7ec3\u662f\u5728COCO\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7684\uff0c # coco\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f classes = [ 'person' , 'bicycle' , 'car' , 'motorcycle' , 'airplane' , 'bus' , 'train' , 'truck' , 'boat' , 'traffic light' , 'fire hydrant' , 'stop sign' , 'parking meter' , 'bench' , 'bird' , 'cat' , 'dog' , 'horse' , 'sheep' , 'cow' , 'elephant' , 'bear' , 'zebra' , 'giraffe' , 'backpack' , 'umbrella' , 'handbag' , 'tie' , 'suitcase' , 'frisbee' , 'skis' , 'snowboard' , 'sports ball' , 'kite' , 'baseball bat' , 'baseball glove' , 'skateboard' , 'surfboard' , 'tennis racket' , 'bottle' , 'wine glass' , 'cup' , 'fork' , 'knife' , 'spoon' , 'bowl' , 'banana' , 'apple' , 'sandwich' , 'orange' , 'broccoli' , 'carrot' , 'hot dog' , 'pizza' , 'donut' , 'cake' , 'chair' , 'couch' , 'potted plant' , 'bed' , 'dining table' , 'toilet' , 'tv' , 'laptop' , 'mouse' , 'remote' , 'keyboard' , 'cell phone' , 'microwave' , 'oven' , 'toaster' , 'sink' , 'refrigerator' , 'book' , 'clock' , 'vase' , 'scissors' , 'teddy bear' , 'hair drier' , 'toothbrush' ] for bounding in boundings : # \u7ed8\u5236\u6846 rect = Rectangle (( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy ()), bounding [ 2 ] . numpy ( ) - bounding [ 0 ] . numpy (), bounding [ 3 ] . numpy () - bounding [ 1 ] . numpy (), color = 'r' , fill = False ) # \u5c06\u6846\u663e\u793a\u5728\u56fe\u50cf\u4e0a ax . add_patch ( rect ) # \u663e\u793a\u7c7b\u522b\u4fe1\u606f # \u83b7\u53d6\u7c7b\u522b\u4fe1\u606f\u7684id label_id = bounding [ 5 ] . numpy () . astype ( 'int32' ) # \u83b7\u53d6\u7c7b\u522b label = classes [ label_id ] # \u5c06\u6807\u6ce8\u4fe1\u606f\u6dfb\u52a0\u5728\u56fe\u50cf\u4e0a ax . text ( bounding [ 0 ] . numpy (), bounding [ 1 ] . numpy () + 8 , label , color = 'w' , size = 11 , backgroundcolor = \"none\" ) # \u4e0b\u4e00\u4e2a\u7ed3\u679c # \u663e\u793a\u56fe\u50cf plt . show () \u9884\u6d4b\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u603b\u7ed3 \u719f\u6089TFRecord\u6587\u4ef6\u7684\u4f7f\u7528\u65b9\u6cd5 TFRecord\u662fGoogle\u5b98\u65b9\u63a8\u8350\u4f7f\u7528\u7684\u6570\u636e\u683c\u5f0f\u5316\u5b58\u50a8\u5de5\u5177\uff0c\u4e3aTensorFlow\u91cf\u8eab\u6253\u9020\u7684\u3002TFRecord\u5185\u90e8\u5305\u542b\u591a\u4e2atf.train.Example\uff0c\u4e00\u822c\u6765\u8bf4\u5bf9\u5e94\u4e00\u4e2a\u56fe\u50cf\u6570\u636e\uff0c\u5728\u4e00\u4e2aExample\u6d88\u606f\u4f53\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u7684tf.train.feature\u5c5e\u6027\uff0c\u800c \u6bcf\u4e00\u4e2afeature\u662f\u4e00\u4e2akey-value\u7684\u952e\u503c\u5bf9\u3002 \u77e5\u9053YoloV3\u6a21\u578b\u7ed3\u6784\u53ca\u6784\u5efa\u65b9\u6cd5 \u57fa\u672c\u7ec4\u4ef6\u7684\u6784\u5efa\uff0cbackbone\uff0coutput, yoloV3, \u8f93\u51fa\u503c\u7684\u8f6c\u6362 \u77e5\u9053\u6570\u636e\u5904\u7406\u65b9\u6cd5 \u77e5\u9053\u5bf9\u56fe\u50cf\u8fdb\u884cresize,\u4fdd\u6301\u5bbd\u9ad8\u6bd4\uff0c\u8fdb\u884cpad\u7684\u65b9\u6cd5 \u80fd\u591f\u5229\u7528yoloV3\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b \u77e5\u9053\u635f\u5931\u51fd\u6570\uff0c\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\uff0c\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002","title":"4.3 \u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/06.ssd/","text":"4.6 SSD\u7b97\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e24\u7c7b\uff1a Two-stage\u65b9\u6cd5\uff1a\u5982R-CNN\u7cfb\u5217\u7b97\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u901a\u8fc7Selective Search\u6216\u8005CNN\u7f51\u7edc\u4ea7\u751f\u4e00\u7cfb\u5217\u7684\u7a00\u758f\u77e9\u9635\u7684\u5019\u9009\u533a\u57df\uff0c\u7136\u540e\u5bf9\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0ctwo-stage\u7684\u65b9\u6cd5\u4f18\u52bf\u5728\u4e8e\u51c6\u786e\u7387\u5ea6\u9ad8\uff1b One-stage\u65b9\u6cd5\uff1a\u5982YOLO\u7cfb\u5217\u65b9\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u5747\u5300\u5730\u5728\u56fe\u7247\u4e0a\u4e0d\u540c\u4f4d\u7f6e\u8fdb\u884c\u5bc6\u96c6\u91c7\u6837\uff0c\u91c7\u6837\u65f6\u4f7f\u7528\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4box\uff0c\u7136\u540e\u5229\u7528CNN\u63d0\u53d6\u7279\u5f81\u540e\u76f4\u63a5\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u6574\u4e2a\u8fc7\u7a0b\u53ea\u9700\u8981\u4e00\u6b65\uff0c\u6240\u4ee5\u4f18\u52bf\u5728\u4e8e\u901f\u5ea6\u5feb\u3002\u6211\u4eec\u63a5\u4e0b\u6765\u4ecb\u7ecd\u7684SSD\u65b9\u6cd5\u4e5f\u662f\u5355\u9636\u6bb5\u7684\u7b97\u6cd5\u3002 SSD\u7b97\u6cd5\u7684\u5168\u540d\u662fSingle Shot MultiBox Detector\uff0cSingle shot\u6307\u660e\u4e86SSD\u7b97\u6cd5\u5c5e\u4e8eone-stage\u65b9\u6cd5\uff0cMultiBox\u6307\u660e\u4e86SSD\u662f\u591a\u6846\u9884\u6d4b\u3002\u5bf9\u4e8eFaster R-CNN\uff0c\u5148\u901a\u8fc7CNN\u5f97\u5230\u5019\u9009\u6846\uff0c\u7136\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u800cYOLO\u548cSSD\u53ef\u4ee5\u4e00\u6b65\u5b8c\u6210\u68c0\u6d4b\uff0cSSD\u7684\u7279\u70b9\u662f\uff1a SSD\u63d0\u53d6\u4e86\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u6765\u505a\u68c0\u6d4b\uff0c\u5927\u5c3a\u5ea6\u7279\u5f81\u56fe\u53ef\u4ee5\u7528\u6765\u68c0\u6d4b\u5c0f\u7269\u4f53\uff0c\u800c\u5c0f\u7279\u5f81\u56fe\u7528\u6765\u68c0\u6d4b\u5927\u7269\u4f53\uff1b SSD\u91c7\u7528\u4e86\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u7684\u5148\u9a8c\u6846\uff0c\u5728faster r-cnn\u548cyoloV2,V3\u4e2d\u79f0\u4e3aAnchors\u3002 1\u3001 SSD\u7f51\u7edc\u7ed3\u6784 \u00b6 SSD\u662fYOLO V1\u51fa\u6765\u540e\uff0cYOLO V2\u51fa\u6765\u524d\u7684\u4e00\u6b3eOne-stage\u76ee\u6807\u68c0\u6d4b\u5668\u3002SSD\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u5728\u4e4b\u540e\u7684YOLO V3\u7684darknet53\u4e2d\uff0c\u4e5f\u662f\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u601d\u60f3\u3002\u8f83\u6d45\u5c42\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u4e0d\u662f\u5f88\u5927\uff0c\u6240\u4ee5\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u7269\u4f53\uff0c\u800c\u5728\u8f83\u6df1\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u5c31\u6bd4\u8f83\u5927\u4e86\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u7269\u4f53\u3002 SSD\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u7136\u540e\u5728VGG16\u7684\u57fa\u7840\u4e0a\u65b0\u589e\u4e86\u5377\u79ef\u5c42\u6765\u83b7\u5f97\u66f4\u591a\u7684\u7279\u5f81\u56fe\u4ee5\u7528\u4e8e\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7279\u5f81\u56fe\u5206\u4e3a\u4e09\u90e8\u5206\uff1a backbone: VGGnet\u7528\u4e8e\u56fe\u7247\u7279\u5f81\u63d0\u53d6\u7684\u7f51\u7edc Extra: \u7528\u4e8e\u5f15\u51fa\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc Loc\u548ccls: \u7528\u4e8e\u6846\u4f4d\u7f6e\u56de\u5f52\u548c\u76ee\u6807\u5206\u7c7b\u7684\u7f51\u7edc 1.1 backbone \u00b6 \u7f51\u7edc\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u7528imagenet\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\u540e\uff0c\u5c06conv4-1\u524d\u4e00\u5c42\u7684maxpooling\u4e2d\u6c60\u5316\u6a21\u5f0fpadding\u6539\u4e3asame(\u56fe\u4e2d\u5bf9\u5e94pytorch\u4e2d\u7684ceil_mode),\u4f7f\u5f97\u8f93\u51fa\u4e3a38x38\uff0cConv4-3\u5c31\u662f\u591a\u5c3a\u5ea6\u7279\u5f81\u4e2d\u7684\u7b2c\u4e00\u4e2a38x38\u7684\u7279\u5f81\u56fe\uff0c\u56e0\u4e3a\u8be5\u5c42\u6bd4\u8f83\u9760\u524d\uff0c\u6240\u4ee5\u5728\u5176\u540e\u9762\u589e\u52a0\u4e86\u4e00\u4e2aL2 Normalization\u5c42\uff0c\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728channle\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\u3002VGG16\u6700\u540e\u7684\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u8f6c\u6362\u6210 3x3 \u5377\u79ef\u5c42 conv6\u548c \u5377\u79ef\u5c42conv7\uff0c\u540c\u65f6\u5c06\u6700\u540e\u7684\u6c60\u5316\u5c42\u7531\u539f\u6765\u7684stride=2\u7684 2x2 \u53d8\u6210stride=1\u7684 3x3\u7684\u6c60\u5316\u5c42\u3002 \u5176\u4e2dconv6\u4f7f\u7528\u7684Dilated Convolutions\uff0c\u53ef\u4ee5\u7ffb\u8bd1\u4e3a\u6269\u5f20\u5377\u79ef\u6216\u7a7a\u6d1e\u5377\u79ef\u3002\u4e0e\u666e\u901a\u7684\u5377\u79ef\u76f8\u6bd4\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u6269\u5f20\u7387(dilation rate)\u53c2\u6570\uff0c\u4e3b\u8981\u7528\u6765\u8868\u793a\u6269\u5f20\u7684\u5927\u5c0f\u3002\u6269\u5f20\u5377\u79ef\u4e0e\u666e\u901a\u5377\u79ef\u7684\u76f8\u540c\u70b9\u5728\u4e8e\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f\u662f\u4e00\u6837\u7684\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u53c2\u6570\u6570\u91cf\u4e0d\u53d8\uff0c\u533a\u522b\u5728\u4e8e\u6269\u5f20\u5377\u79ef\u5177\u6709\u66f4\u5927\u7684\u611f\u53d7\u91ce\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a (a) \u666e\u901a\u5377\u79ef\uff0c1-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 3 \\times 3 = 9 3 \\times 3 = 9 \u3002 (b) \u6269\u5f20\u5377\u79ef\uff0c2-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 7 \\times 7 = 49 7 \\times 7 = 49 \u3002 \u00a9 \u6269\u5f20\u5377\u79ef\uff0c4-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 15 \\times 15 = 225 15 \\times 15 = 225 \u3002 \u6269\u5f20\u5377\u79ef\u7684\u611f\u53d7\u91ce\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5728tensorflow\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u662f\uff1a(\u4e0e\u666e\u901a\u5377\u79ef\u4e0d\u540c\u7684\u662f\u6307\u5b9adilation_rate\u5373\u53ef) layers.Conv2D(1024, 3, padding='same',dilation_rate=6, activation='relu'), \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5377\u79ef\u6838\u7684\u53c2\u6570\u4e2a\u6570\u4fdd\u6301\u4e0d\u53d8\uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u968f\u7740\u201cdilation rate\u201d\u53c2\u6570\u7684\u589e\u52a0\u5448\u6307\u6570\u589e\u957f\u3002 1.2 extra\u90e8\u5206 \u00b6 \u4e3a\u4e86\u8fdb\u884c\u540e\u7eed\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\uff0c\u5728Backbone\u540e\u9762\u6dfb\u52a0\u4e86\u5377\u79ef\u7f51\u7edc\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u65b0\u589e\u7684Conv8_2\uff0cConv9_2\uff0cConv10_2\uff0cConv11_2\u63d0\u53d6\u7528\u4e8e\u68c0\u6d4b\u7684\u7279\u5f81\u56fe\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5982\u4e0b\u8868\u6240\u793a\uff1a \u7ea2\u6846\u4e2d\u7684\u5185\u5bb9\u662f\u8fdb\u884c\u591a\u5c3a\u5ea6\u5206\u6790\u7684\u7279\u5f81\u56fe\uff0c\u5728\u52a0\u4e0abackbone\u90e8\u5206\u7684Conv4_3\u548cConv7\u83b7\u53d6\u7684\u7279\u5f81\u56fe\uff0c\u5171\u63d0\u53d6\u4e866\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5927\u5c0f\u5206\u522b\u662f (38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)\uff0c\u6211\u4eec\u5c06\u5176\u9001\u5165\u5230loc\u548ccls\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002 1.3 loc\u548ccls \u00b6 \u5728backbone\u548c Extras \u5728\u63d0\u53d6\u76846\u4e2a\u7279\u5f81\u56fe\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u884c\u4f4d\u7f6e\u4fe1\u606f\u548c\u5206\u7c7b\u4fe1\u606f\u7684\u63d0\u53d6\uff0c\u5176\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u90e8\u5206\u4e3b\u8981\u67093\u4e2a\u652f\u8def\u6784\u6210\uff0c PriorBox\u5c42\uff0c\u7528\u6765\u751f\u6210\u5148\u9a8c\u6846\uff0c\u4e5f\u5c31\u662f\u5728fasterRCNN\u4e2d\u7684anchorbox\uff0c\u5047\u8bbe\u5148\u9a8c\u6846\u79cd\u7c7b\u67093\u4e2a\uff08\u4e00\u4e2a\u5355\u5143\u4e0a\u67093\u4e2a\u5148\u9a8c\u6846\uff09\uff0c\u4e00\u5171\u4ea7\u751f5x5x3=75\u4e2a\u5148\u9a8c\u6846 Localization: \u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u6709\u56db\u4e2a\u5750\u6807\uff0c\u5171\u67095x5x3x4\u4e2a\u9884\u6d4b\u7ed3\u679c \u7c7b\u522b\u7f6e\u4fe1\u5ea6confdence\uff1a\u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u670921\u4e2a\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\uff08VOC\u6570\u636e\u96c6\uff09\uff0c\u5171\u67095x5x3x21\u4e2a\u9884\u6d4b\u7ed3\u679c \u6574\u4e2a\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a 1.3.1 PriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5 \u00b6 \u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecdPriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5\uff1a SSD\u4e00\u5171\u67096\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u6570\u91cf\u4e0d\u540c\u7684\uff08\u540c\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u5355\u5143\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u91cc\u7684\u6570\u76ee\u6307\u7684\u662f\u4e00\u4e2a\u5355\u5143\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff09\u3002 \u5148\u9a8c\u6846\u7684\u8bbe\u7f6e\uff1a\u5305\u62ec\u5c3a\u5ea6\uff08\u6216\u8005\u8bf4\u5927\u5c0f\uff09\u548c\u957f\u5bbd\u6bd4\u4e24\u4e2a\u65b9\u9762\u3002 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u9075\u5b88\u4e00\u4e2a\u7ebf\u6027\u9012\u589e\u89c4\u5219\uff1a\u968f\u7740\u7279\u5f81\u56fe\u5927\u5c0f\u964d\u4f4e\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u7ebf\u6027\u589e\u52a0\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6709\u4e0b\u5f0f\u51b3\u5b9a\uff1a s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] \u5176\u4e2d\uff1a m m \u6307\u7684\u7279\u5f81\u56fe\u4e2a\u6570\uff0c\u8fd9\u91cc\u8bbe\u4e3a5 \uff0c\u56e0\u4e3a\u7b2c\u4e00\u5c42\uff08Conv4_3\u5c42\uff09\u662f\u5355\u72ec\u8bbe\u7f6e\u7684\u3002 s_k s_k \u8868\u793a\u5148\u9a8c\u6846\u5927\u5c0f\u76f8\u5bf9\u4e8e\u56fe\u7247\u7684\u6bd4\u4f8b\uff0c\u800c s_{min} s_{min} \u548c s_{max} s_{max} \u8868\u793a\u6bd4\u4f8b\u7684\u6700\u5c0f\u503c\u4e0e\u6700\u5927\u503c\uff0c\u53d6\u503c\u4e3a0.2\u548c0.9\u3002 1\u3001\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6bd4\u4f8b\u4e00\u822c\u8bbe\u7f6e\u4e3a s_{min}/2=0.1 s_{min}/2=0.1 \uff0c\u5c3a\u5ea6\u4e3a 300\\times 0.1=30 300\\times 0.1=30 \u3002 2\u3001\u5bf9\u4e8e\u540e\u9762\u7684\u7279\u5f81\u56fe\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u6309\u7167 s_k s_k \u7ebf\u6027\u589e\u52a0\uff0c\u589e\u957f\u6b65\u957f\u4e3a: \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 3\u3001\u6839\u636e\u4e0a\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5404\u4e2a\u5c3a\u5ea6 s_k s_k \u7684\u53d6\u503c\u4e3a0.20, 0.37,0. 54, 0.71, 0.88 4\u3001\u7136\u540e\u518d\u4e58\u4ee5\u539f\u56fe\u7684\u5927\u5c0f300\uff0c\u518d\u7efc\u5408\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\uff0c\u5219\u53ef\u5f97\u5404\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\u4e3a30,60,111, 162,213,264\u3002 \u5148\u9a8c\u6846\u7684\u957f\u5bbd\u6bd4 \u4e00\u822c\u9009\u53d6 a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} \uff0c\u5bf9\u4e8e\u7279\u5b9a\u7684\u957f\u5bbd\u6bd4\uff0c\u6309\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\u5148\u9a8c\u6846\u7684\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\uff08\u540e\u9762\u7684 s_k s_k \u5747\u6307\u7684\u662f\u5148\u9a8c\u6846\u5b9e\u9645\u5c3a\u5ea6\uff0c\u800c\u4e0d\u662f\u5c3a\u5ea6\u6bd4\u4f8b\uff09: w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4f1a\u6709\u4e00\u4e2a a_r=1 a_r=1 \u4e14\u5c3a\u5ea6\u4e3a s_k s_k \u7684\u5148\u9a8c\u6846\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u5c3a\u5ea6\u4e3a s'_{k}=\\sqrt{s_k s_{k+1}} s'_{k}=\\sqrt{s_k s_{k+1}} \u4e14 a_r=1 a_r=1 \u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u6bcf\u4e2a\u7279\u5f81\u56fe\u90fd\u8bbe\u7f6e\u4e86\u4e24\u4e2a\u957f\u5bbd\u6bd4\u4e3a1\u4f46\u5927\u5c0f\u4e0d\u540c\u7684\u6b63\u65b9\u5f62\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e00\u5171\u6709 6 \u4e2a\u5148\u9a8c\u6846 {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} \uff0c\u4f46\u662f\u5728\u5b9e\u73b0\u65f6\uff0cConv4_3\uff0cConv10_2\u548cConv11_2\u5c42\u4ec5\u4f7f\u75284\u4e2a\u5148\u9a8c\u6846\uff0c\u5b83\u4eec\u4e0d\u4f7f\u7528\u957f\u5bbd\u6bd4\u4e3a 3,\\frac{1}{3} 3,\\frac{1}{3} \u7684\u5148\u9a8c\u6846\u3002 \u4ee4 n_k n_k \u4e3a\u8be5\u7279\u5f81\u56fe\u6240\u91c7\u7528\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff0c\u90a3\u4e48\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k n_k \uff0c\u800c\u8fb9\u754c\u6846\u4f4d\u7f6e\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k\\times 4 n_k\\times 4 \u3002\u7531\u4e8e\u6bcf\u4e2a\u5148\u9a8c\u6846\u90fd\u4f1a\u9884\u6d4b\u4e00\u4e2a\u8fb9\u754c\u6846\uff0c \u6240\u4ee5SSD\u4e00\u5171\u53ef\u4ee5\u9884\u6d4b 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 \u4e2a\u8fb9\u754c\u6846\uff0c\u5bf9\u4e8e\u4e00\u4e2a300x300\u7684\u56fe\u50cf\u5c31\u67098732\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u662f\u975e\u5e38\u7684\u591a\u7684\uff0c\u6240\u4ee5\u8bf4SSD\u672c\u8d28\u4e0a\u662f\u5bc6\u96c6\u91c7\u6837\u3002 1.3.2 loc\u7684\u9884\u6d4b\u7ed3\u679c \u00b6 \u7f51\u7edc\u9884\u6d4b\u8f93\u51fa\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u7684\u8fb9\u754c\u6846\u4e4b\u95f4\u5b58\u5728\u8f6c\u6362\u5173\u7cfb\uff0c\u5177\u4f53\u5982\u4e0b\uff1a \u5148\u9a8c\u6846\u4f4d\u7f6e\uff1a l= (l^{cx}, l^{cy}, l^{w}, l^{h}) l= (l^{cx}, l^{cy}, l^{w}, l^{h}) \u771f\u5b9e\u6846\u7684\u4f4d\u7f6e\uff1a p = (p^{cx}, p^{cy}, p^{w}, p^{h}) p = (p^{cx}, p^{cy}, p^{w}, p^{h}) \u90a3\u4e48\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c d d \u4e0e\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u5b58\u5728\u5173\u7cfb\uff1a p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h}) p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h}) 2.\u6a21\u578b\u8bad\u7ec3 \u00b6 2.1 \u6b63\u8d1f\u6837\u672c\u6807\u8bb0 \u00b6 \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u9996\u5148\u9700\u8981\u786e\u5b9a\u8bad\u7ec3\u56fe\u7247\u4e2d\u7684 ground truth \u4e0e\u54ea\u4e00\u4e2a\u5148\u9a8c\u6846\u6765\u8fdb\u884c\u5339\u914d\uff0c\u4e0e\u4e4b\u5339\u914d\u7684\u5148\u9a8c\u6846\u6240\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u5c06\u8d1f\u8d23\u9884\u6d4b\u5b83\u3002 SSD\u7684\u5148\u9a8c\u6846\u548cground truth\u5339\u914d\u539f\u5219\uff1a \u6b63\u6837\u672c 1\u3001\u5bf9\u4e8e\u56fe\u7247\u4e2d\u7684\u6bcf\u4e2agt\uff0c\u627e\u5230\u4e0e\u5176IOU\u6700\u5927\u7684\u5148\u9a8c\u6846\uff0c\u8be5\u5148\u9a8c\u6846\u4e0e\u5176\u5339\u914d\uff0c\u8fd9\u6837\u53ef\u4ee5\u4fdd\u8bc1\u6bcf\u4e2agt\u4e00\u5b9a\u4e0e\u67d0\u4e2a\u5148\u9a8c\u6846\u5339\u914d\u3002 2\u3001\u5bf9\u4e8e\u5269\u4f59\u672a\u5339\u914d\u7684\u5148\u9a8c\u6846\uff0c\u82e5\u67d0\u4e2agt\u7684IOU\u5927\u4e8e\u67d0\u4e2a\u9608\u503c(\u4e00\u822c0.5)\uff0c\u90a3\u4e48\u8be5\u5148\u9a8c\u6846\u4e0e\u8fd9\u4e2agt\u5339\u914d \u8d1f\u6837\u672c \u5176\u5b83\u7684\u5148\u9a8c\u6846\u6807\u8bb0\u4e3a\u8d1f\u6837\u672c \u6ce8\u610f\uff1a 1\u3001\u67d0\u4e2agt\u53ef\u4ee5\u548c\u591a\u4e2a\u5148\u9a8c\u6846\u5339\u914d\uff0c\u800c\u6bcf\u4e2a\u5148\u9a8c\u6846\u53ea\u80fd\u548c\u4e00\u4e2agt\u8fdb\u884c\u5339\u914d 2\u3001\u5982\u679c\u591a\u4e2agt\u548c\u67d0\u4e00\u4e2a\u5148\u9a8c\u6846\u7684IOU\u5747\u5927\u4e8e\u9608\u503c\uff0c\u90a3\u4e48\u5148\u9a8c\u6846\u53ea\u4e0eIOU\u6700\u5927\u7684\u90a3\u4e2a\u8fdb\u884c\u5339\u914d 2.2 \u635f\u5931\u51fd\u6570 \u00b6 SSD\u7684\u635f\u5931\u51fd\u6570\u662f\u4f4d\u7f6e\u635f\u5931\uff08 loc\uff09\u4e0e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u635f\u5931\uff08conf\uff09\u7684\u52a0\u6743\u548c\uff1a L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) \u5176\u4e2d N N \u662f\u5148\u9a8c\u6846\u7684\u6b63\u6837\u672c\u6570\u91cf\uff0c c c \u4e3a\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\uff0c l l \u4e3a\u5148\u9a8c\u6846\u7684\u6240\u5bf9\u5e94\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u9884\u6d4b\u503c\uff0c\u800c g g \u662fground truth\u7684\u4f4d\u7f6e\u53c2\u6570\uff0c\u6743\u91cd\u7cfb\u6570 \\alpha \\alpha \u8bbe\u7f6e\u4e3a1\u3002 \u4f4d\u7f6e\u635f\u5931\u51fd\u6570\uff1a \u9488\u5bf9\u6240\u6709\u7684\u6b63\u6837\u672c\uff0c\u91c7\u7528 Smooth L1 Loss\u635f\u5931 \u5206\u7c7b\u635f\u5931\u51fd\u6570 \u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u4e0efasterRCNN\u4e00\u6837\u91c7\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002 2.3 \u56f0\u96be\u6837\u672c\u6316\u6398 \u00b6 \u56f0\u96be\u6837\u672c\u6316\u6398\u7684\u601d\u60f3\u662f\u4f7f\u7528\u7f51\u7edc\u5bf9\u6837\u672c\u8fdb\u884c\u5904\u7406\uff0c\u628a\u5176\u4e2d\u9884\u6d4b\u9519\u8bef\u7684\u8d1f\u6837\u672c(hard negative)\u653e\u5165\u8d1f\u6837\u672c\u96c6\u5408\u518d\u7ee7\u7eed\u8bad\u7ec3\u7f51\u7edc\u6a21\u578b\u3002 \u5728SSD\u4e2d\u5904\u7406\u65b9\u5f0f\u662f\uff1a \u4f7f\u75281\uff1a3\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u8bad\u7ec3\u7f51\u7edc\uff0c \u5bf9\u8f93\u5165\u7684\u9884\u6d4b\u7ed3\u679c\u6309\u7167\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5e8f\uff0c\u53d6\u51fa\u524dk\u4e2a\u8d1f\u6837\u672c \u5c06\u8fd9k\u4e2a\u8d1f\u6837\u672c\u52a0\u5165\u4e0b\u6b21\u8fed\u4ee3\u7684\u8d1f\u6837\u672c\u4e2d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002 3.\u6a21\u578b\u9884\u6d4b \u00b6 \u9884\u6d4b\u8fc7\u7a0b\u6bd4\u8f83\u7b80\u5355\uff0c \u4e3b\u8981\u6b65\u9aa4\u5982\u4e0b\uff1a \u5bf9\u4e8e\u6bcf\u4e2a\u9884\u6d4b\u6846\uff0c\u9996\u5148\u6839\u636e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u786e\u5b9a\u5176\u7c7b\u522b\uff08\u7f6e\u4fe1\u5ea6\u6700\u5927\u8005\uff09\u4e0e\u7f6e\u4fe1\u5ea6\u503c\uff0c\u5e76\u8fc7\u6ee4\u6389\u5c5e\u4e8e\u80cc\u666f\u7684\u9884\u6d4b\u6846\u3002 \u7136\u540e\u6839\u636e\u7f6e\u4fe1\u5ea6\u9608\u503c\uff08\u59820.5\uff09\u8fc7\u6ee4\u6389\u9608\u503c\u8f83\u4f4e\u7684\u9884\u6d4b\u6846\u3002 \u5bf9\u4e8e\u7559\u4e0b\u7684\u9884\u6d4b\u6846\u8fdb\u884c\u89e3\u7801\uff0c\u6839\u636e\u5148\u9a8c\u6846\u5f97\u5230\u5176\u771f\u5b9e\u7684\u4f4d\u7f6e\u53c2\u6570\uff08\u89e3\u7801\u540e\u4e00\u822c\u8fd8\u9700\u8981\u505aclip\uff0c\u9632\u6b62\u9884\u6d4b\u6846\u4f4d\u7f6e\u8d85\u51fa\u56fe\u7247\uff09\u3002 \u89e3\u7801\u4e4b\u540e\uff0c\u4e00\u822c\u9700\u8981\u6839\u636e\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5217\uff0c\u7136\u540e\u4ec5\u4fdd\u7559top-k\uff08\u5982400\uff09\u4e2a\u9884\u6d4b\u6846\u3002 \u8fdb\u884cNMS\u7b97\u6cd5\uff0c\u8fc7\u6ee4\u6389\u90a3\u4e9b\u91cd\u53e0\u5ea6\u8f83\u5927\u7684\u9884\u6d4b\u6846\u3002 \u6700\u540e\u5269\u4f59\u7684\u9884\u6d4b\u6846\u5c31\u662f\u68c0\u6d4b\u7ed3\u679c\u4e86\u3002 \u603b\u7ed3 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc SSD\u63d0\u53d6\u4e866\u4e2a\u4e0d\u540c\u7279\u5f81\u56fe\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f SSD\u5728\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u7684\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u662f\u4e0d\u4e00\u6837\u7684 \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u5206\u7c7b\u548c\u56de\u5f52\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u548c","title":"SSD\u7b97\u6cd5"},{"location":"objectdection/06.ssd/#46-ssd","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e24\u7c7b\uff1a Two-stage\u65b9\u6cd5\uff1a\u5982R-CNN\u7cfb\u5217\u7b97\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u901a\u8fc7Selective Search\u6216\u8005CNN\u7f51\u7edc\u4ea7\u751f\u4e00\u7cfb\u5217\u7684\u7a00\u758f\u77e9\u9635\u7684\u5019\u9009\u533a\u57df\uff0c\u7136\u540e\u5bf9\u8fd9\u4e9b\u5019\u9009\u533a\u57df\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0ctwo-stage\u7684\u65b9\u6cd5\u4f18\u52bf\u5728\u4e8e\u51c6\u786e\u7387\u5ea6\u9ad8\uff1b One-stage\u65b9\u6cd5\uff1a\u5982YOLO\u7cfb\u5217\u65b9\u6cd5\uff0c\u4e3b\u8981\u601d\u8def\u5c31\u662f\u5747\u5300\u5730\u5728\u56fe\u7247\u4e0a\u4e0d\u540c\u4f4d\u7f6e\u8fdb\u884c\u5bc6\u96c6\u91c7\u6837\uff0c\u91c7\u6837\u65f6\u4f7f\u7528\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4box\uff0c\u7136\u540e\u5229\u7528CNN\u63d0\u53d6\u7279\u5f81\u540e\u76f4\u63a5\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u6574\u4e2a\u8fc7\u7a0b\u53ea\u9700\u8981\u4e00\u6b65\uff0c\u6240\u4ee5\u4f18\u52bf\u5728\u4e8e\u901f\u5ea6\u5feb\u3002\u6211\u4eec\u63a5\u4e0b\u6765\u4ecb\u7ecd\u7684SSD\u65b9\u6cd5\u4e5f\u662f\u5355\u9636\u6bb5\u7684\u7b97\u6cd5\u3002 SSD\u7b97\u6cd5\u7684\u5168\u540d\u662fSingle Shot MultiBox Detector\uff0cSingle shot\u6307\u660e\u4e86SSD\u7b97\u6cd5\u5c5e\u4e8eone-stage\u65b9\u6cd5\uff0cMultiBox\u6307\u660e\u4e86SSD\u662f\u591a\u6846\u9884\u6d4b\u3002\u5bf9\u4e8eFaster R-CNN\uff0c\u5148\u901a\u8fc7CNN\u5f97\u5230\u5019\u9009\u6846\uff0c\u7136\u540e\u8fdb\u884c\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u800cYOLO\u548cSSD\u53ef\u4ee5\u4e00\u6b65\u5b8c\u6210\u68c0\u6d4b\uff0cSSD\u7684\u7279\u70b9\u662f\uff1a SSD\u63d0\u53d6\u4e86\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u6765\u505a\u68c0\u6d4b\uff0c\u5927\u5c3a\u5ea6\u7279\u5f81\u56fe\u53ef\u4ee5\u7528\u6765\u68c0\u6d4b\u5c0f\u7269\u4f53\uff0c\u800c\u5c0f\u7279\u5f81\u56fe\u7528\u6765\u68c0\u6d4b\u5927\u7269\u4f53\uff1b SSD\u91c7\u7528\u4e86\u4e0d\u540c\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u7684\u5148\u9a8c\u6846\uff0c\u5728faster r-cnn\u548cyoloV2,V3\u4e2d\u79f0\u4e3aAnchors\u3002","title":"4.6 SSD\u7b97\u6cd5"},{"location":"objectdection/06.ssd/#1-ssd","text":"SSD\u662fYOLO V1\u51fa\u6765\u540e\uff0cYOLO V2\u51fa\u6765\u524d\u7684\u4e00\u6b3eOne-stage\u76ee\u6807\u68c0\u6d4b\u5668\u3002SSD\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u5728\u4e4b\u540e\u7684YOLO V3\u7684darknet53\u4e2d\uff0c\u4e5f\u662f\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u601d\u60f3\u3002\u8f83\u6d45\u5c42\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u4e0d\u662f\u5f88\u5927\uff0c\u6240\u4ee5\u9002\u5408\u68c0\u6d4b\u8f83\u5c0f\u7684\u7269\u4f53\uff0c\u800c\u5728\u8f83\u6df1\u7684\u7279\u5f81\u56fe\u4e0a\uff0c\u6bcf\u4e2acell\u7684\u611f\u53d7\u91ce\u5c31\u6bd4\u8f83\u5927\u4e86\uff0c\u9002\u5408\u68c0\u6d4b\u8f83\u5927\u7684\u7269\u4f53\u3002 SSD\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u7136\u540e\u5728VGG16\u7684\u57fa\u7840\u4e0a\u65b0\u589e\u4e86\u5377\u79ef\u5c42\u6765\u83b7\u5f97\u66f4\u591a\u7684\u7279\u5f81\u56fe\u4ee5\u7528\u4e8e\u68c0\u6d4b\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6574\u4e2a\u7279\u5f81\u56fe\u5206\u4e3a\u4e09\u90e8\u5206\uff1a backbone: VGGnet\u7528\u4e8e\u56fe\u7247\u7279\u5f81\u63d0\u53d6\u7684\u7f51\u7edc Extra: \u7528\u4e8e\u5f15\u51fa\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc Loc\u548ccls: \u7528\u4e8e\u6846\u4f4d\u7f6e\u56de\u5f52\u548c\u76ee\u6807\u5206\u7c7b\u7684\u7f51\u7edc","title":"1\u3001 SSD\u7f51\u7edc\u7ed3\u6784"},{"location":"objectdection/06.ssd/#11-backbone","text":"\u7f51\u7edc\u91c7\u7528VGG16\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u7528imagenet\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\u540e\uff0c\u5c06conv4-1\u524d\u4e00\u5c42\u7684maxpooling\u4e2d\u6c60\u5316\u6a21\u5f0fpadding\u6539\u4e3asame(\u56fe\u4e2d\u5bf9\u5e94pytorch\u4e2d\u7684ceil_mode),\u4f7f\u5f97\u8f93\u51fa\u4e3a38x38\uff0cConv4-3\u5c31\u662f\u591a\u5c3a\u5ea6\u7279\u5f81\u4e2d\u7684\u7b2c\u4e00\u4e2a38x38\u7684\u7279\u5f81\u56fe\uff0c\u56e0\u4e3a\u8be5\u5c42\u6bd4\u8f83\u9760\u524d\uff0c\u6240\u4ee5\u5728\u5176\u540e\u9762\u589e\u52a0\u4e86\u4e00\u4e2aL2 Normalization\u5c42\uff0c\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728channle\u7ef4\u5ea6\u505a\u5f52\u4e00\u5316\u3002VGG16\u6700\u540e\u7684\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u8f6c\u6362\u6210 3x3 \u5377\u79ef\u5c42 conv6\u548c \u5377\u79ef\u5c42conv7\uff0c\u540c\u65f6\u5c06\u6700\u540e\u7684\u6c60\u5316\u5c42\u7531\u539f\u6765\u7684stride=2\u7684 2x2 \u53d8\u6210stride=1\u7684 3x3\u7684\u6c60\u5316\u5c42\u3002 \u5176\u4e2dconv6\u4f7f\u7528\u7684Dilated Convolutions\uff0c\u53ef\u4ee5\u7ffb\u8bd1\u4e3a\u6269\u5f20\u5377\u79ef\u6216\u7a7a\u6d1e\u5377\u79ef\u3002\u4e0e\u666e\u901a\u7684\u5377\u79ef\u76f8\u6bd4\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u6269\u5f20\u7387(dilation rate)\u53c2\u6570\uff0c\u4e3b\u8981\u7528\u6765\u8868\u793a\u6269\u5f20\u7684\u5927\u5c0f\u3002\u6269\u5f20\u5377\u79ef\u4e0e\u666e\u901a\u5377\u79ef\u7684\u76f8\u540c\u70b9\u5728\u4e8e\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f\u662f\u4e00\u6837\u7684\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u53c2\u6570\u6570\u91cf\u4e0d\u53d8\uff0c\u533a\u522b\u5728\u4e8e\u6269\u5f20\u5377\u79ef\u5177\u6709\u66f4\u5927\u7684\u611f\u53d7\u91ce\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a (a) \u666e\u901a\u5377\u79ef\uff0c1-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 3 \\times 3 = 9 3 \\times 3 = 9 \u3002 (b) \u6269\u5f20\u5377\u79ef\uff0c2-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 7 \\times 7 = 49 7 \\times 7 = 49 \u3002 \u00a9 \u6269\u5f20\u5377\u79ef\uff0c4-dilated convolution\uff0c\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\u4e3a 15 \\times 15 = 225 15 \\times 15 = 225 \u3002 \u6269\u5f20\u5377\u79ef\u7684\u611f\u53d7\u91ce\u7684\u8ba1\u7b97\u65b9\u6cd5\u662f\uff1a \u5728tensorflow\u4e2d\u5b9e\u73b0\u4f7f\u7528\u7684\u662f\uff1a(\u4e0e\u666e\u901a\u5377\u79ef\u4e0d\u540c\u7684\u662f\u6307\u5b9adilation_rate\u5373\u53ef) layers.Conv2D(1024, 3, padding='same',dilation_rate=6, activation='relu'), \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5377\u79ef\u6838\u7684\u53c2\u6570\u4e2a\u6570\u4fdd\u6301\u4e0d\u53d8\uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u968f\u7740\u201cdilation rate\u201d\u53c2\u6570\u7684\u589e\u52a0\u5448\u6307\u6570\u589e\u957f\u3002","title":"1.1 backbone"},{"location":"objectdection/06.ssd/#12-extra","text":"\u4e3a\u4e86\u8fdb\u884c\u540e\u7eed\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\uff0c\u5728Backbone\u540e\u9762\u6dfb\u52a0\u4e86\u5377\u79ef\u7f51\u7edc\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u65b0\u589e\u7684Conv8_2\uff0cConv9_2\uff0cConv10_2\uff0cConv11_2\u63d0\u53d6\u7528\u4e8e\u68c0\u6d4b\u7684\u7279\u5f81\u56fe\uff0c\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u5982\u4e0b\u8868\u6240\u793a\uff1a \u7ea2\u6846\u4e2d\u7684\u5185\u5bb9\u662f\u8fdb\u884c\u591a\u5c3a\u5ea6\u5206\u6790\u7684\u7279\u5f81\u56fe\uff0c\u5728\u52a0\u4e0abackbone\u90e8\u5206\u7684Conv4_3\u548cConv7\u83b7\u53d6\u7684\u7279\u5f81\u56fe\uff0c\u5171\u63d0\u53d6\u4e866\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5927\u5c0f\u5206\u522b\u662f (38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)\uff0c\u6211\u4eec\u5c06\u5176\u9001\u5165\u5230loc\u548ccls\u4e2d\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u3002","title":"1.2 extra\u90e8\u5206"},{"location":"objectdection/06.ssd/#13-loccls","text":"\u5728backbone\u548c Extras \u5728\u63d0\u53d6\u76846\u4e2a\u7279\u5f81\u56fe\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u884c\u4f4d\u7f6e\u4fe1\u606f\u548c\u5206\u7c7b\u4fe1\u606f\u7684\u63d0\u53d6\uff0c\u5176\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u8be5\u90e8\u5206\u4e3b\u8981\u67093\u4e2a\u652f\u8def\u6784\u6210\uff0c PriorBox\u5c42\uff0c\u7528\u6765\u751f\u6210\u5148\u9a8c\u6846\uff0c\u4e5f\u5c31\u662f\u5728fasterRCNN\u4e2d\u7684anchorbox\uff0c\u5047\u8bbe\u5148\u9a8c\u6846\u79cd\u7c7b\u67093\u4e2a\uff08\u4e00\u4e2a\u5355\u5143\u4e0a\u67093\u4e2a\u5148\u9a8c\u6846\uff09\uff0c\u4e00\u5171\u4ea7\u751f5x5x3=75\u4e2a\u5148\u9a8c\u6846 Localization: \u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u6709\u56db\u4e2a\u5750\u6807\uff0c\u5171\u67095x5x3x4\u4e2a\u9884\u6d4b\u7ed3\u679c \u7c7b\u522b\u7f6e\u4fe1\u5ea6confdence\uff1a\u91c7\u7528\u4e00\u6b21 3\\times3 3\\times3 \u5377\u79ef\u6765\u8fdb\u884c\u5b8c\u6210\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u670921\u4e2a\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\uff08VOC\u6570\u636e\u96c6\uff09\uff0c\u5171\u67095x5x3x21\u4e2a\u9884\u6d4b\u7ed3\u679c \u6574\u4e2a\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a","title":"1.3 loc\u548ccls"},{"location":"objectdection/06.ssd/#131-priorbox","text":"\u5728\u8fd9\u91cc\u6211\u4eec\u7740\u91cd\u4ecb\u7ecdPriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5\uff1a SSD\u4e00\u5171\u67096\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u6570\u91cf\u4e0d\u540c\u7684\uff08\u540c\u4e00\u4e2a\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u5355\u5143\u8bbe\u7f6e\u7684\u5148\u9a8c\u6846\u662f\u76f8\u540c\u7684\uff0c\u8fd9\u91cc\u7684\u6570\u76ee\u6307\u7684\u662f\u4e00\u4e2a\u5355\u5143\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff09\u3002 \u5148\u9a8c\u6846\u7684\u8bbe\u7f6e\uff1a\u5305\u62ec\u5c3a\u5ea6\uff08\u6216\u8005\u8bf4\u5927\u5c0f\uff09\u548c\u957f\u5bbd\u6bd4\u4e24\u4e2a\u65b9\u9762\u3002 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6 \u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u9075\u5b88\u4e00\u4e2a\u7ebf\u6027\u9012\u589e\u89c4\u5219\uff1a\u968f\u7740\u7279\u5f81\u56fe\u5927\u5c0f\u964d\u4f4e\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u7ebf\u6027\u589e\u52a0\uff0c\u6bcf\u4e2a\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6709\u4e0b\u5f0f\u51b3\u5b9a\uff1a s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] s_k = s_{min} + \\frac{s_{max} - s_{min}}{m-1}(k-1), k\\in[1,m] \u5176\u4e2d\uff1a m m \u6307\u7684\u7279\u5f81\u56fe\u4e2a\u6570\uff0c\u8fd9\u91cc\u8bbe\u4e3a5 \uff0c\u56e0\u4e3a\u7b2c\u4e00\u5c42\uff08Conv4_3\u5c42\uff09\u662f\u5355\u72ec\u8bbe\u7f6e\u7684\u3002 s_k s_k \u8868\u793a\u5148\u9a8c\u6846\u5927\u5c0f\u76f8\u5bf9\u4e8e\u56fe\u7247\u7684\u6bd4\u4f8b\uff0c\u800c s_{min} s_{min} \u548c s_{max} s_{max} \u8868\u793a\u6bd4\u4f8b\u7684\u6700\u5c0f\u503c\u4e0e\u6700\u5927\u503c\uff0c\u53d6\u503c\u4e3a0.2\u548c0.9\u3002 1\u3001\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5176\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u6bd4\u4f8b\u4e00\u822c\u8bbe\u7f6e\u4e3a s_{min}/2=0.1 s_{min}/2=0.1 \uff0c\u5c3a\u5ea6\u4e3a 300\\times 0.1=30 300\\times 0.1=30 \u3002 2\u3001\u5bf9\u4e8e\u540e\u9762\u7684\u7279\u5f81\u56fe\uff0c\u5148\u9a8c\u6846\u5c3a\u5ea6\u6309\u7167 s_k s_k \u7ebf\u6027\u589e\u52a0\uff0c\u589e\u957f\u6b65\u957f\u4e3a: \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 \\lfloor\\frac{\\lfloor s_{max}\\rfloor - \\lfloor s_{min}\\rfloor}{m-1}\\rfloor=0.17 3\u3001\u6839\u636e\u4e0a\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5404\u4e2a\u5c3a\u5ea6 s_k s_k \u7684\u53d6\u503c\u4e3a0.20, 0.37,0. 54, 0.71, 0.88 4\u3001\u7136\u540e\u518d\u4e58\u4ee5\u539f\u56fe\u7684\u5927\u5c0f300\uff0c\u518d\u7efc\u5408\u7b2c\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\uff0c\u5219\u53ef\u5f97\u5404\u4e2a\u7279\u5f81\u56fe\u7684\u5148\u9a8c\u6846\u5c3a\u5bf8\u4e3a30,60,111, 162,213,264\u3002 \u5148\u9a8c\u6846\u7684\u957f\u5bbd\u6bd4 \u4e00\u822c\u9009\u53d6 a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} a_r\\in {1,2,3,\\frac{1}{2},\\frac{1}{3}} \uff0c\u5bf9\u4e8e\u7279\u5b9a\u7684\u957f\u5bbd\u6bd4\uff0c\u6309\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\u5148\u9a8c\u6846\u7684\u5bbd\u5ea6\u4e0e\u9ad8\u5ea6\uff08\u540e\u9762\u7684 s_k s_k \u5747\u6307\u7684\u662f\u5148\u9a8c\u6846\u5b9e\u9645\u5c3a\u5ea6\uff0c\u800c\u4e0d\u662f\u5c3a\u5ea6\u6bd4\u4f8b\uff09: w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} w^a_{k}=s_k\\sqrt{a_r},\\space h^a_{k}=s_k/\\sqrt{a_r} \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4f1a\u6709\u4e00\u4e2a a_r=1 a_r=1 \u4e14\u5c3a\u5ea6\u4e3a s_k s_k \u7684\u5148\u9a8c\u6846\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u5c3a\u5ea6\u4e3a s'_{k}=\\sqrt{s_k s_{k+1}} s'_{k}=\\sqrt{s_k s_{k+1}} \u4e14 a_r=1 a_r=1 \u7684\u5148\u9a8c\u6846\uff0c\u8fd9\u6837\u6bcf\u4e2a\u7279\u5f81\u56fe\u90fd\u8bbe\u7f6e\u4e86\u4e24\u4e2a\u957f\u5bbd\u6bd4\u4e3a1\u4f46\u5927\u5c0f\u4e0d\u540c\u7684\u6b63\u65b9\u5f62\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\uff0c\u6bcf\u4e2a\u7279\u5f81\u56fe\u4e00\u5171\u6709 6 \u4e2a\u5148\u9a8c\u6846 {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} {1,2,3,\\frac{1}{2},\\frac{1}{3},1'} \uff0c\u4f46\u662f\u5728\u5b9e\u73b0\u65f6\uff0cConv4_3\uff0cConv10_2\u548cConv11_2\u5c42\u4ec5\u4f7f\u75284\u4e2a\u5148\u9a8c\u6846\uff0c\u5b83\u4eec\u4e0d\u4f7f\u7528\u957f\u5bbd\u6bd4\u4e3a 3,\\frac{1}{3} 3,\\frac{1}{3} \u7684\u5148\u9a8c\u6846\u3002 \u4ee4 n_k n_k \u4e3a\u8be5\u7279\u5f81\u56fe\u6240\u91c7\u7528\u7684\u5148\u9a8c\u6846\u6570\u76ee\uff0c\u90a3\u4e48\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k n_k \uff0c\u800c\u8fb9\u754c\u6846\u4f4d\u7f6e\u9700\u8981\u7684\u5377\u79ef\u6838\u6570\u91cf\u4e3a n_k\\times 4 n_k\\times 4 \u3002\u7531\u4e8e\u6bcf\u4e2a\u5148\u9a8c\u6846\u90fd\u4f1a\u9884\u6d4b\u4e00\u4e2a\u8fb9\u754c\u6846\uff0c \u6240\u4ee5SSD\u4e00\u5171\u53ef\u4ee5\u9884\u6d4b 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 38\\times38\\times4+19\\times19\\times6+10\\times10\\times6+5\\times5\\times6+3\\times3\\times4+1\\times1\\times4=8732 \u4e2a\u8fb9\u754c\u6846\uff0c\u5bf9\u4e8e\u4e00\u4e2a300x300\u7684\u56fe\u50cf\u5c31\u67098732\u4e2a\u9884\u6d4b\u7ed3\u679c\uff0c\u662f\u975e\u5e38\u7684\u591a\u7684\uff0c\u6240\u4ee5\u8bf4SSD\u672c\u8d28\u4e0a\u662f\u5bc6\u96c6\u91c7\u6837\u3002","title":"1.3.1 PriorBox\u5c42\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u6cd5"},{"location":"objectdection/06.ssd/#132-loc","text":"\u7f51\u7edc\u9884\u6d4b\u8f93\u51fa\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u7684\u8fb9\u754c\u6846\u4e4b\u95f4\u5b58\u5728\u8f6c\u6362\u5173\u7cfb\uff0c\u5177\u4f53\u5982\u4e0b\uff1a \u5148\u9a8c\u6846\u4f4d\u7f6e\uff1a l= (l^{cx}, l^{cy}, l^{w}, l^{h}) l= (l^{cx}, l^{cy}, l^{w}, l^{h}) \u771f\u5b9e\u6846\u7684\u4f4d\u7f6e\uff1a p = (p^{cx}, p^{cy}, p^{w}, p^{h}) p = (p^{cx}, p^{cy}, p^{w}, p^{h}) \u90a3\u4e48\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c d d \u4e0e\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u5b58\u5728\u5173\u7cfb\uff1a p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{cx} =l^{w}d^{cx} +l^{cx}, p^{cy} = l^{y}d^{cy} +l^{cy} p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h}) p^{w} = l^{w}exp(d^{w}), p^{h} = l^{h}exp(d^{h})","title":"1.3.2 loc\u7684\u9884\u6d4b\u7ed3\u679c"},{"location":"objectdection/06.ssd/#2","text":"","title":"2.\u6a21\u578b\u8bad\u7ec3"},{"location":"objectdection/06.ssd/#21","text":"\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u9996\u5148\u9700\u8981\u786e\u5b9a\u8bad\u7ec3\u56fe\u7247\u4e2d\u7684 ground truth \u4e0e\u54ea\u4e00\u4e2a\u5148\u9a8c\u6846\u6765\u8fdb\u884c\u5339\u914d\uff0c\u4e0e\u4e4b\u5339\u914d\u7684\u5148\u9a8c\u6846\u6240\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u5c06\u8d1f\u8d23\u9884\u6d4b\u5b83\u3002 SSD\u7684\u5148\u9a8c\u6846\u548cground truth\u5339\u914d\u539f\u5219\uff1a \u6b63\u6837\u672c 1\u3001\u5bf9\u4e8e\u56fe\u7247\u4e2d\u7684\u6bcf\u4e2agt\uff0c\u627e\u5230\u4e0e\u5176IOU\u6700\u5927\u7684\u5148\u9a8c\u6846\uff0c\u8be5\u5148\u9a8c\u6846\u4e0e\u5176\u5339\u914d\uff0c\u8fd9\u6837\u53ef\u4ee5\u4fdd\u8bc1\u6bcf\u4e2agt\u4e00\u5b9a\u4e0e\u67d0\u4e2a\u5148\u9a8c\u6846\u5339\u914d\u3002 2\u3001\u5bf9\u4e8e\u5269\u4f59\u672a\u5339\u914d\u7684\u5148\u9a8c\u6846\uff0c\u82e5\u67d0\u4e2agt\u7684IOU\u5927\u4e8e\u67d0\u4e2a\u9608\u503c(\u4e00\u822c0.5)\uff0c\u90a3\u4e48\u8be5\u5148\u9a8c\u6846\u4e0e\u8fd9\u4e2agt\u5339\u914d \u8d1f\u6837\u672c \u5176\u5b83\u7684\u5148\u9a8c\u6846\u6807\u8bb0\u4e3a\u8d1f\u6837\u672c \u6ce8\u610f\uff1a 1\u3001\u67d0\u4e2agt\u53ef\u4ee5\u548c\u591a\u4e2a\u5148\u9a8c\u6846\u5339\u914d\uff0c\u800c\u6bcf\u4e2a\u5148\u9a8c\u6846\u53ea\u80fd\u548c\u4e00\u4e2agt\u8fdb\u884c\u5339\u914d 2\u3001\u5982\u679c\u591a\u4e2agt\u548c\u67d0\u4e00\u4e2a\u5148\u9a8c\u6846\u7684IOU\u5747\u5927\u4e8e\u9608\u503c\uff0c\u90a3\u4e48\u5148\u9a8c\u6846\u53ea\u4e0eIOU\u6700\u5927\u7684\u90a3\u4e2a\u8fdb\u884c\u5339\u914d","title":"2.1 \u6b63\u8d1f\u6837\u672c\u6807\u8bb0"},{"location":"objectdection/06.ssd/#22","text":"SSD\u7684\u635f\u5931\u51fd\u6570\u662f\u4f4d\u7f6e\u635f\u5931\uff08 loc\uff09\u4e0e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u635f\u5931\uff08conf\uff09\u7684\u52a0\u6743\u548c\uff1a L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) L(x, c, l, g) = \\frac{1}{N}(L_{conf}(x,c) + \\alpha L_{loc}(x,l,g)) \u5176\u4e2d N N \u662f\u5148\u9a8c\u6846\u7684\u6b63\u6837\u672c\u6570\u91cf\uff0c c c \u4e3a\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\uff0c l l \u4e3a\u5148\u9a8c\u6846\u7684\u6240\u5bf9\u5e94\u8fb9\u754c\u6846\u7684\u4f4d\u7f6e\u9884\u6d4b\u503c\uff0c\u800c g g \u662fground truth\u7684\u4f4d\u7f6e\u53c2\u6570\uff0c\u6743\u91cd\u7cfb\u6570 \\alpha \\alpha \u8bbe\u7f6e\u4e3a1\u3002 \u4f4d\u7f6e\u635f\u5931\u51fd\u6570\uff1a \u9488\u5bf9\u6240\u6709\u7684\u6b63\u6837\u672c\uff0c\u91c7\u7528 Smooth L1 Loss\u635f\u5931 \u5206\u7c7b\u635f\u5931\u51fd\u6570 \u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u4e0efasterRCNN\u4e00\u6837\u91c7\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002","title":"2.2 \u635f\u5931\u51fd\u6570"},{"location":"objectdection/06.ssd/#23","text":"\u56f0\u96be\u6837\u672c\u6316\u6398\u7684\u601d\u60f3\u662f\u4f7f\u7528\u7f51\u7edc\u5bf9\u6837\u672c\u8fdb\u884c\u5904\u7406\uff0c\u628a\u5176\u4e2d\u9884\u6d4b\u9519\u8bef\u7684\u8d1f\u6837\u672c(hard negative)\u653e\u5165\u8d1f\u6837\u672c\u96c6\u5408\u518d\u7ee7\u7eed\u8bad\u7ec3\u7f51\u7edc\u6a21\u578b\u3002 \u5728SSD\u4e2d\u5904\u7406\u65b9\u5f0f\u662f\uff1a \u4f7f\u75281\uff1a3\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u8bad\u7ec3\u7f51\u7edc\uff0c \u5bf9\u8f93\u5165\u7684\u9884\u6d4b\u7ed3\u679c\u6309\u7167\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5e8f\uff0c\u53d6\u51fa\u524dk\u4e2a\u8d1f\u6837\u672c \u5c06\u8fd9k\u4e2a\u8d1f\u6837\u672c\u52a0\u5165\u4e0b\u6b21\u8fed\u4ee3\u7684\u8d1f\u6837\u672c\u4e2d\u5bf9\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\u3002","title":"2.3 \u56f0\u96be\u6837\u672c\u6316\u6398"},{"location":"objectdection/06.ssd/#3","text":"\u9884\u6d4b\u8fc7\u7a0b\u6bd4\u8f83\u7b80\u5355\uff0c \u4e3b\u8981\u6b65\u9aa4\u5982\u4e0b\uff1a \u5bf9\u4e8e\u6bcf\u4e2a\u9884\u6d4b\u6846\uff0c\u9996\u5148\u6839\u636e\u7c7b\u522b\u7f6e\u4fe1\u5ea6\u786e\u5b9a\u5176\u7c7b\u522b\uff08\u7f6e\u4fe1\u5ea6\u6700\u5927\u8005\uff09\u4e0e\u7f6e\u4fe1\u5ea6\u503c\uff0c\u5e76\u8fc7\u6ee4\u6389\u5c5e\u4e8e\u80cc\u666f\u7684\u9884\u6d4b\u6846\u3002 \u7136\u540e\u6839\u636e\u7f6e\u4fe1\u5ea6\u9608\u503c\uff08\u59820.5\uff09\u8fc7\u6ee4\u6389\u9608\u503c\u8f83\u4f4e\u7684\u9884\u6d4b\u6846\u3002 \u5bf9\u4e8e\u7559\u4e0b\u7684\u9884\u6d4b\u6846\u8fdb\u884c\u89e3\u7801\uff0c\u6839\u636e\u5148\u9a8c\u6846\u5f97\u5230\u5176\u771f\u5b9e\u7684\u4f4d\u7f6e\u53c2\u6570\uff08\u89e3\u7801\u540e\u4e00\u822c\u8fd8\u9700\u8981\u505aclip\uff0c\u9632\u6b62\u9884\u6d4b\u6846\u4f4d\u7f6e\u8d85\u51fa\u56fe\u7247\uff09\u3002 \u89e3\u7801\u4e4b\u540e\uff0c\u4e00\u822c\u9700\u8981\u6839\u636e\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u964d\u5e8f\u6392\u5217\uff0c\u7136\u540e\u4ec5\u4fdd\u7559top-k\uff08\u5982400\uff09\u4e2a\u9884\u6d4b\u6846\u3002 \u8fdb\u884cNMS\u7b97\u6cd5\uff0c\u8fc7\u6ee4\u6389\u90a3\u4e9b\u91cd\u53e0\u5ea6\u8f83\u5927\u7684\u9884\u6d4b\u6846\u3002 \u6700\u540e\u5269\u4f59\u7684\u9884\u6d4b\u6846\u5c31\u662f\u68c0\u6d4b\u7ed3\u679c\u4e86\u3002 \u603b\u7ed3 \u77e5\u9053SSD\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u7f51\u7edc SSD\u63d0\u53d6\u4e866\u4e2a\u4e0d\u540c\u7279\u5f81\u56fe\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b \u77e5\u9053SSD\u4e2d\u5148\u9a8c\u6846\u7684\u751f\u6210\u65b9\u5f0f SSD\u5728\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u7684\u5148\u9a8c\u6846\u7684\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4\u662f\u4e0d\u4e00\u6837\u7684 \u77e5\u9053SSD\u7684\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1 \u5206\u7c7b\u548c\u56de\u5f52\u635f\u5931\u51fd\u6570\u7684\u52a0\u6743\u548c","title":"3.\u6a21\u578b\u9884\u6d4b"},{"location":"tensorFlow/","text":"\u6df1\u5165\u6d45\u51faTensorFlow \u00b6 \u4e86\u89e3Tensorflow\u6846\u67b6\u7684\u7ec4\u6210\u3001\u63a5\u53e3 \u4e86\u89e3TensorFlow\u6846\u67b6\u7684\u5b89\u88c5 \u77e5\u9053tf.keras\u7684\u7279\u70b9\u548c\u4f7f\u7528 \u638c\u63e1TensorFlow\u57fa\u672c\u5f20\u91cf\u64cd\u4f5c \u638c\u63e1TensorFlow\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236 \u6a21\u578b\u7684\u6784\u5efa\uff1a `tf.keras.Model` \u548c `tf.keras.layers` \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a `tf.keras.losses` \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a `tf.keras.optimizer` \u6a21\u578b\u7684\u8bc4\u4f30\uff1a `tf.keras.metrics` \u638c\u63e1keras pipline\u7684\u4f7f\u7528 \u638c\u63e1keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528 \u638c\u63e1Checkpoint\u4f7f\u7528 \u638c\u63e1TensorBoard\u4f7f\u7528 \u638c\u63e1data\u6a21\u5757\u4f7f\u7528 \u638c\u63e1tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b \u638c\u63e1TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528 \u5e94\u7528Tensorflow\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u9884\u6d4b \u5e94\u7528\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u63a8\u7406","title":"\u6df1\u5165\u6d45\u51faTensorFlow"},{"location":"tensorFlow/#tensorflow","text":"\u4e86\u89e3Tensorflow\u6846\u67b6\u7684\u7ec4\u6210\u3001\u63a5\u53e3 \u4e86\u89e3TensorFlow\u6846\u67b6\u7684\u5b89\u88c5 \u77e5\u9053tf.keras\u7684\u7279\u70b9\u548c\u4f7f\u7528 \u638c\u63e1TensorFlow\u57fa\u672c\u5f20\u91cf\u64cd\u4f5c \u638c\u63e1TensorFlow\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236 \u6a21\u578b\u7684\u6784\u5efa\uff1a `tf.keras.Model` \u548c `tf.keras.layers` \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a `tf.keras.losses` \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a `tf.keras.optimizer` \u6a21\u578b\u7684\u8bc4\u4f30\uff1a `tf.keras.metrics` \u638c\u63e1keras pipline\u7684\u4f7f\u7528 \u638c\u63e1keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528 \u638c\u63e1Checkpoint\u4f7f\u7528 \u638c\u63e1TensorBoard\u4f7f\u7528 \u638c\u63e1data\u6a21\u5757\u4f7f\u7528 \u638c\u63e1tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b \u638c\u63e1TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528 \u5e94\u7528Tensorflow\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u9884\u6d4b \u5e94\u7528\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u548c\u63a8\u7406","title":"\u6df1\u5165\u6d45\u51faTensorFlow"},{"location":"tensorFlow/section1/","text":"\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-TensorFlow \u00b6 \u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5 1.1 TensorFlow\u4ecb\u7ecd \u00b6 \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u4e00\u7ecf\u53d1\u5e03\uff0c\u5c31\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8\uff0c\u5e76\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u97f3\u9891\u5904\u7406\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u573a\u666f\u4e0b\u90fd\u88ab\u5927\u9762\u79ef\u63a8\u5e7f\u4f7f\u7528\uff0c\u73b0\u5728\u5df2\u53d1\u5e032.3.0\u7248\u672c\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u6df1\u5165\u6d45\u51fa\u7684\u4ecb\u7ecdTensorflow\u7684\u76f8\u5173\u5e94\u7528\u3002 TensorFlow\u7684\u4f9d\u8d56\u89c6\u56fe\u5982\u4e0b\u6240\u793a\uff1a TF\u6258\u7ba1\u5728github\u5e73\u53f0\uff0c\u6709google groups\u548ccontributors\u5171\u540c\u7ef4\u62a4\u3002 TF\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684API\uff0c\u652f\u6301Python\u548cC/C++\u63a5\u53e3\u3002 TF\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177Tensorboard\uff0c\u65b9\u4fbf\u5206\u6790\u548c\u8c03\u6574\u6a21\u578b\u3002 TF\u652f\u6301Linux\u5e73\u53f0\uff0cWindows\u5e73\u53f0\uff0cMac\u5e73\u53f0\uff0c\u751a\u81f3\u624b\u673a\u79fb\u52a8\u8bbe\u5907\u7b49\u5404\u79cd\u5e73\u53f0\u3002 TensorFlow 2.0 \u5c06\u4e13\u6ce8\u4e8e\u7b80\u5355\u6027\u548c\u6613\u7528\u6027\uff0c\u5de5\u4f5c\u6d41\u7a0b\u5982\u4e0b\u6240\u793a\uff1a 1\u3001\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e\u3002 \u4f7f\u7528tf.data\u5b9e\u4f8b\u5316\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5\uff1a \u4f7f\u7528\u52a8\u6001\u56fe\u6a21\u5f0f Eager Execution \u548c\u8457\u540d\u7684\u795e\u7ecf\u7f51\u7edc\u9ad8\u5c42 API \u6846\u67b6 Keras\uff0c\u7ed3\u5408\u53ef\u89c6\u5316\u5de5\u5177 TensorBoard\uff0c\u7b80\u6613\u3001\u5feb\u901f\u5730\u5efa\u7acb\u548c\u8c03\u8bd5\u6a21\u578b\uff1b 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3\uff1a \u652f\u6301 CPU / \u5355 GPU / \u5355\u673a\u591a\u5361 GPU / \u591a\u673a\u96c6\u7fa4 / TPU \u8bad\u7ec3\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528\u6d77\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u9ad8\u6548\u8bad\u7ec3\uff1b 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528\uff1a \u901a\u8fc7 TensorFlow Hub\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u8c03\u7528\u9884\u8bad\u7ec3\u5b8c\u6bd5\u7684\u5df2\u6709\u6210\u719f\u6a21\u578b\u3002 5\u3001\u6a21\u578b\u7684\u90e8\u7f72\uff1a \u901a\u8fc7 TensorFlow Serving\u3001TensorFlow Lite\u3001TensorFlow.js \u7b49\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5c06TensorFlow \u6a21\u578b\u90e8\u7f72\u5230\u670d\u52a1\u5668\u3001\u79fb\u52a8\u7aef\u3001\u5d4c\u5165\u5f0f\u7aef\u7b49\u591a\u79cd\u4f7f\u7528\u573a\u666f\uff1b 1.2 TensorFlow\u7684\u5b89\u88c5 \u00b6 \u5b89\u88c5 TensorFlow\u572864 \u4f4d\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\u8fd9\u4e9b\u7cfb\u7edf\u652f\u6301 TensorFlow\uff1a Ubuntu 16.04 \u6216\u66f4\u9ad8\u7248\u672c Windows 7 \u6216\u66f4\u9ad8\u7248\u672c macOS 10.12.6 (Sierra) \u6216\u66f4\u9ad8\u7248\u672c\uff08\u4e0d\u652f\u6301 GPU\uff09 \u8fdb\u5165\u865a\u62df\u73af\u5883\u5f53\u4e2d\u518d\u5b89\u88c5\u3002\u63a8\u8350\u4f7f\u7528anoconda\u8fdb\u884c\u5b89\u88c5 1\u3001\u975eGPU\u7248\u672c\u5b89\u88c5 ubuntu\u5b89\u88c5 pip install tensorflow==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 2\u3001GPU\u7248\u672c\u5b89\u88c5 pip install tensorflow-gpu==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple \u6ce8\uff1a\u5982\u679c\u9700\u8981\u4e0b\u8f7dGPU\u7248\u672c\u7684\uff08TensorFlow\u53ea\u63d0\u4f9bwindows\u548clinux\u7248\u672c\u7684\uff0c\u6ca1\u6709Macos\u7248\u672c\u7684\uff09\u3002 1.3 \u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u00b6 1.3.1 \u5f20\u91cfTensor \u00b6 \u5f20\u91cf\u662f\u4e00\u4e2a\u591a\u7ef4\u6570\u7ec4\u3002 \u4e0eNumPy ndarray\u5bf9\u8c61\u7c7b\u4f3c\uff0ctf.Tensor\u5bf9\u8c61\u4e5f\u5177\u6709\u6570\u636e\u7c7b\u578b\u548c\u5f62\u72b6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b64\u5916\uff0ctf.Tensors\u53ef\u4ee5\u4fdd\u7559\u5728GPU\u4e2d\u3002 TensorFlow\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u64cd\u4f5c\u5e93\uff08tf.add\uff0ctf.matmul\uff0ctf.linalg.inv\u7b49\uff09\uff0c\u5b83\u4eec\u4f7f\u7528\u548c\u751f\u6210tf.Tensor\u3002\u5728\u8fdb\u884c\u5f20\u91cf\u64cd\u4f5c\u4e4b\u524d\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import numpy as np 1.\u57fa\u672c\u65b9\u6cd5 \u00b6 \u9996\u5148\u8ba9\u6211\u4eec\u521b\u5efa\u57fa\u7840\u7684\u5f20\u91cf\uff1a # \u521b\u5efaint32\u7c7b\u578b\u76840\u7ef4\u5f20\u91cf\uff0c\u5373\u6807\u91cf rank_0_tensor = tf . constant ( 4 ) print ( rank_0_tensor ) # \u521b\u5efafloat32\u7c7b\u578b\u76841\u7ef4\u5f20\u91cf rank_1_tensor = tf . constant ([ 2.0 , 3.0 , 4.0 ]) print ( rank_1_tensor ) # \u521b\u5efafloat16\u7c7b\u578b\u7684\u4e8c\u7ef4\u5f20\u91cf rank_2_tensor = tf . constant ([[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ]], dtype = tf . float16 ) print ( rank_2_tensor ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( 4 , shape = (), dtype = int32 ) tf . Tensor ([ 2. 3. 4. ], shape = ( 3 ,), dtype = float32 ) tf . Tensor ( [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ]], shape = ( 3 , 2 ), dtype = float16 ) \u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u66f4\u9ad8\u7ef4\u7684\u5f20\u91cf\uff1a # \u521b\u5efafloat32\u7c7b\u578b\u7684\u5f20\u91cf rank_3_tensor = tf . constant ([ [[ 0 , 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 , 9 ]], [[ 10 , 11 , 12 , 13 , 14 ], [ 15 , 16 , 17 , 18 , 19 ]], [[ 20 , 21 , 22 , 23 , 24 ], [ 25 , 26 , 27 , 28 , 29 ]],]) print ( rank_3_tensor ) \u8be5\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u6709\u66f4\u591a\u7684\u65b9\u5f0f\u5c06\u5176\u5c55\u793a\u51fa\u6765\uff1a 2.\u8f6c\u6362\u6210numpy \u00b6 \u6211\u4eec\u53ef\u5c06\u5f20\u91cf\u8f6c\u6362\u4e3anumpy\u4e2d\u7684ndarray\u7684\u5f62\u5f0f\uff0c\u8f6c\u6362\u65b9\u6cd5\u6709\u4e24\u79cd\uff0c\u4ee5\u5f20\u91cfrank_2_tensor\u4e3a\u4f8b\uff1a np.array np . array ( rank_2_tensor ) Tensor.numpy() rank_2_tensor . numpy () 3.\u5e38\u7528\u51fd\u6570 \u00b6 \u6211\u4eec\u53ef\u4ee5\u5bf9\u5f20\u91cf\u505a\u4e00\u4e9b\u57fa\u672c\u7684\u6570\u5b66\u8fd0\u7b97\uff0c\u5305\u62ec\u52a0\u6cd5\u3001\u5143\u7d20\u4e58\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\u7b49\uff1a # \u5b9a\u4e49\u5f20\u91cfa\u548cb a = tf . constant ([[ 1 , 2 ], [ 3 , 4 ]]) b = tf . constant ([[ 1 , 1 ], [ 1 , 1 ]]) print ( tf . add ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u548c print ( tf . multiply ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u5143\u7d20\u4e58\u6cd5 print ( tf . matmul ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u4e58\u6cd5 \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 2 3 ] [ 4 5 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 1 2 ] [ 3 4 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 3 3 ] [ 7 7 ]], shape = ( 2 , 2 ), dtype = int32 ) \u53e6\u5916\u5f20\u91cf\u4e5f\u53ef\u7528\u4e8e\u5404\u79cd\u805a\u5408\u8fd0\u7b97\uff1a tf . reduce_sum () # \u6c42\u548c tf . reduce_mean () # \u5e73\u5747\u503c tf . reduce_max () # \u6700\u5927\u503c tf . reduce_min () # \u6700\u5c0f\u503c tf . argmax () # \u6700\u5927\u503c\u7684\u7d22\u5f15 tf . argmin () # \u6700\u5c0f\u503c\u7684\u7d22\u5f15 \u4f8b\u5982\uff1a c = tf . constant ([[ 4.0 , 5.0 ], [ 10.0 , 1.0 ]]) # \u6700\u5927\u503c print ( tf . reduce_max ( c )) # \u6700\u5927\u503c\u7d22\u5f15 print ( tf . argmax ( c )) # \u8ba1\u7b97\u5747\u503c print ( tf . reduce_mean ( c )) \u8f93\u51fa\u4e3a\uff1a tf . Tensor ( 10.0 , shape = (), dtype = float32 ) tf . Tensor ([ 1 0 ], shape = ( 2 ,), dtype = int64 ) tf . Tensor ( 5.0 , shape = (), dtype = float32 ) 4.\u53d8\u91cf \u00b6 \u53d8\u91cf\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5f20\u91cf\uff0c\u5f62\u72b6\u662f\u4e0d\u53ef\u53d8\uff0c\u4f46\u53ef\u4ee5\u66f4\u6539\u5176\u4e2d\u7684\u53c2\u6570\u3002\u5b9a\u4e49\u65f6\u7684\u65b9\u6cd5\u662f\uff1a my_variable = tf . Variable ([[ 1.0 , 2.0 ], [ 3.0 , 4.0 ]]) \u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u53d6\u5b83\u7684\u5f62\u72b6\uff0c\u7c7b\u578b\u53ca\u8f6c\u6362\u4e3andarray: print ( \"Shape: \" , my_variable . shape ) print ( \"DType: \" , my_variable . dtype ) print ( \"As NumPy: \" , my_variable . numpy ) \u8f93\u51fa\u4e3a\uff1a Shape: (2, 2) DType: <dtype: 'float32'> As NumPy: <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>> 1.4 tf.keras\u4ecb\u7ecd \u00b6 tf.keras\u662fTensorFlow 2.0\u7684\u9ad8\u9636API\u63a5\u53e3\uff0c\u4e3aTensorFlow\u7684\u4ee3\u7801\u63d0\u4f9b\u4e86\u65b0\u7684\u98ce\u683c\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5927\u5927\u63d0\u5347\u4e86TF\u4ee3\u7801\u7684\u7b80\u6d01\u6027\u548c\u590d\u7528\u6027\uff0c\u5b98\u65b9\u4e5f\u63a8\u8350\u4f7f\u7528tf.keras\u6765\u8fdb\u884c\u6a21\u578b\u8bbe\u8ba1\u548c\u5f00\u53d1\u3002 1.4.1 \u5e38\u7528\u6a21\u5757 \u00b6 tf.keras\u4e2d\u5e38\u7528\u6a21\u5757\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6a21\u5757 \u6982\u8ff0 activations \u6fc0\u6d3b\u51fd\u6570 applications \u9884\u8bad\u7ec3\u7f51\u7edc\u6a21\u5757 Callbacks \u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u88ab\u8c03\u7528 datasets tf.keras\u6570\u636e\u96c6\u6a21\u5757\uff0c\u5305\u62ecboston_housing\uff0ccifar10\uff0cfashion_mnist\uff0cimdb \uff0cmnist layers Keras\u5c42API losses \u5404\u79cd\u635f\u5931\u51fd\u6570 metircs \u5404\u79cd\u8bc4\u4ef7\u6307\u6807 models \u6a21\u578b\u521b\u5efa\u6a21\u5757\uff0c\u4ee5\u53ca\u4e0e\u6a21\u578b\u76f8\u5173\u7684API optimizers \u4f18\u5316\u65b9\u6cd5 preprocessing Keras\u6570\u636e\u7684\u9884\u5904\u7406\u6a21\u5757 regularizers \u6b63\u5219\u5316\uff0cL1,L2\u7b49 utils \u8f85\u52a9\u529f\u80fd\u5b9e\u73b0 1.4.2 \u5e38\u7528\u65b9\u6cd5 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a1.\u6570\u636e\u83b7\u53d6\uff0c2\uff0c\u6570\u636e\u5904\u7406\uff0c3.\u6a21\u578b\u521b\u5efa\u4e0e\u8bad\u7ec3\uff0c4 \u6a21\u578b\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\uff0c5.\u6a21\u578b\u9884\u6d4b 1.\u5bfc\u5165tf.keras \u00b6 \u4f7f\u7528 tf.keras \uff0c\u9996\u5148\u9700\u8981\u5728\u4ee3\u7801\u5f00\u59cb\u65f6\u5bfc\u5165 tf.keras import tensorflow as tf from tensorflow import keras 2.\u6570\u636e\u8f93\u5165 \u00b6 \u5bf9\u4e8e\u5c0f\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528numpy\u683c\u5f0f\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3001\u8bc4\u4f30\u6a21\u578b\uff0c\u5bf9\u4e8e\u5927\u578b\u6570\u636e\u96c6\u6216\u8005\u8981\u8fdb\u884c\u8de8\u8bbe\u5907\u8bad\u7ec3\u65f6\u4f7f\u7528tf.data.datasets\u6765\u8fdb\u884c\u6570\u636e\u8f93\u5165\u3002 3.\u6a21\u578b\u6784\u5efa \u00b6 \u7b80\u5355\u6a21\u578b\u4f7f\u7528Sequential\u8fdb\u884c\u6784\u5efa \u590d\u6742\u6a21\u578b\u4f7f\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u6765\u6784\u5efa \u81ea\u5b9a\u4e49layers 4.\u8bad\u7ec3\u4e0e\u8bc4\u4f30 \u00b6 \u914d\u7f6e\u8bad\u7ec3\u8fc7\u7a0b\uff1a # \u914d\u7f6e\u4f18\u5316\u65b9\u6cd5\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = tf . train . AdamOptimizer ( 0.001 ), loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) \u6a21\u578b\u8bad\u7ec3 # \u6307\u660e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8bad\u7ec3epoch,\u6279\u6b21\u5927\u5c0f\u548c\u9a8c\u8bc1\u96c6\u6570\u636e model . fit / fit_generator ( dataset , epochs = 10 , batch_size = 3 , validation_data = val_dataset , ) \u6a21\u578b\u8bc4\u4f30 # \u6307\u660e\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u6279\u6b21\u5927\u5c0f model . evaluate ( x , y , batch_size = 32 ) \u6a21\u578b\u9884\u6d4b # \u5bf9\u65b0\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b model . predict ( x , batch_size = 32 ) 5.\u56de\u8c03\u51fd\u6570\uff08callbacks\uff09 \u00b6 \u56de\u8c03\u51fd\u6570\u7528\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6765\u63a7\u5236\u6a21\u578b\u8bad\u7ec3\u884c\u4e3a\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff0c\u4e5f\u53ef\u4f7f\u7528tf.keras.callbacks \u5185\u7f6e\u7684 callback \uff1a ModelCheckpoint\uff1a\u5b9a\u671f\u4fdd\u5b58 checkpoints\u3002 LearningRateScheduler\uff1a\u52a8\u6001\u6539\u53d8\u5b66\u4e60\u901f\u7387\u3002 EarlyStopping\uff1a\u5f53\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u4e0d\u518d\u63d0\u9ad8\u65f6\uff0c\u7ec8\u6b62\u8bad\u7ec3\u3002 TensorBoard\uff1a\u4f7f\u7528 TensorBoard \u76d1\u6d4b\u6a21\u578b\u7684\u72b6\u6001\u3002 6.\u6a21\u578b\u7684\u4fdd\u5b58\u548c\u6062\u590d \u00b6 \u53ea\u4fdd\u5b58\u53c2\u6570 # \u53ea\u4fdd\u5b58\u6a21\u578b\u7684\u6743\u91cd model . save_weights ( './my_model' ) # \u52a0\u8f7d\u6a21\u578b\u7684\u6743\u91cd model . load_weights ( 'my_model' ) \u4fdd\u5b58\u6574\u4e2a\u6a21\u578b # \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b 1.\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528 5\u3001\u6a21\u578b\u7684\u90e8\u7f72 \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u5f20\u91cf\u662f\u591a\u7ef4\u6570\u7ec4\u3002 1\u3001\u521b\u5efa\u65b9\u6cd5\uff1atf.constant() 2\u3001\u8f6c\u6362\u4e3anumpy: np.array()\u6216tensor.asnumpy() 3\u3001\u5e38\u7528\u51fd\u6570\uff1a\u52a0\u6cd5\uff0c\u4e58\u6cd5\uff0c\u53ca\u5404\u79cd\u805a\u5408\u8fd0\u7b97 4\u3001\u53d8\u91cf\uff1atf.Variable() \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5 \u5e38\u7528\u6a21\u5757\uff1amodels,losses,application\u7b49 \u5e38\u7528\u65b9\u6cd5\uff1a 1\u3001\u5bfc\u5165tf.keras 2\u3001\u6570\u636e\u8f93\u5165 3\u3001\u6a21\u578b\u6784\u5efa 4\u3001\u8bad\u7ec3\u4e0e\u8bc4\u4f30 5\u3001\u56de\u8c03\u51fd\u6570 6\u3001\u6a21\u578b\u7684\u4fdd\u5b58\u4e0e\u6062\u590d","title":"tensorflow\u548ckeras\u7b80\u4ecb"},{"location":"tensorFlow/section1/#-tensorflow","text":"\u5b66\u4e60\u76ee\u6807 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5","title":"\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-TensorFlow"},{"location":"tensorFlow/section1/#11-tensorflow","text":"\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6TensorFlow\u4e00\u7ecf\u53d1\u5e03\uff0c\u5c31\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8\uff0c\u5e76\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u97f3\u9891\u5904\u7406\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u573a\u666f\u4e0b\u90fd\u88ab\u5927\u9762\u79ef\u63a8\u5e7f\u4f7f\u7528\uff0c\u73b0\u5728\u5df2\u53d1\u5e032.3.0\u7248\u672c\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u6df1\u5165\u6d45\u51fa\u7684\u4ecb\u7ecdTensorflow\u7684\u76f8\u5173\u5e94\u7528\u3002 TensorFlow\u7684\u4f9d\u8d56\u89c6\u56fe\u5982\u4e0b\u6240\u793a\uff1a TF\u6258\u7ba1\u5728github\u5e73\u53f0\uff0c\u6709google groups\u548ccontributors\u5171\u540c\u7ef4\u62a4\u3002 TF\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684API\uff0c\u652f\u6301Python\u548cC/C++\u63a5\u53e3\u3002 TF\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177Tensorboard\uff0c\u65b9\u4fbf\u5206\u6790\u548c\u8c03\u6574\u6a21\u578b\u3002 TF\u652f\u6301Linux\u5e73\u53f0\uff0cWindows\u5e73\u53f0\uff0cMac\u5e73\u53f0\uff0c\u751a\u81f3\u624b\u673a\u79fb\u52a8\u8bbe\u5907\u7b49\u5404\u79cd\u5e73\u53f0\u3002 TensorFlow 2.0 \u5c06\u4e13\u6ce8\u4e8e\u7b80\u5355\u6027\u548c\u6613\u7528\u6027\uff0c\u5de5\u4f5c\u6d41\u7a0b\u5982\u4e0b\u6240\u793a\uff1a 1\u3001\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e\u3002 \u4f7f\u7528tf.data\u5b9e\u4f8b\u5316\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5\uff1a \u4f7f\u7528\u52a8\u6001\u56fe\u6a21\u5f0f Eager Execution \u548c\u8457\u540d\u7684\u795e\u7ecf\u7f51\u7edc\u9ad8\u5c42 API \u6846\u67b6 Keras\uff0c\u7ed3\u5408\u53ef\u89c6\u5316\u5de5\u5177 TensorBoard\uff0c\u7b80\u6613\u3001\u5feb\u901f\u5730\u5efa\u7acb\u548c\u8c03\u8bd5\u6a21\u578b\uff1b 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3\uff1a \u652f\u6301 CPU / \u5355 GPU / \u5355\u673a\u591a\u5361 GPU / \u591a\u673a\u96c6\u7fa4 / TPU \u8bad\u7ec3\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528\u6d77\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u9ad8\u6548\u8bad\u7ec3\uff1b 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528\uff1a \u901a\u8fc7 TensorFlow Hub\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u8c03\u7528\u9884\u8bad\u7ec3\u5b8c\u6bd5\u7684\u5df2\u6709\u6210\u719f\u6a21\u578b\u3002 5\u3001\u6a21\u578b\u7684\u90e8\u7f72\uff1a \u901a\u8fc7 TensorFlow Serving\u3001TensorFlow Lite\u3001TensorFlow.js \u7b49\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5c06TensorFlow \u6a21\u578b\u90e8\u7f72\u5230\u670d\u52a1\u5668\u3001\u79fb\u52a8\u7aef\u3001\u5d4c\u5165\u5f0f\u7aef\u7b49\u591a\u79cd\u4f7f\u7528\u573a\u666f\uff1b","title":"1.1 TensorFlow\u4ecb\u7ecd"},{"location":"tensorFlow/section1/#12-tensorflow","text":"\u5b89\u88c5 TensorFlow\u572864 \u4f4d\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\u8fd9\u4e9b\u7cfb\u7edf\u652f\u6301 TensorFlow\uff1a Ubuntu 16.04 \u6216\u66f4\u9ad8\u7248\u672c Windows 7 \u6216\u66f4\u9ad8\u7248\u672c macOS 10.12.6 (Sierra) \u6216\u66f4\u9ad8\u7248\u672c\uff08\u4e0d\u652f\u6301 GPU\uff09 \u8fdb\u5165\u865a\u62df\u73af\u5883\u5f53\u4e2d\u518d\u5b89\u88c5\u3002\u63a8\u8350\u4f7f\u7528anoconda\u8fdb\u884c\u5b89\u88c5 1\u3001\u975eGPU\u7248\u672c\u5b89\u88c5 ubuntu\u5b89\u88c5 pip install tensorflow==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 2\u3001GPU\u7248\u672c\u5b89\u88c5 pip install tensorflow-gpu==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple \u6ce8\uff1a\u5982\u679c\u9700\u8981\u4e0b\u8f7dGPU\u7248\u672c\u7684\uff08TensorFlow\u53ea\u63d0\u4f9bwindows\u548clinux\u7248\u672c\u7684\uff0c\u6ca1\u6709Macos\u7248\u672c\u7684\uff09\u3002","title":"1.2 TensorFlow\u7684\u5b89\u88c5"},{"location":"tensorFlow/section1/#13","text":"","title":"1.3 \u5f20\u91cf\u53ca\u5176\u64cd\u4f5c"},{"location":"tensorFlow/section1/#131-tensor","text":"\u5f20\u91cf\u662f\u4e00\u4e2a\u591a\u7ef4\u6570\u7ec4\u3002 \u4e0eNumPy ndarray\u5bf9\u8c61\u7c7b\u4f3c\uff0ctf.Tensor\u5bf9\u8c61\u4e5f\u5177\u6709\u6570\u636e\u7c7b\u578b\u548c\u5f62\u72b6\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u6b64\u5916\uff0ctf.Tensors\u53ef\u4ee5\u4fdd\u7559\u5728GPU\u4e2d\u3002 TensorFlow\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u64cd\u4f5c\u5e93\uff08tf.add\uff0ctf.matmul\uff0ctf.linalg.inv\u7b49\uff09\uff0c\u5b83\u4eec\u4f7f\u7528\u548c\u751f\u6210tf.Tensor\u3002\u5728\u8fdb\u884c\u5f20\u91cf\u64cd\u4f5c\u4e4b\u524d\u5148\u5bfc\u5165\u76f8\u5e94\u7684\u5de5\u5177\u5305\uff1a import tensorflow as tf import numpy as np","title":"1.3.1 \u5f20\u91cfTensor"},{"location":"tensorFlow/section1/#1","text":"\u9996\u5148\u8ba9\u6211\u4eec\u521b\u5efa\u57fa\u7840\u7684\u5f20\u91cf\uff1a # \u521b\u5efaint32\u7c7b\u578b\u76840\u7ef4\u5f20\u91cf\uff0c\u5373\u6807\u91cf rank_0_tensor = tf . constant ( 4 ) print ( rank_0_tensor ) # \u521b\u5efafloat32\u7c7b\u578b\u76841\u7ef4\u5f20\u91cf rank_1_tensor = tf . constant ([ 2.0 , 3.0 , 4.0 ]) print ( rank_1_tensor ) # \u521b\u5efafloat16\u7c7b\u578b\u7684\u4e8c\u7ef4\u5f20\u91cf rank_2_tensor = tf . constant ([[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ]], dtype = tf . float16 ) print ( rank_2_tensor ) \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( 4 , shape = (), dtype = int32 ) tf . Tensor ([ 2. 3. 4. ], shape = ( 3 ,), dtype = float32 ) tf . Tensor ( [[ 1. 2. ] [ 3. 4. ] [ 5. 6. ]], shape = ( 3 , 2 ), dtype = float16 ) \u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u66f4\u9ad8\u7ef4\u7684\u5f20\u91cf\uff1a # \u521b\u5efafloat32\u7c7b\u578b\u7684\u5f20\u91cf rank_3_tensor = tf . constant ([ [[ 0 , 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 , 9 ]], [[ 10 , 11 , 12 , 13 , 14 ], [ 15 , 16 , 17 , 18 , 19 ]], [[ 20 , 21 , 22 , 23 , 24 ], [ 25 , 26 , 27 , 28 , 29 ]],]) print ( rank_3_tensor ) \u8be5\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u6709\u66f4\u591a\u7684\u65b9\u5f0f\u5c06\u5176\u5c55\u793a\u51fa\u6765\uff1a","title":"1.\u57fa\u672c\u65b9\u6cd5"},{"location":"tensorFlow/section1/#2numpy","text":"\u6211\u4eec\u53ef\u5c06\u5f20\u91cf\u8f6c\u6362\u4e3anumpy\u4e2d\u7684ndarray\u7684\u5f62\u5f0f\uff0c\u8f6c\u6362\u65b9\u6cd5\u6709\u4e24\u79cd\uff0c\u4ee5\u5f20\u91cfrank_2_tensor\u4e3a\u4f8b\uff1a np.array np . array ( rank_2_tensor ) Tensor.numpy() rank_2_tensor . numpy ()","title":"2.\u8f6c\u6362\u6210numpy"},{"location":"tensorFlow/section1/#3","text":"\u6211\u4eec\u53ef\u4ee5\u5bf9\u5f20\u91cf\u505a\u4e00\u4e9b\u57fa\u672c\u7684\u6570\u5b66\u8fd0\u7b97\uff0c\u5305\u62ec\u52a0\u6cd5\u3001\u5143\u7d20\u4e58\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\u7b49\uff1a # \u5b9a\u4e49\u5f20\u91cfa\u548cb a = tf . constant ([[ 1 , 2 ], [ 3 , 4 ]]) b = tf . constant ([[ 1 , 1 ], [ 1 , 1 ]]) print ( tf . add ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u548c print ( tf . multiply ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u5f20\u91cf\u7684\u5143\u7d20\u4e58\u6cd5 print ( tf . matmul ( a , b ), \" \\n \" ) # \u8ba1\u7b97\u4e58\u6cd5 \u8f93\u51fa\u7ed3\u679c\u4e3a\uff1a tf . Tensor ( [[ 2 3 ] [ 4 5 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 1 2 ] [ 3 4 ]], shape = ( 2 , 2 ), dtype = int32 ) tf . Tensor ( [[ 3 3 ] [ 7 7 ]], shape = ( 2 , 2 ), dtype = int32 ) \u53e6\u5916\u5f20\u91cf\u4e5f\u53ef\u7528\u4e8e\u5404\u79cd\u805a\u5408\u8fd0\u7b97\uff1a tf . reduce_sum () # \u6c42\u548c tf . reduce_mean () # \u5e73\u5747\u503c tf . reduce_max () # \u6700\u5927\u503c tf . reduce_min () # \u6700\u5c0f\u503c tf . argmax () # \u6700\u5927\u503c\u7684\u7d22\u5f15 tf . argmin () # \u6700\u5c0f\u503c\u7684\u7d22\u5f15 \u4f8b\u5982\uff1a c = tf . constant ([[ 4.0 , 5.0 ], [ 10.0 , 1.0 ]]) # \u6700\u5927\u503c print ( tf . reduce_max ( c )) # \u6700\u5927\u503c\u7d22\u5f15 print ( tf . argmax ( c )) # \u8ba1\u7b97\u5747\u503c print ( tf . reduce_mean ( c )) \u8f93\u51fa\u4e3a\uff1a tf . Tensor ( 10.0 , shape = (), dtype = float32 ) tf . Tensor ([ 1 0 ], shape = ( 2 ,), dtype = int64 ) tf . Tensor ( 5.0 , shape = (), dtype = float32 )","title":"3.\u5e38\u7528\u51fd\u6570"},{"location":"tensorFlow/section1/#4","text":"\u53d8\u91cf\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5f20\u91cf\uff0c\u5f62\u72b6\u662f\u4e0d\u53ef\u53d8\uff0c\u4f46\u53ef\u4ee5\u66f4\u6539\u5176\u4e2d\u7684\u53c2\u6570\u3002\u5b9a\u4e49\u65f6\u7684\u65b9\u6cd5\u662f\uff1a my_variable = tf . Variable ([[ 1.0 , 2.0 ], [ 3.0 , 4.0 ]]) \u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u53d6\u5b83\u7684\u5f62\u72b6\uff0c\u7c7b\u578b\u53ca\u8f6c\u6362\u4e3andarray: print ( \"Shape: \" , my_variable . shape ) print ( \"DType: \" , my_variable . dtype ) print ( \"As NumPy: \" , my_variable . numpy ) \u8f93\u51fa\u4e3a\uff1a Shape: (2, 2) DType: <dtype: 'float32'> As NumPy: <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy= array([[1., 2.], [3., 4.]], dtype=float32)>>","title":"4.\u53d8\u91cf"},{"location":"tensorFlow/section1/#14-tfkeras","text":"tf.keras\u662fTensorFlow 2.0\u7684\u9ad8\u9636API\u63a5\u53e3\uff0c\u4e3aTensorFlow\u7684\u4ee3\u7801\u63d0\u4f9b\u4e86\u65b0\u7684\u98ce\u683c\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5927\u5927\u63d0\u5347\u4e86TF\u4ee3\u7801\u7684\u7b80\u6d01\u6027\u548c\u590d\u7528\u6027\uff0c\u5b98\u65b9\u4e5f\u63a8\u8350\u4f7f\u7528tf.keras\u6765\u8fdb\u884c\u6a21\u578b\u8bbe\u8ba1\u548c\u5f00\u53d1\u3002","title":"1.4 tf.keras\u4ecb\u7ecd"},{"location":"tensorFlow/section1/#141","text":"tf.keras\u4e2d\u5e38\u7528\u6a21\u5757\u5982\u4e0b\u8868\u6240\u793a\uff1a \u6a21\u5757 \u6982\u8ff0 activations \u6fc0\u6d3b\u51fd\u6570 applications \u9884\u8bad\u7ec3\u7f51\u7edc\u6a21\u5757 Callbacks \u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u88ab\u8c03\u7528 datasets tf.keras\u6570\u636e\u96c6\u6a21\u5757\uff0c\u5305\u62ecboston_housing\uff0ccifar10\uff0cfashion_mnist\uff0cimdb \uff0cmnist layers Keras\u5c42API losses \u5404\u79cd\u635f\u5931\u51fd\u6570 metircs \u5404\u79cd\u8bc4\u4ef7\u6307\u6807 models \u6a21\u578b\u521b\u5efa\u6a21\u5757\uff0c\u4ee5\u53ca\u4e0e\u6a21\u578b\u76f8\u5173\u7684API optimizers \u4f18\u5316\u65b9\u6cd5 preprocessing Keras\u6570\u636e\u7684\u9884\u5904\u7406\u6a21\u5757 regularizers \u6b63\u5219\u5316\uff0cL1,L2\u7b49 utils \u8f85\u52a9\u529f\u80fd\u5b9e\u73b0","title":"1.4.1 \u5e38\u7528\u6a21\u5757"},{"location":"tensorFlow/section1/#142","text":"\u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a1.\u6570\u636e\u83b7\u53d6\uff0c2\uff0c\u6570\u636e\u5904\u7406\uff0c3.\u6a21\u578b\u521b\u5efa\u4e0e\u8bad\u7ec3\uff0c4 \u6a21\u578b\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\uff0c5.\u6a21\u578b\u9884\u6d4b","title":"1.4.2 \u5e38\u7528\u65b9\u6cd5"},{"location":"tensorFlow/section1/#1tfkeras","text":"\u4f7f\u7528 tf.keras \uff0c\u9996\u5148\u9700\u8981\u5728\u4ee3\u7801\u5f00\u59cb\u65f6\u5bfc\u5165 tf.keras import tensorflow as tf from tensorflow import keras","title":"1.\u5bfc\u5165tf.keras"},{"location":"tensorFlow/section1/#2","text":"\u5bf9\u4e8e\u5c0f\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528numpy\u683c\u5f0f\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3001\u8bc4\u4f30\u6a21\u578b\uff0c\u5bf9\u4e8e\u5927\u578b\u6570\u636e\u96c6\u6216\u8005\u8981\u8fdb\u884c\u8de8\u8bbe\u5907\u8bad\u7ec3\u65f6\u4f7f\u7528tf.data.datasets\u6765\u8fdb\u884c\u6570\u636e\u8f93\u5165\u3002","title":"2.\u6570\u636e\u8f93\u5165"},{"location":"tensorFlow/section1/#3_1","text":"\u7b80\u5355\u6a21\u578b\u4f7f\u7528Sequential\u8fdb\u884c\u6784\u5efa \u590d\u6742\u6a21\u578b\u4f7f\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u6765\u6784\u5efa \u81ea\u5b9a\u4e49layers","title":"3.\u6a21\u578b\u6784\u5efa"},{"location":"tensorFlow/section1/#4_1","text":"\u914d\u7f6e\u8bad\u7ec3\u8fc7\u7a0b\uff1a # \u914d\u7f6e\u4f18\u5316\u65b9\u6cd5\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = tf . train . AdamOptimizer ( 0.001 ), loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) \u6a21\u578b\u8bad\u7ec3 # \u6307\u660e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8bad\u7ec3epoch,\u6279\u6b21\u5927\u5c0f\u548c\u9a8c\u8bc1\u96c6\u6570\u636e model . fit / fit_generator ( dataset , epochs = 10 , batch_size = 3 , validation_data = val_dataset , ) \u6a21\u578b\u8bc4\u4f30 # \u6307\u660e\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u6279\u6b21\u5927\u5c0f model . evaluate ( x , y , batch_size = 32 ) \u6a21\u578b\u9884\u6d4b # \u5bf9\u65b0\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b model . predict ( x , batch_size = 32 )","title":"4.\u8bad\u7ec3\u4e0e\u8bc4\u4f30"},{"location":"tensorFlow/section1/#5callbacks","text":"\u56de\u8c03\u51fd\u6570\u7528\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6765\u63a7\u5236\u6a21\u578b\u8bad\u7ec3\u884c\u4e3a\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\uff0c\u4e5f\u53ef\u4f7f\u7528tf.keras.callbacks \u5185\u7f6e\u7684 callback \uff1a ModelCheckpoint\uff1a\u5b9a\u671f\u4fdd\u5b58 checkpoints\u3002 LearningRateScheduler\uff1a\u52a8\u6001\u6539\u53d8\u5b66\u4e60\u901f\u7387\u3002 EarlyStopping\uff1a\u5f53\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u4e0d\u518d\u63d0\u9ad8\u65f6\uff0c\u7ec8\u6b62\u8bad\u7ec3\u3002 TensorBoard\uff1a\u4f7f\u7528 TensorBoard \u76d1\u6d4b\u6a21\u578b\u7684\u72b6\u6001\u3002","title":"5.\u56de\u8c03\u51fd\u6570\uff08callbacks\uff09"},{"location":"tensorFlow/section1/#6","text":"\u53ea\u4fdd\u5b58\u53c2\u6570 # \u53ea\u4fdd\u5b58\u6a21\u578b\u7684\u6743\u91cd model . save_weights ( './my_model' ) # \u52a0\u8f7d\u6a21\u578b\u7684\u6743\u91cd model . load_weights ( 'my_model' ) \u4fdd\u5b58\u6574\u4e2a\u6a21\u578b # \u4fdd\u5b58\u6a21\u578b\u67b6\u6784\u4e0e\u6743\u91cd\u5728h5\u6587\u4ef6\u4e2d model . save ( 'my_model.h5' ) # \u52a0\u8f7d\u6a21\u578b\uff1a\u5305\u62ec\u67b6\u6784\u548c\u5bf9\u5e94\u7684\u6743\u91cd model = keras . models . load_model ( 'my_model.h5' ) \u603b\u7ed3 \u4e86\u89e3Tensorflow2.0\u6846\u67b6\u7684\u7528\u9014\u53ca\u6d41\u7a0b 1.\u4f7f\u7528tf.data\u52a0\u8f7d\u6570\u636e 2\u3001\u6a21\u578b\u7684\u5efa\u7acb\u4e0e\u8c03\u8bd5 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3 4\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u8c03\u7528 5\u3001\u6a21\u578b\u7684\u90e8\u7f72 \u77e5\u9053tf2.0\u7684\u5f20\u91cf\u53ca\u5176\u64cd\u4f5c \u5f20\u91cf\u662f\u591a\u7ef4\u6570\u7ec4\u3002 1\u3001\u521b\u5efa\u65b9\u6cd5\uff1atf.constant() 2\u3001\u8f6c\u6362\u4e3anumpy: np.array()\u6216tensor.asnumpy() 3\u3001\u5e38\u7528\u51fd\u6570\uff1a\u52a0\u6cd5\uff0c\u4e58\u6cd5\uff0c\u53ca\u5404\u79cd\u805a\u5408\u8fd0\u7b97 4\u3001\u53d8\u91cf\uff1atf.Variable() \u77e5\u9053tf.keras\u4e2d\u7684\u76f8\u5173\u6a21\u5757\u53ca\u5e38\u7528\u65b9\u6cd5 \u5e38\u7528\u6a21\u5757\uff1amodels,losses,application\u7b49 \u5e38\u7528\u65b9\u6cd5\uff1a 1\u3001\u5bfc\u5165tf.keras 2\u3001\u6570\u636e\u8f93\u5165 3\u3001\u6a21\u578b\u6784\u5efa 4\u3001\u8bad\u7ec3\u4e0e\u8bc4\u4f30 5\u3001\u56de\u8c03\u51fd\u6570 6\u3001\u6a21\u578b\u7684\u4fdd\u5b58\u4e0e\u6062\u590d","title":"6.\u6a21\u578b\u7684\u4fdd\u5b58\u548c\u6062\u590d"},{"location":"tensorFlow/section10/","text":"4.10 \u7efc\u5408\u6848\u4f8b\uff1a\u5783\u573e\u5206\u7c7b\u4e4b\u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1EfficientNet\u6a21\u578b\u539f\u7406 \u638c\u63e1warmup\u4ee5\u53ca\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u539f\u7406 \u5e94\u7528 \u5e94\u7528\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u8fc7\u7a0b \u5e94\u7528\u5b8c\u6210\u4f59\u5f26\u9000\u706b\u4e0ewarmup\u7684\u5b9e\u73b0 4.10.1 EfficientNet\u6a21\u578b\u4ecb\u7ecd \u00b6 \u5148\u518d\u6765\u770b\u4e00\u904defficientnet\u7684\u53d6\u5f97\u7684\u6210\u7ee9 \u53ef\u4ee5\u770b\u51fa EfficientNet \u7cfb\u5217\u5b8c\u80dc\u4e86\u5176\u4ed6\u6240\u6709\u7684\u5377\u79ef\u7f51\u7edc\u3002\u5176\u4e2dEfficientNet-B7\u5b9e\u73b0\u4e86ImageNet\u7684state-of-the-art\u7387\uff0c\u8fbe\u5230\u4e86 84.4%\u3002\u4f46\u662f\u5b83\u7684\u53c2\u6570\u91cf\u76f8\u6bd4 GPipe \u51cf\u5c11\u4e86 8.4 \u500d\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u8fbe\u5230\u4e86 GPipe \u7684 6.1 \u500d\u3002\u66f4\u52a0\u7ec6\u8282\u7684\u6570\u636e\u53ef\u4ee5\u53c2\u8003\u540e\u9762\u7684\u5b9e\u9a8c\u90e8\u5206\u3002 \u8bba\u6587\u5730\u5740\uff1a https://arxiv.org/pdf/1905.11946.pdf 4.10.1.1 \u6458\u8981 \u00b6 \u4f5c\u8005\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u6a21\u578b\u7f29\u653e\u5e76\u4e14\u4ed4\u7ec6\u9a8c\u8bc1\u4e86**\u7f51\u7edc\u6df1\u5ea6\u3001\u5bbd\u5ea6\u548c\u5206\u8fa8\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u53ef\u4ee5\u5bfc\u81f4\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0**\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f29\u653e\u65b9\u6cd5\u2014\u2014\u4f7f\u7528\u4e00\u4e2a\u7b80\u5355\u9ad8\u6548\u7684\u590d\u5408\u7cfb\u6570\u6765\u5b8c\u6210\u5bf9\u6df1\u5ea6/\u5bbd\u5ea6/\u5206\u8fa8\u7387\u6240\u6709\u7ef4\u5ea6\u7684\u7edf\u4e00\u7f29\u653e\u3002\u5728MobileNets\u548cResNet\u4e0a\u5c55\u793a\u4e86\u8fd9\u79cd\u7f29\u653e\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u6211\u4eec\u4f7f\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u8bbe\u8ba1\u4e86\u4e00\u4e2abaseline\u7f51\u7edc\u3002 \u4f7f\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u6765\u8bbe\u8ba1\u65b0\u7684baseline\u5e76\u8fdb\u884c\u6269\u5c55\u4ee5\u83b7\u5f97\u4e00\u7cfb\u5217\u6a21\u578b\uff0c\u79f0EfficientNets\u3002 \u5f15\u5165\uff1a \u4e00\u822cConvNets\u7684\u7cbe\u5ea6\u968f\u7740\u5b83\u7684size\u589e\u52a0\uff0c\u6709\u5f88\u591a\u5de5\u4f5c\u901a\u8fc7\u589e\u52a0ConvNets\u7684\u5bbd\u5ea6\u3001\u6df1\u5ea6\u6216\u8005\u56fe\u50cf\u5206\u8fa8\u7387\u53bb\u63d0\u5347\u7f51\u7edc\u7684\u6027\u80fd\u3002\u5c3d\u7ba1\u53ef\u4ee5\u4efb\u610f\u7f29\u653e\u4e8c\u7ef4\u6216\u4e09\u7ef4\uff0c\u4f46\u4efb\u610f\u7f29\u653e\u9700\u8981\u7e41\u7410\u7684\u624b\u52a8\u8c03\u6574\uff0c\u5e76\u4e14\u4ecd\u7136\u7ecf\u5e38\u4ea7\u751f\u6b21\u4f18\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002 \u4f5c\u8005\u91cd\u65b0\u601d\u8003\u548c\u7814\u7a76\u4e86ConvNets\u7684\u7f29\u653e\u95ee\u9898\uff0c\u662f\u5426\u5b58\u5728\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u7f29\u653eConvNets\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff1f\u4f5c\u8005\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u5e73\u8861\u7f51\u7edc\u5bbd\u5ea6/\u6df1\u5ea6/\u5206\u8fa8\u7387\u7684\u6240\u6709\u7ef4\u5ea6\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u4e14\u53ef\u901a\u8fc7\u7b80\u5355\u5730\u6309\u6bd4\u4f8b\u7f29\u653e\u6bcf\u4e2a\u7ef4\u5ea6\u6765\u5b9e\u73b0\u8fd9\u79cd\u5e73\u8861\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u590d\u5408\u7f29\u653e\u65b9\u6cd5\u3002 4.10.1.2 \u539f\u7406\u4ecb\u7ecd \u00b6 \u8fd9\u79cd\u590d\u5408\u7f29\u653e\u65b9\u6cd5\u662f\u6709\u610f\u4e49\u7684\uff0c\u56e0\u4e3a\u5982\u679c\u8f93\u5165\u56fe\u50cf\u66f4\u5927\uff0c\u5219\u7f51\u7edc\u9700\u8981\u66f4\u591a\u5c42\u6765\u589e\u52a0\u611f\u77e5\u573a\uff0c\u5e76\u4e14\u9700\u8981\u66f4\u591a\u901a\u9053\u6765\u6355\u83b7\u66f4\u5927\u56fe\u50cf\u4e0a\u7684\u66f4\u7ec6\u7c92\u5ea6\u56fe\u6848\u3002 \u6df1\u5ea6( )\uff1a \u66f4\u6df1\u7684\u7f51\u7edc\u53ef\u4ee5\u6355\u83b7\u66f4\u4e30\u5bcc\u3001\u66f4\u590d\u6742\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u53ef\u4ee5\u5f88\u597d\u5730\u6cdb\u5316\u65b0\u4efb\u52a1\u3002 \u7136\u800c\u7531\u4e8e\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u66f4\u6df1\u5c42\u6b21\u7684\u7f51\u7edc\u4e5f\u66f4\u96be\u8bad\u7ec3\u3002\u867d\u7136\u8df3\u5c42\u8fde\u63a5\u548c\u6279\u91cf\u5f52\u4e00\u5316\u7b49\u53ef\u4ee5\u7f13\u89e3\u8bad\u7ec3\u95ee\u9898\uff0c\u4f46\u975e\u5e38\u6df1\u7684\u7f51\u7edc\u7684\u51c6\u786e\u5ea6\u589e\u76ca\u4f1a\u51cf\u5c11\uff1a\u4f8b\u5982\uff0cResNet-1000\u548cResNet-101\u6709\u76f8\u4f3c\u7cbe\u5ea6\u3002 \u5bbd\u5ea6( )\uff1a\u66f4\u5bbd\u7684\u7f51\u7edc\u5f80\u5f80\u80fd\u591f\u6355\u83b7\u66f4\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u66f4\u5bb9\u6613\u8bad\u7ec3\u3002 \u7136\u800c\uff0c\u6781\u5bbd\u4f46\u6d45\u7684\u7f51\u7edc\u5f80\u5f80\u96be\u4ee5\u6355\u83b7\u66f4\u9ad8\u7ea7\u522b\u7684\u7279\u5f81\u3002 \u5206\u8fa8\u7387( )\uff1a\u4f7f\u7528\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u7f51\u7edc\u53ef\u4ee5\u6355\u83b7\u66f4\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u3002 1\u3001\u590d\u5408\u6a21\u578b\u7f29\u653e-\u95ee\u9898\u5efa\u6a21 \u00b6 \u5bf9\u4e8eConvNet\uff08\u5377\u79ef\u7f51\u7edc\uff09\u7684\u7b2c \u5c42\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u51fd\u6570\uff1a \u3002\u6a21\u578b\u7f29\u653e\u8ddfConvNet\u8bbe\u8ba1\u53bb\u5bfb\u627e\u6700\u4f18\u7ed3\u6784 \u4e0d\u4e00\u6837\uff0c\u6a21\u578b\u7f29\u653e\u662f\u53bb\u5bfb\u627e \u7684\u6700\u4f73\u5bbd\u5ea6 \u3001\u957f\u5ea6 \u548c\u5206\u8fa8\u7387 \uff0c\u901a\u8fc7\u56fa\u5b9a\u4f4f \uff0c\u6a21\u578b\u7f29\u653e\u7b80\u5316\u4e86\u8d44\u6e90\u9650\u5236\u95ee\u9898\u3002\u5728\u7ed9\u5b9a\u8d44\u6e90\u9650\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u53bb\u6700\u5927\u5316\u6a21\u578b\u7684\u7cbe\u5ea6\uff0c\u5c31\u53d8\u6210\u4e86\u4ee5\u4e0b\u4f18\u5316\u95ee\u9898\uff1a 1\u3001\u6700\u4e0a\u65b9\u4e3a\u8981\u4f18\u5316\u7684\u51c6\u786e\u7387 2\u3001\u4e2d\u95f4N\u4ee3\u8868\u4e00\u4e2a\u5b8c\u6574\u5377\u79ef\u7f51\u7edc F_{i}^{L} F_{i}^{L} <span><span class=\"MathJax_Preview\">F_{i}^{L}</span><script type=\"math/tex\">F_{i}^{L} \u8868\u793a\u67d0layerF\u88ab\u91cd\u590d\u4e86L\u6b21\u5728\u5377\u79ef\u7ed3\u6784\u5c42i\u4e2d\uff08\u53ef\u4ee5\u7406\u89e3Resnet\u67d0\u4e2a\u7ed3\u6784\u91cd\u590d\u82e5\u5e72\u6b21\uff09 X X <span><span class=\"MathJax_Preview\">X</span><script type=\"math/tex\">X \u4e3a\u67d0i\u5c42\u7684\u8f93\u5165\u5206\u522b\u4e3aH\uff0cW\uff0cC \u4e0b\u9762\u4e24\u5f20\u56fe\u8868\u793a\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u5f71\u54cd\u548c\u4e09\u4e2a\u7ef4\u5ea6\u7684\u6bd4\u7387\u8c03\u6574\u7684\u5f71\u54cd \u8868\u793a\u6bd4\u8f83\u4e86\u4e0d\u540c\u7f51\u7edc\u6df1\u5ea6\u548c\u5206\u8fa8\u7387\u4e0b\u7684\u5bbd\u5ea6\u7f29\u653e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5728\u4e0d\u6539\u53d8\u6df1\u5ea6\uff08d = 1.0\uff09\u548c\u5206\u8fa8\u7387\uff08r = 1.0\uff09\u7684\u60c5\u51b5\u4e0b\u7f29\u653e\u7f51\u7edc\u5bbd\u5ea6w\uff0c\u5219\u7cbe\u5ea6\u4f1a\u5f88\u5feb\u8fbe\u5230\u9971\u548c\u3002 \u968f\u7740\u66f4\u6df1\uff08d = 2.0\uff09\u548c\u66f4\u9ad8\u5206\u8fa8\u7387\uff08r = 2.0\uff09\uff0c\u5bbd\u5ea6\u7f29\u653e\u5728\u76f8\u540c\u7684FLOPS\u6210\u672c\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u7cbe\u5ea6\u3002 2\u3001\u65b0\u7684\u590d\u5408\u65b9\u6cd5 \u00b6 \u4f7f\u7528\u4e00\u4e2a\u590d\u5408\u7cfb\u6570 \u4ee5\u539f\u5219\u65b9\u5f0f\u7edf\u4e00\u7f29\u653e\u7f51\u7edc\u5bbd\u5ea6\u3001\u6df1\u5ea6\u548c\u5206\u8fa8\u7387 \u5176\u4e2d \u662f\u53ef\u4ee5\u901a\u8fc7\u5c0f\u7f51\u683c\u641c\u7d22\u786e\u5b9a\u7684\u5e38\u6570\u3002 \u662f\u7528\u6237\u6307\u5b9a\u7684\u7cfb\u6570\uff0c\u63a7\u5236\u6709\u591a\u5c11\u8d44\u6e90\u53ef\u7528\u4e8e\u6a21\u578b\u7f29\u653e\uff0c\u800c \u6307\u5b9a\u5982\u4f55\u5c06\u8fd9\u4e9b\u989d\u5916\u8d44\u6e90\u5206\u914d\u7ed9\u7f51\u7edc\u5bbd\u5ea6\uff0c\u6df1\u5ea6\u548c\u5206\u8fa8\u7387\u3002\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u7ea6\u675f \uff0c\u4f7f\u5f97\u5bf9\u4e8e\u4efb\u4f55\u65b0\u7684 \uff0c\u603bFLOPS\u5c06\u5927\u7ea6\u589e\u52a0 \u3002 \u62d3\u5c55\uff1a\u5e38\u89c4\u5377\u79ef\u8fd0\u7b97\u7684FLOPS\u4e0e \u6210\u6b63\u6bd4\uff0c\u5373\u53cc\u500d\u7f51\u7edc\u6df1\u5ea6\u5c06\u4f7fFLOPS\u52a0\u500d\u3002\u4f46\u7f51\u7edc\u5bbd\u5ea6\u6216\u5206\u8fa8\u7387\u52a0\u500d\u4f1a\u4f7fFLOPS\u589e\u52a0\u56db\u500d\u3002 4.10.1.3 Efficientnet \u67b6\u6784 \u00b6 \u6240\u4ee5\u901a\u8fc7\u4e0a\u9762\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u627e\u5230\u4e86\u4e00\u4e2a\u65b0\u7684baseline\uff08\uff08MBConv\uff09\uff0c\u7c7b\u4f3c\u4e8eMobileNetV2\u548cMnasNet\uff09\u6765\u8bc4\u4f30\uff0c\u79f0\u4e3aEfficientNet-B0\u3002 \u6b65\u9aa41\uff1a\u9996\u5148\u786e\u5b9a\u03c6= 1\uff0c\u5047\u8bbe\u6709\u4e24\u500d\u7684\u53ef\u7528\u8d44\u6e90\uff0c\u5e76\u6839\u636e\u516c\u5f0f2\u548c3\u8fdb\u884c \u7684\u5c0f\u7f51\u683c\u641c\u7d22\u3002\u4f5c\u8005\u627e\u5230\u4e86EfficientNet-B0\u6ee1\u8db3\u7ea6\u675f\u7684\u6700\u4f73\u503c \u6b65\u9aa42\uff1a\u7136\u540e\u6211\u4eec\u5c06 \u56fa\u5b9a\u4e3a\u5e38\u6570\uff0c\u5e76\u4f7f\u7528\u516c\u5f0f3\u6269\u5c55\u5177\u6709\u4e0d\u540c \u7684\u57fa\u7ebf\u7f51\u7edc\uff0c\u4ee5\u83b7\u5f97EfficientNet-B1\u81f3B7\uff08 \u4e5f\u5c31\u662f\u6839\u636e\u81ea\u5df1\u7684\u8ba1\u7b97\u8d44\u6e90\u6765\u9009\u62e9\u5408\u9002\u5927\u5c0f\u7684\u7f51\u7edc \uff09\uff0c\u7ec6\u8282\u5982\u4e0b 4.10.1.4 \u5b9e\u9a8c \u00b6 \u5bf9MobileNets \u548c ResNets\u8fdb\u884c\u7f29\u653e \u8fd9\u4e2a\u590d\u5408\u7f29\u653e\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6240\u6709\u8fd9\u4e9b\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u8868\u660e\u4e86\u7f29\u653e\u65b9\u6cd5\u5bf9\u73b0\u6709\u7684\u5377\u79ef\u7f51\u7edc\u7ed3\u6784\u6709\u6548\u6027\u3002 \u7c7b\u6fc0\u6d3b\u56fe\u8bf4\u660e\u4e86\u5177\u6709\u590d\u5408\u7f29\u653e\u7684\u6a21\u578b\u503e\u5411\u4e8e\u5173\u6ce8\u5177\u6709\u66f4\u591a\u5bf9\u8c61\u7ec6\u8282\u7684\u66f4\u76f8\u5173\u533a\u57df\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u8981\u4e48\u7f3a\u5c11\u5bf9\u8c61\u7ec6\u8282\uff0c\u8981\u4e48\u65e0\u6cd5\u6355\u83b7\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u5bf9\u8c61\u3002 \u5728\u5404\u6bd4\u8d5b\u4e2d\u505a\u8fc1\u79fb\u5b66\u4e60\u5f97\u6210\u5c31 \u4e0e\u516c\u5f00\u53ef\u7528\u6a21\u578b\u76f8\u6bd4\uff0cEfficientNet\u6a21\u578b\u51cf\u5c11\u4e86\u5e73\u57474.7\u500d\uff08\u6700\u591a21\u500d\uff09\u7684\u53c2\u6570\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cbe\u5ea6\u3002 \u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u76f8\u6bd4\uff0cEfficientNet\u6a21\u578b\u57288\u4e2a\u6570\u636e\u96c6\u4e2d\u67095\u4e2a\u4ecd\u7136\u8d85\u8fc7\u4e86\u5b83\u4eec\u7684\u51c6\u786e\u5ea6\uff0c\u4e14\u4f7f\u7528\u7684\u53c2\u6570\u51cf\u5c11\u4e869.6\u500d\u3002 \u6700\u7ec8\u5404\u79cd\u6a21\u578b\u7684\u7cbe\u5ea6 - \u53c2\u6570\u66f2\u7ebf\uff0c\u7ea2\u8272\u4e3aEfficientNet\u7684\u7ed3\u679c\uff0c\u660e\u663e\u6bd4\u5404\u4e2a\u6a21\u578b\u7cbe\u5ea6\u9ad8\uff0c\u53c2\u6570\u91cf\u5c11\u3002 \u6ce8\uff1a\u6700\u7ec8\u7684\u6548\u679c\u6bd4\u7387\uff0c\u90fd\u662f\u5728\u5927\u91cf\u7684\u8bbe\u5907\u548c\u6a21\u578b\u4e0a\u8ba1\u7b97\u5f97\u6765\u7684\uff0c\u8d44\u6e90\u6d88\u8017\u4e0d\u53ef\u60f3\u8c61\u3002Google\u6709\u8db3\u591f\u7684\u8d44\u6e90\u548c\u8bbe\u5907\uff08TPU\uff09\u53bb\u505a\u3002 4.10.2 \u5783\u573e\u5206\u7c7b\u5f00\u6e90EfficientNet\u5b9e\u73b0\u4ecb\u7ecd \u00b6 4.10.2.1 \u6a21\u578b\u76ee\u5f55 \u00b6 TensorFlow2.0 \u53ef\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u7684\u5b9e\u73b0\u7248\u672c\u4e0d\u5b58\u5728efficientnet\uff0c\u9700\u8981\u7b2c\u4e09\u65b9\u5b9e\u73b0\u7684\u6a21\u578b\u4e24\u79cd\u9009\u62e9\uff1a \u00b6 1\u3001\u53ef\u8fc1\u79fb\u5b66\u4e60\u7684TF\u4f4e\u7248\u672c\u80fd\u4f7f\u7528**\uff08\u90e8\u5206\u64cd\u4f5c\u4e0d\u652f\u6301\u9ed8\u8ba4Eager \u6a21\u5f0f\uff09** https://github.com/calmisential/Basic_CNNs_TensorFlow2 \u6211\u4eec\u9009\u62e9\u7684\u662f\u8fd9\u4e2a\u7248\u672c\uff0c\u53ef\u4ee5\u5728\u4e0e\u8bad\u7ec3\u6a21\u578b\u4e0a\u8fc1\u79fb\uff0c\u4f7f\u7528\u7b80\u5355 from efficientnet import EfficientNetB0 EfficientNetB0 ( weights = None , include_top = False , input_shape = ( 336 , 336 , 3 )) 2\u3001TF2.0\u5b9e\u73b0\u7248\u672c\u4e0d\u80fd\u4f7f\u7528\u5728imagenet\u4e0a\u7684\u4e0e\u8bad\u7ec3\u6a21\u578b\uff0c\u7248\u672c\u7b80\u5355\u6613\u61c2\uff0c\u9879\u76ee\u4e2d\u4e5f\u542b\u6709\u5176\u4ed6\u7684\u6a21\u578b https://github.com/Tony607/efficientnet_keras_transfer_learning model.py: \u6a21\u578b\u7684\u4e3b\u7ed3\u6784 \u5176\u4ed6\u6587\u4ef6\u4e3a\u76f8\u5173\u5c01\u88c5\u63a5\u53e3 \u53bb\u5de5\u7a0b\u4e2d\u770b\u770b\u6307\u5b9a\u6a21\u578b\u3002\u5176\u4e2d\u53c2\u6570include_top\uff0c\u6307\u5b9a\u4e86\u6211\u4eec\u53ef\u4ee5\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff1a if include_top : x = KL . GlobalAveragePooling2D ( data_format = global_params . data_format )( x ) if global_params . dropout_rate > 0 : x = KL . Dropout ( global_params . dropout_rate )( x ) x = KL . Dense ( global_params . num_classes , kernel_initializer = DenseKernalInitializer ())( x ) x = KL . Activation ( 'softmax' )( x ) else : if pooling == 'avg' : x = KL . GlobalAveragePooling2D ( data_format = global_params . data_format )( x ) elif pooling == 'max' : x = KL . GlobalMaxPooling2D ( data_format = global_params . data_format )( x ) 4.10.3 \u4f18\u5316\u7b97\u6cd5\u4ee5\u53ca\u5b66\u4e60\u7387trick \u00b6 4.10.2.1 Rectified Adam(Adam with warm up) \u00b6 RAdam\u80fd\u6839\u636e\u65b9\u5dee\u5206\u6563\u5ea6\uff0c\u52a8\u6001\u5730\u6253\u5f00\u6216\u8005 \u5173\u95ed\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e0d\u9700\u8981\u53ef \u8c03\u53c2\u6570\u5b66\u4e60\u7387\u9884\u70ed\u7684\u65b9\u6cd5\u3002 \u4e0a\u8ff0\u7ed3\u679c\u8868\u660e\u4f7f\u7528\u539f\u59cbAdam\u5fc5\u987b\u9884\u70ed\uff0c\u5426\u5219\u6b63\u6001\u5206\u5e03\u4f1a\u53d8\u5f97\u626d\u66f2 4.10.2.2 Warmup \u00b6 \u5b9a\u4e49\uff1a\u5b66\u4e60\u7387\u9884\u70ed\u5c31\u662f\u5728\u521a\u5f00\u59cb\u8bad\u7ec3\u7684\u65f6\u5019\u5148\u4f7f\u7528\u4e00\u4e2a\u8f83\u5c0f\u7684\u5b66\u4e60\u7387\uff0c\u8bad\u7ec3\u4e00\u4e9bepoches\u6216iterations\uff0c\u7b49\u6a21\u578b\u7a33\u5b9a\u65f6\u518d\u4fee\u6539\u4e3a\u9884\u5148\u8bbe\u7f6e\u7684\u5b66\u4e60\u7387\u8fdb\u884c\u8bad\u7ec3\u3002 \u5b66\u4e60\u7387\u662f\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u6700\u91cd\u8981\u7684\u8d85\u53c2\u6570\u4e4b\u4e00\uff0c\u9488\u5bf9\u5b66\u4e60\u7387\u7684\u6280\u5de7\u6709\u5f88\u591a\u3002Warm up\u662f\u5728ResNet\u8bba\u6587\u4e2d\u63d0\u5230\u7684\u4e00\u79cd\u5b66\u4e60\u7387\u9884\u70ed\u7684\u65b9\u6cd5\u3002 \u539f\u56e0\uff1a\u7531\u4e8e\u521a\u5f00\u59cb\u8bad\u7ec3\u65f6\u6a21\u578b\u7684\u6743\u91cd(weights)\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u6b64\u65f6\u9009\u62e9\u4e00\u4e2a\u8f83\u5927\u7684\u5b66\u4e60\u7387\uff0c\u53ef\u80fd\u4f1a\u5e26\u6765\u6a21\u578b\u7684\u4e0d\u7a33\u5b9a\u3002 \u8bba\u6587\u4e2d\u4f7f\u7528\u4e00\u4e2a110\u5c42\u7684ResNet\u5728cifar10\u4e0a\u8bad\u7ec3\u65f6\uff0c\u5148\u75280.01\u7684\u5b66\u4e60\u7387\u8bad\u7ec3\u76f4\u5230\u8bad\u7ec3\u8bef\u5dee\u4f4e\u4e8e80%(\u5927\u6982\u8bad\u7ec3\u4e86400\u4e2aiterations)\uff0c\u7136\u540e\u4f7f\u75280.1\u7684\u5b66\u4e60\u7387\u8fdb\u884c\u8bad\u7ec3\u3002 \u7406\u89e3\uff1a\u521a\u5f00\u59cb\u6a21\u578b\u5bf9\u6570\u636e\u7684\u201c\u5206\u5e03\u201d\u7406\u89e3\u4e3a\u96f6\uff0c\u6216\u8005\u662f\u8bf4\u201c\u5747\u5300\u5206\u5e03\u201d\uff1b\u5728\u7b2c\u4e00\u8f6e\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6bcf\u4e2a\u6570\u636e\u70b9\u5bf9\u6a21\u578b\u6765\u8bf4\u90fd\u662f\u65b0\u7684\uff0c\u6a21\u578b\u4f1a\u5f88\u5feb\u5730\u8fdb\u884c\u6570\u636e\u5206\u5e03\u4fee\u6b63\uff0c\u5982\u679c\u8fd9\u65f6\u5019\u5b66\u4e60\u7387\u5c31\u5f88\u5927\uff0c\u6781\u6709\u53ef\u80fd\u5bfc\u81f4\u5f00\u59cb\u7684\u65f6\u5019\u5c31\u5bf9\u8be5\u6570\u636e\u201c\u8fc7\u62df\u5408\u201d\uff0c\u540e\u9762\u8981\u901a\u8fc7\u591a\u8f6e\u8bad\u7ec3\u624d\u80fd\u62c9\u56de\u6765\uff0c\u6d6a\u8d39\u65f6\u95f4\u3002 4.10.2.3 \u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf\uff08Cosine Learning rate decay\uff09 \u00b6 \u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf\u7684\u65b9\u5f0f\uff0cCosine Learning rate decay\u3002\u516c\u5f0f\u5982\u4e0b\uff1a $$ \\eta_t=\\frac{1}{2} (1+cos(\\frac{t\\pi}{T})) $$ \u4e0b\u56fe\u662f\u9010\u6b65\u8870\u51cf\u5b66\u4e60\u7387\u4e0e\u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf\u7684\u65b9\u5f0f\u5bf9\u6bd4\uff1a \u73b0\u8c61\uff1a\u5f53Step Decay\u65b9\u6cd5\u7684\u5b66\u4e60\u7387\u5df2\u7ecf\u8f83\u5c0f\u7684\u65f6\u5019\uff0cCos Decay\u65b9\u6cd5\u7684\u5b66\u4e60\u4ecd\u6bd4\u8f83\u5927\uff0c\u56e0\u800c\u80fd\u591f\u52a0\u901f\u6574\u4e2a\u8bad\u7ec3\u7684\u8fc7\u7a0b\u3002\u4f46\u662f\u770b\u56fe\u4e2db\uff0c\u5f88\u660e\u663eStep Decay\u518d\u8870\u51cf\u4e4b\u540e\uff0c\u51c6\u786e\u7387\u5c31\u4e0a\u6765\u4e86\uff0c\u8bf4\u660e\u8870\u51cf\u4e4b\u524d\u7684\u6570\u91cf\u7ea7\u6548\u7528\u5df2\u7ecf\u4e0d\u5f3a\u4e86\uff0c\u8fd9\u4e2a\u65f6\u5019Cos decay\u8fd8\u662f\u90a3\u4e2a\u6570\u91cf\u7ea7\uff0c\u6240\u4ee5\u901f\u5ea6\u5c31\u6bd4Step Decay\u6162\u4e86 \u7ed3\u679c\uff1a 1\u3001cos\u7684\u5b66\u4e60\u7387\u7684\u524d\u671f\u662fwarm-up\u9636\u6bb5\uff0c\u8fd9\u4e2a\u65f6\u5019\u662f\u4ee5\u7ebf\u6027\u589e\u957f\u7684\u65b9\u5f0f\u589e\u957f\u5230\u521d\u59cb\u5b66\u4e60\u7387\uff0c\u7136\u540e\u5f00\u59cb\u6267\u884ccos\u7684\u5b66\u4e60\u7387\u53d8\u5316\uff0c\u6700\u7ec8\u4e24\u79cd\u5b66\u4e60\u7387\u8fbe\u5230\u4e00\u81f4\u3002 \u4ece\u51c6\u786e\u6027\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u4f7f\u7528step\u7684\u65b9\u5f0f\u4f3c\u4e4e\u5b66\u4e60\u7684\u66f4\u5feb\u4e00\u4e9b\u3002\u800c\u4e14\u5176\u53d8\u5316\u7684\u62d0\u70b9\u548c\u5176\u5b66\u4e60\u7387\u7684\u62d0\u70b9\u662f\u5bf9\u5e94\u7740\u7684\uff0c\u5373\u5b66\u4e60\u7387\u964d\u4e86\u4e4b\u540e\uff0c\u9a8c\u8bc1\u7684\u51c6\u786e\u6027\u4e5f\u8ddf\u7740\u5f00\u59cb\u63d0\u5347\uff0c\u800ccos\u5b66\u4e60\u7387\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u51c6\u786e\u6027\u90fd\u5f88\u5e73\u7a33\uff0c\u6700\u7ec8\u4e24\u8005\u7684\u51c6\u786e\u6027\u4e5f\u662f\u4e00\u81f4\u3002 2\u3001\u533a\u522b\u5728\u4e8e\u4e2d\u95f4\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u800c\u4e14step\u7684\u65b9\u5f0f\u6709\u4e00\u5b9a\u7684\u968f\u673a\u6027\uff0c\u4e0d\u77e5\u9053\u8981\u4ee5\u591a\u5927\u7684step\u6765\u6539\u53d8\u5b66\u4e60\u7387\uff0c\u5982\u679c\u8fd9\u4e2a\u2019step\u2019\u53ef\u4ee5\u6839\u636e\u67d0\u79cd\u65b9\u5f0f\u91cf\u5316 \u5b9a\u4e49\uff1a\u5e38\u7528\u7684Learning Rate Decay\u662fStep Decay\uff0c\u5373\u6bcf\u9694N\u4e2aEpoch\uff0clearning rate\u4e58\u4e0a\u4e00\u4e2a\u56fa\u5b9adecay\u7cfb\u6570\u3002 \u4f46\u662fStep Decay\u4e0d\u597d\u7684\u5730\u65b9\u5728\u4e8e\u5b66\u4e60\u7387\u8870\u51cf\u7684\u65f6\u5019\uff0c\u8df3\u8dc3\u53d8\u5316\u8f83\u5927\uff0c\u5e26\u6765\u4e86\u8f83\u5927\u7684\u51b2\u91cfMomentum 4.10.2.4 TensorFlow\u5b9e\u73b0 \u00b6 Keras \u7684 callbacks \u4e2d\u6709 ReduceLROnPlateau() \u548c LearningRateScheduler() \u51fd\u6570\u53ef\u4ee5\u52a8\u6001\u7684\u8c03\u6574\u5b66\u4e60\u7387\u3002\u4f46\u662f\u524d\u8005\u53ea\u5728\u9a8c\u8bc1\u8bef\u5dee\u505c\u6b62\u8870\u51cf\u7684\u65f6\u5019\u51cf\u5c0f\u5b66\u4e60\u7387\uff0c\u540e\u8005\u53ea\u80fd\u5728\u6bcf\u4e2a Epoch \u5f00\u59cb\u6216\u7ed3\u675f\u7684\u65f6\u5019\uff0c\u6539\u53d8\u5b66\u4e60\u7387\u4e24\u8005\u4f7f\u7528\u53c2\u8003\u6587\u6863\uff1a https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler#class_learningratescheduler \u5982\u679c\u9700\u8981\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u6bcf\u6279\u6b21\u66f4\u52a0\u7ec6\u81f4\u7684\u63a7\u5236\u5b66\u4e60\u7387\uff0c\u9700\u8981\u81ea\u5b9a\u4e49\u56de\u8c03\u65b9\u6cd5 1\u3001tf.keras.callbacks.Callback \u00b6 \u8be5\u7c7b\u5728 Model \u7684 .fit() \u65b9\u6cd5\u4e2d\u4f1a\u8c03\u7528\u4e00\u4e0b\u56de\u8c03\u65b9\u6cd5 on_batch_begin( batch, logs=None) \u4e00\u6279\u6b21\u6570\u636e\u5f00\u59cb\u65f6\u7684\u5904\u7406 on_batch_end(batch, logs=None) \u4e00\u6279\u6b21\u6570\u636e\u5904\u7406\u7ed3\u675f on_epoch_begin\u548con_epoch_end 4.10.3 \u5783\u573e\u5206\u7c7b\u5e26\u6709warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8c03\u5ea6\u5b9e\u73b0 \u00b6 4.10.3.1 \u6d41\u7a0b\u5206\u6790 \u00b6 \u5206\u4e3a\u4e24\u4e2a\u7ed3\u7b97 warmup\u9636\u6bb5 \u4f59\u5f26\u9000\u706b\u9636\u6bb5 4.10.3.2 \u5b8c\u6574\u4ee3\u7801\u8fc7\u7a0b\u5b9e\u73b0 \u00b6 \u53c2\u8003\u6587\u4ef6\uff0c\u5e76\u8fd0\u884c\u6d4b\u8bd5 \u6b65\u9aa4\uff1a 1\u3001\u81ea\u5b9a\u4e49WarmUpCosineDecayScheduler\u8c03\u5ea6\u5668\uff0c\u5b9e\u73b0\u6279\u6b21\u524d\u540e\u7684\u5904\u7406\u903b\u8f91 2\u3001\u5b9e\u73b0warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97\u65b9\u6cd5 1\u3001\u81ea\u5b9a\u4e49WarmUpCosineDecayScheduler\u8c03\u5ea6\u5668\uff0c\u5b9e\u73b0\u6279\u6b21\u524d\u540e\u7684\u5904\u7406\u903b\u8f91 import numpy as np import tensorflow as tf from tensorflow.keras import backend as K from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" class WarmUpCosineDecayScheduler ( tf . keras . callbacks . Callback ): \"\"\"\u5e26\u6709warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8c03\u5ea6 \"\"\" def __init__ ( self , learning_rate_base , total_steps , global_step_init = 0 , warmup_learning_rate = 0.0 , warmup_steps = 0 , hold_base_rate_steps = 0 , verbose = 0 ): \"\"\" \u521d\u59cb\u5316\u53c2\u6570 :param learning_rate_base: \u57fa\u7840\u5b66\u4e60\u7387 :param total_steps: \u603b\u5171\u8fed\u4ee3\u7684\u6279\u6b21\u6b65\u6570 epoch * num_samples / batch_size :param global_step_init: \u521d\u59cb :param warmup_learning_rate: \u9884\u70ed\u5b66\u4e60\u7387\u9ed8\u8ba40.0 :param warmup_steps:\u9884\u70ed\u7684\u6b65\u6570\u9ed8\u8ba40 :param hold_base_rate_steps: :param verbose: \"\"\" super ( WarmUpCosineDecayScheduler , self ) . __init__ () self . learning_rate_base = learning_rate_base self . total_steps = total_steps self . global_step = global_step_init self . warmup_learning_rate = warmup_learning_rate self . warmup_steps = warmup_steps self . hold_base_rate_steps = hold_base_rate_steps # \u662f\u5426\u5728\u6bcf\u6b21\u8bad\u7ec3\u7ed3\u675f\u6253\u5370\u5b66\u4e60\u7387 self . verbose = verbose # \u8bb0\u5f55\u6240\u6709\u6279\u6b21\u4e0b\u6765\u7684\u6bcf\u6b21\u51c6\u786e\u7684\u5b66\u4e60\u7387\uff0c\u53ef\u4ee5\u7528\u4e8e\u6253\u5370\u663e\u793a self . learning_rates = [] def on_batch_end ( self , batch , logs = None ): # 1\u3001\u6279\u6b21\u5f00\u59cb\u524d\u5f53\u524d\u6b65\u6570+1 self . global_step = self . global_step + 1 # 2\u3001\u83b7\u53d6\u4f18\u5316\u5668\u4e0a\u4e00\u6b21\u7684\u5b66\u4e60\u7387\uff0c\u5e76\u8bb0\u5f55 lr = K . get_value ( self . model . optimizer . lr ) self . learning_rates . append ( lr ) def on_batch_begin ( self , batch , logs = None ): # 1\u3001\u901a\u8fc7\u53c2\u6570\u4ee5\u53ca\u8bb0\u5f55\u7684\u6b21\u6570\u548c\u4e0a\u6b21\u5b66\u4e60\u7387 lr = cosine_decay_with_warmup ( global_step = self . global_step , learning_rate_base = self . learning_rate_base , total_steps = self . total_steps , warmup_learning_rate = self . warmup_learning_rate , warmup_steps = self . warmup_steps , hold_base_rate_steps = self . hold_base_rate_steps ) # 2\u3001\u8bbe\u7f6e\u4f18\u5316\u5668\u672c\u6b21\u7684\u5b66\u4e60\u7387 K . set_value ( self . model . optimizer . lr , lr ) if self . verbose > 0 : print ( ' \\n \u6279\u6b21\u6570 %05d : \u8bbe\u7f6e\u5b66\u4e60\u7387\u4e3a' ' %s .' % ( self . global_step + 1 , lr )) \u8fd9\u91cc\u9762\u6d89\u53ca\u5230\u4e00\u4e2a\u8bbe\u7f6e\u5f53\u524d\u4f18\u5316\u5668\u5b66\u4e60\u7387\u7684\u4f7f\u7528\uff0c\u4f1a\u7528\u5230keras.backend\u8fd9\u4e2a\u6a21\u5757\u3002keras\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u5757\u7684\u9ad8\u7ea7\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u6846\u67b6\uff0c\u5b83\u5e76\u6ca1\u6709\u4ec5\u4f9d\u8d56\u4e8e\u67d0\u4e00\u79cd\u9ad8\u901f\u5e95\u5c42\u5f20\u91cf\u5e93\uff0c\u800c\u662f\u5bf9\u5404\u79cd\u5e95\u5c42\u5f20\u91cf\u5e93\u8fdb\u884c\u9ad8\u5c42\u6a21\u5757\u5c01\u88c5\uff0c\u8ba9\u5e95\u5c42\u5e93\u5b8c\u6210\u8bf8\u5982\u5f20\u91cf\u79ef\u3001\u5377\u79ef\u64cd\u4f5c\u3002\u5728keras\u4e2d\uff0c\u5404\u79cd\u5e95\u5c42\u5e93\uff08Google\u5f00\u53d1\u7684TensorFlow\u3001\u8499\u7279\u5229\u5c14\u5927\u5b66\u5b9e\u9a8c\u5ba4\u5f00\u53d1\u7684Theano\u3001\u5fae\u8f6f\u5f00\u53d1\u7684CNTK\uff09\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u540e\u7aef\uff08backend\uff09\u5f15\u64ce\u4e3akeras\u6a21\u5757\u63d0\u4f9b\u670d\u52a1\u3002 \u95ee\u9898\uff1a\u5982\u4f55\u4fee\u6539Keras\u4f7f\u7528\u7684backend \u00b6 \uff081\uff09\u901a\u8fc7\u4fee\u6539keras\u914d\u7f6e\u6587\u4ef6\u6765\u4fee\u6539backend \u4e00\u65e6\u8fd0\u884c\u8fc7\u4e00\u6b21Keras\uff0c\u5c31\u4f1a\u5728$HOME/.keras\u4e0b\u751f\u6210\u914d\u7f6e\u6587\u4ef6keras.json\uff0c\u8be5\u6587\u4ef6\u7684\"backend\"\u5b57\u6bb5\u7684\u503c\u5373\u4e3akeras\u6240\u4f7f\u7528\u7684\u540e\u7aef\u5e93\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8be5\u503c\u4e3a\"tensorflow\"\u3002\u7528\u6237\u53ef\u4ee5\u6839\u636e\u9700\u8981\u9009\u62e9\u53e6\u5916\u4e24\u4e2a\u5e93\"theano\"\u3001\"cntk\"\uff0c\u751a\u81f3\u81ea\u5df1\u5199\u7684\u5e95\u5c42\u5e93\u3002 \uff082\uff09\u901a\u8fc7\u8fd0\u884cPython\u811a\u672c\u65f6\u589e\u52a0\u914d\u7f6e\u9879\u6307\u5b9abackend $ KERAS_BACKEND = theano python -c \"from keras import backend\" Using Theano backend. \u5bfc\u5165\u4f7f\u7528\uff1a from keras import backend as K \u5176\u4e2d\u4e24\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u8bbe\u7f6e\u5f20\u91cf\u7684\u503c\uff1a lr = K . get_value ( self . model . optimizer . lr ) K . set_value ( self . model . optimizer . lr , lr ) 2\u3001\u5b9e\u73b0warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97\u65b9\u6cd5 \u00b6 \u6b65\u9aa4\uff1a 1\u3001\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97 2\u3001warmup\u4e4b\u540e\u7684\u5b66\u4e60\u7387\u8ba1\u7b97 \u5982\u679c\u9884\u7559\u5927\u4e8e0\uff0c\u5224\u65ad\u76ee\u524d\u6b65\u6570\u662f\u5426 > warmup\u6b65\u6570+\u9884\u7559\u6b65\u6570\uff0c\u662f\u7684\u8bdd\u8fd4\u56de\u521a\u624d\u4e0a\u9762\u8ba1\u7b97\u7684\u5b66\u4e60\u7387\uff0c\u4e0d\u662f\u7684\u8bdd\u4f7f\u7528warmup\u4e4b\u540e\u7684\u57fa\u7840\u5b66\u4e60\u7387 3\u3001warmup\u5b66\u4e60\u7387\u8ba1\u7b97\uff0c\u5e76\u5224\u65ad\u5927\u5c0f 4\u3001\u5982\u679c\u6700\u540e\u5f53\u524d\u5230\u8fbe\u7684\u6b65\u6570\u5927\u4e8e\u603b\u6b65\u6570\uff0c\u5219\u5f520\uff0c\u5426\u5219\u8fd4\u56de\u5f53\u524d\u7684\u8ba1\u7b97\u51fa\u6765\u7684\u5b66\u4e60\u7387\uff08\u53ef\u80fd\u662fwarmup\u5b66\u4e60\u7387\u4e5f\u53ef\u80fd\u662f\u4f59\u5f26\u8870\u51cf\u7ed3\u679c\uff09 \u4ee3\u7801\u5982\u4e0b def cosine_decay_with_warmup ( global_step , learning_rate_base , total_steps , warmup_learning_rate = 0.0 , warmup_steps = 0 , hold_base_rate_steps = 0 ): \"\"\" \u6bcf\u6279\u6b21\u5e26\u6709warmup\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97 :param global_step: \u5f53\u524d\u5230\u8fbe\u7684\u6b65\u6570 :param learning_rate_base: warmup\u4e4b\u540e\u7684\u57fa\u7840\u5b66\u4e60\u7387 :param total_steps: \u603b\u9700\u8981\u6279\u6b21\u6570 :param warmup_learning_rate: warmup\u5f00\u59cb\u7684\u5b66\u4e60\u7387 :param warmup_steps:warmup\u5b66\u4e60\u7387 \u6b65\u6570 :param hold_base_rate_steps: \u9884\u7559\u603b\u6b65\u6570\u548cwarmup\u6b65\u6570\u95f4\u9694 :return: \"\"\" if total_steps < warmup_steps : raise ValueError ( '\u603b\u6b65\u6570\u5fc5\u987b\u5927\u4e8ewarmup' ) # 1\u3001\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97 # \u4ecewarmup\u7ed3\u675f\u4e4b\u540e\u8ba1\u7b97 # 0.5 * 0.01 * (1 + cos(pi*(1-5-0)/(10 - 5 - 0)) learning_rate = 0.5 * learning_rate_base * ( 1 + np . cos ( np . pi * ( global_step - warmup_steps - hold_base_rate_steps ) / float ( total_steps - warmup_steps - hold_base_rate_steps ))) # 2\u3001warmup\u4e4b\u540e\u7684\u5b66\u4e60\u7387\u8ba1\u7b97 # \u5982\u679c\u9884\u7559\u5927\u4e8e0\uff0c\u5224\u65ad\u76ee\u524d\u6b65\u6570\u662f\u5426 > warmup\u6b65\u6570+\u9884\u7559\u6b65\u6570\uff0c\u662f\u7684\u8bdd\u8fd4\u56de\u521a\u624d\u4e0a\u9762\u8ba1\u7b97\u7684\u5b66\u4e60\u7387\uff0c\u4e0d\u662f\u7684\u8bdd\u4f7f\u7528warmup\u4e4b\u540e\u7684\u57fa\u7840\u5b66\u4e60\u7387 if hold_base_rate_steps > 0 : learning_rate = np . where ( global_step > warmup_steps + hold_base_rate_steps , learning_rate , learning_rate_base ) # 3\u3001warmup\u6b65\u6570\u662f\u5927\u4e8e0\u7684 if warmup_steps > 0 : if learning_rate_base < warmup_learning_rate : raise ValueError ( 'warmup\u540e\u5b66\u4e60\u7387\u5fc5\u987b\u5927\u4e8ewarmup\u5f00\u59cb\u5b66\u4e60\u7387' ) # 1\u3001\u8ba1\u7b97\u4e00\u4e2a0.01\u548c0.000006\u7684\u5dee\u8ddd/warmup_steps\uff0c\u5f97\u5230warmup\u7ed3\u675f\u524d\u589e\u52a0\u591a\u5c11 slope = ( learning_rate_base - warmup_learning_rate ) / warmup_steps # 2\u3001\u8ba1\u7b97warmup\u4e0b\u4e00\u6b65\u7b2cglobal_step\u7684\u5b66\u4e60\u7387 warmup_rate = slope * global_step + warmup_learning_rate # 3\u3001\u5224\u65adglobal_step\u5c0f\u4e8ewarmup_steps\u7684\u8bdd\uff0c\u8fd4\u56de\u8fd9\u4e2awarmup\u5f53\u65f6\u7684\u5b66\u4e60\u7387\uff0c\u5426\u5219\u76f4\u63a5\u8fd4\u56de\u4f59\u5f26\u9000\u706b\u8ba1\u7b97\u7684 learning_rate = np . where ( global_step < warmup_steps , warmup_rate , learning_rate ) # 4\u3001\u5982\u679c\u6700\u540e\u5f53\u524d\u5230\u8fbe\u7684\u6b65\u6570\u5927\u4e8e\u603b\u6b65\u6570\uff0c\u5219\u5f520\uff0c\u5426\u5219\u8fd4\u56de\u5f53\u524d\u7684\u8ba1\u7b97\u51fa\u6765\u7684\u5b66\u4e60\u7387\uff08\u53ef\u80fd\u662fwarmup\u5b66\u4e60\u7387\u4e5f\u53ef\u80fd\u662f\u4f59\u5f26\u8870\u51cf\u7ed3\u679c\uff09 return np . where ( global_step > total_steps , 0.0 , learning_rate ) \u901a\u8fc7\u4ee5\u4e0b\u4ee3\u7801\u8fdb\u884c\u6d4b\u8bd5\uff1a if __name__ == '__main__' : # 1\u3001\u521b\u5efa\u6a21\u578b model = Sequential () model . add ( Dense ( 32 , activation = 'relu' , input_dim = 100 )) model . add ( Dense ( 10 , activation = 'softmax' )) model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # 2\u3001\u53c2\u6570\u8bbe\u7f6e sample_count = 1000 # \u6837\u672c\u6570 epochs = 4 # \u603b\u8fed\u4ee3\u6b21\u6570 warmup_epoch = 3 # warmup \u8fed\u4ee3\u6b21\u6570 batch_size = 16 # \u6279\u6b21\u5927\u5c0f learning_rate_base = 0.0001 # warmup\u540e\u7684\u521d\u59cb\u5b66\u4e60\u7387 total_steps = int ( epochs * sample_count / batch_size ) # \u603b\u8fed\u4ee3\u6279\u6b21\u6b65\u6570 warmup_steps = int ( warmup_epoch * sample_count / batch_size ) # warmup\u603b\u6279\u6b21\u6570 # 3\u3001\u521b\u5efa\u6d4b\u8bd5\u6570\u636e data = np . random . random (( sample_count , 100 )) labels = np . random . randint ( 10 , size = ( sample_count , 1 )) # \u8f6c\u6362\u76ee\u6807\u7c7b\u522b one_hot_labels = tf . keras . utils . to_categorical ( labels , num_classes = 10 ) # 5\u3001\u521b\u5efa\u4f59\u5f26warmup\u8c03\u5ea6\u5668 warm_up_lr = WarmUpCosineDecayScheduler ( learning_rate_base = learning_rate_base , total_steps = total_steps , warmup_learning_rate = 4e-06 , # warmup\u5f00\u59cb\u5b66\u4e60\u7387 warmup_steps = warmup_steps , hold_base_rate_steps = 0 , ) # \u8bad\u7ec3\u6a21\u578b model . fit ( data , one_hot_labels , epochs = epochs , batch_size = batch_size , verbose = 0 , callbacks = [ warm_up_lr ]) print ( warm_up_lr . learning_rates ) \u7ed3\u679c\uff1a [ 4e-06 , 4.513369e-06 , .... , 7.281053e-05 , 7.0564354e-05 , 6.826705e-05 , 6.592433e-05 , 6.354202e-05 , 6.112605e-05 , 5.868241e-05 , 5.6217184e-05 , 5.3736505e-05 , 5.1246534e-05 , 4.8753467e-05 , 4.6263496e-05 , 4.3782813e-05 , 4.131759e-05 , 3.8873954e-05 , 3.6457976e-05 , 3.4075667e-05 , 3.173295e-05 , 2.9435645e-05 , 2.7189468e-05 , 2.5e-05 , 2.2872688e-05 , 2.0812817e-05 , 1.882551e-05 , 1.6915708e-05 , 1.5088159e-05 , 1.3347407e-05 , 1.1697778e-05 , 1.0143374e-05 , 8.688061e-06 , 7.335456e-06 , 6.0889215e-06 , 4.9515565e-06 , 3.9261895e-06 , 3.015369e-06 , 2.2213596e-06 , 1.5461356e-06 , 9.913756e-07 , 5.584587e-07 , 2.4846122e-07 , 6.215394e-08 , 0.0 , 0.0 ] 4.10.4 \u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u5b9e\u73b0 \u00b6 \u6b65\u9aa4\uff1a 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 \u6a21\u578b\u4fee\u6539 \u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u5668\u6307\u5b9a 3\u3001\u6307\u5b9a\u8bad\u7ec3\u7684callbacks\uff0c\u5e76\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3 4\u3001\u8bad\u7ec3\u6307\u5b9a \u5176\u4e2d\u4ee3\u7801\u8fd0\u884c\u903b\u8f91 if __name__ == '__main__' : args = parser . parse_args () train_model ( args ) \u53c2\u6570\u6307\u5b9a\u4f7f\u7528argparse\u5de5\u5177\uff1apip install argparse parser = argparse . ArgumentParser () parser . add_argument ( \"data_url\" , type = str , default = './data/garbage_classify/train_data' , help = \"data dir\" , nargs = '?' ) parser . add_argument ( \"train_url\" , type = str , default = './garbage_ckpt/' , help = \"save model dir\" , nargs = '?' ) parser . add_argument ( \"num_classes\" , type = int , default = 40 , help = \"num_classes\" , nargs = '?' ) parser . add_argument ( \"input_size\" , type = int , default = 300 , help = \"input_size\" , nargs = '?' ) parser . add_argument ( \"batch_size\" , type = int , default = 16 , help = \"batch_size\" , nargs = '?' ) parser . add_argument ( \"learning_rate\" , type = float , default = 0.0001 , help = \"learning_rate\" , nargs = '?' ) parser . add_argument ( \"max_epochs\" , type = int , default = 30 , help = \"max_epochs\" , nargs = '?' ) parser . add_argument ( \"deploy_script_path\" , type = str , default = '' , help = \"deploy_script_path\" , nargs = '?' ) parser . add_argument ( \"test_data_url\" , type = str , default = '' , help = \"test_data_url\" , nargs = '?' ) \u5176\u4e2dnargs\u662f\u4e3a\u4e86\u5728pycharm\u4e2d\u8fd0\u884c\u65f6\uff0c\u4e0d\u8f93\u5165\u547d\u4ee4\u884c\u53c2\u6570\u503c\u4e5f\u80fd\u76f4\u63a5\u8fd0\u884c\u3002\u5426\u5219\u9700\u8981\u547d\u4ee4\u884c\u8fd0\u884c python train . py data_url ..... 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence import multiprocessing import numpy as np import argparse import tensorflow as tf from tensorflow.keras.callbacks import TensorBoard , Callback from tensorflow.keras.layers import Dense , GlobalAveragePooling2D from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam , RMSprop from efficientnet import model as EfficientNet from data_gen import data_from_sequence from utils.lr_scheduler import WarmUpCosineDecayScheduler import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" # \u6ce8\u610f\u5173\u95ed\u9ed8\u8ba4\u7684eager\u6a21\u5f0f tf . compat . v1 . disable_eager_execution () def train_model ( param ): \"\"\"\u8bad\u7ec3\u6a21\u578b :param param: \u4f20\u5165\u7684\u547d\u4ee4\u53c2\u6570 :return: \"\"\" # 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence train_sequence , validation_sequence = data_from_sequence ( param . data_url , param . batch_size , param . num_classes , param . input_size ) 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 # 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 model = model_fn ( param ) optimizer = Adam ( lr = param . learning_rate ) objective = 'categorical_crossentropy' metrics = [ 'accuracy' ] # \u6a21\u578b\u4fee\u6539 # \u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u5668\u6307\u5b9a model . compile ( loss = objective , optimizer = optimizer , metrics = metrics ) model . summary () # \u5224\u65ad\u6a21\u578b\u662f\u5426\u52a0\u8f7d\u5386\u53f2\u6a21\u578b if os . path . exists ( param . train_url ): filenames = os . listdir ( param . train_url ) model . load_weights ( filenames [ - 1 ]) print ( \"\u52a0\u8f7d\u5b8c\u6210!!!\" ) def model_fn ( param ): \"\"\"\u8fc1\u79fb\u5b66\u4e60\u4fee\u6539\u6a21\u578b\u51fd\u6570 :param param: :return: \"\"\" base_model = EfficientNet . EfficientNetB3 ( include_top = False , input_shape = ( param . input_size , param . input_size , 3 ), classes = param . num_classes ) x = base_model . output x = GlobalAveragePooling2D ( name = 'avg_pool' )( x ) predictions = Dense ( param . num_classes , activation = 'softmax' )( x ) model = Model ( inputs = base_model . input , outputs = predictions ) return model 3\u3001\u6307\u5b9a\u8bad\u7ec3\u7684callbacks\uff0c\u5e76\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3 sample_count = len ( train_sequence ) * param . batch_size epochs = param . max_epochs warmup_epoch = 5 batch_size = param . batch_size learning_rate_base = param . learning_rate total_steps = int ( epochs * sample_count / batch_size ) warmup_steps = int ( warmup_epoch * sample_count / batch_size ) warm_up_lr = WarmUpCosineDecayScheduler ( learning_rate_base = learning_rate_base , total_steps = total_steps , warmup_learning_rate = 0 , warmup_steps = warmup_steps , hold_base_rate_steps = 0 , ) #\uff083\uff09\u6a21\u578b\u4fdd\u5b58\u76f8\u5173\u53c2\u6570 check = tf . keras . callbacks . ModelCheckpoint ( param . train_url + 'weights_{epoch:02d}-{val_accuracy:.2f}.h5' , monitor = 'val_accuracy' , save_best_only = True , save_weights_only = False , mode = 'auto' , period = 1 ) 4\u3001\u8bad\u7ec3 \u8fd9\u91cc\u4f7f\u7528model.fit_generator\u51fd\u6570\uff0c\u56e0\u4e3a\u586b\u5165\u53c2\u6570\u7684\u662f\u4e00\u4e2a\u8fed\u4ee3\u5e8f\u5217\uff0c\u6307\u5b9a\u5de5\u4f5c\u7ebf\u7a0b\u6570(multiprocessing.cpu_count() * 0.7\u3002 model . fit_generator ( train_sequence , steps_per_epoch = int ( sample_count / batch_size ), epochs = param . max_epochs , verbose = 1 , callbacks = [ check , tensorboard , warm_up_lr ], validation_data = validation_sequence , max_queue_size = 10 , workers = int ( multiprocessing . cpu_count () * 0.7 ), use_multiprocessing = True , shuffle = True ) 4.10.5 \u603b\u7ed3 \u00b6 EfficientNet\u6a21\u578b\u539f\u7406 warmup\u4ee5\u53ca\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u539f\u7406 \u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u8fc7\u7a0b \u5b8c\u6210\u4f59\u5f26\u9000\u706b\u4e0ewarmup\u7684\u5b9e\u73b0","title":"4.10 \u7efc\u5408\u6848\u4f8b\uff1a\u5783\u573e\u5206\u7c7b\u4e4b\u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3"},{"location":"tensorFlow/section10/#410","text":"","title":"4.10 \u7efc\u5408\u6848\u4f8b\uff1a\u5783\u573e\u5206\u7c7b\u4e4b\u6a21\u578b\u6784\u5efa\u4e0e\u8bad\u7ec3"},{"location":"tensorFlow/section10/#_1","text":"\u76ee\u6807 \u638c\u63e1EfficientNet\u6a21\u578b\u539f\u7406 \u638c\u63e1warmup\u4ee5\u53ca\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u539f\u7406 \u5e94\u7528 \u5e94\u7528\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u8fc7\u7a0b \u5e94\u7528\u5b8c\u6210\u4f59\u5f26\u9000\u706b\u4e0ewarmup\u7684\u5b9e\u73b0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section10/#4101-efficientnet","text":"\u5148\u518d\u6765\u770b\u4e00\u904defficientnet\u7684\u53d6\u5f97\u7684\u6210\u7ee9 \u53ef\u4ee5\u770b\u51fa EfficientNet \u7cfb\u5217\u5b8c\u80dc\u4e86\u5176\u4ed6\u6240\u6709\u7684\u5377\u79ef\u7f51\u7edc\u3002\u5176\u4e2dEfficientNet-B7\u5b9e\u73b0\u4e86ImageNet\u7684state-of-the-art\u7387\uff0c\u8fbe\u5230\u4e86 84.4%\u3002\u4f46\u662f\u5b83\u7684\u53c2\u6570\u91cf\u76f8\u6bd4 GPipe \u51cf\u5c11\u4e86 8.4 \u500d\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u8fbe\u5230\u4e86 GPipe \u7684 6.1 \u500d\u3002\u66f4\u52a0\u7ec6\u8282\u7684\u6570\u636e\u53ef\u4ee5\u53c2\u8003\u540e\u9762\u7684\u5b9e\u9a8c\u90e8\u5206\u3002 \u8bba\u6587\u5730\u5740\uff1a https://arxiv.org/pdf/1905.11946.pdf","title":"4.10.1 EfficientNet\u6a21\u578b\u4ecb\u7ecd"},{"location":"tensorFlow/section10/#41011","text":"\u4f5c\u8005\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u6a21\u578b\u7f29\u653e\u5e76\u4e14\u4ed4\u7ec6\u9a8c\u8bc1\u4e86**\u7f51\u7edc\u6df1\u5ea6\u3001\u5bbd\u5ea6\u548c\u5206\u8fa8\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u53ef\u4ee5\u5bfc\u81f4\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0**\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f29\u653e\u65b9\u6cd5\u2014\u2014\u4f7f\u7528\u4e00\u4e2a\u7b80\u5355\u9ad8\u6548\u7684\u590d\u5408\u7cfb\u6570\u6765\u5b8c\u6210\u5bf9\u6df1\u5ea6/\u5bbd\u5ea6/\u5206\u8fa8\u7387\u6240\u6709\u7ef4\u5ea6\u7684\u7edf\u4e00\u7f29\u653e\u3002\u5728MobileNets\u548cResNet\u4e0a\u5c55\u793a\u4e86\u8fd9\u79cd\u7f29\u653e\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u6211\u4eec\u4f7f\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u8bbe\u8ba1\u4e86\u4e00\u4e2abaseline\u7f51\u7edc\u3002 \u4f7f\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u6765\u8bbe\u8ba1\u65b0\u7684baseline\u5e76\u8fdb\u884c\u6269\u5c55\u4ee5\u83b7\u5f97\u4e00\u7cfb\u5217\u6a21\u578b\uff0c\u79f0EfficientNets\u3002 \u5f15\u5165\uff1a \u4e00\u822cConvNets\u7684\u7cbe\u5ea6\u968f\u7740\u5b83\u7684size\u589e\u52a0\uff0c\u6709\u5f88\u591a\u5de5\u4f5c\u901a\u8fc7\u589e\u52a0ConvNets\u7684\u5bbd\u5ea6\u3001\u6df1\u5ea6\u6216\u8005\u56fe\u50cf\u5206\u8fa8\u7387\u53bb\u63d0\u5347\u7f51\u7edc\u7684\u6027\u80fd\u3002\u5c3d\u7ba1\u53ef\u4ee5\u4efb\u610f\u7f29\u653e\u4e8c\u7ef4\u6216\u4e09\u7ef4\uff0c\u4f46\u4efb\u610f\u7f29\u653e\u9700\u8981\u7e41\u7410\u7684\u624b\u52a8\u8c03\u6574\uff0c\u5e76\u4e14\u4ecd\u7136\u7ecf\u5e38\u4ea7\u751f\u6b21\u4f18\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002 \u4f5c\u8005\u91cd\u65b0\u601d\u8003\u548c\u7814\u7a76\u4e86ConvNets\u7684\u7f29\u653e\u95ee\u9898\uff0c\u662f\u5426\u5b58\u5728\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u7f29\u653eConvNets\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff1f\u4f5c\u8005\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u5e73\u8861\u7f51\u7edc\u5bbd\u5ea6/\u6df1\u5ea6/\u5206\u8fa8\u7387\u7684\u6240\u6709\u7ef4\u5ea6\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u4e14\u53ef\u901a\u8fc7\u7b80\u5355\u5730\u6309\u6bd4\u4f8b\u7f29\u653e\u6bcf\u4e2a\u7ef4\u5ea6\u6765\u5b9e\u73b0\u8fd9\u79cd\u5e73\u8861\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u590d\u5408\u7f29\u653e\u65b9\u6cd5\u3002","title":"4.10.1.1 \u6458\u8981"},{"location":"tensorFlow/section10/#41012","text":"\u8fd9\u79cd\u590d\u5408\u7f29\u653e\u65b9\u6cd5\u662f\u6709\u610f\u4e49\u7684\uff0c\u56e0\u4e3a\u5982\u679c\u8f93\u5165\u56fe\u50cf\u66f4\u5927\uff0c\u5219\u7f51\u7edc\u9700\u8981\u66f4\u591a\u5c42\u6765\u589e\u52a0\u611f\u77e5\u573a\uff0c\u5e76\u4e14\u9700\u8981\u66f4\u591a\u901a\u9053\u6765\u6355\u83b7\u66f4\u5927\u56fe\u50cf\u4e0a\u7684\u66f4\u7ec6\u7c92\u5ea6\u56fe\u6848\u3002 \u6df1\u5ea6( )\uff1a \u66f4\u6df1\u7684\u7f51\u7edc\u53ef\u4ee5\u6355\u83b7\u66f4\u4e30\u5bcc\u3001\u66f4\u590d\u6742\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u53ef\u4ee5\u5f88\u597d\u5730\u6cdb\u5316\u65b0\u4efb\u52a1\u3002 \u7136\u800c\u7531\u4e8e\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u66f4\u6df1\u5c42\u6b21\u7684\u7f51\u7edc\u4e5f\u66f4\u96be\u8bad\u7ec3\u3002\u867d\u7136\u8df3\u5c42\u8fde\u63a5\u548c\u6279\u91cf\u5f52\u4e00\u5316\u7b49\u53ef\u4ee5\u7f13\u89e3\u8bad\u7ec3\u95ee\u9898\uff0c\u4f46\u975e\u5e38\u6df1\u7684\u7f51\u7edc\u7684\u51c6\u786e\u5ea6\u589e\u76ca\u4f1a\u51cf\u5c11\uff1a\u4f8b\u5982\uff0cResNet-1000\u548cResNet-101\u6709\u76f8\u4f3c\u7cbe\u5ea6\u3002 \u5bbd\u5ea6( )\uff1a\u66f4\u5bbd\u7684\u7f51\u7edc\u5f80\u5f80\u80fd\u591f\u6355\u83b7\u66f4\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u66f4\u5bb9\u6613\u8bad\u7ec3\u3002 \u7136\u800c\uff0c\u6781\u5bbd\u4f46\u6d45\u7684\u7f51\u7edc\u5f80\u5f80\u96be\u4ee5\u6355\u83b7\u66f4\u9ad8\u7ea7\u522b\u7684\u7279\u5f81\u3002 \u5206\u8fa8\u7387( )\uff1a\u4f7f\u7528\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u7f51\u7edc\u53ef\u4ee5\u6355\u83b7\u66f4\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u3002","title":"4.10.1.2 \u539f\u7406\u4ecb\u7ecd"},{"location":"tensorFlow/section10/#1-","text":"\u5bf9\u4e8eConvNet\uff08\u5377\u79ef\u7f51\u7edc\uff09\u7684\u7b2c \u5c42\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u51fd\u6570\uff1a \u3002\u6a21\u578b\u7f29\u653e\u8ddfConvNet\u8bbe\u8ba1\u53bb\u5bfb\u627e\u6700\u4f18\u7ed3\u6784 \u4e0d\u4e00\u6837\uff0c\u6a21\u578b\u7f29\u653e\u662f\u53bb\u5bfb\u627e \u7684\u6700\u4f73\u5bbd\u5ea6 \u3001\u957f\u5ea6 \u548c\u5206\u8fa8\u7387 \uff0c\u901a\u8fc7\u56fa\u5b9a\u4f4f \uff0c\u6a21\u578b\u7f29\u653e\u7b80\u5316\u4e86\u8d44\u6e90\u9650\u5236\u95ee\u9898\u3002\u5728\u7ed9\u5b9a\u8d44\u6e90\u9650\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u53bb\u6700\u5927\u5316\u6a21\u578b\u7684\u7cbe\u5ea6\uff0c\u5c31\u53d8\u6210\u4e86\u4ee5\u4e0b\u4f18\u5316\u95ee\u9898\uff1a 1\u3001\u6700\u4e0a\u65b9\u4e3a\u8981\u4f18\u5316\u7684\u51c6\u786e\u7387 2\u3001\u4e2d\u95f4N\u4ee3\u8868\u4e00\u4e2a\u5b8c\u6574\u5377\u79ef\u7f51\u7edc F_{i}^{L} F_{i}^{L} <span><span class=\"MathJax_Preview\">F_{i}^{L}</span><script type=\"math/tex\">F_{i}^{L} \u8868\u793a\u67d0layerF\u88ab\u91cd\u590d\u4e86L\u6b21\u5728\u5377\u79ef\u7ed3\u6784\u5c42i\u4e2d\uff08\u53ef\u4ee5\u7406\u89e3Resnet\u67d0\u4e2a\u7ed3\u6784\u91cd\u590d\u82e5\u5e72\u6b21\uff09 X X <span><span class=\"MathJax_Preview\">X</span><script type=\"math/tex\">X \u4e3a\u67d0i\u5c42\u7684\u8f93\u5165\u5206\u522b\u4e3aH\uff0cW\uff0cC \u4e0b\u9762\u4e24\u5f20\u56fe\u8868\u793a\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u5f71\u54cd\u548c\u4e09\u4e2a\u7ef4\u5ea6\u7684\u6bd4\u7387\u8c03\u6574\u7684\u5f71\u54cd \u8868\u793a\u6bd4\u8f83\u4e86\u4e0d\u540c\u7f51\u7edc\u6df1\u5ea6\u548c\u5206\u8fa8\u7387\u4e0b\u7684\u5bbd\u5ea6\u7f29\u653e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5728\u4e0d\u6539\u53d8\u6df1\u5ea6\uff08d = 1.0\uff09\u548c\u5206\u8fa8\u7387\uff08r = 1.0\uff09\u7684\u60c5\u51b5\u4e0b\u7f29\u653e\u7f51\u7edc\u5bbd\u5ea6w\uff0c\u5219\u7cbe\u5ea6\u4f1a\u5f88\u5feb\u8fbe\u5230\u9971\u548c\u3002 \u968f\u7740\u66f4\u6df1\uff08d = 2.0\uff09\u548c\u66f4\u9ad8\u5206\u8fa8\u7387\uff08r = 2.0\uff09\uff0c\u5bbd\u5ea6\u7f29\u653e\u5728\u76f8\u540c\u7684FLOPS\u6210\u672c\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u7cbe\u5ea6\u3002","title":"1\u3001\u590d\u5408\u6a21\u578b\u7f29\u653e-\u95ee\u9898\u5efa\u6a21"},{"location":"tensorFlow/section10/#2","text":"\u4f7f\u7528\u4e00\u4e2a\u590d\u5408\u7cfb\u6570 \u4ee5\u539f\u5219\u65b9\u5f0f\u7edf\u4e00\u7f29\u653e\u7f51\u7edc\u5bbd\u5ea6\u3001\u6df1\u5ea6\u548c\u5206\u8fa8\u7387 \u5176\u4e2d \u662f\u53ef\u4ee5\u901a\u8fc7\u5c0f\u7f51\u683c\u641c\u7d22\u786e\u5b9a\u7684\u5e38\u6570\u3002 \u662f\u7528\u6237\u6307\u5b9a\u7684\u7cfb\u6570\uff0c\u63a7\u5236\u6709\u591a\u5c11\u8d44\u6e90\u53ef\u7528\u4e8e\u6a21\u578b\u7f29\u653e\uff0c\u800c \u6307\u5b9a\u5982\u4f55\u5c06\u8fd9\u4e9b\u989d\u5916\u8d44\u6e90\u5206\u914d\u7ed9\u7f51\u7edc\u5bbd\u5ea6\uff0c\u6df1\u5ea6\u548c\u5206\u8fa8\u7387\u3002\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u7ea6\u675f \uff0c\u4f7f\u5f97\u5bf9\u4e8e\u4efb\u4f55\u65b0\u7684 \uff0c\u603bFLOPS\u5c06\u5927\u7ea6\u589e\u52a0 \u3002 \u62d3\u5c55\uff1a\u5e38\u89c4\u5377\u79ef\u8fd0\u7b97\u7684FLOPS\u4e0e \u6210\u6b63\u6bd4\uff0c\u5373\u53cc\u500d\u7f51\u7edc\u6df1\u5ea6\u5c06\u4f7fFLOPS\u52a0\u500d\u3002\u4f46\u7f51\u7edc\u5bbd\u5ea6\u6216\u5206\u8fa8\u7387\u52a0\u500d\u4f1a\u4f7fFLOPS\u589e\u52a0\u56db\u500d\u3002","title":"2\u3001\u65b0\u7684\u590d\u5408\u65b9\u6cd5"},{"location":"tensorFlow/section10/#41013-efficientnet","text":"\u6240\u4ee5\u901a\u8fc7\u4e0a\u9762\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u627e\u5230\u4e86\u4e00\u4e2a\u65b0\u7684baseline\uff08\uff08MBConv\uff09\uff0c\u7c7b\u4f3c\u4e8eMobileNetV2\u548cMnasNet\uff09\u6765\u8bc4\u4f30\uff0c\u79f0\u4e3aEfficientNet-B0\u3002 \u6b65\u9aa41\uff1a\u9996\u5148\u786e\u5b9a\u03c6= 1\uff0c\u5047\u8bbe\u6709\u4e24\u500d\u7684\u53ef\u7528\u8d44\u6e90\uff0c\u5e76\u6839\u636e\u516c\u5f0f2\u548c3\u8fdb\u884c \u7684\u5c0f\u7f51\u683c\u641c\u7d22\u3002\u4f5c\u8005\u627e\u5230\u4e86EfficientNet-B0\u6ee1\u8db3\u7ea6\u675f\u7684\u6700\u4f73\u503c \u6b65\u9aa42\uff1a\u7136\u540e\u6211\u4eec\u5c06 \u56fa\u5b9a\u4e3a\u5e38\u6570\uff0c\u5e76\u4f7f\u7528\u516c\u5f0f3\u6269\u5c55\u5177\u6709\u4e0d\u540c \u7684\u57fa\u7ebf\u7f51\u7edc\uff0c\u4ee5\u83b7\u5f97EfficientNet-B1\u81f3B7\uff08 \u4e5f\u5c31\u662f\u6839\u636e\u81ea\u5df1\u7684\u8ba1\u7b97\u8d44\u6e90\u6765\u9009\u62e9\u5408\u9002\u5927\u5c0f\u7684\u7f51\u7edc \uff09\uff0c\u7ec6\u8282\u5982\u4e0b","title":"4.10.1.3 Efficientnet \u67b6\u6784"},{"location":"tensorFlow/section10/#41014","text":"\u5bf9MobileNets \u548c ResNets\u8fdb\u884c\u7f29\u653e \u8fd9\u4e2a\u590d\u5408\u7f29\u653e\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6240\u6709\u8fd9\u4e9b\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u8868\u660e\u4e86\u7f29\u653e\u65b9\u6cd5\u5bf9\u73b0\u6709\u7684\u5377\u79ef\u7f51\u7edc\u7ed3\u6784\u6709\u6548\u6027\u3002 \u7c7b\u6fc0\u6d3b\u56fe\u8bf4\u660e\u4e86\u5177\u6709\u590d\u5408\u7f29\u653e\u7684\u6a21\u578b\u503e\u5411\u4e8e\u5173\u6ce8\u5177\u6709\u66f4\u591a\u5bf9\u8c61\u7ec6\u8282\u7684\u66f4\u76f8\u5173\u533a\u57df\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u8981\u4e48\u7f3a\u5c11\u5bf9\u8c61\u7ec6\u8282\uff0c\u8981\u4e48\u65e0\u6cd5\u6355\u83b7\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u5bf9\u8c61\u3002 \u5728\u5404\u6bd4\u8d5b\u4e2d\u505a\u8fc1\u79fb\u5b66\u4e60\u5f97\u6210\u5c31 \u4e0e\u516c\u5f00\u53ef\u7528\u6a21\u578b\u76f8\u6bd4\uff0cEfficientNet\u6a21\u578b\u51cf\u5c11\u4e86\u5e73\u57474.7\u500d\uff08\u6700\u591a21\u500d\uff09\u7684\u53c2\u6570\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cbe\u5ea6\u3002 \u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u76f8\u6bd4\uff0cEfficientNet\u6a21\u578b\u57288\u4e2a\u6570\u636e\u96c6\u4e2d\u67095\u4e2a\u4ecd\u7136\u8d85\u8fc7\u4e86\u5b83\u4eec\u7684\u51c6\u786e\u5ea6\uff0c\u4e14\u4f7f\u7528\u7684\u53c2\u6570\u51cf\u5c11\u4e869.6\u500d\u3002 \u6700\u7ec8\u5404\u79cd\u6a21\u578b\u7684\u7cbe\u5ea6 - \u53c2\u6570\u66f2\u7ebf\uff0c\u7ea2\u8272\u4e3aEfficientNet\u7684\u7ed3\u679c\uff0c\u660e\u663e\u6bd4\u5404\u4e2a\u6a21\u578b\u7cbe\u5ea6\u9ad8\uff0c\u53c2\u6570\u91cf\u5c11\u3002 \u6ce8\uff1a\u6700\u7ec8\u7684\u6548\u679c\u6bd4\u7387\uff0c\u90fd\u662f\u5728\u5927\u91cf\u7684\u8bbe\u5907\u548c\u6a21\u578b\u4e0a\u8ba1\u7b97\u5f97\u6765\u7684\uff0c\u8d44\u6e90\u6d88\u8017\u4e0d\u53ef\u60f3\u8c61\u3002Google\u6709\u8db3\u591f\u7684\u8d44\u6e90\u548c\u8bbe\u5907\uff08TPU\uff09\u53bb\u505a\u3002","title":"4.10.1.4 \u5b9e\u9a8c"},{"location":"tensorFlow/section10/#4102-efficientnet","text":"","title":"4.10.2 \u5783\u573e\u5206\u7c7b\u5f00\u6e90EfficientNet\u5b9e\u73b0\u4ecb\u7ecd"},{"location":"tensorFlow/section10/#41021","text":"","title":"4.10.2.1 \u6a21\u578b\u76ee\u5f55"},{"location":"tensorFlow/section10/#tensorflow20-efficientnet","text":"1\u3001\u53ef\u8fc1\u79fb\u5b66\u4e60\u7684TF\u4f4e\u7248\u672c\u80fd\u4f7f\u7528**\uff08\u90e8\u5206\u64cd\u4f5c\u4e0d\u652f\u6301\u9ed8\u8ba4Eager \u6a21\u5f0f\uff09** https://github.com/calmisential/Basic_CNNs_TensorFlow2 \u6211\u4eec\u9009\u62e9\u7684\u662f\u8fd9\u4e2a\u7248\u672c\uff0c\u53ef\u4ee5\u5728\u4e0e\u8bad\u7ec3\u6a21\u578b\u4e0a\u8fc1\u79fb\uff0c\u4f7f\u7528\u7b80\u5355 from efficientnet import EfficientNetB0 EfficientNetB0 ( weights = None , include_top = False , input_shape = ( 336 , 336 , 3 )) 2\u3001TF2.0\u5b9e\u73b0\u7248\u672c\u4e0d\u80fd\u4f7f\u7528\u5728imagenet\u4e0a\u7684\u4e0e\u8bad\u7ec3\u6a21\u578b\uff0c\u7248\u672c\u7b80\u5355\u6613\u61c2\uff0c\u9879\u76ee\u4e2d\u4e5f\u542b\u6709\u5176\u4ed6\u7684\u6a21\u578b https://github.com/Tony607/efficientnet_keras_transfer_learning model.py: \u6a21\u578b\u7684\u4e3b\u7ed3\u6784 \u5176\u4ed6\u6587\u4ef6\u4e3a\u76f8\u5173\u5c01\u88c5\u63a5\u53e3 \u53bb\u5de5\u7a0b\u4e2d\u770b\u770b\u6307\u5b9a\u6a21\u578b\u3002\u5176\u4e2d\u53c2\u6570include_top\uff0c\u6307\u5b9a\u4e86\u6211\u4eec\u53ef\u4ee5\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff1a if include_top : x = KL . GlobalAveragePooling2D ( data_format = global_params . data_format )( x ) if global_params . dropout_rate > 0 : x = KL . Dropout ( global_params . dropout_rate )( x ) x = KL . Dense ( global_params . num_classes , kernel_initializer = DenseKernalInitializer ())( x ) x = KL . Activation ( 'softmax' )( x ) else : if pooling == 'avg' : x = KL . GlobalAveragePooling2D ( data_format = global_params . data_format )( x ) elif pooling == 'max' : x = KL . GlobalMaxPooling2D ( data_format = global_params . data_format )( x )","title":"TensorFlow2.0 \u53ef\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u7684\u5b9e\u73b0\u7248\u672c\u4e0d\u5b58\u5728efficientnet\uff0c\u9700\u8981\u7b2c\u4e09\u65b9\u5b9e\u73b0\u7684\u6a21\u578b\u4e24\u79cd\u9009\u62e9\uff1a"},{"location":"tensorFlow/section10/#4103-trick","text":"","title":"4.10.3 \u4f18\u5316\u7b97\u6cd5\u4ee5\u53ca\u5b66\u4e60\u7387trick"},{"location":"tensorFlow/section10/#41021-rectified-adamadam-with-warm-up","text":"RAdam\u80fd\u6839\u636e\u65b9\u5dee\u5206\u6563\u5ea6\uff0c\u52a8\u6001\u5730\u6253\u5f00\u6216\u8005 \u5173\u95ed\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e0d\u9700\u8981\u53ef \u8c03\u53c2\u6570\u5b66\u4e60\u7387\u9884\u70ed\u7684\u65b9\u6cd5\u3002 \u4e0a\u8ff0\u7ed3\u679c\u8868\u660e\u4f7f\u7528\u539f\u59cbAdam\u5fc5\u987b\u9884\u70ed\uff0c\u5426\u5219\u6b63\u6001\u5206\u5e03\u4f1a\u53d8\u5f97\u626d\u66f2","title":"4.10.2.1 Rectified Adam(Adam with warm up)"},{"location":"tensorFlow/section10/#41022-warmup","text":"\u5b9a\u4e49\uff1a\u5b66\u4e60\u7387\u9884\u70ed\u5c31\u662f\u5728\u521a\u5f00\u59cb\u8bad\u7ec3\u7684\u65f6\u5019\u5148\u4f7f\u7528\u4e00\u4e2a\u8f83\u5c0f\u7684\u5b66\u4e60\u7387\uff0c\u8bad\u7ec3\u4e00\u4e9bepoches\u6216iterations\uff0c\u7b49\u6a21\u578b\u7a33\u5b9a\u65f6\u518d\u4fee\u6539\u4e3a\u9884\u5148\u8bbe\u7f6e\u7684\u5b66\u4e60\u7387\u8fdb\u884c\u8bad\u7ec3\u3002 \u5b66\u4e60\u7387\u662f\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u6700\u91cd\u8981\u7684\u8d85\u53c2\u6570\u4e4b\u4e00\uff0c\u9488\u5bf9\u5b66\u4e60\u7387\u7684\u6280\u5de7\u6709\u5f88\u591a\u3002Warm up\u662f\u5728ResNet\u8bba\u6587\u4e2d\u63d0\u5230\u7684\u4e00\u79cd\u5b66\u4e60\u7387\u9884\u70ed\u7684\u65b9\u6cd5\u3002 \u539f\u56e0\uff1a\u7531\u4e8e\u521a\u5f00\u59cb\u8bad\u7ec3\u65f6\u6a21\u578b\u7684\u6743\u91cd(weights)\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u6b64\u65f6\u9009\u62e9\u4e00\u4e2a\u8f83\u5927\u7684\u5b66\u4e60\u7387\uff0c\u53ef\u80fd\u4f1a\u5e26\u6765\u6a21\u578b\u7684\u4e0d\u7a33\u5b9a\u3002 \u8bba\u6587\u4e2d\u4f7f\u7528\u4e00\u4e2a110\u5c42\u7684ResNet\u5728cifar10\u4e0a\u8bad\u7ec3\u65f6\uff0c\u5148\u75280.01\u7684\u5b66\u4e60\u7387\u8bad\u7ec3\u76f4\u5230\u8bad\u7ec3\u8bef\u5dee\u4f4e\u4e8e80%(\u5927\u6982\u8bad\u7ec3\u4e86400\u4e2aiterations)\uff0c\u7136\u540e\u4f7f\u75280.1\u7684\u5b66\u4e60\u7387\u8fdb\u884c\u8bad\u7ec3\u3002 \u7406\u89e3\uff1a\u521a\u5f00\u59cb\u6a21\u578b\u5bf9\u6570\u636e\u7684\u201c\u5206\u5e03\u201d\u7406\u89e3\u4e3a\u96f6\uff0c\u6216\u8005\u662f\u8bf4\u201c\u5747\u5300\u5206\u5e03\u201d\uff1b\u5728\u7b2c\u4e00\u8f6e\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6bcf\u4e2a\u6570\u636e\u70b9\u5bf9\u6a21\u578b\u6765\u8bf4\u90fd\u662f\u65b0\u7684\uff0c\u6a21\u578b\u4f1a\u5f88\u5feb\u5730\u8fdb\u884c\u6570\u636e\u5206\u5e03\u4fee\u6b63\uff0c\u5982\u679c\u8fd9\u65f6\u5019\u5b66\u4e60\u7387\u5c31\u5f88\u5927\uff0c\u6781\u6709\u53ef\u80fd\u5bfc\u81f4\u5f00\u59cb\u7684\u65f6\u5019\u5c31\u5bf9\u8be5\u6570\u636e\u201c\u8fc7\u62df\u5408\u201d\uff0c\u540e\u9762\u8981\u901a\u8fc7\u591a\u8f6e\u8bad\u7ec3\u624d\u80fd\u62c9\u56de\u6765\uff0c\u6d6a\u8d39\u65f6\u95f4\u3002","title":"4.10.2.2 Warmup"},{"location":"tensorFlow/section10/#41023-cosine-learning-rate-decay","text":"\u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf\u7684\u65b9\u5f0f\uff0cCosine Learning rate decay\u3002\u516c\u5f0f\u5982\u4e0b\uff1a $$ \\eta_t=\\frac{1}{2} (1+cos(\\frac{t\\pi}{T})) $$ \u4e0b\u56fe\u662f\u9010\u6b65\u8870\u51cf\u5b66\u4e60\u7387\u4e0e\u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf\u7684\u65b9\u5f0f\u5bf9\u6bd4\uff1a \u73b0\u8c61\uff1a\u5f53Step Decay\u65b9\u6cd5\u7684\u5b66\u4e60\u7387\u5df2\u7ecf\u8f83\u5c0f\u7684\u65f6\u5019\uff0cCos Decay\u65b9\u6cd5\u7684\u5b66\u4e60\u4ecd\u6bd4\u8f83\u5927\uff0c\u56e0\u800c\u80fd\u591f\u52a0\u901f\u6574\u4e2a\u8bad\u7ec3\u7684\u8fc7\u7a0b\u3002\u4f46\u662f\u770b\u56fe\u4e2db\uff0c\u5f88\u660e\u663eStep Decay\u518d\u8870\u51cf\u4e4b\u540e\uff0c\u51c6\u786e\u7387\u5c31\u4e0a\u6765\u4e86\uff0c\u8bf4\u660e\u8870\u51cf\u4e4b\u524d\u7684\u6570\u91cf\u7ea7\u6548\u7528\u5df2\u7ecf\u4e0d\u5f3a\u4e86\uff0c\u8fd9\u4e2a\u65f6\u5019Cos decay\u8fd8\u662f\u90a3\u4e2a\u6570\u91cf\u7ea7\uff0c\u6240\u4ee5\u901f\u5ea6\u5c31\u6bd4Step Decay\u6162\u4e86 \u7ed3\u679c\uff1a 1\u3001cos\u7684\u5b66\u4e60\u7387\u7684\u524d\u671f\u662fwarm-up\u9636\u6bb5\uff0c\u8fd9\u4e2a\u65f6\u5019\u662f\u4ee5\u7ebf\u6027\u589e\u957f\u7684\u65b9\u5f0f\u589e\u957f\u5230\u521d\u59cb\u5b66\u4e60\u7387\uff0c\u7136\u540e\u5f00\u59cb\u6267\u884ccos\u7684\u5b66\u4e60\u7387\u53d8\u5316\uff0c\u6700\u7ec8\u4e24\u79cd\u5b66\u4e60\u7387\u8fbe\u5230\u4e00\u81f4\u3002 \u4ece\u51c6\u786e\u6027\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u4f7f\u7528step\u7684\u65b9\u5f0f\u4f3c\u4e4e\u5b66\u4e60\u7684\u66f4\u5feb\u4e00\u4e9b\u3002\u800c\u4e14\u5176\u53d8\u5316\u7684\u62d0\u70b9\u548c\u5176\u5b66\u4e60\u7387\u7684\u62d0\u70b9\u662f\u5bf9\u5e94\u7740\u7684\uff0c\u5373\u5b66\u4e60\u7387\u964d\u4e86\u4e4b\u540e\uff0c\u9a8c\u8bc1\u7684\u51c6\u786e\u6027\u4e5f\u8ddf\u7740\u5f00\u59cb\u63d0\u5347\uff0c\u800ccos\u5b66\u4e60\u7387\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u51c6\u786e\u6027\u90fd\u5f88\u5e73\u7a33\uff0c\u6700\u7ec8\u4e24\u8005\u7684\u51c6\u786e\u6027\u4e5f\u662f\u4e00\u81f4\u3002 2\u3001\u533a\u522b\u5728\u4e8e\u4e2d\u95f4\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u800c\u4e14step\u7684\u65b9\u5f0f\u6709\u4e00\u5b9a\u7684\u968f\u673a\u6027\uff0c\u4e0d\u77e5\u9053\u8981\u4ee5\u591a\u5927\u7684step\u6765\u6539\u53d8\u5b66\u4e60\u7387\uff0c\u5982\u679c\u8fd9\u4e2a\u2019step\u2019\u53ef\u4ee5\u6839\u636e\u67d0\u79cd\u65b9\u5f0f\u91cf\u5316 \u5b9a\u4e49\uff1a\u5e38\u7528\u7684Learning Rate Decay\u662fStep Decay\uff0c\u5373\u6bcf\u9694N\u4e2aEpoch\uff0clearning rate\u4e58\u4e0a\u4e00\u4e2a\u56fa\u5b9adecay\u7cfb\u6570\u3002 \u4f46\u662fStep Decay\u4e0d\u597d\u7684\u5730\u65b9\u5728\u4e8e\u5b66\u4e60\u7387\u8870\u51cf\u7684\u65f6\u5019\uff0c\u8df3\u8dc3\u53d8\u5316\u8f83\u5927\uff0c\u5e26\u6765\u4e86\u8f83\u5927\u7684\u51b2\u91cfMomentum","title":"4.10.2.3 \u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf\uff08Cosine Learning rate decay\uff09"},{"location":"tensorFlow/section10/#41024-tensorflow","text":"Keras \u7684 callbacks \u4e2d\u6709 ReduceLROnPlateau() \u548c LearningRateScheduler() \u51fd\u6570\u53ef\u4ee5\u52a8\u6001\u7684\u8c03\u6574\u5b66\u4e60\u7387\u3002\u4f46\u662f\u524d\u8005\u53ea\u5728\u9a8c\u8bc1\u8bef\u5dee\u505c\u6b62\u8870\u51cf\u7684\u65f6\u5019\u51cf\u5c0f\u5b66\u4e60\u7387\uff0c\u540e\u8005\u53ea\u80fd\u5728\u6bcf\u4e2a Epoch \u5f00\u59cb\u6216\u7ed3\u675f\u7684\u65f6\u5019\uff0c\u6539\u53d8\u5b66\u4e60\u7387\u4e24\u8005\u4f7f\u7528\u53c2\u8003\u6587\u6863\uff1a https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler#class_learningratescheduler \u5982\u679c\u9700\u8981\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u6bcf\u6279\u6b21\u66f4\u52a0\u7ec6\u81f4\u7684\u63a7\u5236\u5b66\u4e60\u7387\uff0c\u9700\u8981\u81ea\u5b9a\u4e49\u56de\u8c03\u65b9\u6cd5","title":"4.10.2.4 TensorFlow\u5b9e\u73b0"},{"location":"tensorFlow/section10/#1tfkerascallbackscallback","text":"\u8be5\u7c7b\u5728 Model \u7684 .fit() \u65b9\u6cd5\u4e2d\u4f1a\u8c03\u7528\u4e00\u4e0b\u56de\u8c03\u65b9\u6cd5 on_batch_begin( batch, logs=None) \u4e00\u6279\u6b21\u6570\u636e\u5f00\u59cb\u65f6\u7684\u5904\u7406 on_batch_end(batch, logs=None) \u4e00\u6279\u6b21\u6570\u636e\u5904\u7406\u7ed3\u675f on_epoch_begin\u548con_epoch_end","title":"1\u3001tf.keras.callbacks.Callback"},{"location":"tensorFlow/section10/#4103-warmup","text":"","title":"4.10.3 \u5783\u573e\u5206\u7c7b\u5e26\u6709warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8c03\u5ea6\u5b9e\u73b0"},{"location":"tensorFlow/section10/#41031","text":"\u5206\u4e3a\u4e24\u4e2a\u7ed3\u7b97 warmup\u9636\u6bb5 \u4f59\u5f26\u9000\u706b\u9636\u6bb5","title":"4.10.3.1 \u6d41\u7a0b\u5206\u6790"},{"location":"tensorFlow/section10/#41032","text":"\u53c2\u8003\u6587\u4ef6\uff0c\u5e76\u8fd0\u884c\u6d4b\u8bd5 \u6b65\u9aa4\uff1a 1\u3001\u81ea\u5b9a\u4e49WarmUpCosineDecayScheduler\u8c03\u5ea6\u5668\uff0c\u5b9e\u73b0\u6279\u6b21\u524d\u540e\u7684\u5904\u7406\u903b\u8f91 2\u3001\u5b9e\u73b0warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97\u65b9\u6cd5 1\u3001\u81ea\u5b9a\u4e49WarmUpCosineDecayScheduler\u8c03\u5ea6\u5668\uff0c\u5b9e\u73b0\u6279\u6b21\u524d\u540e\u7684\u5904\u7406\u903b\u8f91 import numpy as np import tensorflow as tf from tensorflow.keras import backend as K from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" class WarmUpCosineDecayScheduler ( tf . keras . callbacks . Callback ): \"\"\"\u5e26\u6709warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8c03\u5ea6 \"\"\" def __init__ ( self , learning_rate_base , total_steps , global_step_init = 0 , warmup_learning_rate = 0.0 , warmup_steps = 0 , hold_base_rate_steps = 0 , verbose = 0 ): \"\"\" \u521d\u59cb\u5316\u53c2\u6570 :param learning_rate_base: \u57fa\u7840\u5b66\u4e60\u7387 :param total_steps: \u603b\u5171\u8fed\u4ee3\u7684\u6279\u6b21\u6b65\u6570 epoch * num_samples / batch_size :param global_step_init: \u521d\u59cb :param warmup_learning_rate: \u9884\u70ed\u5b66\u4e60\u7387\u9ed8\u8ba40.0 :param warmup_steps:\u9884\u70ed\u7684\u6b65\u6570\u9ed8\u8ba40 :param hold_base_rate_steps: :param verbose: \"\"\" super ( WarmUpCosineDecayScheduler , self ) . __init__ () self . learning_rate_base = learning_rate_base self . total_steps = total_steps self . global_step = global_step_init self . warmup_learning_rate = warmup_learning_rate self . warmup_steps = warmup_steps self . hold_base_rate_steps = hold_base_rate_steps # \u662f\u5426\u5728\u6bcf\u6b21\u8bad\u7ec3\u7ed3\u675f\u6253\u5370\u5b66\u4e60\u7387 self . verbose = verbose # \u8bb0\u5f55\u6240\u6709\u6279\u6b21\u4e0b\u6765\u7684\u6bcf\u6b21\u51c6\u786e\u7684\u5b66\u4e60\u7387\uff0c\u53ef\u4ee5\u7528\u4e8e\u6253\u5370\u663e\u793a self . learning_rates = [] def on_batch_end ( self , batch , logs = None ): # 1\u3001\u6279\u6b21\u5f00\u59cb\u524d\u5f53\u524d\u6b65\u6570+1 self . global_step = self . global_step + 1 # 2\u3001\u83b7\u53d6\u4f18\u5316\u5668\u4e0a\u4e00\u6b21\u7684\u5b66\u4e60\u7387\uff0c\u5e76\u8bb0\u5f55 lr = K . get_value ( self . model . optimizer . lr ) self . learning_rates . append ( lr ) def on_batch_begin ( self , batch , logs = None ): # 1\u3001\u901a\u8fc7\u53c2\u6570\u4ee5\u53ca\u8bb0\u5f55\u7684\u6b21\u6570\u548c\u4e0a\u6b21\u5b66\u4e60\u7387 lr = cosine_decay_with_warmup ( global_step = self . global_step , learning_rate_base = self . learning_rate_base , total_steps = self . total_steps , warmup_learning_rate = self . warmup_learning_rate , warmup_steps = self . warmup_steps , hold_base_rate_steps = self . hold_base_rate_steps ) # 2\u3001\u8bbe\u7f6e\u4f18\u5316\u5668\u672c\u6b21\u7684\u5b66\u4e60\u7387 K . set_value ( self . model . optimizer . lr , lr ) if self . verbose > 0 : print ( ' \\n \u6279\u6b21\u6570 %05d : \u8bbe\u7f6e\u5b66\u4e60\u7387\u4e3a' ' %s .' % ( self . global_step + 1 , lr )) \u8fd9\u91cc\u9762\u6d89\u53ca\u5230\u4e00\u4e2a\u8bbe\u7f6e\u5f53\u524d\u4f18\u5316\u5668\u5b66\u4e60\u7387\u7684\u4f7f\u7528\uff0c\u4f1a\u7528\u5230keras.backend\u8fd9\u4e2a\u6a21\u5757\u3002keras\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u5757\u7684\u9ad8\u7ea7\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u6846\u67b6\uff0c\u5b83\u5e76\u6ca1\u6709\u4ec5\u4f9d\u8d56\u4e8e\u67d0\u4e00\u79cd\u9ad8\u901f\u5e95\u5c42\u5f20\u91cf\u5e93\uff0c\u800c\u662f\u5bf9\u5404\u79cd\u5e95\u5c42\u5f20\u91cf\u5e93\u8fdb\u884c\u9ad8\u5c42\u6a21\u5757\u5c01\u88c5\uff0c\u8ba9\u5e95\u5c42\u5e93\u5b8c\u6210\u8bf8\u5982\u5f20\u91cf\u79ef\u3001\u5377\u79ef\u64cd\u4f5c\u3002\u5728keras\u4e2d\uff0c\u5404\u79cd\u5e95\u5c42\u5e93\uff08Google\u5f00\u53d1\u7684TensorFlow\u3001\u8499\u7279\u5229\u5c14\u5927\u5b66\u5b9e\u9a8c\u5ba4\u5f00\u53d1\u7684Theano\u3001\u5fae\u8f6f\u5f00\u53d1\u7684CNTK\uff09\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u540e\u7aef\uff08backend\uff09\u5f15\u64ce\u4e3akeras\u6a21\u5757\u63d0\u4f9b\u670d\u52a1\u3002","title":"4.10.3.2 \u5b8c\u6574\u4ee3\u7801\u8fc7\u7a0b\u5b9e\u73b0"},{"location":"tensorFlow/section10/#kerasbackend","text":"\uff081\uff09\u901a\u8fc7\u4fee\u6539keras\u914d\u7f6e\u6587\u4ef6\u6765\u4fee\u6539backend \u4e00\u65e6\u8fd0\u884c\u8fc7\u4e00\u6b21Keras\uff0c\u5c31\u4f1a\u5728$HOME/.keras\u4e0b\u751f\u6210\u914d\u7f6e\u6587\u4ef6keras.json\uff0c\u8be5\u6587\u4ef6\u7684\"backend\"\u5b57\u6bb5\u7684\u503c\u5373\u4e3akeras\u6240\u4f7f\u7528\u7684\u540e\u7aef\u5e93\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8be5\u503c\u4e3a\"tensorflow\"\u3002\u7528\u6237\u53ef\u4ee5\u6839\u636e\u9700\u8981\u9009\u62e9\u53e6\u5916\u4e24\u4e2a\u5e93\"theano\"\u3001\"cntk\"\uff0c\u751a\u81f3\u81ea\u5df1\u5199\u7684\u5e95\u5c42\u5e93\u3002 \uff082\uff09\u901a\u8fc7\u8fd0\u884cPython\u811a\u672c\u65f6\u589e\u52a0\u914d\u7f6e\u9879\u6307\u5b9abackend $ KERAS_BACKEND = theano python -c \"from keras import backend\" Using Theano backend. \u5bfc\u5165\u4f7f\u7528\uff1a from keras import backend as K \u5176\u4e2d\u4e24\u4e2a\u65b9\u6cd5\u53ef\u4ee5\u8bbe\u7f6e\u5f20\u91cf\u7684\u503c\uff1a lr = K . get_value ( self . model . optimizer . lr ) K . set_value ( self . model . optimizer . lr , lr )","title":"\u95ee\u9898\uff1a\u5982\u4f55\u4fee\u6539Keras\u4f7f\u7528\u7684backend"},{"location":"tensorFlow/section10/#2warmup","text":"\u6b65\u9aa4\uff1a 1\u3001\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97 2\u3001warmup\u4e4b\u540e\u7684\u5b66\u4e60\u7387\u8ba1\u7b97 \u5982\u679c\u9884\u7559\u5927\u4e8e0\uff0c\u5224\u65ad\u76ee\u524d\u6b65\u6570\u662f\u5426 > warmup\u6b65\u6570+\u9884\u7559\u6b65\u6570\uff0c\u662f\u7684\u8bdd\u8fd4\u56de\u521a\u624d\u4e0a\u9762\u8ba1\u7b97\u7684\u5b66\u4e60\u7387\uff0c\u4e0d\u662f\u7684\u8bdd\u4f7f\u7528warmup\u4e4b\u540e\u7684\u57fa\u7840\u5b66\u4e60\u7387 3\u3001warmup\u5b66\u4e60\u7387\u8ba1\u7b97\uff0c\u5e76\u5224\u65ad\u5927\u5c0f 4\u3001\u5982\u679c\u6700\u540e\u5f53\u524d\u5230\u8fbe\u7684\u6b65\u6570\u5927\u4e8e\u603b\u6b65\u6570\uff0c\u5219\u5f520\uff0c\u5426\u5219\u8fd4\u56de\u5f53\u524d\u7684\u8ba1\u7b97\u51fa\u6765\u7684\u5b66\u4e60\u7387\uff08\u53ef\u80fd\u662fwarmup\u5b66\u4e60\u7387\u4e5f\u53ef\u80fd\u662f\u4f59\u5f26\u8870\u51cf\u7ed3\u679c\uff09 \u4ee3\u7801\u5982\u4e0b def cosine_decay_with_warmup ( global_step , learning_rate_base , total_steps , warmup_learning_rate = 0.0 , warmup_steps = 0 , hold_base_rate_steps = 0 ): \"\"\" \u6bcf\u6279\u6b21\u5e26\u6709warmup\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97 :param global_step: \u5f53\u524d\u5230\u8fbe\u7684\u6b65\u6570 :param learning_rate_base: warmup\u4e4b\u540e\u7684\u57fa\u7840\u5b66\u4e60\u7387 :param total_steps: \u603b\u9700\u8981\u6279\u6b21\u6570 :param warmup_learning_rate: warmup\u5f00\u59cb\u7684\u5b66\u4e60\u7387 :param warmup_steps:warmup\u5b66\u4e60\u7387 \u6b65\u6570 :param hold_base_rate_steps: \u9884\u7559\u603b\u6b65\u6570\u548cwarmup\u6b65\u6570\u95f4\u9694 :return: \"\"\" if total_steps < warmup_steps : raise ValueError ( '\u603b\u6b65\u6570\u5fc5\u987b\u5927\u4e8ewarmup' ) # 1\u3001\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97 # \u4ecewarmup\u7ed3\u675f\u4e4b\u540e\u8ba1\u7b97 # 0.5 * 0.01 * (1 + cos(pi*(1-5-0)/(10 - 5 - 0)) learning_rate = 0.5 * learning_rate_base * ( 1 + np . cos ( np . pi * ( global_step - warmup_steps - hold_base_rate_steps ) / float ( total_steps - warmup_steps - hold_base_rate_steps ))) # 2\u3001warmup\u4e4b\u540e\u7684\u5b66\u4e60\u7387\u8ba1\u7b97 # \u5982\u679c\u9884\u7559\u5927\u4e8e0\uff0c\u5224\u65ad\u76ee\u524d\u6b65\u6570\u662f\u5426 > warmup\u6b65\u6570+\u9884\u7559\u6b65\u6570\uff0c\u662f\u7684\u8bdd\u8fd4\u56de\u521a\u624d\u4e0a\u9762\u8ba1\u7b97\u7684\u5b66\u4e60\u7387\uff0c\u4e0d\u662f\u7684\u8bdd\u4f7f\u7528warmup\u4e4b\u540e\u7684\u57fa\u7840\u5b66\u4e60\u7387 if hold_base_rate_steps > 0 : learning_rate = np . where ( global_step > warmup_steps + hold_base_rate_steps , learning_rate , learning_rate_base ) # 3\u3001warmup\u6b65\u6570\u662f\u5927\u4e8e0\u7684 if warmup_steps > 0 : if learning_rate_base < warmup_learning_rate : raise ValueError ( 'warmup\u540e\u5b66\u4e60\u7387\u5fc5\u987b\u5927\u4e8ewarmup\u5f00\u59cb\u5b66\u4e60\u7387' ) # 1\u3001\u8ba1\u7b97\u4e00\u4e2a0.01\u548c0.000006\u7684\u5dee\u8ddd/warmup_steps\uff0c\u5f97\u5230warmup\u7ed3\u675f\u524d\u589e\u52a0\u591a\u5c11 slope = ( learning_rate_base - warmup_learning_rate ) / warmup_steps # 2\u3001\u8ba1\u7b97warmup\u4e0b\u4e00\u6b65\u7b2cglobal_step\u7684\u5b66\u4e60\u7387 warmup_rate = slope * global_step + warmup_learning_rate # 3\u3001\u5224\u65adglobal_step\u5c0f\u4e8ewarmup_steps\u7684\u8bdd\uff0c\u8fd4\u56de\u8fd9\u4e2awarmup\u5f53\u65f6\u7684\u5b66\u4e60\u7387\uff0c\u5426\u5219\u76f4\u63a5\u8fd4\u56de\u4f59\u5f26\u9000\u706b\u8ba1\u7b97\u7684 learning_rate = np . where ( global_step < warmup_steps , warmup_rate , learning_rate ) # 4\u3001\u5982\u679c\u6700\u540e\u5f53\u524d\u5230\u8fbe\u7684\u6b65\u6570\u5927\u4e8e\u603b\u6b65\u6570\uff0c\u5219\u5f520\uff0c\u5426\u5219\u8fd4\u56de\u5f53\u524d\u7684\u8ba1\u7b97\u51fa\u6765\u7684\u5b66\u4e60\u7387\uff08\u53ef\u80fd\u662fwarmup\u5b66\u4e60\u7387\u4e5f\u53ef\u80fd\u662f\u4f59\u5f26\u8870\u51cf\u7ed3\u679c\uff09 return np . where ( global_step > total_steps , 0.0 , learning_rate ) \u901a\u8fc7\u4ee5\u4e0b\u4ee3\u7801\u8fdb\u884c\u6d4b\u8bd5\uff1a if __name__ == '__main__' : # 1\u3001\u521b\u5efa\u6a21\u578b model = Sequential () model . add ( Dense ( 32 , activation = 'relu' , input_dim = 100 )) model . add ( Dense ( 10 , activation = 'softmax' )) model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # 2\u3001\u53c2\u6570\u8bbe\u7f6e sample_count = 1000 # \u6837\u672c\u6570 epochs = 4 # \u603b\u8fed\u4ee3\u6b21\u6570 warmup_epoch = 3 # warmup \u8fed\u4ee3\u6b21\u6570 batch_size = 16 # \u6279\u6b21\u5927\u5c0f learning_rate_base = 0.0001 # warmup\u540e\u7684\u521d\u59cb\u5b66\u4e60\u7387 total_steps = int ( epochs * sample_count / batch_size ) # \u603b\u8fed\u4ee3\u6279\u6b21\u6b65\u6570 warmup_steps = int ( warmup_epoch * sample_count / batch_size ) # warmup\u603b\u6279\u6b21\u6570 # 3\u3001\u521b\u5efa\u6d4b\u8bd5\u6570\u636e data = np . random . random (( sample_count , 100 )) labels = np . random . randint ( 10 , size = ( sample_count , 1 )) # \u8f6c\u6362\u76ee\u6807\u7c7b\u522b one_hot_labels = tf . keras . utils . to_categorical ( labels , num_classes = 10 ) # 5\u3001\u521b\u5efa\u4f59\u5f26warmup\u8c03\u5ea6\u5668 warm_up_lr = WarmUpCosineDecayScheduler ( learning_rate_base = learning_rate_base , total_steps = total_steps , warmup_learning_rate = 4e-06 , # warmup\u5f00\u59cb\u5b66\u4e60\u7387 warmup_steps = warmup_steps , hold_base_rate_steps = 0 , ) # \u8bad\u7ec3\u6a21\u578b model . fit ( data , one_hot_labels , epochs = epochs , batch_size = batch_size , verbose = 0 , callbacks = [ warm_up_lr ]) print ( warm_up_lr . learning_rates ) \u7ed3\u679c\uff1a [ 4e-06 , 4.513369e-06 , .... , 7.281053e-05 , 7.0564354e-05 , 6.826705e-05 , 6.592433e-05 , 6.354202e-05 , 6.112605e-05 , 5.868241e-05 , 5.6217184e-05 , 5.3736505e-05 , 5.1246534e-05 , 4.8753467e-05 , 4.6263496e-05 , 4.3782813e-05 , 4.131759e-05 , 3.8873954e-05 , 3.6457976e-05 , 3.4075667e-05 , 3.173295e-05 , 2.9435645e-05 , 2.7189468e-05 , 2.5e-05 , 2.2872688e-05 , 2.0812817e-05 , 1.882551e-05 , 1.6915708e-05 , 1.5088159e-05 , 1.3347407e-05 , 1.1697778e-05 , 1.0143374e-05 , 8.688061e-06 , 7.335456e-06 , 6.0889215e-06 , 4.9515565e-06 , 3.9261895e-06 , 3.015369e-06 , 2.2213596e-06 , 1.5461356e-06 , 9.913756e-07 , 5.584587e-07 , 2.4846122e-07 , 6.215394e-08 , 0.0 , 0.0 ]","title":"2\u3001\u5b9e\u73b0warmup\u7684\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u8ba1\u7b97\u65b9\u6cd5"},{"location":"tensorFlow/section10/#4104","text":"\u6b65\u9aa4\uff1a 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 \u6a21\u578b\u4fee\u6539 \u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u5668\u6307\u5b9a 3\u3001\u6307\u5b9a\u8bad\u7ec3\u7684callbacks\uff0c\u5e76\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3 4\u3001\u8bad\u7ec3\u6307\u5b9a \u5176\u4e2d\u4ee3\u7801\u8fd0\u884c\u903b\u8f91 if __name__ == '__main__' : args = parser . parse_args () train_model ( args ) \u53c2\u6570\u6307\u5b9a\u4f7f\u7528argparse\u5de5\u5177\uff1apip install argparse parser = argparse . ArgumentParser () parser . add_argument ( \"data_url\" , type = str , default = './data/garbage_classify/train_data' , help = \"data dir\" , nargs = '?' ) parser . add_argument ( \"train_url\" , type = str , default = './garbage_ckpt/' , help = \"save model dir\" , nargs = '?' ) parser . add_argument ( \"num_classes\" , type = int , default = 40 , help = \"num_classes\" , nargs = '?' ) parser . add_argument ( \"input_size\" , type = int , default = 300 , help = \"input_size\" , nargs = '?' ) parser . add_argument ( \"batch_size\" , type = int , default = 16 , help = \"batch_size\" , nargs = '?' ) parser . add_argument ( \"learning_rate\" , type = float , default = 0.0001 , help = \"learning_rate\" , nargs = '?' ) parser . add_argument ( \"max_epochs\" , type = int , default = 30 , help = \"max_epochs\" , nargs = '?' ) parser . add_argument ( \"deploy_script_path\" , type = str , default = '' , help = \"deploy_script_path\" , nargs = '?' ) parser . add_argument ( \"test_data_url\" , type = str , default = '' , help = \"test_data_url\" , nargs = '?' ) \u5176\u4e2dnargs\u662f\u4e3a\u4e86\u5728pycharm\u4e2d\u8fd0\u884c\u65f6\uff0c\u4e0d\u8f93\u5165\u547d\u4ee4\u884c\u53c2\u6570\u503c\u4e5f\u80fd\u76f4\u63a5\u8fd0\u884c\u3002\u5426\u5219\u9700\u8981\u547d\u4ee4\u884c\u8fd0\u884c python train . py data_url ..... 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence import multiprocessing import numpy as np import argparse import tensorflow as tf from tensorflow.keras.callbacks import TensorBoard , Callback from tensorflow.keras.layers import Dense , GlobalAveragePooling2D from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam , RMSprop from efficientnet import model as EfficientNet from data_gen import data_from_sequence from utils.lr_scheduler import WarmUpCosineDecayScheduler import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" # \u6ce8\u610f\u5173\u95ed\u9ed8\u8ba4\u7684eager\u6a21\u5f0f tf . compat . v1 . disable_eager_execution () def train_model ( param ): \"\"\"\u8bad\u7ec3\u6a21\u578b :param param: \u4f20\u5165\u7684\u547d\u4ee4\u53c2\u6570 :return: \"\"\" # 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence train_sequence , validation_sequence = data_from_sequence ( param . data_url , param . batch_size , param . num_classes , param . input_size ) 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 # 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 model = model_fn ( param ) optimizer = Adam ( lr = param . learning_rate ) objective = 'categorical_crossentropy' metrics = [ 'accuracy' ] # \u6a21\u578b\u4fee\u6539 # \u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u5668\u6307\u5b9a model . compile ( loss = objective , optimizer = optimizer , metrics = metrics ) model . summary () # \u5224\u65ad\u6a21\u578b\u662f\u5426\u52a0\u8f7d\u5386\u53f2\u6a21\u578b if os . path . exists ( param . train_url ): filenames = os . listdir ( param . train_url ) model . load_weights ( filenames [ - 1 ]) print ( \"\u52a0\u8f7d\u5b8c\u6210!!!\" ) def model_fn ( param ): \"\"\"\u8fc1\u79fb\u5b66\u4e60\u4fee\u6539\u6a21\u578b\u51fd\u6570 :param param: :return: \"\"\" base_model = EfficientNet . EfficientNetB3 ( include_top = False , input_shape = ( param . input_size , param . input_size , 3 ), classes = param . num_classes ) x = base_model . output x = GlobalAveragePooling2D ( name = 'avg_pool' )( x ) predictions = Dense ( param . num_classes , activation = 'softmax' )( x ) model = Model ( inputs = base_model . input , outputs = predictions ) return model 3\u3001\u6307\u5b9a\u8bad\u7ec3\u7684callbacks\uff0c\u5e76\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3 sample_count = len ( train_sequence ) * param . batch_size epochs = param . max_epochs warmup_epoch = 5 batch_size = param . batch_size learning_rate_base = param . learning_rate total_steps = int ( epochs * sample_count / batch_size ) warmup_steps = int ( warmup_epoch * sample_count / batch_size ) warm_up_lr = WarmUpCosineDecayScheduler ( learning_rate_base = learning_rate_base , total_steps = total_steps , warmup_learning_rate = 0 , warmup_steps = warmup_steps , hold_base_rate_steps = 0 , ) #\uff083\uff09\u6a21\u578b\u4fdd\u5b58\u76f8\u5173\u53c2\u6570 check = tf . keras . callbacks . ModelCheckpoint ( param . train_url + 'weights_{epoch:02d}-{val_accuracy:.2f}.h5' , monitor = 'val_accuracy' , save_best_only = True , save_weights_only = False , mode = 'auto' , period = 1 ) 4\u3001\u8bad\u7ec3 \u8fd9\u91cc\u4f7f\u7528model.fit_generator\u51fd\u6570\uff0c\u56e0\u4e3a\u586b\u5165\u53c2\u6570\u7684\u662f\u4e00\u4e2a\u8fed\u4ee3\u5e8f\u5217\uff0c\u6307\u5b9a\u5de5\u4f5c\u7ebf\u7a0b\u6570(multiprocessing.cpu_count() * 0.7\u3002 model . fit_generator ( train_sequence , steps_per_epoch = int ( sample_count / batch_size ), epochs = param . max_epochs , verbose = 1 , callbacks = [ check , tensorboard , warm_up_lr ], validation_data = validation_sequence , max_queue_size = 10 , workers = int ( multiprocessing . cpu_count () * 0.7 ), use_multiprocessing = True , shuffle = True )","title":"4.10.4 \u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u5b9e\u73b0"},{"location":"tensorFlow/section10/#4105","text":"EfficientNet\u6a21\u578b\u539f\u7406 warmup\u4ee5\u53ca\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387\u539f\u7406 \u5b8c\u6210\u5783\u573e\u5206\u7c7b\u7684\u8bad\u7ec3\u8fc7\u7a0b \u5b8c\u6210\u4f59\u5f26\u9000\u706b\u4e0ewarmup\u7684\u5b9e\u73b0","title":"4.10.5 \u603b\u7ed3"},{"location":"tensorFlow/section11/","text":"4.11 \u7efc\u5408\u6848\u4f8b\uff1a\u6a21\u578b\u5bfc\u51fa\u4e0e\u90e8\u7f72 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1TensorFlow\u6a21\u578b\u7684\u5bfc\u51fa(saved_model\u683c\u5f0f) \u638c\u63e1Tensorflow\u6a21\u578b\u7684\u90e8\u7f72 \u638c\u63e1TensorFlow\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u8c03\u7528 \u638c\u63e1TensorFlow\u6a21\u578b\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u4f7f\u7528 \u5e94\u7528 \u65e0 4.11.1 TensorFlow \u6a21\u578b\u5bfc\u51fa \u00b6 \u5728\u90e8\u7f72\u6a21\u578b\u65f6\uff0c\u6211\u4eec\u7684\u7b2c\u4e00\u6b65\u5f80\u5f80\u662f\u5c06\u8bad\u7ec3\u597d\u7684\u6574\u4e2a\u6a21\u578b\u5b8c\u6574\u5bfc\u51fa\u4e3a\u4e00\u7cfb\u5217\u6807\u51c6\u683c\u5f0f\u7684\u6587\u4ef6\uff0c\u7136\u540e\u5373\u53ef\u5728\u4e0d\u540c\u7684\u5e73\u53f0\u4e0a\u90e8\u7f72\u6a21\u578b\u6587\u4ef6\u3002\u8fd9\u65f6\uff0cTensorFlow \u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86 SavedModel \u8fd9\u4e00\u683c\u5f0f\u3002 \u4e0e\u524d\u9762\u4ecb\u7ecd\u7684 Checkpoint \u4e0d\u540c\uff0cSavedModel \u5305\u542b\u4e86\u4e00\u4e2a TensorFlow \u7a0b\u5e8f\u7684\u5b8c\u6574\u4fe1\u606f\uff1a \u4e0d\u4ec5\u5305\u542b\u53c2\u6570\u7684\u6743\u503c\uff0c\u8fd8\u5305\u542b\u8ba1\u7b97\u7684\u6d41\u7a0b\uff08\u5373\u8ba1\u7b97\u56fe\uff09 \u3002 \u7279\u70b9\uff1a\u5f53\u6a21\u578b\u5bfc\u51fa\u4e3a SavedModel \u6587\u4ef6\u65f6\uff0c\u65e0\u9700\u5efa\u7acb\u6a21\u578b\u7684\u6e90\u4ee3\u7801\u5373\u53ef\u518d\u6b21\u8fd0\u884c\u6a21\u578b\uff0c\u8fd9\u4f7f\u5f97 SavedModel \u5c24\u5176\u9002\u7528\u4e8e\u6a21\u578b\u7684\u5206\u4eab\u548c\u90e8\u7f72\u3002\u540e\u6587\u7684 TensorFlow Serving\uff08\u670d\u52a1\u5668\u7aef\u90e8\u7f72\u6a21\u578b\uff09\u3001TensorFlow Lite\uff08\u79fb\u52a8\u7aef\u90e8\u7f72\u6a21\u578b\uff09\u4ee5\u53ca TensorFlow.js \u90fd\u4f1a\u7528\u5230\u8fd9\u4e00\u683c\u5f0f\u3002 \u9664\u4e86CheckPointTensorFlow\u8fd8\u4f1a\u6709\u5176\u4ed6\u683c\u5f0f\uff0c\u8fd9\u91cc\u505a\u7edf\u4e00\u4ecb\u7ecd\uff1a\u90e8\u7f72\u5728\u7ebf\u670d\u52a1\uff08Serving\uff09\u65f6\u5b98\u65b9\u63a8\u8350\u4f7f\u7528 SavedModel \u683c\u5f0f\uff0c\u800c\u90e8\u7f72\u5230\u624b\u673a\u7b49\u79fb\u52a8\u7aef\u7684\u6a21\u578b\u4e00\u822c\u4f7f\u7528 FrozenGraphDef \u683c\u5f0f\uff08\u6700\u8fd1\u63a8\u51fa\u7684 TensorFlow Lite \u4e5f\u6709\u4e13\u95e8\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\u683c\u5f0f *.lite\uff0c\u548c FrozenGraphDef \u5341\u5206\u7c7b\u4f3c\uff09\u3002\u8fd9\u4e9b\u683c\u5f0f\u4e4b\u95f4\u5173\u7cfb\u5bc6\u5207\uff0c\u53ef\u4ee5\u4f7f\u7528 TensorFlow \u63d0\u4f9b\u7684 API \u6765\u4e92\u76f8\u8f6c\u6362\u3002\u4e0b\u9762\u7b80\u5355\u4ecb\u7ecd\u51e0\u79cd\u683c\u5f0f\uff1a 1\u3001GraphDef \u8fd9\u79cd\u683c\u5f0f\u6587\u4ef6\u5305\u542b protobuf \u5bf9\u8c61\u5e8f\u5217\u5316\u540e\u7684\u6570\u636e\uff0c\u5305\u542b\u4e86\u8ba1\u7b97\u56fe\uff0c\u53ef\u4ee5\u4ece\u4e2d\u5f97\u5230\u6240\u6709\u8fd0\u7b97\u7b26\uff08operators\uff09\u7684\u7ec6\u8282\uff0c\u4e5f\u5305\u542b\u5f20\u91cf\uff08tensors\uff09\u548c Variables \u5b9a\u4e49\uff0c\u4f46\u4e0d\u5305\u542b Variable \u7684\u503c\uff0c\u56e0\u6b64\u53ea\u80fd\u4ece\u4e2d\u6062\u590d\u8ba1\u7b97\u56fe\uff0c\u4f46\u4e00\u4e9b\u8bad\u7ec3\u7684\u6743\u503c\u4ecd\u9700\u8981\u4ece checkpoint \u4e2d\u6062\u590d\u3002 2\u3001*.pb TensorFlow \u4e00\u4e9b\u4f8b\u7a0b\u4e2d\u7528\u5230*.pb \u6587\u4ef6\u4f5c\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u8fd9\u548c\u4e0a\u9762 GraphDef \u683c\u5f0f\u7a0d\u6709\u4e0d\u540c\uff0c\u5c5e\u4e8e\u51bb\u7ed3\uff08Frozen\uff09\u540e\u7684 GraphDef \u6587\u4ef6\uff0c\u7b80\u79f0 FrozenGraphDef \u683c\u5f0f\u3002\u8fd9\u79cd\u6587\u4ef6\u683c\u5f0f\u4e0d\u5305\u542b Variables \u8282\u70b9\u3002\u5c06 GraphDef \u4e2d\u6240\u6709 Variable \u8282\u70b9\u8f6c\u6362\u4e3a\u5e38\u91cf\uff08\u5176\u503c\u4ece checkpoint \u83b7\u53d6\uff09\uff0c\u5c31\u53d8\u4e3a FrozenGraphDef \u683c\u5f0f\u3002 3\u3001SavedModel \u5728\u4f7f\u7528 TensorFlow Serving \u65f6\uff0c\u4f1a\u7528\u5230\u8fd9\u79cd\u683c\u5f0f\u7684\u6a21\u578b\u3002\u8be5\u683c\u5f0f\u4e3a GraphDef \u548c CheckPoint \u7684\u7ed3\u5408\u4f53\uff0c\u53e6\u5916\u8fd8\u6709\u6807\u8bb0\u6a21\u578b\u8f93\u5165\u548c\u8f93\u51fa\u53c2\u6570\u7684 SignatureDef\u3002\u4ece SavedModel \u4e2d\u53ef\u4ee5\u63d0\u53d6 GraphDef \u548c CheckPoint \u5bf9\u8c61\u3002 \u5176\u4e2d saved_model.pb\uff08\u6216 saved_model.pbtxt\uff09\u5305\u542b\u4f7f\u7528 MetaGraphDef protobuf \u5bf9\u8c61\u5b9a\u4e49\u7684\u8ba1\u7b97\u56fe\uff1bassets \u5305\u542b\u9644\u52a0\u6587\u4ef6\uff1bvariables \u76ee\u5f55\u5305\u542b tf.train.Saver() \u5bf9\u8c61\u8c03\u7528 save() API \u751f\u6210\u7684\u6587\u4ef6\u3002 \u4f7f\u7528\u4e0b\u9762\u7684\u4ee3\u7801\u5373\u53ef\u5c06\u6a21\u578b\u5bfc\u51fa\u4e3a SavedModel\uff1a tf . saved_model . save ( model , \"\u4fdd\u5b58\u7684\u76ee\u6807\u6587\u4ef6\u5939\u540d\u79f0\" ) \u5728\u9700\u8981\u8f7d\u5165 SavedModel \u6587\u4ef6\u65f6\uff0c\u4f7f\u7528\u5373\u53ef model = tf . saved_model . load ( \"\u4fdd\u5b58\u7684\u76ee\u6807\u6587\u4ef6\u5939\u540d\u79f0\" ) 4.11.2 \u4f7f\u7528\u6848\u4f8b \u00b6 1\u3001\u5c06\u4e4b\u524dCIFAE100\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u5bfc\u51fa\u548c\u5bfc\u5165\uff0c\u5bfc\u51fa\u6a21\u578b\u5230 saved/mlp/1 \u6587\u4ef6\u5939\u4e2d\uff0cmlp\u53ef\u4ee5\u81ea\u5df1\u6307\u5b9a\u7684\u4e00\u4e2a\u6a21\u578b\u540d\u79f0\uff0c1\u4e3a\u7248\u672c\u53f7\uff0c\u5fc5\u987b\u63d0\u4f9b\uff0c\u540e\u9762\u5f00\u542f\u670d\u52a1\u9700\u8981\u6709\u7248\u672c\u53f7 import tensorflow as tf import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" def main (): num_epochs = 1 batch_size = 32 learning_rate = 0.001 model = tf . keras . models . Sequential ([ tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 120 , activation = tf . nn . relu ), tf . keras . layers . Dense ( 100 ), tf . keras . layers . Softmax () ]) ( train , train_label ), ( test , test_label ) = \\ tf . keras . datasets . cifar100 . load_data () model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) model . fit ( train , train_label , epochs = num_epochs , batch_size = batch_size ) tf . saved_model . save ( model , \"./saved/mlp/1\" ) 2\u3001\u5e76\u4e14\u6a21\u578b\u52a0\u8f7d\u51fa\u6765\uff0c\u6d4b\u8bd5\u6027\u80fd\u5c31\u80fd\u591f \u6ce8\u610f\uff1a\u8fd9\u91cc\u52a0\u8f7d\u6a21\u578b\u53ef\u4ee5\u4e0d\u7528\u521d\u59cb\u5316\u4e4b\u524d\u7684\u6a21\u578b\uff08\u4e0d\u9700\u8981\uff09\uff0c\u76f4\u63a5\u52a0\u8f7d\u5230model\u4f7f\u7528 def test (): model = tf . saved_model . load ( \"./saved/mlp/1\" ) sparse_categorical_accuracy = tf . keras . metrics . SparseCategoricalAccuracy () ( train , train_label ), ( test , test_label ) = \\ tf . keras . datasets . cifar100 . load_data () y_pred = model ( test ) sparse_categorical_accuracy . update_state ( y_true = test_label , y_pred = y_pred ) print ( \"test accuracy: %f \" % sparse_categorical_accuracy . result ()) \u8f93\u51fa\u7ed3\u679c test accuracy: 0.010000 3\u3001\u81ea\u5b9a\u4e49\u7684keras\u6a21\u578b\u4f7f\u7528\uff1a \u00b6 \u4f7f\u7528\u7ee7\u627f tf.keras.Model \u7c7b\u5efa\u7acb\u7684 Keras \u6a21\u578b\u540c\u6837\u53ef\u4ee5\u4ee5\u76f8\u540c\u65b9\u6cd5\u5bfc\u51fa\uff0c\u552f\u987b\u6ce8\u610f call \u65b9\u6cd5\u9700\u8981\u4ee5 @tf.function \u4fee\u9970\uff0c\u4ee5\u8f6c\u5316\u4e3a SavedModel \u652f\u6301\u7684\u8ba1\u7b97\u56fe\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a def __init__ ( self ): super () . __init__ () self . flatten = tf . keras . layers . Flatten () self . dense1 = tf . keras . layers . Dense ( units = 100 , activation = tf . nn . relu ) self . dense2 = tf . keras . layers . Dense ( units = 10 ) @tf.function def call ( self , inputs ): # [batch_size, 28, 28, 1] x = self . flatten ( inputs ) # [batch_size, 784] x = self . dense1 ( x ) # [batch_size, 100] x = self . dense2 ( x ) # [batch_size, 10] output = tf . nn . softmax ( x ) return output model = MLP () 4.11.3 TensorFlow Serving \u00b6 \u80cc\u666f\uff1a\u5f53\u6211\u4eec\u5c06\u6a21\u578b\u8bad\u7ec3\u5b8c\u6bd5\u540e\uff0c\u5f80\u5f80\u9700\u8981\u5c06\u6a21\u578b\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u3002\u6700\u5e38\u89c1\u7684\u65b9\u5f0f\uff0c\u662f\u5728\u670d\u52a1\u5668\u4e0a\u63d0\u4f9b\u4e00\u4e2a API\uff0c\u5373\u5ba2\u6237\u673a\u5411\u670d\u52a1\u5668\u7684\u67d0\u4e2a API \u53d1\u9001\u7279\u5b9a\u683c\u5f0f\u7684\u8bf7\u6c42\uff0c\u670d\u52a1\u5668\u6536\u5230\u8bf7\u6c42\u6570\u636e\u540e\u901a\u8fc7\u6a21\u578b\u8fdb\u884c\u8ba1\u7b97\uff0c\u5e76\u8fd4\u56de\u7ed3\u679c\u3002\u5982\u679c\u4ec5\u4ec5\u662f\u505a\u4e00\u4e2a Demo\uff0c\u4e0d\u8003\u8651\u9ad8\u5e76\u53d1\u548c\u6027\u80fd\u95ee\u9898\uff0c\u5176\u5b9e\u914d\u5408Django\u3001Flask\u7b49 Python \u4e0b\u7684 Web \u6846\u67b6\u5c31\u80fd\u975e\u5e38\u8f7b\u677e\u5730\u5b9e\u73b0\u670d\u52a1\u5668 API\u3002\u4e0d\u8fc7\uff0c\u5982\u679c\u662f\u5728\u771f\u7684\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u8fd9\u6837\u7684\u65b9\u5f0f\u5c31\u663e\u5f97\u529b\u4e0d\u4ece\u5fc3\u4e86\u3002\u8fd9\u65f6\uff0cTensorFlow \u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86 TensorFlow Serving \u8fd9\u4e00\u7ec4\u4ef6\uff0c\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u7075\u6d3b\u4e14\u9ad8\u6027\u80fd\u5730\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002 TensorFlow Serving\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u9ad8\u6027\u80fd\u670d\u52a1\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4e13\u4e3a\u751f\u4ea7\u73af\u5883\u800c\u8bbe\u8ba1\u3002TensorFlow Serving\u53ef\u4ee5\u8f7b\u677e\u90e8\u7f72\u65b0\u7b97\u6cd5\u548c\u5b9e\u9a8c\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u670d\u52a1\u5668\u67b6\u6784\u548cAPI\u3002TensorFlow Serving\u63d0\u4f9b\u4e0eTensorFlow\u6a21\u578b\u7684\u5f00\u7bb1\u5373\u7528\u96c6\u6210\uff0c\u4f46\u53ef\u4ee5\u8f7b\u677e\u6269\u5c55\u4ee5\u63d0\u4f9b\u5176\u4ed6\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6570\u636e\u3002 \u7279\u70b9\uff1aTensorFlow Serving \u652f\u6301\u70ed\u66f4\u65b0\u6a21\u578b\uff0c\u5176\u5178\u578b\u7684\u6a21\u578b\u6587\u4ef6\u5939\u7ed3\u6784\u5982\u4e0b\uff1a /saved_model_files /1 # \u7248\u672c\u53f7\u4e3a1\u7684\u6a21\u578b\u6587\u4ef6 /assets /variables saved_model.pb ... /N # \u7248\u672c\u53f7\u4e3aN\u7684\u6a21\u578b\u6587\u4ef6 /assets /variables saved_model.pb \u4e0a\u9762 1~N \u7684\u5b50\u6587\u4ef6\u5939\u4ee3\u8868\u4e0d\u540c\u7248\u672c\u53f7\u7684\u6a21\u578b\u3002\u5f53\u6307\u5b9a --model_base_path \u65f6\uff0c\u53ea\u9700\u8981\u6307\u5b9a\u6839\u76ee\u5f55\u7684 \u7edd\u5bf9\u5730\u5740 \uff08\u4e0d\u662f\u76f8\u5bf9\u5730\u5740\uff09\u5373\u53ef\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4e0a\u8ff0\u6587\u4ef6\u5939\u7ed3\u6784\u5b58\u653e\u5728 home/snowkylin \u6587\u4ef6\u5939\u5185\uff0c\u5219 --model_base_path \u5e94\u5f53\u8bbe\u7f6e\u4e3a home/snowkylin/saved_model_files \uff08\u4e0d\u9644\u5e26\u6a21\u578b\u7248\u672c\u53f7\uff09\u3002TensorFlow Serving \u4f1a\u81ea\u52a8\u9009\u62e9\u7248\u672c\u53f7\u6700\u5927\u7684\u6a21\u578b\u8fdb\u884c\u8f7d\u5165\u3002 4.11.3.1 \u5b89\u88c5Tensorflow Serving \u00b6 \u5b89\u88c5\u8fc7\u7a0b\u8be6\u7ec6\u53c2\u8003\u5b98\u7f51 https://www.tensorflow.org/serving/setup \u4f7f\u7528Docker\u5b89\u88c5\u8fdb\u884c\uff0c\u9996\u5148\u4f60\u7684\u7535\u8111\u5f53\u4e2d\u5df2\u7ecf\u5b89\u88c5\u8fc7docker\u5bb9\u5668 Centos\uff1a\u53c2\u8003\uff1a https://www.cnblogs.com/wdliu/p/10194332.html TensorFlow Serving \u53ef\u4ee5\u4f7f\u7528 apt-get \u6216 Docker \u5b89\u88c5\u3002\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u63a8\u8350 \u4f7f\u7528 Docker \u90e8\u7f72 TensorFlow Serving \u3002 4.11.3.2 TensorFlow Serving Docker \u4f7f\u7528\u4ecb\u7ecd \u00b6 \u83b7\u53d6\u6700\u65b0TF Serving docker\u955c\u50cf docker pull tensorflow/serving \u67e5\u770bdocker\u955c\u50cf docker images \u8fd0\u884ctf serving\uff08\u5373\u521b\u5efa\u4e00\u4e2adocker\u5bb9\u5668\u6765\u8fd0\u884c\uff09 docker run -p 8501 :8501 -p 8500 :8500 --mount type = bind,source = /home/ubuntu/detectedmodel/commodity,target = /models/commodity -e MODEL_NAME = commodity -t tensorflow/serving \u8bf4\u660e\uff1a -p 8501:8501 \u4e3a\u7aef\u53e3\u6620\u5c04\uff0c -p \u4e3b\u673a\u7aef\u53e3:docker\u5bb9\u5668\u7a0b\u5e8f(tf serving)\u4f7f\u7528\u7aef\u53e3 \uff0c\u8bbf\u95ee\u4e3b\u673a8501\u7aef\u53e3\u5c31\u76f8\u5f53\u4e8e\u8bbf\u95ee\u4e86tf serving\u7a0b\u5e8f\u76848501\u7aef\u53e3 tf serving \u4f7f\u75288501\u7aef\u53e3\u5bf9\u5916\u63d0\u4f9bHTTP\u670d\u52a1\uff0c\u4f7f\u75288500\u5bf9\u5916\u63d0\u4f9bgRPC\u670d\u52a1\uff0c\u8fd9\u91cc\u540c\u65f6\u5f00\u653e\u4e86\u4e24\u4e2a\u7aef\u53e3\u7684\u4f7f\u7528 --mount type=bind,source=/home/ubuntu/detectedmodel/commodity,target=/models/commodity \u4e3a\u6587\u4ef6\u6620\u5c04\uff0c\u5c06\u4e3b\u673a(source)\u7684\u6a21\u578b\u6587\u4ef6\u6620\u5c04\u5230docker\u5bb9\u5668\u7a0b\u5e8f\uff08target)\u7684\u4f4d\u7f6e\uff0c\u4ee5\u4fbftf serving\u4f7f\u7528\u6a21\u578b\uff0c target \u53c2\u6570\u4e3a /models/\u6211\u7684\u6a21\u578b -e MODEL_NAME=commodity \u8bbe\u7f6e\u4e86\u4e00\u4e2a\u73af\u5883\u53d8\u91cf\uff0c\u540d\u4e3a MODEL_NAME \uff0c\u6b64\u53d8\u91cf\u88abtf serving\u8bfb\u53d6\uff0c\u7528\u6765\u6309\u540d\u5b57\u5bfb\u627e\u6a21\u578b\uff0c\u4e0e\u4e0a\u9762target\u53c2\u6570\u4e2d \u6211\u7684\u6a21\u578b \u5bf9\u5e94 -t \u4e3atf serving\u521b\u5efa\u4e00\u4e2a\u4f2a\u7ec8\u7aef\uff0c\u4f9b\u7a0b\u5e8f\u8fd0\u884c tensorflow/serving \u4e3a\u955c\u50cf\u540d \u5e38\u89c1docker\u547d\u4ee4\uff1a docker ps:\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u5bb9\u5668 docker images:\u67e5\u770b\u5df2\u4e0b\u8f7d\u7684\u666f\u8c61 docker stop 8779b492e4aa\uff1a\u505c\u6b62\u6b63\u5728\u8fd0\u884c\u7684ID\u4e3a8779b492e4aa\u7684\u5bb9\u5668\uff0cIP\u53ef\u4ee5\u901a\u8fc7docker ps\u67e5\u770b 4.11.3.3 \u6848\u4f8b\u64cd\u4f5c\uff1acommodity\u6a21\u578b\u670d\u52a1\u8fd0\u884c \u00b6 1\u3001\u8fd0\u884c\u547d\u4ee4 docker run - p 8501 : 8501 - p 8500 : 8500 -- mount type = bind , source =/ root / cv_project / tf_example / saved / mlp , target =/ models / mlp - e MODEL_NAME = mlp - t tensorflow / serving & 2\u3001\u67e5\u770b\u662f\u5426\u8fd0\u884c itcast : ~ $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS POR TS NAMES 1354 f9aeab33 tensorflow / serving \"/usr/bin/tf_serving\u2026\" 7 seconds ago Up 5 seconds 0.0 . 0.0 : 8500 - 8501 -> 8500 - 8501 / tcp gifted_jackson 4.11.5 \u5728\u5ba2\u6237\u7aef\u8c03\u7528\u4ee5 TensorFlow Serving \u90e8\u7f72\u7684\u6a21\u578b \u00b6 TensorFlow Serving \u652f\u6301\u4ee5 gRPC \u548c RESTful API \u8c03\u7528\u4ee5 TensorFlow Serving \u90e8\u7f72\u7684\u6a21\u578b\u3002RESTful API \u4ee5\u6807\u51c6\u7684 HTTP POST \u65b9\u6cd5\u8fdb\u884c\u4ea4\u4e92\uff0c\u8bf7\u6c42\u548c\u56de\u590d\u5747\u4e3a JSON \u5bf9\u8c61\u3002\u4e3a\u4e86\u8c03\u7528\u670d\u52a1\u5668\u7aef\u7684\u6a21\u578b\uff0c\u6211\u4eec\u5728\u5ba2\u6237\u7aef\u5411\u670d\u52a1\u5668\u53d1\u9001\u4ee5\u4e0b\u683c\u5f0f\u7684\u8bf7\u6c42\uff1a\u670d\u52a1\u5668 URI\uff1a http://\u670d\u52a1\u5668\u5730\u5740:\u7aef\u53e3\u53f7/v1/models/\u6a21\u578b\u540d:predict \u8bf7\u6c42\u5185\u5bb9\uff1a { \"signature_name\": \"\u9700\u8981\u8c03\u7528\u7684\u51fd\u6570\u7b7e\u540d\uff08Sequential\u6a21\u5f0f\u4e0d\u9700\u8981\uff09\", \"instances\": \u8f93\u5165\u6570\u636e } \u56de\u590d\u4e3a\uff1a { \"predictions\": \u8fd4\u56de\u503c } 4.11.5.1 \u76f4\u63a5\u4f7f\u7528curl \u00b6 \u8fd0\u884c\u4e0b\u9762\u547d\u4ee4 curl - d '{\"instances\": [image_data]}' \\ - X POST http : // localhost : 8501 / v1 / models / mlp : predict 4.11.5.2 \u7f16\u5199\u5ba2\u6237\u7aef\u4ee3\u7801 \u00b6 \u793a\u4f8b\u4f7f\u7528Python \u7684 Requests \u5e93\uff08\u4f60\u53ef\u80fd\u9700\u8981\u4f7f\u7528 pip install requests \u5b89\u88c5\u8be5\u5e93\uff09\u5411\u672c\u673a\u7684 TensorFlow Serving \u670d\u52a1\u5668\u53d1\u900120\u5f20\u56fe\u50cf\u5e76\u8fd4\u56de\u9884\u6d4b\u7ed3\u679c\uff0c\u540c\u65f6\u4e0e\u6d4b\u8bd5\u96c6\u7684\u771f\u5b9e\u6807\u7b7e\u8fdb\u884c\u6bd4\u8f83\u3002 def client(): import json import numpy as np import requests (_, _), (test, test_label) = \\ tf.keras.datasets.cifar100.load_data() data = json.dumps({ \"instances\": test[0:20].tolist() # array\u8f6c\u6362\u6210\u5217\u8868\u5f62\u5f0f }) headers = {\"content-type\": \"application/json\"} json_response = requests.post( 'http://localhost:8501/v1/models/mlp:predict', data=data, headers=headers) predictions = np.array(json.loads(json_response.text)['predictions']) print(np.argmax(predictions, axis=-1)) print(test_label[0:20]) if __name__ == '__main__': # main() # test() client() \u8f93\u51fa\uff1a [ 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 ] [[ 49 ] [ 33 ] [ 72 ] [ 51 ] [ 71 ] [ 92 ] [ 15 ] [ 14 ] [ 23 ] [ 0 ] [ 71 ] [ 75 ] [ 81 ] [ 69 ] [ 40 ] [ 43 ] [ 92 ] [ 97 ] [ 70 ] [ 53 ]] \u56e0\u4e3a\u6a21\u578b\u5e76\u6ca1\u6709\u8bad\u7ec3\u591a\u4e45\uff0c\u53ea\u8fed\u4ee3\u4e00\u6b21\uff0c\u6240\u4ee5\u6548\u679c\u4e0d\u597d\uff0c\u4e3b\u8981\u662f\u5b8c\u6210\u6574\u4e2a\u6d41\u7a0b\u3002 4.11.5 HParams-\u8d85\u53c2\u6570\u8c03\u4f18 \u00b6 \u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65f6\uff0c\u9700\u8981\u9009\u62e9\u5404\u79cd\u8d85\u53c2\u6570\uff0c\u4f8b\u5982\u6a21\u578b\u4e2d\u7684\u5b66\u4e60\u7387\uff0c\u4f18\u5316\u5668\uff0c\u795e\u7ecf\u5143\u4e2a\u6570\u7b49\u3002\u8fd9\u4e9b\u51b3\u7b56\u4f1a\u5f71\u54cd\u6a21\u578b\u6307\u6807\uff0c\u4f8b\u5982\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4\u662f\u4e3a\u60a8\u7684\u95ee\u9898\u786e\u5b9a\u6700\u4f73\u7684\u8d85\u53c2\u6570\uff0c\u8fd9\u901a\u5e38\u6d89\u53ca\u5b9e\u9a8c\u3002\u6b64\u8fc7\u7a0b\u79f0\u4e3a\u201c\u8d85\u53c2\u6570\u4f18\u5316\u201d\u6216\u201c\u8d85\u53c2\u6570\u8c03\u6574\u201d\u3002TensorBoard\u4e2d\u7684HParams\u4eea\u8868\u677f\u63d0\u4f9b\u4e86\u591a\u79cd\u5de5\u5177\uff0c\u5e2e\u52a9\u786e\u5b9a\u6700\u4f73\u5b9e\u9a8c\u6216\u6700\u6709\u5e0c\u671b\u7684\u8d85\u53c2\u6570\u96c6\u3002 \u6ce8\uff1aNote: The HParams summary APIs and dashboard UI are in a preview stage and will change over time. \u4f7f\u7528\u5bfc\u5165 from tensorboard.plugins.hparams import api as hp 4.11.5.1 \u6848\u4f8b\uff1aCIFAR100\u5206\u7c7b\u6a21\u578b\u6dfb\u52a0\u53c2\u6570\u8fdb\u884c\u8c03\u4f18 \u00b6 \u4f7f\u7528\u6b65\u9aa4 1\u3001\u901a\u8fc7hp\u8bbe\u7f6eHParams \u5b9e\u9a8c\u8d85\u53c2\u6570 2\u3001\u5c06\u8bd5\u9a8c\u53c2\u6570\u6dfb\u52a0\u5230\u6a21\u578b\u6307\u5b9a\u7ed3\u6784\u5f53\u4e2d\uff0c\u6216\u8005\u7f16\u8bd1\u8bad\u7ec3\u7684\u8fc7\u7a0b\u53c2\u6570\u4e2d 3\u3001\u4f7f\u7528\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\u5bf9\u4e0d\u540c\u7684\u8d85\u53c2\u6570\u96c6\u8bad\u7ec3\u6bcf\u4e2a\u5b9e\u9a8c\u7ec4\u5408 1\u3001\u8bbe\u7f6eHParams \u5b9e\u9a8c\u53c2\u6570 hp.Discrete:\u8bbe\u7f6e\u79bb\u6563\u7c7b\u578b\u7684\u53c2\u6570\u503c\uff0c\u6bd4\u5982\u795e\u7ecf\u5143\u4e2a\u6570\uff0c\u4f18\u5316\u65b9\u6cd5 \u901a\u8fc7HP_NUM_UNITS.domain.values\u83b7\u53d6\u6240\u6709\u7684\u503c hp.RealInterval:\u8bbe\u7f6e\u8fde\u7eed\u578b\u7c7b\u578b\u7684\u4e0a\u4e0b\u9650\uff0c\u80fd\u591f\u83b7\u53d6\u6700\u5927\u503c\u6700\u5c0f\u503c HP_DROPOUT.domain.min_value:\u83b7\u53d6\u6700\u5c0f\u503c HP_DROPOUT.domain.max_value:\u83b7\u53d6\u6700\u5927\u503c HP_NUM_UNITS = hp . HParam ( 'num_units' , hp . Discrete ([ 1024 , 512 ])) HP_DROPOUT = hp . HParam ( 'dropout' , hp . RealInterval ( 0.2 , 0.3 )) HP_OPTIMIZER = hp . HParam ( 'optimizer' , hp . Discrete ([ 'adam' , 'sgd' ])) 2\u3001\u5c06\u8bd5\u9a8c\u53c2\u6570\u6dfb\u52a0\u5230\u6a21\u578b\u6307\u5b9a\u7ed3\u6784\u5f53\u4e2d\uff0c\u6216\u8005\u7f16\u8bd1\u8bad\u7ec3\u7684\u8fc7\u7a0b\u53c2\u6570\u4e2d (1)\u5728\u9700\u8981\u8bbe\u7f6e\u8d85\u53c2\u6570\u7684\u4f4d\u7f6e\u586b\u5165hparams\u53c2\u6570\u503c (2)\u6dfb\u52a0\u8bb0\u5f55hparams\u7684\u56de\u8c03hp.KerasCallback('./logs/hparam_tuning/', hparams) \u5176\u4e2d\u76ee\u5f55\u81ea\u5df1\u8bbe\u5b9a\u5373\u53ef def train_test_model ( self , hparams ): \"\"\"\u8bad\u7ec3\u9a8c\u8bc1\u6a21\u578b :return: \"\"\" # 1\u3001\u5b9a\u4e49\u6a21\u578b\u4e2d\u52a0\u5165\u4e86\u4e00\u4e2adropout model = tf . keras . Sequential ([ tf . keras . layers . Conv2D ( 32 , kernel_size = 5 , strides = 1 , padding = 'same' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), tf . keras . layers . Conv2D ( 64 , kernel_size = 5 , strides = 1 , padding = 'same' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), tf . keras . layers . Flatten (), tf . keras . layers . Dense ( hparams [ HP_NUM_UNITS ], activation = tf . nn . relu ), tf . keras . layers . Dropout ( hparams [ HP_DROPOUT ]), tf . keras . layers . Dense ( 100 , activation = tf . nn . softmax ) ]) # 2\u3001\u6a21\u578b\u8bbe\u7f6e\u4ee5\u53ca\u8bad\u7ec3 model . compile ( optimizer = hparams [ HP_OPTIMIZER ], loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ 'accuracy' ]) tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) # \u6dfb\u52a0\u8bb0\u5f55hparams\u7684\u56de\u8c03hp.KerasCallback('./graph/', hparams) model . fit ( self . train , self . train_label , epochs = 1 , batch_size = 32 , callbacks = [ tensorboard , hp . KerasCallback ( './logs/hparam_tuning/' , hparams )], validation_data = ( self . test , self . test_label )) return None 3\u3001\u4f7f\u7528\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\u5bf9\u4e0d\u540c\u7684\u8d85\u53c2\u6570\u96c6\u8bad\u7ec3\u6bcf\u4e2a\u5b9e\u9a8c\u7ec4\u5408 \u4f7f\u7528\u7f51\u683c\u641c\u7d22\uff1a\u5c1d\u8bd5\u4f7f\u7528\u79bb\u6563\u53c2\u6570\u7684\u6240\u6709\u7ec4\u5408\u6216\u8005\u8fde\u7eed\u578b\u503c\u53c2\u6570\u7684\u4e0a\u9650\u548c\u4e0b\u9650\u3002\u5bf9\u4e8e\u66f4\u590d\u6742\u7684\u573a\u666f\uff0c\u968f\u673a\u9009\u62e9\u6bcf\u4e2a\u8d85\u53c2\u6570\u503c\u4f1a\u66f4\u6709\u6548\uff08\u968f\u673a\u641c\u7d22\uff09\u3002 def hyper_parameter ( self ): \"\"\"\u8d85\u53c2\u6570\u8c03\u4f18 :return: \"\"\" session_num = 0 for num_units in HP_NUM_UNITS . domain . values : for dropout_rate in ( HP_DROPOUT . domain . min_value , HP_DROPOUT . domain . max_value ): for optimizer in HP_OPTIMIZER . domain . values : hparams = { HP_NUM_UNITS : num_units , HP_DROPOUT : dropout_rate , HP_OPTIMIZER : optimizer , } print ( '--- \u5f00\u59cb \u5b9e\u9a8c: %s ' % session_num ) print ({ h . name : hparams [ h ] for h in hparams }) self . train_test_model ( hparams ) session_num += 1 return None \u6ce8\uff1a\u5176\u4e2d\u5982\u679c\u5bf9\u4e8e\u8fde\u7eed\u7684\u503c\u6bd4\u5982\u8bf4\u4f60\u7684\u6a21\u578b\u4e2dlearning_rate,\u5047\u8bbe\u8bbe\u7f6e0.0001~0.1\uff0c\u53ef\u4ee5\u8fd9\u6837\u8fed\u4ee3\u4f7f\u7528 for lr_tate in tf.linspace( HP_LR.domain.min_value, HP_LR.domain.max_value, res): \u6700\u7ec8\u6253\u5370\u6548\u679c\u4e3a\uff1a --- \u5f00\u59cb \u5b9e\u9a8c : 0 { 'num_units' : 512 , 'dropout' : 0.2 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 21 : 58 - loss : 4.6257 - accuracy : 0.0000e+002020 - 03 - 22 05 : 02 : 24.239954 : E 50000 / 50000 [ ============================== ] - 61 s 1 ms / sample - loss : 3.6983 - accuracy : 0.1391 - val_loss : 3.1219 - val_accuracy : 0.2460 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 60 s 1 ms / sample - loss : 2.9337 - accuracy : 0.2777 - val_loss : 2.7689 - val_accuracy : 0.3094 --- \u5f00\u59cb \u5b9e\u9a8c : 1 { 'num_units' : 512 , 'dropout' : 0.2 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 12 - loss : 4.5919 - accuracy : 0.0000e+002020 - 03 - 22 05 : 04 : 26.409071 : E 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 4.3805 - accuracy : 0.0404 - val_loss : 4.1078 - val_accuracy : 0.0641 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 3.9086 - accuracy : 0.1072 - val_loss : 3.7098 - val_accuracy : 0.1479 --- \u5f00\u59cb \u5b9e\u9a8c : 2 { 'num_units' : 512 , 'dropout' : 0.3 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 11 : 06 - loss : 4.6464 - accuracy : 0.03122020 - 03 - 22 05 : 06 : 18.355198 : E 50000 / 50000 [ ============================== ] - 61 s 1 ms / sample - loss : 3.7051 - accuracy : 0.1400 - val_loss : 3.1361 - val_accuracy : 0.2422 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 60 s 1 ms / sample - loss : 2.9754 - accuracy : 0.2687 - val_loss : 2.7621 - val_accuracy : 0.3118 --- \u5f00\u59cb \u5b9e\u9a8c : 3 { 'num_units' : 512 , 'dropout' : 0.3 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 03 - loss : 4.5909 - accuracy : 0.0000e+002020 - 03 - 22 05 : 08 : 20.864262 : E 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 4.3802 - accuracy : 0.0399 - val_loss : 4.0482 - val_accuracy : 0.0807 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 3.9227 - accuracy : 0.1036 - val_loss : 3.7022 - val_accuracy : 0.1423 --- \u5f00\u59cb \u5b9e\u9a8c : 4 { 'num_units' : 1024 , 'dropout' : 0.2 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 11 : 28 - loss : 4.6099 - accuracy : 0.0000e+002020 - 03 - 22 05 : 10 : 12.802252 : E 50000 / 50000 [ ============================== ] - 78 s 2 ms / sample - loss : 3.5546 - accuracy : 0.1683 - val_loss : 3.0440 - val_accuracy : 0.2580 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 77 s 2 ms / sample - loss : 2.7925 - accuracy : 0.3048 - val_loss : 2.7049 - val_accuracy : 0.3255 --- \u5f00\u59cb \u5b9e\u9a8c : 5 { 'num_units' : 1024 , 'dropout' : 0.2 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 22 - loss : 4.5938 - accuracy : 0.0000e+002020 - 03 - 22 05 : 12 : 50.161457 : E 50000 / 50000 [ ============================== ] - 68 s 1 ms / sample - loss : 4.3278 - accuracy : 0.0477 - val_loss : 3.9872 - val_accuracy : 0.0849 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 67 s 1 ms / sample - loss : 3.8071 - accuracy : 0.1244 - val_loss : 3.6097 - val_accuracy : 0.1679 --- \u5f00\u59cb \u5b9e\u9a8c : 6 { 'num_units' : 1024 , 'dropout' : 0.3 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 11 : 14 - loss : 4.6129 - accuracy : 0.0000e+002020 - 03 - 22 05 : 15 : 07.480836 : E 50000 / 50000 [ ============================== ] - 78 s 2 ms / sample - loss : 3.6139 - accuracy : 0.1548 - val_loss : 2.9943 - val_accuracy : 0.2691 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 77 s 2 ms / sample - loss : 2.8460 - accuracy : 0.2921 - val_loss : 2.7325 - val_accuracy : 0.3195 --- \u5f00\u59cb \u5b9e\u9a8c : 7 { 'num_units' : 1024 , 'dropout' : 0.3 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 22 - loss : 4.5689 - accuracy : 0.03122020 - 03 - 22 05 : 17 : 44.697445 : E 50000 / 50000 [ ============================== ] - 68 s 1 ms / sample - loss : 4.3251 - accuracy : 0.0469 - val_loss : 3.9708 - val_accuracy : 0.1038 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 67 s 1 ms / sample - loss : 3.8546 - accuracy : 0.1173 - val_loss : 3.6345 - val_accuracy : 0.1653 \u751f\u6210\u5982\u4e0b\u76ee\u5f55 4\u3001\u6700\u7ec8\u53ef\u4ee5\u901a\u8fc7Tensoboard\u5f00\u542f\u8bfb\u53d6\u5bf9\u5e94\u76ee\u5f55\u7684events\u6587\u4ef6\u770b\u5230\u5bf9\u5e94\u7ed3\u679c tensorboard -- logdir './logs/hparam_tuning/' \u53ef\u4ee5\u5728HPARAMS\u83dc\u5355\u4e2d\u67e5\u770b\u5230\u4e0b\u9762\u7684\u6548\u679c(\u5b98\u7f51\u622a\u56fe) \u5e76\u4e14\u5176\u4e2d\u6709\u63d0\u4f9b\u4e86\u4e24\u79cd\u4e3b\u8981\u7684\u4e0d\u540c\u7684\u67e5\u770b\u65b9\u5f0f\uff1a 1\u3001\u8868\u89c6\u56fe(TABLE VIEW)\uff1a\u5217\u51fa\u4e86\u8fd0\u884c\u65f6\uff0c\u4ed6\u4eec\u7684\u8d85\u53c2\u6570\uff0c\u548c\u4ed6\u4eec\u7684\u6307\u6807\u3002 2\u3001\u5e73\u884c\u5750\u6807\u89c6\u56fe\uff1a\u6bcf\u4e2a\u8fd0\u884c\u4e3a\u7ebf\u901a\u8fc7\u6bcf\u4e2ahyperparemeter\u548c\u5ea6\u91cf\u7684\u8f74\u7ebf\u53bb\u3002\u5355\u51fb\u5e76\u5728\u4efb\u4f55\u8f74\u4e0a\u62d6\u52a8\u9f20\u6807\u4ee5\u6807\u8bb0\u4e00\u4e2a\u533a\u57df\uff0c\u8be5\u533a\u57df\u5c06\u4ec5\u7a81\u51fa\u663e\u793a\u901a\u8fc7\u8be5\u533a\u57df\u7684\u8fd0\u884c\u3002\u8fd9\u5bf9\u4e8e\u786e\u5b9a\u54ea\u4e9b\u8d85\u53c2\u6570\u7ec4\u6700\u91cd\u8981\u5f88\u6709\u7528 4.11.6 \u603b\u7ed3 \u00b6 TensorFlow\u6a21\u578b\u7684\u5bfc\u51fa(saved_model\u683c\u5f0f) Tensorflow\u6a21\u578b\u7684\u90e8\u7f72 TensorFlow\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u8c03\u7528 TensorFlow\u6a21\u578b\u7684\u8d85\u53c2\u6570\u8c03\u4f18","title":"4.11 \u7efc\u5408\u6848\u4f8b\uff1a\u6a21\u578b\u5bfc\u51fa\u4e0e\u90e8\u7f72"},{"location":"tensorFlow/section11/#411","text":"","title":"4.11 \u7efc\u5408\u6848\u4f8b\uff1a\u6a21\u578b\u5bfc\u51fa\u4e0e\u90e8\u7f72"},{"location":"tensorFlow/section11/#_1","text":"\u76ee\u6807 \u638c\u63e1TensorFlow\u6a21\u578b\u7684\u5bfc\u51fa(saved_model\u683c\u5f0f) \u638c\u63e1Tensorflow\u6a21\u578b\u7684\u90e8\u7f72 \u638c\u63e1TensorFlow\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u8c03\u7528 \u638c\u63e1TensorFlow\u6a21\u578b\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u4f7f\u7528 \u5e94\u7528 \u65e0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section11/#4111-tensorflow","text":"\u5728\u90e8\u7f72\u6a21\u578b\u65f6\uff0c\u6211\u4eec\u7684\u7b2c\u4e00\u6b65\u5f80\u5f80\u662f\u5c06\u8bad\u7ec3\u597d\u7684\u6574\u4e2a\u6a21\u578b\u5b8c\u6574\u5bfc\u51fa\u4e3a\u4e00\u7cfb\u5217\u6807\u51c6\u683c\u5f0f\u7684\u6587\u4ef6\uff0c\u7136\u540e\u5373\u53ef\u5728\u4e0d\u540c\u7684\u5e73\u53f0\u4e0a\u90e8\u7f72\u6a21\u578b\u6587\u4ef6\u3002\u8fd9\u65f6\uff0cTensorFlow \u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86 SavedModel \u8fd9\u4e00\u683c\u5f0f\u3002 \u4e0e\u524d\u9762\u4ecb\u7ecd\u7684 Checkpoint \u4e0d\u540c\uff0cSavedModel \u5305\u542b\u4e86\u4e00\u4e2a TensorFlow \u7a0b\u5e8f\u7684\u5b8c\u6574\u4fe1\u606f\uff1a \u4e0d\u4ec5\u5305\u542b\u53c2\u6570\u7684\u6743\u503c\uff0c\u8fd8\u5305\u542b\u8ba1\u7b97\u7684\u6d41\u7a0b\uff08\u5373\u8ba1\u7b97\u56fe\uff09 \u3002 \u7279\u70b9\uff1a\u5f53\u6a21\u578b\u5bfc\u51fa\u4e3a SavedModel \u6587\u4ef6\u65f6\uff0c\u65e0\u9700\u5efa\u7acb\u6a21\u578b\u7684\u6e90\u4ee3\u7801\u5373\u53ef\u518d\u6b21\u8fd0\u884c\u6a21\u578b\uff0c\u8fd9\u4f7f\u5f97 SavedModel \u5c24\u5176\u9002\u7528\u4e8e\u6a21\u578b\u7684\u5206\u4eab\u548c\u90e8\u7f72\u3002\u540e\u6587\u7684 TensorFlow Serving\uff08\u670d\u52a1\u5668\u7aef\u90e8\u7f72\u6a21\u578b\uff09\u3001TensorFlow Lite\uff08\u79fb\u52a8\u7aef\u90e8\u7f72\u6a21\u578b\uff09\u4ee5\u53ca TensorFlow.js \u90fd\u4f1a\u7528\u5230\u8fd9\u4e00\u683c\u5f0f\u3002 \u9664\u4e86CheckPointTensorFlow\u8fd8\u4f1a\u6709\u5176\u4ed6\u683c\u5f0f\uff0c\u8fd9\u91cc\u505a\u7edf\u4e00\u4ecb\u7ecd\uff1a\u90e8\u7f72\u5728\u7ebf\u670d\u52a1\uff08Serving\uff09\u65f6\u5b98\u65b9\u63a8\u8350\u4f7f\u7528 SavedModel \u683c\u5f0f\uff0c\u800c\u90e8\u7f72\u5230\u624b\u673a\u7b49\u79fb\u52a8\u7aef\u7684\u6a21\u578b\u4e00\u822c\u4f7f\u7528 FrozenGraphDef \u683c\u5f0f\uff08\u6700\u8fd1\u63a8\u51fa\u7684 TensorFlow Lite \u4e5f\u6709\u4e13\u95e8\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\u683c\u5f0f *.lite\uff0c\u548c FrozenGraphDef \u5341\u5206\u7c7b\u4f3c\uff09\u3002\u8fd9\u4e9b\u683c\u5f0f\u4e4b\u95f4\u5173\u7cfb\u5bc6\u5207\uff0c\u53ef\u4ee5\u4f7f\u7528 TensorFlow \u63d0\u4f9b\u7684 API \u6765\u4e92\u76f8\u8f6c\u6362\u3002\u4e0b\u9762\u7b80\u5355\u4ecb\u7ecd\u51e0\u79cd\u683c\u5f0f\uff1a 1\u3001GraphDef \u8fd9\u79cd\u683c\u5f0f\u6587\u4ef6\u5305\u542b protobuf \u5bf9\u8c61\u5e8f\u5217\u5316\u540e\u7684\u6570\u636e\uff0c\u5305\u542b\u4e86\u8ba1\u7b97\u56fe\uff0c\u53ef\u4ee5\u4ece\u4e2d\u5f97\u5230\u6240\u6709\u8fd0\u7b97\u7b26\uff08operators\uff09\u7684\u7ec6\u8282\uff0c\u4e5f\u5305\u542b\u5f20\u91cf\uff08tensors\uff09\u548c Variables \u5b9a\u4e49\uff0c\u4f46\u4e0d\u5305\u542b Variable \u7684\u503c\uff0c\u56e0\u6b64\u53ea\u80fd\u4ece\u4e2d\u6062\u590d\u8ba1\u7b97\u56fe\uff0c\u4f46\u4e00\u4e9b\u8bad\u7ec3\u7684\u6743\u503c\u4ecd\u9700\u8981\u4ece checkpoint \u4e2d\u6062\u590d\u3002 2\u3001*.pb TensorFlow \u4e00\u4e9b\u4f8b\u7a0b\u4e2d\u7528\u5230*.pb \u6587\u4ef6\u4f5c\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u8fd9\u548c\u4e0a\u9762 GraphDef \u683c\u5f0f\u7a0d\u6709\u4e0d\u540c\uff0c\u5c5e\u4e8e\u51bb\u7ed3\uff08Frozen\uff09\u540e\u7684 GraphDef \u6587\u4ef6\uff0c\u7b80\u79f0 FrozenGraphDef \u683c\u5f0f\u3002\u8fd9\u79cd\u6587\u4ef6\u683c\u5f0f\u4e0d\u5305\u542b Variables \u8282\u70b9\u3002\u5c06 GraphDef \u4e2d\u6240\u6709 Variable \u8282\u70b9\u8f6c\u6362\u4e3a\u5e38\u91cf\uff08\u5176\u503c\u4ece checkpoint \u83b7\u53d6\uff09\uff0c\u5c31\u53d8\u4e3a FrozenGraphDef \u683c\u5f0f\u3002 3\u3001SavedModel \u5728\u4f7f\u7528 TensorFlow Serving \u65f6\uff0c\u4f1a\u7528\u5230\u8fd9\u79cd\u683c\u5f0f\u7684\u6a21\u578b\u3002\u8be5\u683c\u5f0f\u4e3a GraphDef \u548c CheckPoint \u7684\u7ed3\u5408\u4f53\uff0c\u53e6\u5916\u8fd8\u6709\u6807\u8bb0\u6a21\u578b\u8f93\u5165\u548c\u8f93\u51fa\u53c2\u6570\u7684 SignatureDef\u3002\u4ece SavedModel \u4e2d\u53ef\u4ee5\u63d0\u53d6 GraphDef \u548c CheckPoint \u5bf9\u8c61\u3002 \u5176\u4e2d saved_model.pb\uff08\u6216 saved_model.pbtxt\uff09\u5305\u542b\u4f7f\u7528 MetaGraphDef protobuf \u5bf9\u8c61\u5b9a\u4e49\u7684\u8ba1\u7b97\u56fe\uff1bassets \u5305\u542b\u9644\u52a0\u6587\u4ef6\uff1bvariables \u76ee\u5f55\u5305\u542b tf.train.Saver() \u5bf9\u8c61\u8c03\u7528 save() API \u751f\u6210\u7684\u6587\u4ef6\u3002 \u4f7f\u7528\u4e0b\u9762\u7684\u4ee3\u7801\u5373\u53ef\u5c06\u6a21\u578b\u5bfc\u51fa\u4e3a SavedModel\uff1a tf . saved_model . save ( model , \"\u4fdd\u5b58\u7684\u76ee\u6807\u6587\u4ef6\u5939\u540d\u79f0\" ) \u5728\u9700\u8981\u8f7d\u5165 SavedModel \u6587\u4ef6\u65f6\uff0c\u4f7f\u7528\u5373\u53ef model = tf . saved_model . load ( \"\u4fdd\u5b58\u7684\u76ee\u6807\u6587\u4ef6\u5939\u540d\u79f0\" )","title":"4.11.1 TensorFlow \u6a21\u578b\u5bfc\u51fa"},{"location":"tensorFlow/section11/#4112","text":"1\u3001\u5c06\u4e4b\u524dCIFAE100\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u5bfc\u51fa\u548c\u5bfc\u5165\uff0c\u5bfc\u51fa\u6a21\u578b\u5230 saved/mlp/1 \u6587\u4ef6\u5939\u4e2d\uff0cmlp\u53ef\u4ee5\u81ea\u5df1\u6307\u5b9a\u7684\u4e00\u4e2a\u6a21\u578b\u540d\u79f0\uff0c1\u4e3a\u7248\u672c\u53f7\uff0c\u5fc5\u987b\u63d0\u4f9b\uff0c\u540e\u9762\u5f00\u542f\u670d\u52a1\u9700\u8981\u6709\u7248\u672c\u53f7 import tensorflow as tf import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" def main (): num_epochs = 1 batch_size = 32 learning_rate = 0.001 model = tf . keras . models . Sequential ([ tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 120 , activation = tf . nn . relu ), tf . keras . layers . Dense ( 100 ), tf . keras . layers . Softmax () ]) ( train , train_label ), ( test , test_label ) = \\ tf . keras . datasets . cifar100 . load_data () model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) model . fit ( train , train_label , epochs = num_epochs , batch_size = batch_size ) tf . saved_model . save ( model , \"./saved/mlp/1\" ) 2\u3001\u5e76\u4e14\u6a21\u578b\u52a0\u8f7d\u51fa\u6765\uff0c\u6d4b\u8bd5\u6027\u80fd\u5c31\u80fd\u591f \u6ce8\u610f\uff1a\u8fd9\u91cc\u52a0\u8f7d\u6a21\u578b\u53ef\u4ee5\u4e0d\u7528\u521d\u59cb\u5316\u4e4b\u524d\u7684\u6a21\u578b\uff08\u4e0d\u9700\u8981\uff09\uff0c\u76f4\u63a5\u52a0\u8f7d\u5230model\u4f7f\u7528 def test (): model = tf . saved_model . load ( \"./saved/mlp/1\" ) sparse_categorical_accuracy = tf . keras . metrics . SparseCategoricalAccuracy () ( train , train_label ), ( test , test_label ) = \\ tf . keras . datasets . cifar100 . load_data () y_pred = model ( test ) sparse_categorical_accuracy . update_state ( y_true = test_label , y_pred = y_pred ) print ( \"test accuracy: %f \" % sparse_categorical_accuracy . result ()) \u8f93\u51fa\u7ed3\u679c test accuracy: 0.010000","title":"4.11.2 \u4f7f\u7528\u6848\u4f8b"},{"location":"tensorFlow/section11/#3keras","text":"\u4f7f\u7528\u7ee7\u627f tf.keras.Model \u7c7b\u5efa\u7acb\u7684 Keras \u6a21\u578b\u540c\u6837\u53ef\u4ee5\u4ee5\u76f8\u540c\u65b9\u6cd5\u5bfc\u51fa\uff0c\u552f\u987b\u6ce8\u610f call \u65b9\u6cd5\u9700\u8981\u4ee5 @tf.function \u4fee\u9970\uff0c\u4ee5\u8f6c\u5316\u4e3a SavedModel \u652f\u6301\u7684\u8ba1\u7b97\u56fe\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a def __init__ ( self ): super () . __init__ () self . flatten = tf . keras . layers . Flatten () self . dense1 = tf . keras . layers . Dense ( units = 100 , activation = tf . nn . relu ) self . dense2 = tf . keras . layers . Dense ( units = 10 ) @tf.function def call ( self , inputs ): # [batch_size, 28, 28, 1] x = self . flatten ( inputs ) # [batch_size, 784] x = self . dense1 ( x ) # [batch_size, 100] x = self . dense2 ( x ) # [batch_size, 10] output = tf . nn . softmax ( x ) return output model = MLP ()","title":"3\u3001\u81ea\u5b9a\u4e49\u7684keras\u6a21\u578b\u4f7f\u7528\uff1a"},{"location":"tensorFlow/section11/#4113-tensorflow-serving","text":"\u80cc\u666f\uff1a\u5f53\u6211\u4eec\u5c06\u6a21\u578b\u8bad\u7ec3\u5b8c\u6bd5\u540e\uff0c\u5f80\u5f80\u9700\u8981\u5c06\u6a21\u578b\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u3002\u6700\u5e38\u89c1\u7684\u65b9\u5f0f\uff0c\u662f\u5728\u670d\u52a1\u5668\u4e0a\u63d0\u4f9b\u4e00\u4e2a API\uff0c\u5373\u5ba2\u6237\u673a\u5411\u670d\u52a1\u5668\u7684\u67d0\u4e2a API \u53d1\u9001\u7279\u5b9a\u683c\u5f0f\u7684\u8bf7\u6c42\uff0c\u670d\u52a1\u5668\u6536\u5230\u8bf7\u6c42\u6570\u636e\u540e\u901a\u8fc7\u6a21\u578b\u8fdb\u884c\u8ba1\u7b97\uff0c\u5e76\u8fd4\u56de\u7ed3\u679c\u3002\u5982\u679c\u4ec5\u4ec5\u662f\u505a\u4e00\u4e2a Demo\uff0c\u4e0d\u8003\u8651\u9ad8\u5e76\u53d1\u548c\u6027\u80fd\u95ee\u9898\uff0c\u5176\u5b9e\u914d\u5408Django\u3001Flask\u7b49 Python \u4e0b\u7684 Web \u6846\u67b6\u5c31\u80fd\u975e\u5e38\u8f7b\u677e\u5730\u5b9e\u73b0\u670d\u52a1\u5668 API\u3002\u4e0d\u8fc7\uff0c\u5982\u679c\u662f\u5728\u771f\u7684\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u8fd9\u6837\u7684\u65b9\u5f0f\u5c31\u663e\u5f97\u529b\u4e0d\u4ece\u5fc3\u4e86\u3002\u8fd9\u65f6\uff0cTensorFlow \u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86 TensorFlow Serving \u8fd9\u4e00\u7ec4\u4ef6\uff0c\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u7075\u6d3b\u4e14\u9ad8\u6027\u80fd\u5730\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002 TensorFlow Serving\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u9ad8\u6027\u80fd\u670d\u52a1\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4e13\u4e3a\u751f\u4ea7\u73af\u5883\u800c\u8bbe\u8ba1\u3002TensorFlow Serving\u53ef\u4ee5\u8f7b\u677e\u90e8\u7f72\u65b0\u7b97\u6cd5\u548c\u5b9e\u9a8c\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u670d\u52a1\u5668\u67b6\u6784\u548cAPI\u3002TensorFlow Serving\u63d0\u4f9b\u4e0eTensorFlow\u6a21\u578b\u7684\u5f00\u7bb1\u5373\u7528\u96c6\u6210\uff0c\u4f46\u53ef\u4ee5\u8f7b\u677e\u6269\u5c55\u4ee5\u63d0\u4f9b\u5176\u4ed6\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6570\u636e\u3002 \u7279\u70b9\uff1aTensorFlow Serving \u652f\u6301\u70ed\u66f4\u65b0\u6a21\u578b\uff0c\u5176\u5178\u578b\u7684\u6a21\u578b\u6587\u4ef6\u5939\u7ed3\u6784\u5982\u4e0b\uff1a /saved_model_files /1 # \u7248\u672c\u53f7\u4e3a1\u7684\u6a21\u578b\u6587\u4ef6 /assets /variables saved_model.pb ... /N # \u7248\u672c\u53f7\u4e3aN\u7684\u6a21\u578b\u6587\u4ef6 /assets /variables saved_model.pb \u4e0a\u9762 1~N \u7684\u5b50\u6587\u4ef6\u5939\u4ee3\u8868\u4e0d\u540c\u7248\u672c\u53f7\u7684\u6a21\u578b\u3002\u5f53\u6307\u5b9a --model_base_path \u65f6\uff0c\u53ea\u9700\u8981\u6307\u5b9a\u6839\u76ee\u5f55\u7684 \u7edd\u5bf9\u5730\u5740 \uff08\u4e0d\u662f\u76f8\u5bf9\u5730\u5740\uff09\u5373\u53ef\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4e0a\u8ff0\u6587\u4ef6\u5939\u7ed3\u6784\u5b58\u653e\u5728 home/snowkylin \u6587\u4ef6\u5939\u5185\uff0c\u5219 --model_base_path \u5e94\u5f53\u8bbe\u7f6e\u4e3a home/snowkylin/saved_model_files \uff08\u4e0d\u9644\u5e26\u6a21\u578b\u7248\u672c\u53f7\uff09\u3002TensorFlow Serving \u4f1a\u81ea\u52a8\u9009\u62e9\u7248\u672c\u53f7\u6700\u5927\u7684\u6a21\u578b\u8fdb\u884c\u8f7d\u5165\u3002","title":"4.11.3 TensorFlow Serving"},{"location":"tensorFlow/section11/#41131-tensorflow-serving","text":"\u5b89\u88c5\u8fc7\u7a0b\u8be6\u7ec6\u53c2\u8003\u5b98\u7f51 https://www.tensorflow.org/serving/setup \u4f7f\u7528Docker\u5b89\u88c5\u8fdb\u884c\uff0c\u9996\u5148\u4f60\u7684\u7535\u8111\u5f53\u4e2d\u5df2\u7ecf\u5b89\u88c5\u8fc7docker\u5bb9\u5668 Centos\uff1a\u53c2\u8003\uff1a https://www.cnblogs.com/wdliu/p/10194332.html TensorFlow Serving \u53ef\u4ee5\u4f7f\u7528 apt-get \u6216 Docker \u5b89\u88c5\u3002\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u63a8\u8350 \u4f7f\u7528 Docker \u90e8\u7f72 TensorFlow Serving \u3002","title":"4.11.3.1 \u5b89\u88c5Tensorflow Serving"},{"location":"tensorFlow/section11/#41132-tensorflow-serving-docker","text":"\u83b7\u53d6\u6700\u65b0TF Serving docker\u955c\u50cf docker pull tensorflow/serving \u67e5\u770bdocker\u955c\u50cf docker images \u8fd0\u884ctf serving\uff08\u5373\u521b\u5efa\u4e00\u4e2adocker\u5bb9\u5668\u6765\u8fd0\u884c\uff09 docker run -p 8501 :8501 -p 8500 :8500 --mount type = bind,source = /home/ubuntu/detectedmodel/commodity,target = /models/commodity -e MODEL_NAME = commodity -t tensorflow/serving \u8bf4\u660e\uff1a -p 8501:8501 \u4e3a\u7aef\u53e3\u6620\u5c04\uff0c -p \u4e3b\u673a\u7aef\u53e3:docker\u5bb9\u5668\u7a0b\u5e8f(tf serving)\u4f7f\u7528\u7aef\u53e3 \uff0c\u8bbf\u95ee\u4e3b\u673a8501\u7aef\u53e3\u5c31\u76f8\u5f53\u4e8e\u8bbf\u95ee\u4e86tf serving\u7a0b\u5e8f\u76848501\u7aef\u53e3 tf serving \u4f7f\u75288501\u7aef\u53e3\u5bf9\u5916\u63d0\u4f9bHTTP\u670d\u52a1\uff0c\u4f7f\u75288500\u5bf9\u5916\u63d0\u4f9bgRPC\u670d\u52a1\uff0c\u8fd9\u91cc\u540c\u65f6\u5f00\u653e\u4e86\u4e24\u4e2a\u7aef\u53e3\u7684\u4f7f\u7528 --mount type=bind,source=/home/ubuntu/detectedmodel/commodity,target=/models/commodity \u4e3a\u6587\u4ef6\u6620\u5c04\uff0c\u5c06\u4e3b\u673a(source)\u7684\u6a21\u578b\u6587\u4ef6\u6620\u5c04\u5230docker\u5bb9\u5668\u7a0b\u5e8f\uff08target)\u7684\u4f4d\u7f6e\uff0c\u4ee5\u4fbftf serving\u4f7f\u7528\u6a21\u578b\uff0c target \u53c2\u6570\u4e3a /models/\u6211\u7684\u6a21\u578b -e MODEL_NAME=commodity \u8bbe\u7f6e\u4e86\u4e00\u4e2a\u73af\u5883\u53d8\u91cf\uff0c\u540d\u4e3a MODEL_NAME \uff0c\u6b64\u53d8\u91cf\u88abtf serving\u8bfb\u53d6\uff0c\u7528\u6765\u6309\u540d\u5b57\u5bfb\u627e\u6a21\u578b\uff0c\u4e0e\u4e0a\u9762target\u53c2\u6570\u4e2d \u6211\u7684\u6a21\u578b \u5bf9\u5e94 -t \u4e3atf serving\u521b\u5efa\u4e00\u4e2a\u4f2a\u7ec8\u7aef\uff0c\u4f9b\u7a0b\u5e8f\u8fd0\u884c tensorflow/serving \u4e3a\u955c\u50cf\u540d \u5e38\u89c1docker\u547d\u4ee4\uff1a docker ps:\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u5bb9\u5668 docker images:\u67e5\u770b\u5df2\u4e0b\u8f7d\u7684\u666f\u8c61 docker stop 8779b492e4aa\uff1a\u505c\u6b62\u6b63\u5728\u8fd0\u884c\u7684ID\u4e3a8779b492e4aa\u7684\u5bb9\u5668\uff0cIP\u53ef\u4ee5\u901a\u8fc7docker ps\u67e5\u770b","title":"4.11.3.2 TensorFlow Serving Docker \u4f7f\u7528\u4ecb\u7ecd"},{"location":"tensorFlow/section11/#41133-commodity","text":"1\u3001\u8fd0\u884c\u547d\u4ee4 docker run - p 8501 : 8501 - p 8500 : 8500 -- mount type = bind , source =/ root / cv_project / tf_example / saved / mlp , target =/ models / mlp - e MODEL_NAME = mlp - t tensorflow / serving & 2\u3001\u67e5\u770b\u662f\u5426\u8fd0\u884c itcast : ~ $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS POR TS NAMES 1354 f9aeab33 tensorflow / serving \"/usr/bin/tf_serving\u2026\" 7 seconds ago Up 5 seconds 0.0 . 0.0 : 8500 - 8501 -> 8500 - 8501 / tcp gifted_jackson","title":"4.11.3.3 \u6848\u4f8b\u64cd\u4f5c\uff1acommodity\u6a21\u578b\u670d\u52a1\u8fd0\u884c"},{"location":"tensorFlow/section11/#4115-tensorflow-serving","text":"TensorFlow Serving \u652f\u6301\u4ee5 gRPC \u548c RESTful API \u8c03\u7528\u4ee5 TensorFlow Serving \u90e8\u7f72\u7684\u6a21\u578b\u3002RESTful API \u4ee5\u6807\u51c6\u7684 HTTP POST \u65b9\u6cd5\u8fdb\u884c\u4ea4\u4e92\uff0c\u8bf7\u6c42\u548c\u56de\u590d\u5747\u4e3a JSON \u5bf9\u8c61\u3002\u4e3a\u4e86\u8c03\u7528\u670d\u52a1\u5668\u7aef\u7684\u6a21\u578b\uff0c\u6211\u4eec\u5728\u5ba2\u6237\u7aef\u5411\u670d\u52a1\u5668\u53d1\u9001\u4ee5\u4e0b\u683c\u5f0f\u7684\u8bf7\u6c42\uff1a\u670d\u52a1\u5668 URI\uff1a http://\u670d\u52a1\u5668\u5730\u5740:\u7aef\u53e3\u53f7/v1/models/\u6a21\u578b\u540d:predict \u8bf7\u6c42\u5185\u5bb9\uff1a { \"signature_name\": \"\u9700\u8981\u8c03\u7528\u7684\u51fd\u6570\u7b7e\u540d\uff08Sequential\u6a21\u5f0f\u4e0d\u9700\u8981\uff09\", \"instances\": \u8f93\u5165\u6570\u636e } \u56de\u590d\u4e3a\uff1a { \"predictions\": \u8fd4\u56de\u503c }","title":"4.11.5 \u5728\u5ba2\u6237\u7aef\u8c03\u7528\u4ee5 TensorFlow Serving \u90e8\u7f72\u7684\u6a21\u578b"},{"location":"tensorFlow/section11/#41151-curl","text":"\u8fd0\u884c\u4e0b\u9762\u547d\u4ee4 curl - d '{\"instances\": [image_data]}' \\ - X POST http : // localhost : 8501 / v1 / models / mlp : predict","title":"4.11.5.1 \u76f4\u63a5\u4f7f\u7528curl"},{"location":"tensorFlow/section11/#41152","text":"\u793a\u4f8b\u4f7f\u7528Python \u7684 Requests \u5e93\uff08\u4f60\u53ef\u80fd\u9700\u8981\u4f7f\u7528 pip install requests \u5b89\u88c5\u8be5\u5e93\uff09\u5411\u672c\u673a\u7684 TensorFlow Serving \u670d\u52a1\u5668\u53d1\u900120\u5f20\u56fe\u50cf\u5e76\u8fd4\u56de\u9884\u6d4b\u7ed3\u679c\uff0c\u540c\u65f6\u4e0e\u6d4b\u8bd5\u96c6\u7684\u771f\u5b9e\u6807\u7b7e\u8fdb\u884c\u6bd4\u8f83\u3002 def client(): import json import numpy as np import requests (_, _), (test, test_label) = \\ tf.keras.datasets.cifar100.load_data() data = json.dumps({ \"instances\": test[0:20].tolist() # array\u8f6c\u6362\u6210\u5217\u8868\u5f62\u5f0f }) headers = {\"content-type\": \"application/json\"} json_response = requests.post( 'http://localhost:8501/v1/models/mlp:predict', data=data, headers=headers) predictions = np.array(json.loads(json_response.text)['predictions']) print(np.argmax(predictions, axis=-1)) print(test_label[0:20]) if __name__ == '__main__': # main() # test() client() \u8f93\u51fa\uff1a [ 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 ] [[ 49 ] [ 33 ] [ 72 ] [ 51 ] [ 71 ] [ 92 ] [ 15 ] [ 14 ] [ 23 ] [ 0 ] [ 71 ] [ 75 ] [ 81 ] [ 69 ] [ 40 ] [ 43 ] [ 92 ] [ 97 ] [ 70 ] [ 53 ]] \u56e0\u4e3a\u6a21\u578b\u5e76\u6ca1\u6709\u8bad\u7ec3\u591a\u4e45\uff0c\u53ea\u8fed\u4ee3\u4e00\u6b21\uff0c\u6240\u4ee5\u6548\u679c\u4e0d\u597d\uff0c\u4e3b\u8981\u662f\u5b8c\u6210\u6574\u4e2a\u6d41\u7a0b\u3002","title":"4.11.5.2 \u7f16\u5199\u5ba2\u6237\u7aef\u4ee3\u7801"},{"location":"tensorFlow/section11/#4115-hparams-","text":"\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65f6\uff0c\u9700\u8981\u9009\u62e9\u5404\u79cd\u8d85\u53c2\u6570\uff0c\u4f8b\u5982\u6a21\u578b\u4e2d\u7684\u5b66\u4e60\u7387\uff0c\u4f18\u5316\u5668\uff0c\u795e\u7ecf\u5143\u4e2a\u6570\u7b49\u3002\u8fd9\u4e9b\u51b3\u7b56\u4f1a\u5f71\u54cd\u6a21\u578b\u6307\u6807\uff0c\u4f8b\u5982\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4\u662f\u4e3a\u60a8\u7684\u95ee\u9898\u786e\u5b9a\u6700\u4f73\u7684\u8d85\u53c2\u6570\uff0c\u8fd9\u901a\u5e38\u6d89\u53ca\u5b9e\u9a8c\u3002\u6b64\u8fc7\u7a0b\u79f0\u4e3a\u201c\u8d85\u53c2\u6570\u4f18\u5316\u201d\u6216\u201c\u8d85\u53c2\u6570\u8c03\u6574\u201d\u3002TensorBoard\u4e2d\u7684HParams\u4eea\u8868\u677f\u63d0\u4f9b\u4e86\u591a\u79cd\u5de5\u5177\uff0c\u5e2e\u52a9\u786e\u5b9a\u6700\u4f73\u5b9e\u9a8c\u6216\u6700\u6709\u5e0c\u671b\u7684\u8d85\u53c2\u6570\u96c6\u3002 \u6ce8\uff1aNote: The HParams summary APIs and dashboard UI are in a preview stage and will change over time. \u4f7f\u7528\u5bfc\u5165 from tensorboard.plugins.hparams import api as hp","title":"4.11.5 HParams-\u8d85\u53c2\u6570\u8c03\u4f18"},{"location":"tensorFlow/section11/#41151-cifar100","text":"\u4f7f\u7528\u6b65\u9aa4 1\u3001\u901a\u8fc7hp\u8bbe\u7f6eHParams \u5b9e\u9a8c\u8d85\u53c2\u6570 2\u3001\u5c06\u8bd5\u9a8c\u53c2\u6570\u6dfb\u52a0\u5230\u6a21\u578b\u6307\u5b9a\u7ed3\u6784\u5f53\u4e2d\uff0c\u6216\u8005\u7f16\u8bd1\u8bad\u7ec3\u7684\u8fc7\u7a0b\u53c2\u6570\u4e2d 3\u3001\u4f7f\u7528\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\u5bf9\u4e0d\u540c\u7684\u8d85\u53c2\u6570\u96c6\u8bad\u7ec3\u6bcf\u4e2a\u5b9e\u9a8c\u7ec4\u5408 1\u3001\u8bbe\u7f6eHParams \u5b9e\u9a8c\u53c2\u6570 hp.Discrete:\u8bbe\u7f6e\u79bb\u6563\u7c7b\u578b\u7684\u53c2\u6570\u503c\uff0c\u6bd4\u5982\u795e\u7ecf\u5143\u4e2a\u6570\uff0c\u4f18\u5316\u65b9\u6cd5 \u901a\u8fc7HP_NUM_UNITS.domain.values\u83b7\u53d6\u6240\u6709\u7684\u503c hp.RealInterval:\u8bbe\u7f6e\u8fde\u7eed\u578b\u7c7b\u578b\u7684\u4e0a\u4e0b\u9650\uff0c\u80fd\u591f\u83b7\u53d6\u6700\u5927\u503c\u6700\u5c0f\u503c HP_DROPOUT.domain.min_value:\u83b7\u53d6\u6700\u5c0f\u503c HP_DROPOUT.domain.max_value:\u83b7\u53d6\u6700\u5927\u503c HP_NUM_UNITS = hp . HParam ( 'num_units' , hp . Discrete ([ 1024 , 512 ])) HP_DROPOUT = hp . HParam ( 'dropout' , hp . RealInterval ( 0.2 , 0.3 )) HP_OPTIMIZER = hp . HParam ( 'optimizer' , hp . Discrete ([ 'adam' , 'sgd' ])) 2\u3001\u5c06\u8bd5\u9a8c\u53c2\u6570\u6dfb\u52a0\u5230\u6a21\u578b\u6307\u5b9a\u7ed3\u6784\u5f53\u4e2d\uff0c\u6216\u8005\u7f16\u8bd1\u8bad\u7ec3\u7684\u8fc7\u7a0b\u53c2\u6570\u4e2d (1)\u5728\u9700\u8981\u8bbe\u7f6e\u8d85\u53c2\u6570\u7684\u4f4d\u7f6e\u586b\u5165hparams\u53c2\u6570\u503c (2)\u6dfb\u52a0\u8bb0\u5f55hparams\u7684\u56de\u8c03hp.KerasCallback('./logs/hparam_tuning/', hparams) \u5176\u4e2d\u76ee\u5f55\u81ea\u5df1\u8bbe\u5b9a\u5373\u53ef def train_test_model ( self , hparams ): \"\"\"\u8bad\u7ec3\u9a8c\u8bc1\u6a21\u578b :return: \"\"\" # 1\u3001\u5b9a\u4e49\u6a21\u578b\u4e2d\u52a0\u5165\u4e86\u4e00\u4e2adropout model = tf . keras . Sequential ([ tf . keras . layers . Conv2D ( 32 , kernel_size = 5 , strides = 1 , padding = 'same' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), tf . keras . layers . Conv2D ( 64 , kernel_size = 5 , strides = 1 , padding = 'same' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 ), tf . keras . layers . Flatten (), tf . keras . layers . Dense ( hparams [ HP_NUM_UNITS ], activation = tf . nn . relu ), tf . keras . layers . Dropout ( hparams [ HP_DROPOUT ]), tf . keras . layers . Dense ( 100 , activation = tf . nn . softmax ) ]) # 2\u3001\u6a21\u578b\u8bbe\u7f6e\u4ee5\u53ca\u8bad\u7ec3 model . compile ( optimizer = hparams [ HP_OPTIMIZER ], loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ 'accuracy' ]) tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) # \u6dfb\u52a0\u8bb0\u5f55hparams\u7684\u56de\u8c03hp.KerasCallback('./graph/', hparams) model . fit ( self . train , self . train_label , epochs = 1 , batch_size = 32 , callbacks = [ tensorboard , hp . KerasCallback ( './logs/hparam_tuning/' , hparams )], validation_data = ( self . test , self . test_label )) return None 3\u3001\u4f7f\u7528\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\u5bf9\u4e0d\u540c\u7684\u8d85\u53c2\u6570\u96c6\u8bad\u7ec3\u6bcf\u4e2a\u5b9e\u9a8c\u7ec4\u5408 \u4f7f\u7528\u7f51\u683c\u641c\u7d22\uff1a\u5c1d\u8bd5\u4f7f\u7528\u79bb\u6563\u53c2\u6570\u7684\u6240\u6709\u7ec4\u5408\u6216\u8005\u8fde\u7eed\u578b\u503c\u53c2\u6570\u7684\u4e0a\u9650\u548c\u4e0b\u9650\u3002\u5bf9\u4e8e\u66f4\u590d\u6742\u7684\u573a\u666f\uff0c\u968f\u673a\u9009\u62e9\u6bcf\u4e2a\u8d85\u53c2\u6570\u503c\u4f1a\u66f4\u6709\u6548\uff08\u968f\u673a\u641c\u7d22\uff09\u3002 def hyper_parameter ( self ): \"\"\"\u8d85\u53c2\u6570\u8c03\u4f18 :return: \"\"\" session_num = 0 for num_units in HP_NUM_UNITS . domain . values : for dropout_rate in ( HP_DROPOUT . domain . min_value , HP_DROPOUT . domain . max_value ): for optimizer in HP_OPTIMIZER . domain . values : hparams = { HP_NUM_UNITS : num_units , HP_DROPOUT : dropout_rate , HP_OPTIMIZER : optimizer , } print ( '--- \u5f00\u59cb \u5b9e\u9a8c: %s ' % session_num ) print ({ h . name : hparams [ h ] for h in hparams }) self . train_test_model ( hparams ) session_num += 1 return None \u6ce8\uff1a\u5176\u4e2d\u5982\u679c\u5bf9\u4e8e\u8fde\u7eed\u7684\u503c\u6bd4\u5982\u8bf4\u4f60\u7684\u6a21\u578b\u4e2dlearning_rate,\u5047\u8bbe\u8bbe\u7f6e0.0001~0.1\uff0c\u53ef\u4ee5\u8fd9\u6837\u8fed\u4ee3\u4f7f\u7528 for lr_tate in tf.linspace( HP_LR.domain.min_value, HP_LR.domain.max_value, res): \u6700\u7ec8\u6253\u5370\u6548\u679c\u4e3a\uff1a --- \u5f00\u59cb \u5b9e\u9a8c : 0 { 'num_units' : 512 , 'dropout' : 0.2 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 21 : 58 - loss : 4.6257 - accuracy : 0.0000e+002020 - 03 - 22 05 : 02 : 24.239954 : E 50000 / 50000 [ ============================== ] - 61 s 1 ms / sample - loss : 3.6983 - accuracy : 0.1391 - val_loss : 3.1219 - val_accuracy : 0.2460 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 60 s 1 ms / sample - loss : 2.9337 - accuracy : 0.2777 - val_loss : 2.7689 - val_accuracy : 0.3094 --- \u5f00\u59cb \u5b9e\u9a8c : 1 { 'num_units' : 512 , 'dropout' : 0.2 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 12 - loss : 4.5919 - accuracy : 0.0000e+002020 - 03 - 22 05 : 04 : 26.409071 : E 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 4.3805 - accuracy : 0.0404 - val_loss : 4.1078 - val_accuracy : 0.0641 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 3.9086 - accuracy : 0.1072 - val_loss : 3.7098 - val_accuracy : 0.1479 --- \u5f00\u59cb \u5b9e\u9a8c : 2 { 'num_units' : 512 , 'dropout' : 0.3 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 11 : 06 - loss : 4.6464 - accuracy : 0.03122020 - 03 - 22 05 : 06 : 18.355198 : E 50000 / 50000 [ ============================== ] - 61 s 1 ms / sample - loss : 3.7051 - accuracy : 0.1400 - val_loss : 3.1361 - val_accuracy : 0.2422 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 60 s 1 ms / sample - loss : 2.9754 - accuracy : 0.2687 - val_loss : 2.7621 - val_accuracy : 0.3118 --- \u5f00\u59cb \u5b9e\u9a8c : 3 { 'num_units' : 512 , 'dropout' : 0.3 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 03 - loss : 4.5909 - accuracy : 0.0000e+002020 - 03 - 22 05 : 08 : 20.864262 : E 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 4.3802 - accuracy : 0.0399 - val_loss : 4.0482 - val_accuracy : 0.0807 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 55 s 1 ms / sample - loss : 3.9227 - accuracy : 0.1036 - val_loss : 3.7022 - val_accuracy : 0.1423 --- \u5f00\u59cb \u5b9e\u9a8c : 4 { 'num_units' : 1024 , 'dropout' : 0.2 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 11 : 28 - loss : 4.6099 - accuracy : 0.0000e+002020 - 03 - 22 05 : 10 : 12.802252 : E 50000 / 50000 [ ============================== ] - 78 s 2 ms / sample - loss : 3.5546 - accuracy : 0.1683 - val_loss : 3.0440 - val_accuracy : 0.2580 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 77 s 2 ms / sample - loss : 2.7925 - accuracy : 0.3048 - val_loss : 2.7049 - val_accuracy : 0.3255 --- \u5f00\u59cb \u5b9e\u9a8c : 5 { 'num_units' : 1024 , 'dropout' : 0.2 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 22 - loss : 4.5938 - accuracy : 0.0000e+002020 - 03 - 22 05 : 12 : 50.161457 : E 50000 / 50000 [ ============================== ] - 68 s 1 ms / sample - loss : 4.3278 - accuracy : 0.0477 - val_loss : 3.9872 - val_accuracy : 0.0849 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 67 s 1 ms / sample - loss : 3.8071 - accuracy : 0.1244 - val_loss : 3.6097 - val_accuracy : 0.1679 --- \u5f00\u59cb \u5b9e\u9a8c : 6 { 'num_units' : 1024 , 'dropout' : 0.3 , 'optimizer' : 'adam' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 11 : 14 - loss : 4.6129 - accuracy : 0.0000e+002020 - 03 - 22 05 : 15 : 07.480836 : E 50000 / 50000 [ ============================== ] - 78 s 2 ms / sample - loss : 3.6139 - accuracy : 0.1548 - val_loss : 2.9943 - val_accuracy : 0.2691 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 77 s 2 ms / sample - loss : 2.8460 - accuracy : 0.2921 - val_loss : 2.7325 - val_accuracy : 0.3195 --- \u5f00\u59cb \u5b9e\u9a8c : 7 { 'num_units' : 1024 , 'dropout' : 0.3 , 'optimizer' : 'sgd' } Train on 50000 samples , validate on 10000 samples Epoch 1 / 2 32 / 50000 [ .............................. ] - ETA : 9 : 22 - loss : 4.5689 - accuracy : 0.03122020 - 03 - 22 05 : 17 : 44.697445 : E 50000 / 50000 [ ============================== ] - 68 s 1 ms / sample - loss : 4.3251 - accuracy : 0.0469 - val_loss : 3.9708 - val_accuracy : 0.1038 Epoch 2 / 2 50000 / 50000 [ ============================== ] - 67 s 1 ms / sample - loss : 3.8546 - accuracy : 0.1173 - val_loss : 3.6345 - val_accuracy : 0.1653 \u751f\u6210\u5982\u4e0b\u76ee\u5f55 4\u3001\u6700\u7ec8\u53ef\u4ee5\u901a\u8fc7Tensoboard\u5f00\u542f\u8bfb\u53d6\u5bf9\u5e94\u76ee\u5f55\u7684events\u6587\u4ef6\u770b\u5230\u5bf9\u5e94\u7ed3\u679c tensorboard -- logdir './logs/hparam_tuning/' \u53ef\u4ee5\u5728HPARAMS\u83dc\u5355\u4e2d\u67e5\u770b\u5230\u4e0b\u9762\u7684\u6548\u679c(\u5b98\u7f51\u622a\u56fe) \u5e76\u4e14\u5176\u4e2d\u6709\u63d0\u4f9b\u4e86\u4e24\u79cd\u4e3b\u8981\u7684\u4e0d\u540c\u7684\u67e5\u770b\u65b9\u5f0f\uff1a 1\u3001\u8868\u89c6\u56fe(TABLE VIEW)\uff1a\u5217\u51fa\u4e86\u8fd0\u884c\u65f6\uff0c\u4ed6\u4eec\u7684\u8d85\u53c2\u6570\uff0c\u548c\u4ed6\u4eec\u7684\u6307\u6807\u3002 2\u3001\u5e73\u884c\u5750\u6807\u89c6\u56fe\uff1a\u6bcf\u4e2a\u8fd0\u884c\u4e3a\u7ebf\u901a\u8fc7\u6bcf\u4e2ahyperparemeter\u548c\u5ea6\u91cf\u7684\u8f74\u7ebf\u53bb\u3002\u5355\u51fb\u5e76\u5728\u4efb\u4f55\u8f74\u4e0a\u62d6\u52a8\u9f20\u6807\u4ee5\u6807\u8bb0\u4e00\u4e2a\u533a\u57df\uff0c\u8be5\u533a\u57df\u5c06\u4ec5\u7a81\u51fa\u663e\u793a\u901a\u8fc7\u8be5\u533a\u57df\u7684\u8fd0\u884c\u3002\u8fd9\u5bf9\u4e8e\u786e\u5b9a\u54ea\u4e9b\u8d85\u53c2\u6570\u7ec4\u6700\u91cd\u8981\u5f88\u6709\u7528","title":"4.11.5.1 \u6848\u4f8b\uff1aCIFAR100\u5206\u7c7b\u6a21\u578b\u6dfb\u52a0\u53c2\u6570\u8fdb\u884c\u8c03\u4f18"},{"location":"tensorFlow/section11/#4116","text":"TensorFlow\u6a21\u578b\u7684\u5bfc\u51fa(saved_model\u683c\u5f0f) Tensorflow\u6a21\u578b\u7684\u90e8\u7f72 TensorFlow\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u8c03\u7528 TensorFlow\u6a21\u578b\u7684\u8d85\u53c2\u6570\u8c03\u4f18","title":"4.11.6 \u603b\u7ed3"},{"location":"tensorFlow/section2/","text":"1.2 \u5feb\u901f\u5165\u95e8\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4f7f\u7528tf.keras\u7684\u57fa\u672c\u6d41\u7a0b \u4e86\u89e3tf.keras\u5b9e\u73b0\u6a21\u578b\u6784\u5efa\u7684\u65b9\u6cd5 \u4e86\u89e3tf.keras\u4e2d\u6a21\u578b\u8bad\u7ec3\u9a8c\u8bc1\u7684\u76f8\u5173\u65b9\u6cd5 \u4eca\u5929\u6211\u4eec\u901a\u8fc7\u9e22\u5c3e\u82b1\u5206\u7c7b\u6848\u4f8b\uff0c\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecdtf.keras\u7684\u57fa\u672c\u4f7f\u7528\u6d41\u7a0b\u3002tf.keras\u4f7f\u7528tensorflow\u4e2d\u7684\u9ad8\u7ea7\u63a5\u53e3\uff0c\u6211\u4eec\u8c03\u7528\u5b83\u5373\u53ef\u5b8c\u6210\uff1a \u5bfc\u5165\u548c\u89e3\u6790\u6570\u636e\u96c6 \u6784\u5efa\u6a21\u578b \u4f7f\u7528\u6837\u672c\u6570\u636e\u8bad\u7ec3\u8be5\u6a21\u578b \u8bc4\u4f30\u6a21\u578b\u7684\u6548\u679c\u3002 \u7531\u4e8e\u4e0escikiti -learn\u7684\u76f8\u4f3c\u6027\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u901a\u8fc7\u5c06Keras\u4e0escikiti -learn\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ecb\u7ecdtf.Keras\u7684\u76f8\u5173\u4f7f\u7528\u65b9\u6cd5\u3002 1.\u76f8\u5173\u7684\u5e93\u7684\u5bfc\u5165 \u00b6 \u5728\u8fd9\u91cc\u4f7f\u7528sklearn\u548ctf.keras\u5b8c\u6210\u9e22\u5c3e\u82b1\u5206\u7c7b\uff0c\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a # \u7ed8\u56fe import seaborn as sns # \u6570\u503c\u8ba1\u7b97 import numpy as np # sklearn\u4e2d\u7684\u76f8\u5173\u5de5\u5177 # \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 from sklearn.model_selection import train_test_split # \u903b\u8f91\u56de\u5f52 from sklearn.linear_model import LogisticRegressionCV # tf.keras\u4e2d\u4f7f\u7528\u7684\u76f8\u5173\u5de5\u5177 # \u7528\u4e8e\u6a21\u578b\u642d\u5efa from tensorflow.keras.models import Sequential # \u6784\u5efa\u6a21\u578b\u7684\u5c42\u548c\u6fc0\u6d3b\u65b9\u6cd5 from tensorflow.keras.layers import Dense , Activation # \u6570\u636e\u5904\u7406\u7684\u8f85\u52a9\u5de5\u5177 from tensorflow.keras import utils 2.\u6570\u636e\u5c55\u793a\u548c\u5212\u5206 \u00b6 \u5229\u7528seborn\u5bfc\u5165\u76f8\u5173\u7684\u6570\u636e\uff0ciris\u6570\u636e\u4ee5dataFrame\u7684\u65b9\u5f0f\u5728seaborn\u8fdb\u884c\u5b58\u50a8\uff0c\u6211\u4eec\u8bfb\u53d6\u540e\u5e76\u8fdb\u884c\u5c55\u793a\uff1a # \u8bfb\u53d6\u6570\u636e iris = sns . load_dataset ( \"iris\" ) # \u5c55\u793a\u6570\u636e\u7684\u524d\u4e94\u884c iris . head () \u53e6\u5916\uff0c\u5229\u7528seaborn\u4e2dpairplot\u51fd\u6570\u63a2\u7d22\u6570\u636e\u7279\u5f81\u95f4\u7684\u5173\u7cfb\uff1a # \u5c06\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316 sns . pairplot ( iris , hue = 'species' ) \u5c06\u6570\u636e\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff1a\u4eceiris dataframe\u4e2d\u63d0\u53d6\u539f\u59cb\u6570\u636e\uff0c\u5c06\u82b1\u74e3\u548c\u843c\u7247\u6570\u636e\u4fdd\u5b58\u5728\u6570\u7ec4X\u4e2d\uff0c\u6807\u7b7e\u4fdd\u5b58\u5728\u76f8\u5e94\u7684\u6570\u7ec4y\u4e2d\uff1a # \u82b1\u74e3\u548c\u82b1\u843c\u7684\u6570\u636e X = iris . values [:, : 4 ] # \u6807\u7b7e\u503c y = iris . values [:, 4 ] \u5229\u7528train_test_split\u5b8c\u6210\u6570\u636e\u96c6\u5212\u5206\uff1a # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 train_X , test_X , train_y , test_y = train_test_split ( X , y , train_size = 0.5 , test_size = 0.5 , random_state = 0 ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528sklearn\u548ctf.keras\u6765\u5b8c\u6210\u9884\u6d4b 3.sklearn\u5b9e\u73b0 \u00b6 \u5229\u7528\u903b\u8f91\u56de\u5f52\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u4f18\u7684\u8d85\u53c2\u6570\uff0c\u5b9e\u4f8b\u5316LogisticRegressionCV\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff1a # \u5b9e\u4f8b\u5316\u5206\u7c7b\u5668 lr = LogisticRegressionCV () # \u8bad\u7ec3 lr . fit ( train_X , train_y ) \u5229\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u8ba1\u7b97\u51c6\u786e\u7387\uff1a # \u8ba1\u7b97\u51c6\u786e\u7387\u5e76\u8fdb\u884c\u6253\u5370 print ( \"Accuracy = {:.2f}\" . format ( lr . score ( test_X , test_y ))) \u903b\u8f91\u56de\u5f52\u7684\u51c6\u786e\u7387\u4e3a\uff1a Accuracy = 0.93 4.tf.keras\u5b9e\u73b0 \u00b6 \u5728sklearn\u4e2d\u6211\u4eec\u53ea\u8981\u5b9e\u4f8b\u5316\u5206\u7c7b\u5668\u5e76\u5229\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u8861\u91cf\u5b83\u7684\u6027\u80fd\u5c31\u53ef\u4ee5\u4e86\uff0c\u90a3\u5728tf.keras\u4e2d\u4e0e\u5728sklearn\u975e\u5e38\u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u662f\uff1a \u6784\u5efa\u5206\u7c7b\u5668\u65f6\u9700\u8981\u8fdb\u884c\u6a21\u578b\u642d\u5efa \u6570\u636e\u91c7\u96c6\u65f6\uff0csklearn\u53ef\u4ee5\u63a5\u6536\u5b57\u7b26\u4e32\u578b\u7684\u6807\u7b7e\uff0c\u5982\uff1a\u201csetosa\u201d\uff0c\u4f46\u662f\u5728tf.keras\u4e2d\u9700\u8981\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u70ed\u7f16\u7801\uff0c\u6bd4\u5982pandas\u4e2d\u7684get_dummies(),\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras\u4e2d\u7684\u65b9\u6cd5\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8fdb\u884c\u70ed\u7f16\u7801 def one_hot_encode_object_array ( arr ): # \u53bb\u91cd\u83b7\u53d6\u5168\u90e8\u7684\u7c7b\u522b uniques , ids = np . unique ( arr , return_inverse = True ) # \u8fd4\u56de\u70ed\u7f16\u7801\u7684\u7ed3\u679c return utils . to_categorical ( ids , len ( uniques )) 4.1 \u6570\u636e\u5904\u7406 \u00b6 \u63a5\u4e0b\u6765\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8bad\u7ec3\u96c6\u70ed\u7f16\u7801 train_y_ohe = one_hot_encode_object_array ( train_y ) # \u6d4b\u8bd5\u96c6\u70ed\u7f16\u7801 test_y_ohe = one_hot_encode_object_array ( test_y ) 4.2 \u6a21\u578b\u642d\u5efa \u00b6 \u5728sklearn\u4e2d\uff0c\u6a21\u578b\u90fd\u662f\u73b0\u6210\u7684\u3002tf.Keras\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u5e93,\u6211\u4eec\u9700\u8981\u6839\u636e\u6570\u636e\u548c\u6807\u7b7e\u503c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u3002\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u53d1\u73b0\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u4e2a\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u56fe\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u9690\u85cf\u5c42\u3002\u6bcf\u4e2a\u9690\u85cf\u5c42\u90fd\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u795e\u7ecf\u5143\u3002\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u79cd\u7c7b\u522b\uff0c\u8be5\u7a0b\u5e8f\u4f7f\u7528\u7684\u662f\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u79f0\u4e3a\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff1a\u4e00\u4e2a\u5c42\u4e2d\u7684\u795e\u7ecf\u5143\u5c06\u4ece\u4e0a\u4e00\u5c42\u4e2d\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u83b7\u53d6\u8f93\u5165\u8fde\u63a5\u3002\u4f8b\u5982\uff0c\u56fe 2 \u663e\u793a\u4e86\u4e00\u4e2a\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u4e2d\u5305\u542b 1 \u4e2a\u8f93\u5165\u5c42\u30012 \u4e2a\u9690\u85cf\u5c42\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe \u4e2d\u7684\u6a21\u578b\u7ecf\u8fc7\u8bad\u7ec3\u5e76\u9988\u9001\u672a\u6807\u8bb0\u7684\u6837\u672c\u65f6\uff0c\u5b83\u4f1a\u4ea7\u751f 3 \u4e2a\u9884\u6d4b\u7ed3\u679c\uff1a\u76f8\u5e94\u9e22\u5c3e\u82b1\u5c5e\u4e8e\u6307\u5b9a\u54c1\u79cd\u7684\u53ef\u80fd\u6027\u3002\u5bf9\u4e8e\u8be5\u793a\u4f8b\uff0c\u8f93\u51fa\u9884\u6d4b\u7ed3\u679c\u7684\u603b\u548c\u662f 1.0\u3002\u8be5\u9884\u6d4b\u7ed3\u679c\u5206\u89e3\u5982\u4e0b\uff1a\u5c71\u9e22\u5c3e\u4e3a 0.02\uff0c\u53d8\u8272\u9e22\u5c3e\u4e3a 0.95\uff0c\u7ef4\u5409\u5c3c\u4e9a\u9e22\u5c3e\u4e3a 0.03\u3002\u8fd9\u610f\u5473\u7740\u8be5\u6a21\u578b\u9884\u6d4b\u67d0\u4e2a\u65e0\u6807\u7b7e\u9e22\u5c3e\u82b1\u6837\u672c\u662f\u53d8\u8272\u9e22\u5c3e\u7684\u6982\u7387\u4e3a 95\uff05\u3002 TensorFlow tf.keras API \u662f\u521b\u5efa\u6a21\u578b\u548c\u5c42\u7684\u9996\u9009\u65b9\u5f0f\u3002\u901a\u8fc7\u8be5 API\uff0c\u60a8\u53ef\u4ee5\u8f7b\u677e\u5730\u6784\u5efa\u6a21\u578b\u5e76\u8fdb\u884c\u5b9e\u9a8c\uff0c\u800c\u5c06\u6240\u6709\u90e8\u5206\u8fde\u63a5\u5728\u4e00\u8d77\u7684\u590d\u6742\u5de5\u4f5c\u5219\u7531 Keras \u5904\u7406\u3002 tf.keras.Sequential \u6a21\u578b\u662f\u5c42\u7684\u7ebf\u6027\u5806\u53e0\u3002\u8be5\u6a21\u578b\u7684\u6784\u9020\u51fd\u6570\u4f1a\u91c7\u7528\u4e00\u7cfb\u5217\u5c42\u5b9e\u4f8b\uff1b\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u91c7\u7528\u7684\u662f 2 \u4e2a\u5bc6\u96c6\u5c42\uff08\u5206\u522b\u5305\u542b 10 \u4e2a\u8282\u70b9\uff09\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff08\u5305\u542b 3 \u4e2a\u4ee3\u8868\u6807\u7b7e\u9884\u6d4b\u7684\u8282\u70b9\uff09\u3002\u7b2c\u4e00\u4e2a\u5c42\u7684 input_shape \u53c2\u6570\u5bf9\u5e94\u8be5\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5f81\u6570\u91cf\uff1a # \u5229\u7528sequential\u65b9\u5f0f\u6784\u5efa\u6a21\u578b model = Sequential ([ # \u9690\u85cf\u5c421\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu,\u8f93\u5165\u5927\u5c0f\u6709input_shape\u6307\u5b9a Dense ( 10 , activation = \"relu\" , input_shape = ( 4 ,)), # \u9690\u85cf\u5c422\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu Dense ( 10 , activation = \"relu\" ), # \u8f93\u51fa\u5c42 Dense ( 3 , activation = \"softmax\" ) ]) \u901a\u8fc7model.summary\u53ef\u4ee5\u67e5\u770b\u6a21\u578b\u7684\u67b6\u6784\uff1a Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 10) 50 _________________________________________________________________ dense_1 (Dense) (None, 10) 110 _________________________________________________________________ dense_2 (Dense) (None, 3) 33 ================================================================= Total params: 193 Trainable params: 193 Non-trainable params: 0 _________________________________________________________________ \u6fc0\u6d3b\u51fd\u6570\u53ef\u51b3\u5b9a\u5c42\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u5f62\u72b6\u3002\u8fd9\u4e9b\u975e\u7ebf\u6027\u5173\u7cfb\u5f88\u91cd\u8981\uff0c\u5982\u679c\u6ca1\u6709\u5b83\u4eec\uff0c\u6a21\u578b\u5c06\u7b49\u540c\u4e8e\u5355\u4e2a\u5c42\u3002\u6fc0\u6d3b\u51fd\u6570\u6709\u5f88\u591a\uff0c\u4f46\u9690\u85cf\u5c42\u901a\u5e38\u4f7f\u7528 ReLU\u3002 \u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u7406\u60f3\u6570\u91cf\u53d6\u51b3\u4e8e\u95ee\u9898\u548c\u6570\u636e\u96c6\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u591a\u4e2a\u65b9\u9762\u4e00\u6837\uff0c\u9009\u62e9\u6700\u4f73\u7684\u795e\u7ecf\u7f51\u7edc\u5f62\u72b6\u9700\u8981\u4e00\u5b9a\u7684\u77e5\u8bc6\u6c34\u5e73\u548c\u5b9e\u9a8c\u57fa\u7840\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u6570\u91cf\u901a\u5e38\u4f1a\u4ea7\u751f\u66f4\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u800c\u8fd9\u9700\u8981\u66f4\u591a\u6570\u636e\u624d\u80fd\u6709\u6548\u5730\u8fdb\u884c\u8bad\u7ec3\u3002 4.3 \u6a21\u578b\u8bad\u7ec3\u548c\u9884\u6d4b \u00b6 \u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u9636\u6bb5\uff0c\u6211\u4eec\u90fd\u9700\u8981\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u3002\u8fd9\u6837\u53ef\u4ee5\u8861\u91cf\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u9884\u671f\u6807\u7b7e\u6709\u591a\u5927\u504f\u5dee\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6a21\u578b\u7684\u6548\u679c\u6709\u591a\u5dee\u3002\u6211\u4eec\u5e0c\u671b\u5c3d\u53ef\u80fd\u51cf\u5c0f\u6216\u4f18\u5316\u8fd9\u4e2a\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u8bbe\u7f6e\u4f18\u5316\u7b56\u7565\u548c\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u53ca\u6a21\u578b\u7cbe\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff1a # \u8bbe\u7f6e\u6a21\u578b\u7684\u76f8\u5173\u53c2\u6570\uff1a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ \"accuracy\" ]) \u63a5\u4e0b\u6765\u4e0e\u5728sklearn\u4e2d\u76f8\u540c\uff0c\u5206\u522b\u8c03\u7528fit\u548cpredict\u65b9\u6cd5\u8fdb\u884c\u9884\u6d4b\u5373\u53ef\u3002 # \u6a21\u578b\u8bad\u7ec3\uff1aepochs,\u8bad\u7ec3\u6837\u672c\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6b21\u6570\uff0cbatch_size:\u6bcf\u6b21\u8bad\u7ec3\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6837\u672c\u4e2a\u6570 model . fit ( train_X , train_y_ohe , epochs = 10 , batch_size = 1 , verbose = 1 ); \u4e0a\u8ff0\u4ee3\u7801\u5b8c\u6210\u7684\u662f\uff1a \u8fed\u4ee3\u6bcf\u4e2aepoch\u3002\u901a\u8fc7\u4e00\u6b21\u6570\u636e\u96c6\u5373\u4e3a\u4e00\u4e2aepoch\u3002 \u5728\u4e00\u4e2aepoch\u4e2d\uff0c\u904d\u5386\u8bad\u7ec3 Dataset \u4e2d\u7684\u6bcf\u4e2a\u6837\u672c\uff0c\u5e76\u83b7\u53d6\u6837\u672c\u7684\u7279\u5f81 (x) \u548c\u6807\u7b7e (y)\u3002 \u6839\u636e\u6837\u672c\u7684\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u6bd4\u8f83\u9884\u6d4b\u7ed3\u679c\u548c\u6807\u7b7e\u3002\u8861\u91cf\u9884\u6d4b\u7ed3\u679c\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u5e76\u4f7f\u7528\u6240\u5f97\u7684\u503c\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u68af\u5ea6\u3002 \u4f7f\u7528 optimizer \u66f4\u65b0\u6a21\u578b\u7684\u53d8\u91cf\u3002 \u5bf9\u6bcf\u4e2aepoch\u91cd\u590d\u6267\u884c\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u76f4\u5230\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u5c55\u793a\u5982\u4e0b\uff1a Epoch 1/10 75/75 [==============================] - 0s 616us/step - loss: 0.0585 - accuracy: 0.9733 Epoch 2/10 75/75 [==============================] - 0s 535us/step - loss: 0.0541 - accuracy: 0.9867 Epoch 3/10 75/75 [==============================] - 0s 545us/step - loss: 0.0650 - accuracy: 0.9733 Epoch 4/10 75/75 [==============================] - 0s 542us/step - loss: 0.0865 - accuracy: 0.9733 Epoch 5/10 75/75 [==============================] - 0s 510us/step - loss: 0.0607 - accuracy: 0.9733 Epoch 6/10 75/75 [==============================] - 0s 659us/step - loss: 0.0735 - accuracy: 0.9733 Epoch 7/10 75/75 [==============================] - 0s 497us/step - loss: 0.0691 - accuracy: 0.9600 Epoch 8/10 75/75 [==============================] - 0s 497us/step - loss: 0.0724 - accuracy: 0.9733 Epoch 9/10 75/75 [==============================] - 0s 493us/step - loss: 0.0645 - accuracy: 0.9600 Epoch 10/10 75/75 [==============================] - 0s 482us/step - loss: 0.0660 - accuracy: 0.9867 \u4e0esklearn\u4e2d\u4e0d\u540c\uff0c\u5bf9\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0c\u4e0esklearn.score\u65b9\u6cd5\u5bf9\u5e94\u7684\u662ftf.keras.evaluate()\u65b9\u6cd5\uff0c\u8fd4\u56de\u7684\u662f\u635f\u5931\u51fd\u6570\u548c\u5728compile\u6a21\u578b\u65f6\u8981\u6c42\u7684\u6307\u6807: # \u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u51c6\u786e\u7387 loss , accuracy = model . evaluate ( test_X , test_y_ohe , verbose = 1 ) print ( \"Accuracy = {:.2f}\" . format ( accuracy )) \u5206\u7c7b\u5668\u7684\u51c6\u786e\u7387\u4e3a\uff1a 3 / 3 [ ============================== ] - 0 s 591 us / step - loss : 0.1031 - accuracy : 0.9733 Accuracy = 0.97 \u5230\u6b64\u6211\u4eec\u5bf9tf.kears\u7684\u4f7f\u7528\u6709\u4e86\u4e00\u4e2a\u57fa\u672c\u7684\u8ba4\u77e5\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u4f1a\u7ed9\u5927\u5bb6\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5e38\u7528\u7684CNN\u7684\u4f7f\u7528\u3002 \u603b\u7ed3 1.\u4f7f\u7528tf.keras\u8fdb\u884c\u5206\u7c7b\u65f6\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a \u6570\u636e\u5904\u7406-\u6784\u5efa\u6a21\u578b-\u6a21\u578b\u8bad\u7ec3-\u6a21\u578b\u9a8c\u8bc1 2.tf.keras\u4e2d\u6784\u5efa\u6a21\u578b\u53ef\u901a\u8fc7squential()\u6765\u5b9e\u73b0\u5e76\u5229\u7528.fit()\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 3.\u4f7f\u7528evaluate()\u65b9\u6cd5\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387","title":"\u5feb\u901f\u5165\u95e8\u6a21\u578b"},{"location":"tensorFlow/section2/#12","text":"\u5b66\u4e60\u76ee\u6807 \u77e5\u9053\u4f7f\u7528tf.keras\u7684\u57fa\u672c\u6d41\u7a0b \u4e86\u89e3tf.keras\u5b9e\u73b0\u6a21\u578b\u6784\u5efa\u7684\u65b9\u6cd5 \u4e86\u89e3tf.keras\u4e2d\u6a21\u578b\u8bad\u7ec3\u9a8c\u8bc1\u7684\u76f8\u5173\u65b9\u6cd5 \u4eca\u5929\u6211\u4eec\u901a\u8fc7\u9e22\u5c3e\u82b1\u5206\u7c7b\u6848\u4f8b\uff0c\u6765\u7ed9\u5927\u5bb6\u4ecb\u7ecdtf.keras\u7684\u57fa\u672c\u4f7f\u7528\u6d41\u7a0b\u3002tf.keras\u4f7f\u7528tensorflow\u4e2d\u7684\u9ad8\u7ea7\u63a5\u53e3\uff0c\u6211\u4eec\u8c03\u7528\u5b83\u5373\u53ef\u5b8c\u6210\uff1a \u5bfc\u5165\u548c\u89e3\u6790\u6570\u636e\u96c6 \u6784\u5efa\u6a21\u578b \u4f7f\u7528\u6837\u672c\u6570\u636e\u8bad\u7ec3\u8be5\u6a21\u578b \u8bc4\u4f30\u6a21\u578b\u7684\u6548\u679c\u3002 \u7531\u4e8e\u4e0escikiti -learn\u7684\u76f8\u4f3c\u6027\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u901a\u8fc7\u5c06Keras\u4e0escikiti -learn\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ecb\u7ecdtf.Keras\u7684\u76f8\u5173\u4f7f\u7528\u65b9\u6cd5\u3002","title":"1.2 \u5feb\u901f\u5165\u95e8\u6a21\u578b"},{"location":"tensorFlow/section2/#1","text":"\u5728\u8fd9\u91cc\u4f7f\u7528sklearn\u548ctf.keras\u5b8c\u6210\u9e22\u5c3e\u82b1\u5206\u7c7b\uff0c\u5bfc\u5165\u76f8\u5173\u7684\u5de5\u5177\u5305\uff1a # \u7ed8\u56fe import seaborn as sns # \u6570\u503c\u8ba1\u7b97 import numpy as np # sklearn\u4e2d\u7684\u76f8\u5173\u5de5\u5177 # \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 from sklearn.model_selection import train_test_split # \u903b\u8f91\u56de\u5f52 from sklearn.linear_model import LogisticRegressionCV # tf.keras\u4e2d\u4f7f\u7528\u7684\u76f8\u5173\u5de5\u5177 # \u7528\u4e8e\u6a21\u578b\u642d\u5efa from tensorflow.keras.models import Sequential # \u6784\u5efa\u6a21\u578b\u7684\u5c42\u548c\u6fc0\u6d3b\u65b9\u6cd5 from tensorflow.keras.layers import Dense , Activation # \u6570\u636e\u5904\u7406\u7684\u8f85\u52a9\u5de5\u5177 from tensorflow.keras import utils","title":"1.\u76f8\u5173\u7684\u5e93\u7684\u5bfc\u5165"},{"location":"tensorFlow/section2/#2","text":"\u5229\u7528seborn\u5bfc\u5165\u76f8\u5173\u7684\u6570\u636e\uff0ciris\u6570\u636e\u4ee5dataFrame\u7684\u65b9\u5f0f\u5728seaborn\u8fdb\u884c\u5b58\u50a8\uff0c\u6211\u4eec\u8bfb\u53d6\u540e\u5e76\u8fdb\u884c\u5c55\u793a\uff1a # \u8bfb\u53d6\u6570\u636e iris = sns . load_dataset ( \"iris\" ) # \u5c55\u793a\u6570\u636e\u7684\u524d\u4e94\u884c iris . head () \u53e6\u5916\uff0c\u5229\u7528seaborn\u4e2dpairplot\u51fd\u6570\u63a2\u7d22\u6570\u636e\u7279\u5f81\u95f4\u7684\u5173\u7cfb\uff1a # \u5c06\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316 sns . pairplot ( iris , hue = 'species' ) \u5c06\u6570\u636e\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff1a\u4eceiris dataframe\u4e2d\u63d0\u53d6\u539f\u59cb\u6570\u636e\uff0c\u5c06\u82b1\u74e3\u548c\u843c\u7247\u6570\u636e\u4fdd\u5b58\u5728\u6570\u7ec4X\u4e2d\uff0c\u6807\u7b7e\u4fdd\u5b58\u5728\u76f8\u5e94\u7684\u6570\u7ec4y\u4e2d\uff1a # \u82b1\u74e3\u548c\u82b1\u843c\u7684\u6570\u636e X = iris . values [:, : 4 ] # \u6807\u7b7e\u503c y = iris . values [:, 4 ] \u5229\u7528train_test_split\u5b8c\u6210\u6570\u636e\u96c6\u5212\u5206\uff1a # \u5c06\u6570\u636e\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 train_X , test_X , train_y , test_y = train_test_split ( X , y , train_size = 0.5 , test_size = 0.5 , random_state = 0 ) \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528sklearn\u548ctf.keras\u6765\u5b8c\u6210\u9884\u6d4b","title":"2.\u6570\u636e\u5c55\u793a\u548c\u5212\u5206"},{"location":"tensorFlow/section2/#3sklearn","text":"\u5229\u7528\u903b\u8f91\u56de\u5f52\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u4f18\u7684\u8d85\u53c2\u6570\uff0c\u5b9e\u4f8b\u5316LogisticRegressionCV\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff1a # \u5b9e\u4f8b\u5316\u5206\u7c7b\u5668 lr = LogisticRegressionCV () # \u8bad\u7ec3 lr . fit ( train_X , train_y ) \u5229\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u8ba1\u7b97\u51c6\u786e\u7387\uff1a # \u8ba1\u7b97\u51c6\u786e\u7387\u5e76\u8fdb\u884c\u6253\u5370 print ( \"Accuracy = {:.2f}\" . format ( lr . score ( test_X , test_y ))) \u903b\u8f91\u56de\u5f52\u7684\u51c6\u786e\u7387\u4e3a\uff1a Accuracy = 0.93","title":"3.sklearn\u5b9e\u73b0"},{"location":"tensorFlow/section2/#4tfkeras","text":"\u5728sklearn\u4e2d\u6211\u4eec\u53ea\u8981\u5b9e\u4f8b\u5316\u5206\u7c7b\u5668\u5e76\u5229\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u8861\u91cf\u5b83\u7684\u6027\u80fd\u5c31\u53ef\u4ee5\u4e86\uff0c\u90a3\u5728tf.keras\u4e2d\u4e0e\u5728sklearn\u975e\u5e38\u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u662f\uff1a \u6784\u5efa\u5206\u7c7b\u5668\u65f6\u9700\u8981\u8fdb\u884c\u6a21\u578b\u642d\u5efa \u6570\u636e\u91c7\u96c6\u65f6\uff0csklearn\u53ef\u4ee5\u63a5\u6536\u5b57\u7b26\u4e32\u578b\u7684\u6807\u7b7e\uff0c\u5982\uff1a\u201csetosa\u201d\uff0c\u4f46\u662f\u5728tf.keras\u4e2d\u9700\u8981\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff0c\u5982\u4e0b\u6240\u793a\uff1a \u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u70ed\u7f16\u7801\uff0c\u6bd4\u5982pandas\u4e2d\u7684get_dummies(),\u5728\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528tf.keras\u4e2d\u7684\u65b9\u6cd5\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8fdb\u884c\u70ed\u7f16\u7801 def one_hot_encode_object_array ( arr ): # \u53bb\u91cd\u83b7\u53d6\u5168\u90e8\u7684\u7c7b\u522b uniques , ids = np . unique ( arr , return_inverse = True ) # \u8fd4\u56de\u70ed\u7f16\u7801\u7684\u7ed3\u679c return utils . to_categorical ( ids , len ( uniques ))","title":"4.tf.keras\u5b9e\u73b0"},{"location":"tensorFlow/section2/#41","text":"\u63a5\u4e0b\u6765\u5bf9\u6807\u7b7e\u503c\u8fdb\u884c\u70ed\u7f16\u7801\uff1a # \u8bad\u7ec3\u96c6\u70ed\u7f16\u7801 train_y_ohe = one_hot_encode_object_array ( train_y ) # \u6d4b\u8bd5\u96c6\u70ed\u7f16\u7801 test_y_ohe = one_hot_encode_object_array ( test_y )","title":"4.1 \u6570\u636e\u5904\u7406"},{"location":"tensorFlow/section2/#42","text":"\u5728sklearn\u4e2d\uff0c\u6a21\u578b\u90fd\u662f\u73b0\u6210\u7684\u3002tf.Keras\u662f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u5e93,\u6211\u4eec\u9700\u8981\u6839\u636e\u6570\u636e\u548c\u6807\u7b7e\u503c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u3002\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u53d1\u73b0\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002\u795e\u7ecf\u7f51\u7edc\u662f\u4e00\u4e2a\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u56fe\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u9690\u85cf\u5c42\u3002\u6bcf\u4e2a\u9690\u85cf\u5c42\u90fd\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u795e\u7ecf\u5143\u3002\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u79cd\u7c7b\u522b\uff0c\u8be5\u7a0b\u5e8f\u4f7f\u7528\u7684\u662f\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u79f0\u4e3a\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff1a\u4e00\u4e2a\u5c42\u4e2d\u7684\u795e\u7ecf\u5143\u5c06\u4ece\u4e0a\u4e00\u5c42\u4e2d\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u83b7\u53d6\u8f93\u5165\u8fde\u63a5\u3002\u4f8b\u5982\uff0c\u56fe 2 \u663e\u793a\u4e86\u4e00\u4e2a\u5bc6\u96c6\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u4e2d\u5305\u542b 1 \u4e2a\u8f93\u5165\u5c42\u30012 \u4e2a\u9690\u85cf\u5c42\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4e0a\u56fe \u4e2d\u7684\u6a21\u578b\u7ecf\u8fc7\u8bad\u7ec3\u5e76\u9988\u9001\u672a\u6807\u8bb0\u7684\u6837\u672c\u65f6\uff0c\u5b83\u4f1a\u4ea7\u751f 3 \u4e2a\u9884\u6d4b\u7ed3\u679c\uff1a\u76f8\u5e94\u9e22\u5c3e\u82b1\u5c5e\u4e8e\u6307\u5b9a\u54c1\u79cd\u7684\u53ef\u80fd\u6027\u3002\u5bf9\u4e8e\u8be5\u793a\u4f8b\uff0c\u8f93\u51fa\u9884\u6d4b\u7ed3\u679c\u7684\u603b\u548c\u662f 1.0\u3002\u8be5\u9884\u6d4b\u7ed3\u679c\u5206\u89e3\u5982\u4e0b\uff1a\u5c71\u9e22\u5c3e\u4e3a 0.02\uff0c\u53d8\u8272\u9e22\u5c3e\u4e3a 0.95\uff0c\u7ef4\u5409\u5c3c\u4e9a\u9e22\u5c3e\u4e3a 0.03\u3002\u8fd9\u610f\u5473\u7740\u8be5\u6a21\u578b\u9884\u6d4b\u67d0\u4e2a\u65e0\u6807\u7b7e\u9e22\u5c3e\u82b1\u6837\u672c\u662f\u53d8\u8272\u9e22\u5c3e\u7684\u6982\u7387\u4e3a 95\uff05\u3002 TensorFlow tf.keras API \u662f\u521b\u5efa\u6a21\u578b\u548c\u5c42\u7684\u9996\u9009\u65b9\u5f0f\u3002\u901a\u8fc7\u8be5 API\uff0c\u60a8\u53ef\u4ee5\u8f7b\u677e\u5730\u6784\u5efa\u6a21\u578b\u5e76\u8fdb\u884c\u5b9e\u9a8c\uff0c\u800c\u5c06\u6240\u6709\u90e8\u5206\u8fde\u63a5\u5728\u4e00\u8d77\u7684\u590d\u6742\u5de5\u4f5c\u5219\u7531 Keras \u5904\u7406\u3002 tf.keras.Sequential \u6a21\u578b\u662f\u5c42\u7684\u7ebf\u6027\u5806\u53e0\u3002\u8be5\u6a21\u578b\u7684\u6784\u9020\u51fd\u6570\u4f1a\u91c7\u7528\u4e00\u7cfb\u5217\u5c42\u5b9e\u4f8b\uff1b\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u91c7\u7528\u7684\u662f 2 \u4e2a\u5bc6\u96c6\u5c42\uff08\u5206\u522b\u5305\u542b 10 \u4e2a\u8282\u70b9\uff09\u4ee5\u53ca 1 \u4e2a\u8f93\u51fa\u5c42\uff08\u5305\u542b 3 \u4e2a\u4ee3\u8868\u6807\u7b7e\u9884\u6d4b\u7684\u8282\u70b9\uff09\u3002\u7b2c\u4e00\u4e2a\u5c42\u7684 input_shape \u53c2\u6570\u5bf9\u5e94\u8be5\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5f81\u6570\u91cf\uff1a # \u5229\u7528sequential\u65b9\u5f0f\u6784\u5efa\u6a21\u578b model = Sequential ([ # \u9690\u85cf\u5c421\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu,\u8f93\u5165\u5927\u5c0f\u6709input_shape\u6307\u5b9a Dense ( 10 , activation = \"relu\" , input_shape = ( 4 ,)), # \u9690\u85cf\u5c422\uff0c\u6fc0\u6d3b\u51fd\u6570\u662frelu Dense ( 10 , activation = \"relu\" ), # \u8f93\u51fa\u5c42 Dense ( 3 , activation = \"softmax\" ) ]) \u901a\u8fc7model.summary\u53ef\u4ee5\u67e5\u770b\u6a21\u578b\u7684\u67b6\u6784\uff1a Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 10) 50 _________________________________________________________________ dense_1 (Dense) (None, 10) 110 _________________________________________________________________ dense_2 (Dense) (None, 3) 33 ================================================================= Total params: 193 Trainable params: 193 Non-trainable params: 0 _________________________________________________________________ \u6fc0\u6d3b\u51fd\u6570\u53ef\u51b3\u5b9a\u5c42\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u8f93\u51fa\u5f62\u72b6\u3002\u8fd9\u4e9b\u975e\u7ebf\u6027\u5173\u7cfb\u5f88\u91cd\u8981\uff0c\u5982\u679c\u6ca1\u6709\u5b83\u4eec\uff0c\u6a21\u578b\u5c06\u7b49\u540c\u4e8e\u5355\u4e2a\u5c42\u3002\u6fc0\u6d3b\u51fd\u6570\u6709\u5f88\u591a\uff0c\u4f46\u9690\u85cf\u5c42\u901a\u5e38\u4f7f\u7528 ReLU\u3002 \u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u7406\u60f3\u6570\u91cf\u53d6\u51b3\u4e8e\u95ee\u9898\u548c\u6570\u636e\u96c6\u3002\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u591a\u4e2a\u65b9\u9762\u4e00\u6837\uff0c\u9009\u62e9\u6700\u4f73\u7684\u795e\u7ecf\u7f51\u7edc\u5f62\u72b6\u9700\u8981\u4e00\u5b9a\u7684\u77e5\u8bc6\u6c34\u5e73\u548c\u5b9e\u9a8c\u57fa\u7840\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u9690\u85cf\u5c42\u548c\u795e\u7ecf\u5143\u7684\u6570\u91cf\u901a\u5e38\u4f1a\u4ea7\u751f\u66f4\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u800c\u8fd9\u9700\u8981\u66f4\u591a\u6570\u636e\u624d\u80fd\u6709\u6548\u5730\u8fdb\u884c\u8bad\u7ec3\u3002","title":"4.2 \u6a21\u578b\u642d\u5efa"},{"location":"tensorFlow/section2/#43","text":"\u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u9636\u6bb5\uff0c\u6211\u4eec\u90fd\u9700\u8981\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u3002\u8fd9\u6837\u53ef\u4ee5\u8861\u91cf\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u9884\u671f\u6807\u7b7e\u6709\u591a\u5927\u504f\u5dee\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6a21\u578b\u7684\u6548\u679c\u6709\u591a\u5dee\u3002\u6211\u4eec\u5e0c\u671b\u5c3d\u53ef\u80fd\u51cf\u5c0f\u6216\u4f18\u5316\u8fd9\u4e2a\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u8bbe\u7f6e\u4f18\u5316\u7b56\u7565\u548c\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u53ca\u6a21\u578b\u7cbe\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff1a # \u8bbe\u7f6e\u6a21\u578b\u7684\u76f8\u5173\u53c2\u6570\uff1a\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4ef7\u6307\u6807 model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ \"accuracy\" ]) \u63a5\u4e0b\u6765\u4e0e\u5728sklearn\u4e2d\u76f8\u540c\uff0c\u5206\u522b\u8c03\u7528fit\u548cpredict\u65b9\u6cd5\u8fdb\u884c\u9884\u6d4b\u5373\u53ef\u3002 # \u6a21\u578b\u8bad\u7ec3\uff1aepochs,\u8bad\u7ec3\u6837\u672c\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6b21\u6570\uff0cbatch_size:\u6bcf\u6b21\u8bad\u7ec3\u7684\u9001\u5165\u5230\u7f51\u7edc\u4e2d\u7684\u6837\u672c\u4e2a\u6570 model . fit ( train_X , train_y_ohe , epochs = 10 , batch_size = 1 , verbose = 1 ); \u4e0a\u8ff0\u4ee3\u7801\u5b8c\u6210\u7684\u662f\uff1a \u8fed\u4ee3\u6bcf\u4e2aepoch\u3002\u901a\u8fc7\u4e00\u6b21\u6570\u636e\u96c6\u5373\u4e3a\u4e00\u4e2aepoch\u3002 \u5728\u4e00\u4e2aepoch\u4e2d\uff0c\u904d\u5386\u8bad\u7ec3 Dataset \u4e2d\u7684\u6bcf\u4e2a\u6837\u672c\uff0c\u5e76\u83b7\u53d6\u6837\u672c\u7684\u7279\u5f81 (x) \u548c\u6807\u7b7e (y)\u3002 \u6839\u636e\u6837\u672c\u7684\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u6bd4\u8f83\u9884\u6d4b\u7ed3\u679c\u548c\u6807\u7b7e\u3002\u8861\u91cf\u9884\u6d4b\u7ed3\u679c\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u5e76\u4f7f\u7528\u6240\u5f97\u7684\u503c\u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u68af\u5ea6\u3002 \u4f7f\u7528 optimizer \u66f4\u65b0\u6a21\u578b\u7684\u53d8\u91cf\u3002 \u5bf9\u6bcf\u4e2aepoch\u91cd\u590d\u6267\u884c\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u76f4\u5230\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u5c55\u793a\u5982\u4e0b\uff1a Epoch 1/10 75/75 [==============================] - 0s 616us/step - loss: 0.0585 - accuracy: 0.9733 Epoch 2/10 75/75 [==============================] - 0s 535us/step - loss: 0.0541 - accuracy: 0.9867 Epoch 3/10 75/75 [==============================] - 0s 545us/step - loss: 0.0650 - accuracy: 0.9733 Epoch 4/10 75/75 [==============================] - 0s 542us/step - loss: 0.0865 - accuracy: 0.9733 Epoch 5/10 75/75 [==============================] - 0s 510us/step - loss: 0.0607 - accuracy: 0.9733 Epoch 6/10 75/75 [==============================] - 0s 659us/step - loss: 0.0735 - accuracy: 0.9733 Epoch 7/10 75/75 [==============================] - 0s 497us/step - loss: 0.0691 - accuracy: 0.9600 Epoch 8/10 75/75 [==============================] - 0s 497us/step - loss: 0.0724 - accuracy: 0.9733 Epoch 9/10 75/75 [==============================] - 0s 493us/step - loss: 0.0645 - accuracy: 0.9600 Epoch 10/10 75/75 [==============================] - 0s 482us/step - loss: 0.0660 - accuracy: 0.9867 \u4e0esklearn\u4e2d\u4e0d\u540c\uff0c\u5bf9\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0c\u4e0esklearn.score\u65b9\u6cd5\u5bf9\u5e94\u7684\u662ftf.keras.evaluate()\u65b9\u6cd5\uff0c\u8fd4\u56de\u7684\u662f\u635f\u5931\u51fd\u6570\u548c\u5728compile\u6a21\u578b\u65f6\u8981\u6c42\u7684\u6307\u6807: # \u8ba1\u7b97\u6a21\u578b\u7684\u635f\u5931\u548c\u51c6\u786e\u7387 loss , accuracy = model . evaluate ( test_X , test_y_ohe , verbose = 1 ) print ( \"Accuracy = {:.2f}\" . format ( accuracy )) \u5206\u7c7b\u5668\u7684\u51c6\u786e\u7387\u4e3a\uff1a 3 / 3 [ ============================== ] - 0 s 591 us / step - loss : 0.1031 - accuracy : 0.9733 Accuracy = 0.97 \u5230\u6b64\u6211\u4eec\u5bf9tf.kears\u7684\u4f7f\u7528\u6709\u4e86\u4e00\u4e2a\u57fa\u672c\u7684\u8ba4\u77e5\uff0c\u5728\u63a5\u4e0b\u6765\u7684\u8bfe\u7a0b\u4e2d\u4f1a\u7ed9\u5927\u5bb6\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5e38\u7528\u7684CNN\u7684\u4f7f\u7528\u3002 \u603b\u7ed3 1.\u4f7f\u7528tf.keras\u8fdb\u884c\u5206\u7c7b\u65f6\u7684\u4e3b\u8981\u6d41\u7a0b\uff1a \u6570\u636e\u5904\u7406-\u6784\u5efa\u6a21\u578b-\u6a21\u578b\u8bad\u7ec3-\u6a21\u578b\u9a8c\u8bc1 2.tf.keras\u4e2d\u6784\u5efa\u6a21\u578b\u53ef\u901a\u8fc7squential()\u6765\u5b9e\u73b0\u5e76\u5229\u7528.fit()\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 3.\u4f7f\u7528evaluate()\u65b9\u6cd5\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387","title":"4.3 \u6a21\u578b\u8bad\u7ec3\u548c\u9884\u6d4b"},{"location":"tensorFlow/section3/","text":"4.3 TensorFlow\u5feb\u901f\u5165\u95e8\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u6a21\u578b\u7684\u6784\u5efa\uff1a tf.keras.Model \u548c tf.keras.layers \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a tf.keras.losses \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a tf.keras.optimizer \u6a21\u578b\u7684\u8bc4\u4f30\uff1a tf.keras.metrics \u5e94\u7528 \u65e0 4.3.1 \u6a21\u578b\u6784\u5efa-Model\u4e0eLayer \u00b6 \u5728 TensorFlow \u4e2d\uff0c\u63a8\u8350\u4f7f\u7528 Keras\uff08 tf.keras\uff09\u6784\u5efa\u6a21\u578b\u3002Keras \u662f\u4e00\u4e2a\u5e7f\u4e3a\u6d41\u884c\u7684\u9ad8\u7ea7\u795e\u7ecf\u7f51\u7edc API\uff0c\u7b80\u5355\u3001\u5feb\u901f\u800c\u4e0d\u5931\u7075\u6d3b\u6027\uff0c\u73b0\u5df2\u5f97\u5230 TensorFlow \u7684\u5b98\u65b9\u5185\u7f6e\u548c\u5168\u9762\u652f\u6301\u3002 Keras \u6709\u4e24\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a \u6a21\u578b\uff08Model\uff09 \u548c \u5c42\uff08Layer\uff09 \u3002 \u5c42\u5c06\u5404\u79cd\u8ba1\u7b97\u6d41\u7a0b\u548c\u53d8\u91cf\u8fdb\u884c\u4e86\u5c01\u88c5\uff08\u4f8b\u5982\u57fa\u672c\u7684\u5168\u8fde\u63a5\u5c42\uff0cCNN \u7684\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u7b49\uff09 Keras \u5728tf.keras.layers\u4e0b\u5185\u7f6e\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5927\u91cf\u5e38\u7528\u7684\u7684\u9884\u5b9a\u4e49\u5c42\uff0c\u540c\u65f6\u4e5f\u5141\u8bb8\u6211\u4eec\u81ea\u5b9a\u4e49\u5c42\u3002 \u6a21\u578b\u5219\u5c06\u5404\u79cd\u5c42\u8fdb\u884c\u7ec4\u7ec7\u548c\u8fde\u63a5\uff0c\u5e76\u5c01\u88c5\u6210\u4e00\u4e2a\u6574\u4f53\uff0c\u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u8f93\u5165\u6570\u636e\u901a\u8fc7\u5404\u79cd\u5c42\u4ee5\u53ca\u8fd0\u7b97\u800c\u5f97\u5230\u8f93\u51fa\u3002\u5728\u9700\u8981\u6a21\u578b\u8c03\u7528\u7684\u65f6\u5019\uff0c\u4f7f\u7528y_pred = model(X)\u7684\u5f62\u5f0f\u5373\u53ef\u3002 Keras \u6a21\u578b\u4ee5\u7c7b\u7684\u5f62\u5f0f\u5448\u73b0\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f tf.keras.Model\u8fd9\u4e2a Python \u7c7b\u6765\u5b9a\u4e49\u81ea\u5df1\u7684\u6a21\u578b\u3002\u5728\u7ee7\u627f\u7c7b\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u91cd\u5199 __init__() \uff08\u6784\u9020\u51fd\u6570\uff0c\u521d\u59cb\u5316\uff09\u548c call(input) \uff08\u6a21\u578b\u8c03\u7528\uff09\u4e24\u4e2a\u65b9\u6cd5\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u6839\u636e\u9700\u8981\u589e\u52a0\u81ea\u5b9a\u4e49\u7684\u65b9\u6cd5\u3002 class MyModel ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () # \u6b64\u5904\u6dfb\u52a0\u521d\u59cb\u5316\u4ee3\u7801\uff08\u5305\u542b call \u65b9\u6cd5\u4e2d\u4f1a\u7528\u5230\u7684\u5c42\uff09\uff0c\u4f8b\u5982 # layer1 = tf.keras.layers.BuiltInLayer(...) # layer2 = MyCustomLayer(...) def call ( self , input ): # \u6b64\u5904\u6dfb\u52a0\u6a21\u578b\u8c03\u7528\u7684\u4ee3\u7801\uff08\u5904\u7406\u8f93\u5165\u5e76\u8fd4\u56de\u8f93\u51fa\uff09\uff0c\u4f8b\u5982 # x = layer1(input) # output = layer2(x) return output # \u8fd8\u53ef\u4ee5\u6dfb\u52a0\u81ea\u5b9a\u4e49\u7684\u65b9\u6cd5 \u7ee7\u627f tf.keras.Model \u540e\uff0c\u6211\u4eec\u540c\u65f6\u53ef\u4ee5\u4f7f\u7528\u7236\u7c7b\u7684\u82e5\u5e72\u65b9\u6cd5\u548c\u5c5e\u6027\uff0c\u4f8b\u5982\u5728\u5b9e\u4f8b\u5316\u7c7b model = Model() \u540e\uff0c\u53ef\u4ee5\u901a\u8fc7 model.variables \u8fd9\u4e00\u5c5e\u6027\u76f4\u63a5\u83b7\u5f97\u6a21\u578b\u4e2d\u7684\u6240\u6709\u53d8\u91cf\uff0c\u514d\u53bb\u6211\u4eec\u4e00\u4e2a\u4e2a\u663e\u5f0f\u6307\u5b9a\u53d8\u91cf\u7684\u9ebb\u70e6\u3002 4.3.1.1 \u6848\u4f8b\uff1a\u4f7f\u7528Model\u6784\u5efa\u6a21\u578b \u00b6 \u5bf9\u4e8e\u4e0a\u9762\u7684 y_pred = w * X + b \uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u7c7b\u7684\u65b9\u5f0f\u7f16\u5199\u5982\u4e0b\uff1a import tensorflow as tf X = tf . constant ([[ 1.0 , 2.0 , 3.0 ], [ 4.0 , 5.0 , 6.0 ]]) y = tf . constant ([[ 10.0 ], [ 20.0 ]]) # 1\u3001\u6784\u5efa\u7ebf\u6027\u6a21\u578b class Linear ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () self . dense = tf . keras . layers . Dense ( units = 1 , activation = None , kernel_initializer = tf . zeros_initializer (), bias_initializer = tf . zeros_initializer () ) def call ( self , input ): output = self . dense ( input ) return output # \u4ee5\u4e0b\u4ee3\u7801\u7ed3\u6784\u4e0e\u524d\u8282\u7c7b\u4f3c model = Linear () optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for i in range ( 100 ): with tf . GradientTape () as tape : y_pred = model ( X ) loss = tf . reduce_mean ( tf . square ( y_pred - y )) # \u4f7f\u7528 model.variables \u8fd9\u4e00\u5c5e\u6027\u76f4\u63a5\u83b7\u5f97\u6a21\u578b\u4e2d\u7684\u6240\u6709\u53d8\u91cf grads = tape . gradient ( loss , model . variables ) optimizer . apply_gradients ( grads_and_vars = zip ( grads , model . variables )) print ( model . variables ) \u8fd9\u91cc\uff0c\u6211\u4eec\u6ca1\u6709\u663e\u5f0f\u5730\u58f0\u660ea \u548c b \u4e24\u4e2a\u53d8\u91cf\u5e76\u5199\u51fa y_pred = w x X + b \u8fd9\u4e00\u7ebf\u6027\u53d8\u6362\uff0c\u800c\u662f\u5efa\u7acb\u4e86\u4e00\u4e2a\u7ee7\u627f\u4e86 tf.keras.Model \u7684\u6a21\u578b\u7c7b Linear \u3002\u8fd9\u4e2a\u7c7b\u5728\u521d\u59cb\u5316\u90e8\u5206\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a \u5168\u8fde\u63a5\u5c42 \uff08 tf.keras.layers.Dense \uff09\uff0c\u5e76\u5728 call \u65b9\u6cd5\u4e2d\u5bf9\u8fd9\u4e2a\u5c42\u8fdb\u884c\u8c03\u7528\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u53d8\u6362\u7684\u8ba1\u7b97\u3002 4.3.1.1 Keras \u5f53\u4e2d\u7684layer(\u5c42)\u63a5\u53e3 \u00b6 \u5728 Keras \u4e2d\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u7ec4\u5408\u5c42\u6765\u6784\u5efa\u6a21\u578b\u3002\u6a21\u578b\uff08\u901a\u5e38\uff09\u662f\u7531\u5c42\u6784\u6210\u7684\u56fe\u3002\u6700\u5e38\u89c1\u7684\u6a21\u578b\u7c7b\u578b\u662f\u5c42\u7684\u5806\u53e0\uff0ckeras.layers\u4e2d\u5c31\u6709\u5f88\u591a\u6a21\u578b from tensorflow.python.keras.layers import Dense from tensorflow.python.keras.layers import DepthwiseConv2D from tensorflow.python.keras.layers import Dot from tensorflow.python.keras.layers import Dropout from tensorflow.python.keras.layers import ELU from tensorflow.python.keras.layers import Embedding from tensorflow.python.keras.layers import Flatten from tensorflow.python.keras.layers import GRU from tensorflow.python.keras.layers import GRUCell from tensorflow.python.keras.layers import LSTMCell Dense:\u6dfb\u52a0\u4e00\u5c42\u795e\u7ecf\u5143 Dense(units,activation=None,**kwargs) units:\u795e\u7ecf\u5143\u4e2a\u6570 activation\uff1a\u6fc0\u6d3b\u51fd\u6570,\u53c2\u8003tf.nn.relu,tf.nn.softmax,tf.nn.sigmoid,tf.nn.tanh **kwargs:\u8f93\u5165\u4e0a\u5c42\u8f93\u5165\u7684\u5f62\u72b6\uff0cinput_shape=() 4.3.1.2 Models \u00b6 Model(inputs=a, outputs=b) inputs:\u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165,Input\u7c7b\u578b outpts:\u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u51fa def call (self, inputs):\u63a5\u6536\u6765\u81ea\u4e0a\u5c42\u7684\u8f93\u5165 Models\u5c5e\u6027 model.layers \uff1a\u83b7\u53d6\u6a21\u578b\u7ed3\u6784\u5217\u8868 print ( model . layers ) [ < tensorflow . python . keras . layers . core . Flatten object at 0x10864a780 > , < tensorflow . python . keras . layers . core . Dense object at 0x10f95b128 > , < tensorflow . python . keras . layers . core . Dense object at 0x125bd6fd0 > , < tensorflow . python . keras . layers . core . Dense object at 0x125bf9240 > ] model.inputs \u662f\u6a21\u578b\u7684\u8f93\u5165\u5f20\u91cf\u5217\u8868 print ( model . inputs ) [ < tf . Tensor 'flatten_input:0' shape = ( ? , 28 , 28 ) dtype = float32 > ] model.outputs \u662f\u6a21\u578b\u7684\u8f93\u51fa\u5f20\u91cf\u5217\u8868 print ( model . outputs ) [ < tf . Tensor 'dense_2/Softmax:0' shape = ( ? , 10 ) dtype = float32 > ] model.summary() \u6253\u5370\u6a21\u578b\u7684\u6458\u8981\u8868\u793a Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 64) 50240 _________________________________________________________________ dense_1 (Dense) (None, 128) 8320 _________________________________________________________________ dense_2 (Dense) (None, 10) 1290 ================================================================= Total params: 59,850 Trainable params: 59,850 Non-trainable params: 0 4.3.2 \u6848\u4f8b\uff1a\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u8bc6\u522bMnist\u624b\u5199\u6570\u5b57 \u00b6 \u4e00\u4e2a\u6700\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08Multilayer Perceptron, MLP\uff09\uff0c\u6216\u8005\u8bf4 \u201c\u591a\u5c42\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u201d \u5f00\u59cb\uff0c\u4ecb\u7ecd TensorFlow \u7684\u6a21\u578b\u7f16\u5199\u65b9\u5f0f\u3002 \u76ee\u7684\uff1a\u6211\u4eec\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u673a\u5b8c\u6210 MNIST \u624b\u5199\u4f53\u6570\u5b57\u56fe\u7247\u6570\u636e\u96c6\u7684\u5206\u7c7b\u4efb\u52a1 \u6b65\u9aa4\uff1a 1\u3001\u4f7f\u7528 tf.keras.datasets \u83b7\u5f97\u6570\u636e\u96c6\u5e76\u9884\u5904\u7406 2\u3001\u4f7f\u7528 tf.keras.Model \u548c tf.keras.layers \u6784\u5efa\u6a21\u578b 3\u3001\u6784\u5efa\u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b\uff0c\u4f7f\u7528 tf.keras.losses \u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5e76\u4f7f\u7528 tf.keras.optimizer \u4f18\u5316\u6a21\u578b 4\u3001\u6784\u5efa\u6a21\u578b\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4f7f\u7528 tf.keras.metrics \u8ba1\u7b97\u8bc4\u4f30\u6307\u6807 1\u3001\u6570\u636e\u83b7\u53d6\u53ca\u9884\u5904\u7406\uff1a tf.keras.datasets \u00b6 \u5148\u8fdb\u884c\u9884\u5907\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684 MNISTLoader \u7c7b\u6765\u8bfb\u53d6 MNIST \u6570\u636e\u96c6\u6570\u636e\u3002\u8fd9\u91cc\u4f7f\u7528\u4e86 tf.keras.datasets \u5feb\u901f\u8f7d\u5165 MNIST \u6570\u636e\u96c6\u3002 import tensorflow as tf import numpy as np class MNISTLoader ( object ): \"\"\"\u6570\u636e\u52a0\u8f7d\u5904\u7406\u7c7b \"\"\" def __init__ ( self ): \"\"\" \"\"\" # 1\u3001\u83b7\u53d6\u6570\u636e ( self . train_data , self . train_label ), ( self . test_data , self . test_label ) = tf . keras . datasets . mnist . load_data () # 2\u3001\u5904\u7406\u6570\u636e\uff0c\u5f52\u4e00\u5316\uff0c\u7ef4\u5ea6\u4ee5\u53ca\u7c7b\u578b # MNIST\u4e2d\u7684\u56fe\u50cf\u9ed8\u8ba4\u4e3auint8\uff080-255\u7684\u6570\u5b57\uff09\u3002\u4ee5\u4e0b\u4ee3\u7801\u5c06\u5176\u5f52\u4e00\u5316\u52300-1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u5e76\u5728\u6700\u540e\u589e\u52a0\u4e00\u7ef4\u4f5c\u4e3a\u989c\u8272\u901a\u9053 # \u9ed8\u8ba4\u4e0b\u8f7d\u662f(60000, 28, 28)\uff0c\u6269\u5c55\u5230\u56db\u7ef4\u65b9\u4fbf\u8ba1\u7b97\u7406\u89e3[60000, 28, 28, 1] self . train_data = np . expand_dims ( self . train_data . astype ( np . float32 ) / 255.0 , axis =- 1 ) # [10000, 28, 28, 1] self . test_data = np . expand_dims ( self . test_data . astype ( np . float32 ) / 255.0 , axis =- 1 ) self . train_label = self . train_label . astype ( np . int32 ) # [60000] self . test_label = self . test_label . astype ( np . int32 ) # [10000] # \u83b7\u53d6\u6570\u636e\u7684\u5927\u5c0f self . num_train_data , self . num_test_data = self . train_data . shape [ 0 ], self . test_data . shape [ 0 ] def get_batch ( self , batch_size ): \"\"\" \u968f\u673a\u83b7\u53d6\u83b7\u53d6\u6279\u6b21\u6570\u636e :param batch_size: \u6279\u6b21\u5927\u5c0f :return: \"\"\" # \u4ece\u6570\u636e\u96c6\u4e2d\u968f\u673a\u53d6\u51fabatch_size\u4e2a\u5143\u7d20\u5e76\u8fd4\u56de index = np . random . randint ( 0 , np . shape ( self . train_data )[ 0 ], batch_size ) return self . train_data [ index , :], self . train_label [ index ] if __name__ == '__main__' : mnist = MNISTLoader () train_data , train_label = mnist . get_batch ( 50 ) print ( train_data . shape , train_label ) \u6ce8\uff1a\u5728 TensorFlow \u4e2d\uff0c\u56fe\u50cf\u6570\u636e\u96c6\u7684\u4e00\u79cd\u5178\u578b\u8868\u793a\u662f [\u56fe\u50cf\u6570\u76ee\uff0c\u957f\uff0c\u5bbd\uff0c\u8272\u5f69\u901a\u9053\u6570]\u7684\u56db\u7ef4\u5f20\u91cf\u3002 2\u3001\u6a21\u578b\u7684\u6784\u5efa\uff1atf.keras.Model \u548c tf.keras.layers \u00b6 \u591a\u5c42\u611f\u77e5\u673a\u7684\u6a21\u578b\u7c7b\u5b9e\u73b0\u4e0e\u4e0a\u9762\u7684\u7ebf\u6027\u6a21\u578b\u7c7b\u4f3c\uff0c\u4f7f\u7528 tf.keras.Model \u548c tf.keras.layers \u6784\u5efa\uff0c\u5f15\u5165\u4e86\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff08\u8fd9\u91cc\u4f7f\u7528\u4e86 ReLU \u51fd\u6570 \uff0c \u5373\u4e0b\u65b9\u7684 activation=tf.nn.relu \uff09\uff0c\u6a21\u578b\u8f93\u51fa 10 \u7ef4\u7684\u5411\u91cf\uff0c\u5206\u522b\u4ee3\u8868\u8fd9\u5f20\u56fe\u7247\u5c5e\u4e8e 0 \u5230 9 \u7684\u6982\u7387\u3002 \u4e3a\u4e86\u4f7f\u5f97\u6a21\u578b\u7684\u8f93\u51fa\u80fd\u59cb\u7ec8\u6ee1\u8db3\u8fd9\u4e24\u4e2a\u6761\u4ef6\uff0c\u6211\u4eec\u4f7f\u7528 Softmax \u51fd\u6570 \uff08\u5f52\u4e00\u5316\u6307\u6570\u51fd\u6570\uff0c tf.nn.softmax \uff09\u5bf9\u6a21\u578b\u7684\u539f\u59cb\u8f93\u51fa\u8fdb\u884c\u5f52\u4e00\u5316\u3002 class MLP ( tf . keras . Model ): \"\"\"\u81ea\u5b9a\u4e49MLP\u7c7b \"\"\" def __init__ ( self ): super () . __init__ () # \u5b9a\u4e49\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u7b2c\u4e00\u5c42100\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu\uff0c\u7b2c\u4e8c\u5c4210\u4e2a\u795e\u7ecf\u5143\u8f93\u51fa\u7ed9softmax self . flatten = tf . keras . layers . Flatten () self . dense1 = tf . keras . layers . Dense ( units = 100 , activation = tf . nn . relu ) self . dense2 = tf . keras . layers . Dense ( units = 10 ) def call ( self , inputs ): # [batch_size, 28, 28, 1] x = self . flatten ( inputs ) # [batch_size, 784] x = self . dense1 ( x ) # [batch_size, 100] x = self . dense2 ( x ) # [batch_size, 10] output = tf . nn . softmax ( x ) return output 3\u3001\u6a21\u578b\u7684\u8bad\u7ec3\uff1a tf.keras.losses \u548c tf.keras.optimizer \u00b6 \u5b9a\u4e49\u4e00\u4e9b\u6a21\u578b\u8d85\u53c2\u6570\uff1a num_epochs = 5 batch_size = 50 learning_rate = 0.001 \u7136\u540e\u8fed\u4ee3\u8fdb\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a 1\u3001\u4ece DataLoader \u4e2d\u968f\u673a\u53d6\u4e00\u6279\u8bad\u7ec3\u6570\u636e\uff1b 2\u3001\u5c06\u8fd9\u6279\u6570\u636e\u9001\u5165\u6a21\u578b\uff0c\u8ba1\u7b97\u51fa\u6a21\u578b\u7684\u9884\u6d4b\u503c\uff1b 3\u3001\u5c06\u6a21\u578b\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff08loss\uff09\u3002\u8fd9\u91cc\u4f7f\u7528 tf.keras.losses \u4e2d\u7684\u4ea4\u53c9\u71b5\u51fd\u6570\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff1b 4\u3001\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u5173\u4e8e\u6a21\u578b\u53d8\u91cf\u7684\u5bfc\u6570\uff1b 5\u3001\u5c06\u6c42\u51fa\u7684\u5bfc\u6570\u503c\u4f20\u5165\u4f18\u5316\u5668\uff0c\u4f7f\u7528\u4f18\u5316\u5668\u7684 apply_gradients \u65b9\u6cd5\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\uff08\u4f18\u5316\u5668\u7684\u8be6\u7ec6\u4f7f\u7528\u65b9\u6cd5\u89c1 \u524d\u7ae0 \uff09\u3002 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 # \u5b9e\u4f8b\u5316\u6a21\u578b\u548c\u6570\u636e\u8bfb\u53d6\u7c7b\uff0c\u5e76\u5b9e\u4f8b\u5316\u4e00\u4e2a\u4f18\u5316\u5668\uff0c\u8fd9\u91cc\u4f7f\u7528 Adam \u4f18\u5316\u5668 model = MLP () data_loader = MNISTLoader () optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ) # \u8ba1\u7b97\u51fa\u5927\u6982\u9700\u8981\u8fed\u4ee3\u6279\u6b21\u5927\u5c0f num_batches = int ( data_loader . num_train_data // batch_size * num_epochs ) # \u8fdb\u884c\u6279\u6b21\u6570\u636e\u83b7\u53d6 for batch_index in range ( num_batches ): X , y = data_loader . get_batch ( batch_size ) with tf . GradientTape () as tape : y_pred = model ( X ) # \u4f7f\u7528tf.keras.losses\u8ba1\u7b97\u635f\u5931 loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y , y_pred = y_pred ) # \u6c42\u51fa\u5e73\u5747\u635f\u5931 loss = tf . reduce_mean ( loss ) print ( \"batch %d : loss %f \" % ( batch_index , loss . numpy ())) grads = tape . gradient ( loss , model . variables ) optimizer . apply_gradients ( grads_and_vars = zip ( grads , model . variables )) \u6ce8\uff1a\u5728 tf.keras\u4e2d\uff0c\u6709\u4e24\u4e2a\u4ea4\u53c9\u71b5\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570 tf.keras.losses.categorical_crossentropy \u548c tf.keras.losses.sparse_categorical_crossentropy \u3002\u5176\u4e2d sparse \u7684\u542b\u4e49\u662f\uff0c\u771f\u5b9e\u7684\u6807\u7b7e\u503c y_true\u53ef\u4ee5\u76f4\u63a5\u4f20\u5165 int \u7c7b\u578b\u7684\u6807\u7b7e\u7c7b\u522b\u3002\u5177\u4f53\u800c\u8a00\uff1a loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y , y_pred = y_pred ) \u4e0e loss = tf . keras . losses . categorical_crossentropy ( y_true = tf . one_hot ( y , depth = tf . shape ( y_pred )[ - 1 ]), y_pred = y_pred ) \u7684\u7ed3\u679c\u76f8\u540c\u3002 4\u3001\u6a21\u578b\u7684\u8bc4\u4f30\uff1a tf.keras.metrics \u00b6 \u6700\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u4f7f\u7528 tf.keras.metrics \u4e2d\u7684 SparseCategoricalAccuracy \u8bc4\u4f30\u5668\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u3002 \u8fed\u4ee3\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u6bcf\u6b21\u901a\u8fc7 update_state() \u65b9\u6cd5\u5411\u8bc4\u4f30\u5668\u8f93\u5165\u4e24\u4e2a\u53c2\u6570\uff1a y_pred \u548c y_true \uff0c\u5373\u6a21\u578b\u9884\u6d4b\u51fa\u7684\u7ed3\u679c\u548c\u771f\u5b9e\u7ed3\u679c\u3002 \u4f7f\u7528 result() \u65b9\u6cd5\u8f93\u51fa\u6700\u7ec8\u7684\u8bc4\u4f30\u6307\u6807\u503c\uff08\u9884\u6d4b\u6b63\u786e\u7684\u6837\u672c\u6570\u5360\u603b\u6837\u672c\u6570\u7684\u6bd4\u4f8b\uff09\u3002 \u5728\u4ee5\u4e0b\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a tf.keras.metrics.SparseCategoricalAccuracy \u8bc4\u4f30\u5668\uff0c\u5e76\u4f7f\u7528 For \u5faa\u73af\u8fed\u4ee3\u5206\u6279\u6b21\u4f20\u5165\u4e86\u6d4b\u8bd5\u96c6\u6570\u636e\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u7ed3\u679c\uff0c\u5e76\u8f93\u51fa\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u3002 y_pred = model . predict ( data_loader . test_data ) # \u5b9a\u4e49\u8bc4\u4f30\u51fd\u6570 sparse_categorical_accuracy = tf . keras . metrics . SparseCategoricalAccuracy () # \u5b9a\u4e49\u6d4b\u8bd5\u6570\u636e\u96c6\u4e00\u5171\u6279\u6b21\u7684\u5927\u5c0f sparse_categorical_accuracy . update_state ( y_true = data_loader . test_label , y_pred = y_pred ) print ( \"\u6d4b\u8bd5\u51c6\u786e\u7387: %f \" % sparse_categorical_accuracy . result ()) \u8f93\u51fa\u7ed3\u679c: \u6d4b\u8bd5\u51c6\u786e\u7387: 0.972300 4.3.5 \u603b\u7ed3 \u00b6 \u6a21\u578b\u7684\u6784\u5efa\uff1a tf.keras.Model \u548c tf.keras.layers \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a tf.keras.losses \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a tf.keras.optimizer \u6a21\u578b\u7684\u8bc4\u4f30\uff1a tf.keras.metrics","title":"4.3 TensorFlow\u5feb\u901f\u5165\u95e8\u6a21\u578b"},{"location":"tensorFlow/section3/#43-tensorflow","text":"","title":"4.3 TensorFlow\u5feb\u901f\u5165\u95e8\u6a21\u578b"},{"location":"tensorFlow/section3/#_1","text":"\u76ee\u6807 \u6a21\u578b\u7684\u6784\u5efa\uff1a tf.keras.Model \u548c tf.keras.layers \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a tf.keras.losses \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a tf.keras.optimizer \u6a21\u578b\u7684\u8bc4\u4f30\uff1a tf.keras.metrics \u5e94\u7528 \u65e0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section3/#431-modellayer","text":"\u5728 TensorFlow \u4e2d\uff0c\u63a8\u8350\u4f7f\u7528 Keras\uff08 tf.keras\uff09\u6784\u5efa\u6a21\u578b\u3002Keras \u662f\u4e00\u4e2a\u5e7f\u4e3a\u6d41\u884c\u7684\u9ad8\u7ea7\u795e\u7ecf\u7f51\u7edc API\uff0c\u7b80\u5355\u3001\u5feb\u901f\u800c\u4e0d\u5931\u7075\u6d3b\u6027\uff0c\u73b0\u5df2\u5f97\u5230 TensorFlow \u7684\u5b98\u65b9\u5185\u7f6e\u548c\u5168\u9762\u652f\u6301\u3002 Keras \u6709\u4e24\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a \u6a21\u578b\uff08Model\uff09 \u548c \u5c42\uff08Layer\uff09 \u3002 \u5c42\u5c06\u5404\u79cd\u8ba1\u7b97\u6d41\u7a0b\u548c\u53d8\u91cf\u8fdb\u884c\u4e86\u5c01\u88c5\uff08\u4f8b\u5982\u57fa\u672c\u7684\u5168\u8fde\u63a5\u5c42\uff0cCNN \u7684\u5377\u79ef\u5c42\u3001\u6c60\u5316\u5c42\u7b49\uff09 Keras \u5728tf.keras.layers\u4e0b\u5185\u7f6e\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5927\u91cf\u5e38\u7528\u7684\u7684\u9884\u5b9a\u4e49\u5c42\uff0c\u540c\u65f6\u4e5f\u5141\u8bb8\u6211\u4eec\u81ea\u5b9a\u4e49\u5c42\u3002 \u6a21\u578b\u5219\u5c06\u5404\u79cd\u5c42\u8fdb\u884c\u7ec4\u7ec7\u548c\u8fde\u63a5\uff0c\u5e76\u5c01\u88c5\u6210\u4e00\u4e2a\u6574\u4f53\uff0c\u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u8f93\u5165\u6570\u636e\u901a\u8fc7\u5404\u79cd\u5c42\u4ee5\u53ca\u8fd0\u7b97\u800c\u5f97\u5230\u8f93\u51fa\u3002\u5728\u9700\u8981\u6a21\u578b\u8c03\u7528\u7684\u65f6\u5019\uff0c\u4f7f\u7528y_pred = model(X)\u7684\u5f62\u5f0f\u5373\u53ef\u3002 Keras \u6a21\u578b\u4ee5\u7c7b\u7684\u5f62\u5f0f\u5448\u73b0\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f tf.keras.Model\u8fd9\u4e2a Python \u7c7b\u6765\u5b9a\u4e49\u81ea\u5df1\u7684\u6a21\u578b\u3002\u5728\u7ee7\u627f\u7c7b\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u91cd\u5199 __init__() \uff08\u6784\u9020\u51fd\u6570\uff0c\u521d\u59cb\u5316\uff09\u548c call(input) \uff08\u6a21\u578b\u8c03\u7528\uff09\u4e24\u4e2a\u65b9\u6cd5\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u6839\u636e\u9700\u8981\u589e\u52a0\u81ea\u5b9a\u4e49\u7684\u65b9\u6cd5\u3002 class MyModel ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () # \u6b64\u5904\u6dfb\u52a0\u521d\u59cb\u5316\u4ee3\u7801\uff08\u5305\u542b call \u65b9\u6cd5\u4e2d\u4f1a\u7528\u5230\u7684\u5c42\uff09\uff0c\u4f8b\u5982 # layer1 = tf.keras.layers.BuiltInLayer(...) # layer2 = MyCustomLayer(...) def call ( self , input ): # \u6b64\u5904\u6dfb\u52a0\u6a21\u578b\u8c03\u7528\u7684\u4ee3\u7801\uff08\u5904\u7406\u8f93\u5165\u5e76\u8fd4\u56de\u8f93\u51fa\uff09\uff0c\u4f8b\u5982 # x = layer1(input) # output = layer2(x) return output # \u8fd8\u53ef\u4ee5\u6dfb\u52a0\u81ea\u5b9a\u4e49\u7684\u65b9\u6cd5 \u7ee7\u627f tf.keras.Model \u540e\uff0c\u6211\u4eec\u540c\u65f6\u53ef\u4ee5\u4f7f\u7528\u7236\u7c7b\u7684\u82e5\u5e72\u65b9\u6cd5\u548c\u5c5e\u6027\uff0c\u4f8b\u5982\u5728\u5b9e\u4f8b\u5316\u7c7b model = Model() \u540e\uff0c\u53ef\u4ee5\u901a\u8fc7 model.variables \u8fd9\u4e00\u5c5e\u6027\u76f4\u63a5\u83b7\u5f97\u6a21\u578b\u4e2d\u7684\u6240\u6709\u53d8\u91cf\uff0c\u514d\u53bb\u6211\u4eec\u4e00\u4e2a\u4e2a\u663e\u5f0f\u6307\u5b9a\u53d8\u91cf\u7684\u9ebb\u70e6\u3002","title":"4.3.1 \u6a21\u578b\u6784\u5efa-Model\u4e0eLayer"},{"location":"tensorFlow/section3/#4311-model","text":"\u5bf9\u4e8e\u4e0a\u9762\u7684 y_pred = w * X + b \uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u7c7b\u7684\u65b9\u5f0f\u7f16\u5199\u5982\u4e0b\uff1a import tensorflow as tf X = tf . constant ([[ 1.0 , 2.0 , 3.0 ], [ 4.0 , 5.0 , 6.0 ]]) y = tf . constant ([[ 10.0 ], [ 20.0 ]]) # 1\u3001\u6784\u5efa\u7ebf\u6027\u6a21\u578b class Linear ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () self . dense = tf . keras . layers . Dense ( units = 1 , activation = None , kernel_initializer = tf . zeros_initializer (), bias_initializer = tf . zeros_initializer () ) def call ( self , input ): output = self . dense ( input ) return output # \u4ee5\u4e0b\u4ee3\u7801\u7ed3\u6784\u4e0e\u524d\u8282\u7c7b\u4f3c model = Linear () optimizer = tf . keras . optimizers . SGD ( learning_rate = 0.01 ) for i in range ( 100 ): with tf . GradientTape () as tape : y_pred = model ( X ) loss = tf . reduce_mean ( tf . square ( y_pred - y )) # \u4f7f\u7528 model.variables \u8fd9\u4e00\u5c5e\u6027\u76f4\u63a5\u83b7\u5f97\u6a21\u578b\u4e2d\u7684\u6240\u6709\u53d8\u91cf grads = tape . gradient ( loss , model . variables ) optimizer . apply_gradients ( grads_and_vars = zip ( grads , model . variables )) print ( model . variables ) \u8fd9\u91cc\uff0c\u6211\u4eec\u6ca1\u6709\u663e\u5f0f\u5730\u58f0\u660ea \u548c b \u4e24\u4e2a\u53d8\u91cf\u5e76\u5199\u51fa y_pred = w x X + b \u8fd9\u4e00\u7ebf\u6027\u53d8\u6362\uff0c\u800c\u662f\u5efa\u7acb\u4e86\u4e00\u4e2a\u7ee7\u627f\u4e86 tf.keras.Model \u7684\u6a21\u578b\u7c7b Linear \u3002\u8fd9\u4e2a\u7c7b\u5728\u521d\u59cb\u5316\u90e8\u5206\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a \u5168\u8fde\u63a5\u5c42 \uff08 tf.keras.layers.Dense \uff09\uff0c\u5e76\u5728 call \u65b9\u6cd5\u4e2d\u5bf9\u8fd9\u4e2a\u5c42\u8fdb\u884c\u8c03\u7528\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u53d8\u6362\u7684\u8ba1\u7b97\u3002","title":"4.3.1.1 \u6848\u4f8b\uff1a\u4f7f\u7528Model\u6784\u5efa\u6a21\u578b"},{"location":"tensorFlow/section3/#4311-keras-layer","text":"\u5728 Keras \u4e2d\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u7ec4\u5408\u5c42\u6765\u6784\u5efa\u6a21\u578b\u3002\u6a21\u578b\uff08\u901a\u5e38\uff09\u662f\u7531\u5c42\u6784\u6210\u7684\u56fe\u3002\u6700\u5e38\u89c1\u7684\u6a21\u578b\u7c7b\u578b\u662f\u5c42\u7684\u5806\u53e0\uff0ckeras.layers\u4e2d\u5c31\u6709\u5f88\u591a\u6a21\u578b from tensorflow.python.keras.layers import Dense from tensorflow.python.keras.layers import DepthwiseConv2D from tensorflow.python.keras.layers import Dot from tensorflow.python.keras.layers import Dropout from tensorflow.python.keras.layers import ELU from tensorflow.python.keras.layers import Embedding from tensorflow.python.keras.layers import Flatten from tensorflow.python.keras.layers import GRU from tensorflow.python.keras.layers import GRUCell from tensorflow.python.keras.layers import LSTMCell Dense:\u6dfb\u52a0\u4e00\u5c42\u795e\u7ecf\u5143 Dense(units,activation=None,**kwargs) units:\u795e\u7ecf\u5143\u4e2a\u6570 activation\uff1a\u6fc0\u6d3b\u51fd\u6570,\u53c2\u8003tf.nn.relu,tf.nn.softmax,tf.nn.sigmoid,tf.nn.tanh **kwargs:\u8f93\u5165\u4e0a\u5c42\u8f93\u5165\u7684\u5f62\u72b6\uff0cinput_shape=()","title":"4.3.1.1 Keras \u5f53\u4e2d\u7684layer(\u5c42)\u63a5\u53e3"},{"location":"tensorFlow/section3/#4312-models","text":"Model(inputs=a, outputs=b) inputs:\u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u5165,Input\u7c7b\u578b outpts:\u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u51fa def call (self, inputs):\u63a5\u6536\u6765\u81ea\u4e0a\u5c42\u7684\u8f93\u5165 Models\u5c5e\u6027 model.layers \uff1a\u83b7\u53d6\u6a21\u578b\u7ed3\u6784\u5217\u8868 print ( model . layers ) [ < tensorflow . python . keras . layers . core . Flatten object at 0x10864a780 > , < tensorflow . python . keras . layers . core . Dense object at 0x10f95b128 > , < tensorflow . python . keras . layers . core . Dense object at 0x125bd6fd0 > , < tensorflow . python . keras . layers . core . Dense object at 0x125bf9240 > ] model.inputs \u662f\u6a21\u578b\u7684\u8f93\u5165\u5f20\u91cf\u5217\u8868 print ( model . inputs ) [ < tf . Tensor 'flatten_input:0' shape = ( ? , 28 , 28 ) dtype = float32 > ] model.outputs \u662f\u6a21\u578b\u7684\u8f93\u51fa\u5f20\u91cf\u5217\u8868 print ( model . outputs ) [ < tf . Tensor 'dense_2/Softmax:0' shape = ( ? , 10 ) dtype = float32 > ] model.summary() \u6253\u5370\u6a21\u578b\u7684\u6458\u8981\u8868\u793a Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 64) 50240 _________________________________________________________________ dense_1 (Dense) (None, 128) 8320 _________________________________________________________________ dense_2 (Dense) (None, 10) 1290 ================================================================= Total params: 59,850 Trainable params: 59,850 Non-trainable params: 0","title":"4.3.1.2 Models"},{"location":"tensorFlow/section3/#432-mlpmnist","text":"\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08Multilayer Perceptron, MLP\uff09\uff0c\u6216\u8005\u8bf4 \u201c\u591a\u5c42\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u201d \u5f00\u59cb\uff0c\u4ecb\u7ecd TensorFlow \u7684\u6a21\u578b\u7f16\u5199\u65b9\u5f0f\u3002 \u76ee\u7684\uff1a\u6211\u4eec\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u673a\u5b8c\u6210 MNIST \u624b\u5199\u4f53\u6570\u5b57\u56fe\u7247\u6570\u636e\u96c6\u7684\u5206\u7c7b\u4efb\u52a1 \u6b65\u9aa4\uff1a 1\u3001\u4f7f\u7528 tf.keras.datasets \u83b7\u5f97\u6570\u636e\u96c6\u5e76\u9884\u5904\u7406 2\u3001\u4f7f\u7528 tf.keras.Model \u548c tf.keras.layers \u6784\u5efa\u6a21\u578b 3\u3001\u6784\u5efa\u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b\uff0c\u4f7f\u7528 tf.keras.losses \u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff0c\u5e76\u4f7f\u7528 tf.keras.optimizer \u4f18\u5316\u6a21\u578b 4\u3001\u6784\u5efa\u6a21\u578b\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4f7f\u7528 tf.keras.metrics \u8ba1\u7b97\u8bc4\u4f30\u6307\u6807","title":"4.3.2 \u6848\u4f8b\uff1a\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u8bc6\u522bMnist\u624b\u5199\u6570\u5b57"},{"location":"tensorFlow/section3/#1-tfkerasdatasets","text":"\u5148\u8fdb\u884c\u9884\u5907\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684 MNISTLoader \u7c7b\u6765\u8bfb\u53d6 MNIST \u6570\u636e\u96c6\u6570\u636e\u3002\u8fd9\u91cc\u4f7f\u7528\u4e86 tf.keras.datasets \u5feb\u901f\u8f7d\u5165 MNIST \u6570\u636e\u96c6\u3002 import tensorflow as tf import numpy as np class MNISTLoader ( object ): \"\"\"\u6570\u636e\u52a0\u8f7d\u5904\u7406\u7c7b \"\"\" def __init__ ( self ): \"\"\" \"\"\" # 1\u3001\u83b7\u53d6\u6570\u636e ( self . train_data , self . train_label ), ( self . test_data , self . test_label ) = tf . keras . datasets . mnist . load_data () # 2\u3001\u5904\u7406\u6570\u636e\uff0c\u5f52\u4e00\u5316\uff0c\u7ef4\u5ea6\u4ee5\u53ca\u7c7b\u578b # MNIST\u4e2d\u7684\u56fe\u50cf\u9ed8\u8ba4\u4e3auint8\uff080-255\u7684\u6570\u5b57\uff09\u3002\u4ee5\u4e0b\u4ee3\u7801\u5c06\u5176\u5f52\u4e00\u5316\u52300-1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u5e76\u5728\u6700\u540e\u589e\u52a0\u4e00\u7ef4\u4f5c\u4e3a\u989c\u8272\u901a\u9053 # \u9ed8\u8ba4\u4e0b\u8f7d\u662f(60000, 28, 28)\uff0c\u6269\u5c55\u5230\u56db\u7ef4\u65b9\u4fbf\u8ba1\u7b97\u7406\u89e3[60000, 28, 28, 1] self . train_data = np . expand_dims ( self . train_data . astype ( np . float32 ) / 255.0 , axis =- 1 ) # [10000, 28, 28, 1] self . test_data = np . expand_dims ( self . test_data . astype ( np . float32 ) / 255.0 , axis =- 1 ) self . train_label = self . train_label . astype ( np . int32 ) # [60000] self . test_label = self . test_label . astype ( np . int32 ) # [10000] # \u83b7\u53d6\u6570\u636e\u7684\u5927\u5c0f self . num_train_data , self . num_test_data = self . train_data . shape [ 0 ], self . test_data . shape [ 0 ] def get_batch ( self , batch_size ): \"\"\" \u968f\u673a\u83b7\u53d6\u83b7\u53d6\u6279\u6b21\u6570\u636e :param batch_size: \u6279\u6b21\u5927\u5c0f :return: \"\"\" # \u4ece\u6570\u636e\u96c6\u4e2d\u968f\u673a\u53d6\u51fabatch_size\u4e2a\u5143\u7d20\u5e76\u8fd4\u56de index = np . random . randint ( 0 , np . shape ( self . train_data )[ 0 ], batch_size ) return self . train_data [ index , :], self . train_label [ index ] if __name__ == '__main__' : mnist = MNISTLoader () train_data , train_label = mnist . get_batch ( 50 ) print ( train_data . shape , train_label ) \u6ce8\uff1a\u5728 TensorFlow \u4e2d\uff0c\u56fe\u50cf\u6570\u636e\u96c6\u7684\u4e00\u79cd\u5178\u578b\u8868\u793a\u662f [\u56fe\u50cf\u6570\u76ee\uff0c\u957f\uff0c\u5bbd\uff0c\u8272\u5f69\u901a\u9053\u6570]\u7684\u56db\u7ef4\u5f20\u91cf\u3002","title":"1\u3001\u6570\u636e\u83b7\u53d6\u53ca\u9884\u5904\u7406\uff1a tf.keras.datasets"},{"location":"tensorFlow/section3/#2tfkerasmodel-tfkeraslayers","text":"\u591a\u5c42\u611f\u77e5\u673a\u7684\u6a21\u578b\u7c7b\u5b9e\u73b0\u4e0e\u4e0a\u9762\u7684\u7ebf\u6027\u6a21\u578b\u7c7b\u4f3c\uff0c\u4f7f\u7528 tf.keras.Model \u548c tf.keras.layers \u6784\u5efa\uff0c\u5f15\u5165\u4e86\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff08\u8fd9\u91cc\u4f7f\u7528\u4e86 ReLU \u51fd\u6570 \uff0c \u5373\u4e0b\u65b9\u7684 activation=tf.nn.relu \uff09\uff0c\u6a21\u578b\u8f93\u51fa 10 \u7ef4\u7684\u5411\u91cf\uff0c\u5206\u522b\u4ee3\u8868\u8fd9\u5f20\u56fe\u7247\u5c5e\u4e8e 0 \u5230 9 \u7684\u6982\u7387\u3002 \u4e3a\u4e86\u4f7f\u5f97\u6a21\u578b\u7684\u8f93\u51fa\u80fd\u59cb\u7ec8\u6ee1\u8db3\u8fd9\u4e24\u4e2a\u6761\u4ef6\uff0c\u6211\u4eec\u4f7f\u7528 Softmax \u51fd\u6570 \uff08\u5f52\u4e00\u5316\u6307\u6570\u51fd\u6570\uff0c tf.nn.softmax \uff09\u5bf9\u6a21\u578b\u7684\u539f\u59cb\u8f93\u51fa\u8fdb\u884c\u5f52\u4e00\u5316\u3002 class MLP ( tf . keras . Model ): \"\"\"\u81ea\u5b9a\u4e49MLP\u7c7b \"\"\" def __init__ ( self ): super () . __init__ () # \u5b9a\u4e49\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u7b2c\u4e00\u5c42100\u4e2a\u795e\u7ecf\u5143\uff0c\u6fc0\u6d3b\u51fd\u6570relu\uff0c\u7b2c\u4e8c\u5c4210\u4e2a\u795e\u7ecf\u5143\u8f93\u51fa\u7ed9softmax self . flatten = tf . keras . layers . Flatten () self . dense1 = tf . keras . layers . Dense ( units = 100 , activation = tf . nn . relu ) self . dense2 = tf . keras . layers . Dense ( units = 10 ) def call ( self , inputs ): # [batch_size, 28, 28, 1] x = self . flatten ( inputs ) # [batch_size, 784] x = self . dense1 ( x ) # [batch_size, 100] x = self . dense2 ( x ) # [batch_size, 10] output = tf . nn . softmax ( x ) return output","title":"2\u3001\u6a21\u578b\u7684\u6784\u5efa\uff1atf.keras.Model \u548c tf.keras.layers"},{"location":"tensorFlow/section3/#3-tfkeraslosses-tfkerasoptimizer","text":"\u5b9a\u4e49\u4e00\u4e9b\u6a21\u578b\u8d85\u53c2\u6570\uff1a num_epochs = 5 batch_size = 50 learning_rate = 0.001 \u7136\u540e\u8fed\u4ee3\u8fdb\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a 1\u3001\u4ece DataLoader \u4e2d\u968f\u673a\u53d6\u4e00\u6279\u8bad\u7ec3\u6570\u636e\uff1b 2\u3001\u5c06\u8fd9\u6279\u6570\u636e\u9001\u5165\u6a21\u578b\uff0c\u8ba1\u7b97\u51fa\u6a21\u578b\u7684\u9884\u6d4b\u503c\uff1b 3\u3001\u5c06\u6a21\u578b\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\uff08loss\uff09\u3002\u8fd9\u91cc\u4f7f\u7528 tf.keras.losses \u4e2d\u7684\u4ea4\u53c9\u71b5\u51fd\u6570\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff1b 4\u3001\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u5173\u4e8e\u6a21\u578b\u53d8\u91cf\u7684\u5bfc\u6570\uff1b 5\u3001\u5c06\u6c42\u51fa\u7684\u5bfc\u6570\u503c\u4f20\u5165\u4f18\u5316\u5668\uff0c\u4f7f\u7528\u4f18\u5316\u5668\u7684 apply_gradients \u65b9\u6cd5\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\uff08\u4f18\u5316\u5668\u7684\u8be6\u7ec6\u4f7f\u7528\u65b9\u6cd5\u89c1 \u524d\u7ae0 \uff09\u3002 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 # \u5b9e\u4f8b\u5316\u6a21\u578b\u548c\u6570\u636e\u8bfb\u53d6\u7c7b\uff0c\u5e76\u5b9e\u4f8b\u5316\u4e00\u4e2a\u4f18\u5316\u5668\uff0c\u8fd9\u91cc\u4f7f\u7528 Adam \u4f18\u5316\u5668 model = MLP () data_loader = MNISTLoader () optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ) # \u8ba1\u7b97\u51fa\u5927\u6982\u9700\u8981\u8fed\u4ee3\u6279\u6b21\u5927\u5c0f num_batches = int ( data_loader . num_train_data // batch_size * num_epochs ) # \u8fdb\u884c\u6279\u6b21\u6570\u636e\u83b7\u53d6 for batch_index in range ( num_batches ): X , y = data_loader . get_batch ( batch_size ) with tf . GradientTape () as tape : y_pred = model ( X ) # \u4f7f\u7528tf.keras.losses\u8ba1\u7b97\u635f\u5931 loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y , y_pred = y_pred ) # \u6c42\u51fa\u5e73\u5747\u635f\u5931 loss = tf . reduce_mean ( loss ) print ( \"batch %d : loss %f \" % ( batch_index , loss . numpy ())) grads = tape . gradient ( loss , model . variables ) optimizer . apply_gradients ( grads_and_vars = zip ( grads , model . variables )) \u6ce8\uff1a\u5728 tf.keras\u4e2d\uff0c\u6709\u4e24\u4e2a\u4ea4\u53c9\u71b5\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570 tf.keras.losses.categorical_crossentropy \u548c tf.keras.losses.sparse_categorical_crossentropy \u3002\u5176\u4e2d sparse \u7684\u542b\u4e49\u662f\uff0c\u771f\u5b9e\u7684\u6807\u7b7e\u503c y_true\u53ef\u4ee5\u76f4\u63a5\u4f20\u5165 int \u7c7b\u578b\u7684\u6807\u7b7e\u7c7b\u522b\u3002\u5177\u4f53\u800c\u8a00\uff1a loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y , y_pred = y_pred ) \u4e0e loss = tf . keras . losses . categorical_crossentropy ( y_true = tf . one_hot ( y , depth = tf . shape ( y_pred )[ - 1 ]), y_pred = y_pred ) \u7684\u7ed3\u679c\u76f8\u540c\u3002","title":"3\u3001\u6a21\u578b\u7684\u8bad\u7ec3\uff1a tf.keras.losses \u548c tf.keras.optimizer"},{"location":"tensorFlow/section3/#4-tfkerasmetrics","text":"\u6700\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u4f7f\u7528 tf.keras.metrics \u4e2d\u7684 SparseCategoricalAccuracy \u8bc4\u4f30\u5668\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u3002 \u8fed\u4ee3\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u6bcf\u6b21\u901a\u8fc7 update_state() \u65b9\u6cd5\u5411\u8bc4\u4f30\u5668\u8f93\u5165\u4e24\u4e2a\u53c2\u6570\uff1a y_pred \u548c y_true \uff0c\u5373\u6a21\u578b\u9884\u6d4b\u51fa\u7684\u7ed3\u679c\u548c\u771f\u5b9e\u7ed3\u679c\u3002 \u4f7f\u7528 result() \u65b9\u6cd5\u8f93\u51fa\u6700\u7ec8\u7684\u8bc4\u4f30\u6307\u6807\u503c\uff08\u9884\u6d4b\u6b63\u786e\u7684\u6837\u672c\u6570\u5360\u603b\u6837\u672c\u6570\u7684\u6bd4\u4f8b\uff09\u3002 \u5728\u4ee5\u4e0b\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a tf.keras.metrics.SparseCategoricalAccuracy \u8bc4\u4f30\u5668\uff0c\u5e76\u4f7f\u7528 For \u5faa\u73af\u8fed\u4ee3\u5206\u6279\u6b21\u4f20\u5165\u4e86\u6d4b\u8bd5\u96c6\u6570\u636e\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u7ed3\u679c\uff0c\u5e76\u8f93\u51fa\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u3002 y_pred = model . predict ( data_loader . test_data ) # \u5b9a\u4e49\u8bc4\u4f30\u51fd\u6570 sparse_categorical_accuracy = tf . keras . metrics . SparseCategoricalAccuracy () # \u5b9a\u4e49\u6d4b\u8bd5\u6570\u636e\u96c6\u4e00\u5171\u6279\u6b21\u7684\u5927\u5c0f sparse_categorical_accuracy . update_state ( y_true = data_loader . test_label , y_pred = y_pred ) print ( \"\u6d4b\u8bd5\u51c6\u786e\u7387: %f \" % sparse_categorical_accuracy . result ()) \u8f93\u51fa\u7ed3\u679c: \u6d4b\u8bd5\u51c6\u786e\u7387: 0.972300","title":"4\u3001\u6a21\u578b\u7684\u8bc4\u4f30\uff1a tf.keras.metrics"},{"location":"tensorFlow/section3/#435","text":"\u6a21\u578b\u7684\u6784\u5efa\uff1a tf.keras.Model \u548c tf.keras.layers \u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\uff1a tf.keras.losses \u6a21\u578b\u7684\u4f18\u5316\u5668\uff1a tf.keras.optimizer \u6a21\u578b\u7684\u8bc4\u4f30\uff1a tf.keras.metrics","title":"4.3.5 \u603b\u7ed3"},{"location":"tensorFlow/section4/","text":"4.4 \u6848\u4f8b\uff1aCNN\u8fdb\u884c\u5206\u7c7b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1keras\u5377\u79ef\u7f51\u7edc\u76f8\u5173API \u638c\u63e1\u5377\u673a\u7f51\u7edc\u7684\u6784\u5efa \u4e86\u89e3\u8fc1\u79fb\u5b66\u4e60\u4ee5\u53catf.keras.applications\u4f7f\u7528 \u5e94\u7528 4.4.1 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u8bc6\u522b\u624b\u5199\u6570\u5b57 \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u5377\u79ef\u5c42\uff08Convolutional Layer\uff09\u3001\u6c60\u5316\u5c42\uff08Pooling Layer\uff09\u548c\u5168\u8fde\u63a5\u5c42\uff08Fully-connected Layer\uff09\u3002 4.4.1.1 \u4f7f\u7528 Keras \u5b9e\u73b0\u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u4e2a\u5b9e\u73b0\u73b0\u5982\u4e0b\u6240\u793a\uff0c\u65b0\u52a0\u5165\u4e86\u4e00\u4e9b\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\u3002\u5f53\u7136\u8fd9\u4e2a\u7f51\u7edc\u53ef\u4ee5\u589e\u52a0\u3001\u5220\u9664\u6216\u8c03\u6574 CNN \u7684\u7f51\u7edc\u7ed3\u6784\u548c\u53c2\u6570\uff0c\u4ee5\u8fbe\u5230\u66f4\u597d\u6548\u679c\u3002 class CNN ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () self . conv1 = tf . keras . layers . Conv2D ( filters = 32 , # \u5377\u79ef\u5c42\u795e\u7ecf\u5143\uff08\u5377\u79ef\u6838\uff09\u6570\u76ee kernel_size = [ 5 , 5 ], # \u611f\u53d7\u91ce\u5927\u5c0f padding = 'same' , # padding\u7b56\u7565\uff08vaild \u6216 same\uff09 activation = tf . nn . relu # \u6fc0\u6d3b\u51fd\u6570 ) self . pool1 = tf . keras . layers . MaxPool2D ( pool_size = [ 2 , 2 ], strides = 2 ) self . conv2 = tf . keras . layers . Conv2D ( filters = 64 , kernel_size = [ 5 , 5 ], padding = 'same' , activation = tf . nn . relu ) self . pool2 = tf . keras . layers . MaxPool2D ( pool_size = [ 2 , 2 ], strides = 2 ) self . flatten = tf . keras . layers . Reshape ( target_shape = ( 7 * 7 * 64 ,)) self . dense1 = tf . keras . layers . Dense ( units = 1024 , activation = tf . nn . relu ) self . dense2 = tf . keras . layers . Dense ( units = 10 ) def call ( self , inputs ): x = self . conv1 ( inputs ) # [batch_size, 28, 28, 32] x = self . pool1 ( x ) # [batch_size, 14, 14, 32] x = self . conv2 ( x ) # [batch_size, 14, 14, 64] x = self . pool2 ( x ) # [batch_size, 7, 7, 64] x = self . flatten ( x ) # [batch_size, 7 * 7 * 64] x = self . dense1 ( x ) # [batch_size, 1024] x = self . dense2 ( x ) # [batch_size, 10] output = tf . nn . softmax ( x ) return output \u5c06\u524d\u8282\u7684 model = MLP() \u66f4\u6362\u6210 model = CNN() \uff0c\u8bad\u7ec3\u7ed3\u675f\u4ee5\u53ca\u9884\u6d4b\u8f93\u51fa\uff1a \u6279\u6b21 4682 : \u635f\u5931 0.010545 \u6279\u6b21 4683 : \u635f\u5931 0.003783 \u6279\u6b21 4684 : \u635f\u5931 0.000980 \u6d4b\u8bd5\u51c6\u786e\u7387 : 0.990600 \u53ef\u4ee5\u53d1\u73b0\u51c6\u786e\u7387\u76f8\u8f83\u4e8e\u4e4b\u524d\u7684\u591a\u5c42\u611f\u77e5\u673a\u6709\u975e\u5e38\u663e\u8457\u7684\u63d0\u9ad8\u3002 \u6211\u4eec\u6765\u770b\u4e00\u4e2a\u4e2a\u95ee\u9898\u5982\u679c\u6211\u4eec\u8981\u505a\u4e00\u4e2a\u5177\u4f53\u573a\u666f\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff0c\u90a3\u4e48\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2a\u7f51\u7edc\u662f\u5408\u9002\u7684\u9009\u62e9\u5417\uff1f\u600e\u4e48\u6837\u624d\u80fd\u907f\u514d\u6d6a\u8d39\u8fc7\u591a\u7684\u8ba1\u7b97\u65f6\u95f4\uff1f 4.4.2 \u8fc1\u79fb\u5b66\u4e60(Transfer Learning)-Keras \u4e2d\u9884\u5b9a\u4e49\u7684\u7ecf\u5178\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784 \u00b6 4.4.2.1 \u4ecb\u7ecd \u00b6 \u5b9a\u4e49 \u8fc1\u79fb\u5b66\u4e60\u5c31\u662f**\u5229\u7528\u6570\u636e\u3001\u4efb\u52a1\u6216\u6a21\u578b\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5c06\u5728\u65e7\u7684\u9886\u57df\u5b66\u4e60\u8fc7\u6216\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u5e94\u7528\u4e8e\u65b0\u7684\u9886\u57df\u8fd9\u6837\u7684\u4e00\u4e2a\u8fc7\u7a0b\u3002** \u4e24\u4e2a\u4efb\u52a1\u7684\u8f93\u5165\u5c5e\u4e8e\u540c\u4e00\u6027\u8d28\uff1a\u8981\u4e48\u540c\u662f\u56fe\u50cf\u3001\u8981\u4e48\u540c\u662f\u8bed\u97f3\u6216\u5176\u4ed6 \u8fc1\u79fb\u5b66\u4e60\u5230\u5e95\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u4f7f\u7528\u5462\uff1f\u6709\u4e24\u4e2a\u65b9\u9762\u9700\u8981\u6211\u4eec\u8003\u8651\u7684 1\u3001\u5f53\u6211\u4eec\u6709\u6d77\u91cf\u7684\u6570\u636e\u8d44\u6e90\u65f6\uff0c\u53ef\u4ee5\u4e0d\u9700\u8981\u8fc1\u79fb\u5b66\u4e60\uff0c**\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5f88\u5bb9\u6613\u4ece\u6d77\u91cf\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u4e00\u4e2a\u9c81\u68d2\u6027\u5f88\u5f3a\u7684\u6a21\u578b\u3002**\u4f46\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u7814\u7a76\u7684\u9886\u57df\u53ef\u83b7\u5f97\u7684\u6570\u636e\u6781\u4e3a\u6709\u9650\uff0c\u5728\u5c11\u91cf\u7684\u8bad\u7ec3\u6837\u672c\u4e0a\u7cbe\u5ea6\u6781\u9ad8\uff0c\u4f46\u662f\u6cdb\u5316\u6548\u679c\u6781\u5dee\u3002 2\u3001\u8bad\u7ec3\u6210\u672c\uff0c\u5f88\u5c11\u53bb\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u6574\u4e2a\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc\uff0c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u901a\u5e38\u9700\u8981\u8f83\u957f\u65f6\u95f4\u4e14\u4f9d\u8d56\u4e8e\u5f3a\u5927\u7684 GPU \u8ba1\u7b97\u8d44\u6e90\u3002 4.4.2.2 \u65b9\u6cd5 \u00b6 \u6700\u5e38\u89c1\u7684\u79f0\u547c\u53eb\u505afine tuning,\u5373\u5fae\u8c03 \u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u79f0\u4e4b\u4e3aPre-trained model \u901a\u5e38\u6211\u4eec\u9700\u8981\u52a0\u8f7d\u4ee5\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u662f\u4e00\u4e9b\u673a\u6784\u6216\u8005\u516c\u53f8\u5728ImageNet\u7b49\u7c7b\u4f3c\u6bd4\u8d5b\u4e0a\u8fdb\u884c\u8bad\u7ec3\u8fc7\u7684\u6a21\u578b\u3002TensorFlow\u540c\u6837\u4e5f\u63d0\u4f9b\u4e86\u76f8\u5173\u6a21\u578b\u5730\u5740\u4ee5\u53caAPI\uff1a https://www.tensorflow.org/api_docs/python/tf/keras/applications \uff0c\u4e0b\u56fe\u662f\u5176\u4e2d\u5305\u542b\u7684\u4e00\u4e9b\u6a21\u578b\uff1a 2.5.1.3 \u8fc7\u7a0b \u00b6 \u8fd9\u91cc\u6211\u4eec\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5047\u8bbe\u6709\u4e24\u4e2a\u4efb\u52a1A\u548cB\uff0c\u4efb\u52a1 A \u62e5\u6709\u6d77\u91cf\u7684\u6570\u636e\u8d44\u6e90\u4e14\u5df2\u8bad\u7ec3\u597d\uff0c\u4f46\u5e76\u4e0d\u662f\u6211\u4eec\u7684\u76ee\u6807\u4efb\u52a1\uff0c\u4efb\u52a1 B \u662f\u6211\u4eec\u7684\u76ee\u6807\u4efb\u52a1\u3002\u4e0b\u9762\u7684\u7f51\u7edc\u6a21\u578b\u5047\u8bbe\u662f\u5df2\u8bad\u7ec3\u597d\u76841000\u4e2a\u7c7b\u522b\u6a21\u578b \u800cB\u4efb\u52a1\u5047\u8bbe\u662f\u67d0\u4e2a\u5177\u4f53\u573a\u666f\u5982250\u4e2a\u7c7b\u522b\u7684\u98df\u7269\u8bc6\u522b\uff0c\u90a3\u4e48\u8be5\u600e\u4e48\u53bb\u505a 1\u3001\u5efa\u7acb\u81ea\u5df1\u7684\u7f51\u7edc\uff0c\u5728A\u7684\u57fa\u7840\u4e0a\uff0c\u4fee\u6539\u6700\u540e\u8f93\u51fa\u7ed3\u6784\uff0c\u5e76\u52a0\u8f7dA\u7684\u6a21\u578b\u53c2\u6570 2\u3001\u6839\u636e\u6570\u636e\u5927\u5c0f\u8c03\u6574 \u5982\u679cB\u4efb\u52a1\u6570\u636e\u91cf\u5c0f\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u5c06A\u6a21\u578b\u7684\u6240\u6709\u7684\u5c42\u8fdb\u884cfreeze(\u53ef\u4ee5\u901a\u8fc7Tensorflow\u7684trainable=False\u53c2\u6570\u5b9e\u73b0)\uff0c\u800c\u5269\u4e0b\u7684\u8f93\u51fa\u5c42\u90e8\u5206\u53ef\u4ee5\u9009\u62e9\u8c03\u6574\u53c2\u6570\u8bad\u7ec3 \u5982\u679cB\u4efb\u52a1\u7684\u6570\u636e\u91cf\u5927\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u5c06A\u4e2d\u4e00\u534a\u6216\u8005\u5927\u90e8\u5206\u7684\u5c42\u8fdb\u884cfreeze,\u800c\u5269\u4e0b\u90e8\u5206\u7684layer\u53ef\u4ee5\u8fdb\u884c\u65b0\u4efb\u52a1\u6570\u636e\u57fa\u7840\u4e0a\u7684\u5fae\u8c03 4.4.2 \u4f7f\u7528 \u00b6 tf.keras.applications \u4e2d\u6709\u4e00\u4e9b\u9884\u5b9a\u4e49\u597d\u7684\u7ecf\u5178\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u5982 VGG16 \u3001 VGG19 \u3001 ResNet \u3001 MobileNet \u7b49\u3002\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u8fd9\u4e9b\u7ecf\u5178\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff08\u751a\u81f3\u8f7d\u5165\u9884\u8bad\u7ec3\u7684\u53c2\u6570\uff09\uff0c\u800c\u65e0\u9700\u624b\u52a8\u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784\u3002 \u652f\u6301\u4ee5\u4e0b\u7ed3\u6784\uff1a densenet module: DenseNet models for Keras. imagenet_utils module: Utilities for ImageNet data preprocessing & prediction decoding. inception_resnet_v2 module: Inception-ResNet V2 model for Keras. inception_v3 module: Inception V3 model for Keras. mobilenet module: MobileNet v1 models for Keras. mobilenet_v2 module: MobileNet v2 models for Keras. nasnet module: NASNet-A models for Keras. resnet module: ResNet models for Keras. resnet50 module: Public API for tf.keras.applications.resnet50 namespace. resnet_v2 module: ResNet v2 models for Keras. vgg16 module: VGG16 model for Keras. vgg19 module: VGG19 model for Keras. xception module: Xception V1 model for Keras. \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u6765\u5b9e\u4f8b\u5316\u4e00\u4e2a MobileNetV2 \u7f51\u7edc\u7ed3\u6784\uff1a model = tf.keras.applications.MobileNetV2() input_shape \uff1a\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\uff08\u4e0d\u542b\u7b2c\u4e00\u7ef4\u7684 Batch\uff09\uff0c\u5927\u591a\u9ed8\u8ba4\u4e3a 224 \u00d7 224 \u00d7 3 \u3002\u4e00\u822c\u800c\u8a00\uff0c\u6a21\u578b\u5bf9\u8f93\u5165\u5f20\u91cf\u7684\u5927\u5c0f\u6709\u4e0b\u9650\uff0c\u957f\u548c\u5bbd\u81f3\u5c11\u4e3a 32 \u00d7 32 \u6216 75 \u00d7 75 \uff1b include_top \uff1a\u5728\u7f51\u7edc\u7684\u6700\u540e\u662f\u5426\u5305\u542b\u5168\u8fde\u63a5\u5c42\uff0c\u9ed8\u8ba4\u4e3a True \uff1b weights \uff1a\u9884\u8bad\u7ec3\u6743\u503c\uff0c\u9ed8\u8ba4\u4e3a 'imagenet' \uff0c\u5373\u4e3a\u5f53\u524d\u6a21\u578b\u8f7d\u5165\u5728 ImageNet \u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\u3002\u5982\u9700\u968f\u673a\u521d\u59cb\u5316\u53d8\u91cf\u53ef\u8bbe\u4e3a None \uff1b classes \uff1a\u5206\u7c7b\u6570\uff0c\u9ed8\u8ba4\u4e3a 1000\u3002\u4fee\u6539\u8be5\u53c2\u6570\u9700\u8981 include_top \u53c2\u6570\u4e3a True \u4e14 weights \u53c2\u6570\u4e3a None \u3002 \u5f53\u6267\u884c\u4ee5\u4e0a\u4ee3\u7801\u65f6\uff0cTensorFlow \u4f1a\u81ea\u52a8\u4ece\u7f51\u7edc\u4e0a\u4e0b\u8f7d MobileNetV2 \u7f51\u7edc\u7ed3\u6784\uff0c\u56e0\u6b64\u5728\u7b2c\u4e00\u6b21\u6267\u884c\u4ee3\u7801\u65f6\u9700\u8981\u5177\u5907\u7f51\u7edc\u8fde\u63a5\u3002 \u53ef\u4ee5\u4f7f\u7528 MobileNetV2 \u7f51\u7edc\u5bf9\u76f8\u5173\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u770b\u770b\u6548\u679c model = tf . keras . applications . MobileNetV2 ( weights = None , classes = 5 ) 4.4.3 \u603b\u7ed3 \u00b6 \u638c\u63e1keras\u5377\u79ef\u7f51\u7edc\u76f8\u5173API \u5377\u673a\u7f51\u7edc\u7684\u6784\u5efa \u8fc1\u79fb\u5b66\u4e60\u4ee5\u53catf.keras.applications\u4f7f\u7528","title":"4.4 \u6848\u4f8b\uff1aCNN\u8fdb\u884c\u5206\u7c7b"},{"location":"tensorFlow/section4/#44-cnn","text":"","title":"4.4 \u6848\u4f8b\uff1aCNN\u8fdb\u884c\u5206\u7c7b"},{"location":"tensorFlow/section4/#_1","text":"\u76ee\u6807 \u638c\u63e1keras\u5377\u79ef\u7f51\u7edc\u76f8\u5173API \u638c\u63e1\u5377\u673a\u7f51\u7edc\u7684\u6784\u5efa \u4e86\u89e3\u8fc1\u79fb\u5b66\u4e60\u4ee5\u53catf.keras.applications\u4f7f\u7528 \u5e94\u7528","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section4/#441","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u5377\u79ef\u5c42\uff08Convolutional Layer\uff09\u3001\u6c60\u5316\u5c42\uff08Pooling Layer\uff09\u548c\u5168\u8fde\u63a5\u5c42\uff08Fully-connected Layer\uff09\u3002","title":"4.4.1 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u8bc6\u522b\u624b\u5199\u6570\u5b57"},{"location":"tensorFlow/section4/#4411-keras","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u4e2a\u5b9e\u73b0\u73b0\u5982\u4e0b\u6240\u793a\uff0c\u65b0\u52a0\u5165\u4e86\u4e00\u4e9b\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\u3002\u5f53\u7136\u8fd9\u4e2a\u7f51\u7edc\u53ef\u4ee5\u589e\u52a0\u3001\u5220\u9664\u6216\u8c03\u6574 CNN \u7684\u7f51\u7edc\u7ed3\u6784\u548c\u53c2\u6570\uff0c\u4ee5\u8fbe\u5230\u66f4\u597d\u6548\u679c\u3002 class CNN ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () self . conv1 = tf . keras . layers . Conv2D ( filters = 32 , # \u5377\u79ef\u5c42\u795e\u7ecf\u5143\uff08\u5377\u79ef\u6838\uff09\u6570\u76ee kernel_size = [ 5 , 5 ], # \u611f\u53d7\u91ce\u5927\u5c0f padding = 'same' , # padding\u7b56\u7565\uff08vaild \u6216 same\uff09 activation = tf . nn . relu # \u6fc0\u6d3b\u51fd\u6570 ) self . pool1 = tf . keras . layers . MaxPool2D ( pool_size = [ 2 , 2 ], strides = 2 ) self . conv2 = tf . keras . layers . Conv2D ( filters = 64 , kernel_size = [ 5 , 5 ], padding = 'same' , activation = tf . nn . relu ) self . pool2 = tf . keras . layers . MaxPool2D ( pool_size = [ 2 , 2 ], strides = 2 ) self . flatten = tf . keras . layers . Reshape ( target_shape = ( 7 * 7 * 64 ,)) self . dense1 = tf . keras . layers . Dense ( units = 1024 , activation = tf . nn . relu ) self . dense2 = tf . keras . layers . Dense ( units = 10 ) def call ( self , inputs ): x = self . conv1 ( inputs ) # [batch_size, 28, 28, 32] x = self . pool1 ( x ) # [batch_size, 14, 14, 32] x = self . conv2 ( x ) # [batch_size, 14, 14, 64] x = self . pool2 ( x ) # [batch_size, 7, 7, 64] x = self . flatten ( x ) # [batch_size, 7 * 7 * 64] x = self . dense1 ( x ) # [batch_size, 1024] x = self . dense2 ( x ) # [batch_size, 10] output = tf . nn . softmax ( x ) return output \u5c06\u524d\u8282\u7684 model = MLP() \u66f4\u6362\u6210 model = CNN() \uff0c\u8bad\u7ec3\u7ed3\u675f\u4ee5\u53ca\u9884\u6d4b\u8f93\u51fa\uff1a \u6279\u6b21 4682 : \u635f\u5931 0.010545 \u6279\u6b21 4683 : \u635f\u5931 0.003783 \u6279\u6b21 4684 : \u635f\u5931 0.000980 \u6d4b\u8bd5\u51c6\u786e\u7387 : 0.990600 \u53ef\u4ee5\u53d1\u73b0\u51c6\u786e\u7387\u76f8\u8f83\u4e8e\u4e4b\u524d\u7684\u591a\u5c42\u611f\u77e5\u673a\u6709\u975e\u5e38\u663e\u8457\u7684\u63d0\u9ad8\u3002 \u6211\u4eec\u6765\u770b\u4e00\u4e2a\u4e2a\u95ee\u9898\u5982\u679c\u6211\u4eec\u8981\u505a\u4e00\u4e2a\u5177\u4f53\u573a\u666f\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff0c\u90a3\u4e48\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2a\u7f51\u7edc\u662f\u5408\u9002\u7684\u9009\u62e9\u5417\uff1f\u600e\u4e48\u6837\u624d\u80fd\u907f\u514d\u6d6a\u8d39\u8fc7\u591a\u7684\u8ba1\u7b97\u65f6\u95f4\uff1f","title":"4.4.1.1 \u4f7f\u7528 Keras \u5b9e\u73b0\u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"tensorFlow/section4/#442-transfer-learning-keras","text":"","title":"4.4.2 \u8fc1\u79fb\u5b66\u4e60(Transfer Learning)-Keras \u4e2d\u9884\u5b9a\u4e49\u7684\u7ecf\u5178\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784"},{"location":"tensorFlow/section4/#4421","text":"\u5b9a\u4e49 \u8fc1\u79fb\u5b66\u4e60\u5c31\u662f**\u5229\u7528\u6570\u636e\u3001\u4efb\u52a1\u6216\u6a21\u578b\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5c06\u5728\u65e7\u7684\u9886\u57df\u5b66\u4e60\u8fc7\u6216\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u5e94\u7528\u4e8e\u65b0\u7684\u9886\u57df\u8fd9\u6837\u7684\u4e00\u4e2a\u8fc7\u7a0b\u3002** \u4e24\u4e2a\u4efb\u52a1\u7684\u8f93\u5165\u5c5e\u4e8e\u540c\u4e00\u6027\u8d28\uff1a\u8981\u4e48\u540c\u662f\u56fe\u50cf\u3001\u8981\u4e48\u540c\u662f\u8bed\u97f3\u6216\u5176\u4ed6 \u8fc1\u79fb\u5b66\u4e60\u5230\u5e95\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u4f7f\u7528\u5462\uff1f\u6709\u4e24\u4e2a\u65b9\u9762\u9700\u8981\u6211\u4eec\u8003\u8651\u7684 1\u3001\u5f53\u6211\u4eec\u6709\u6d77\u91cf\u7684\u6570\u636e\u8d44\u6e90\u65f6\uff0c\u53ef\u4ee5\u4e0d\u9700\u8981\u8fc1\u79fb\u5b66\u4e60\uff0c**\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5f88\u5bb9\u6613\u4ece\u6d77\u91cf\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u4e00\u4e2a\u9c81\u68d2\u6027\u5f88\u5f3a\u7684\u6a21\u578b\u3002**\u4f46\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u7814\u7a76\u7684\u9886\u57df\u53ef\u83b7\u5f97\u7684\u6570\u636e\u6781\u4e3a\u6709\u9650\uff0c\u5728\u5c11\u91cf\u7684\u8bad\u7ec3\u6837\u672c\u4e0a\u7cbe\u5ea6\u6781\u9ad8\uff0c\u4f46\u662f\u6cdb\u5316\u6548\u679c\u6781\u5dee\u3002 2\u3001\u8bad\u7ec3\u6210\u672c\uff0c\u5f88\u5c11\u53bb\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u6574\u4e2a\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc\uff0c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u901a\u5e38\u9700\u8981\u8f83\u957f\u65f6\u95f4\u4e14\u4f9d\u8d56\u4e8e\u5f3a\u5927\u7684 GPU \u8ba1\u7b97\u8d44\u6e90\u3002","title":"4.4.2.1 \u4ecb\u7ecd"},{"location":"tensorFlow/section4/#4422","text":"\u6700\u5e38\u89c1\u7684\u79f0\u547c\u53eb\u505afine tuning,\u5373\u5fae\u8c03 \u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u79f0\u4e4b\u4e3aPre-trained model \u901a\u5e38\u6211\u4eec\u9700\u8981\u52a0\u8f7d\u4ee5\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u662f\u4e00\u4e9b\u673a\u6784\u6216\u8005\u516c\u53f8\u5728ImageNet\u7b49\u7c7b\u4f3c\u6bd4\u8d5b\u4e0a\u8fdb\u884c\u8bad\u7ec3\u8fc7\u7684\u6a21\u578b\u3002TensorFlow\u540c\u6837\u4e5f\u63d0\u4f9b\u4e86\u76f8\u5173\u6a21\u578b\u5730\u5740\u4ee5\u53caAPI\uff1a https://www.tensorflow.org/api_docs/python/tf/keras/applications \uff0c\u4e0b\u56fe\u662f\u5176\u4e2d\u5305\u542b\u7684\u4e00\u4e9b\u6a21\u578b\uff1a","title":"4.4.2.2 \u65b9\u6cd5"},{"location":"tensorFlow/section4/#2513","text":"\u8fd9\u91cc\u6211\u4eec\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5047\u8bbe\u6709\u4e24\u4e2a\u4efb\u52a1A\u548cB\uff0c\u4efb\u52a1 A \u62e5\u6709\u6d77\u91cf\u7684\u6570\u636e\u8d44\u6e90\u4e14\u5df2\u8bad\u7ec3\u597d\uff0c\u4f46\u5e76\u4e0d\u662f\u6211\u4eec\u7684\u76ee\u6807\u4efb\u52a1\uff0c\u4efb\u52a1 B \u662f\u6211\u4eec\u7684\u76ee\u6807\u4efb\u52a1\u3002\u4e0b\u9762\u7684\u7f51\u7edc\u6a21\u578b\u5047\u8bbe\u662f\u5df2\u8bad\u7ec3\u597d\u76841000\u4e2a\u7c7b\u522b\u6a21\u578b \u800cB\u4efb\u52a1\u5047\u8bbe\u662f\u67d0\u4e2a\u5177\u4f53\u573a\u666f\u5982250\u4e2a\u7c7b\u522b\u7684\u98df\u7269\u8bc6\u522b\uff0c\u90a3\u4e48\u8be5\u600e\u4e48\u53bb\u505a 1\u3001\u5efa\u7acb\u81ea\u5df1\u7684\u7f51\u7edc\uff0c\u5728A\u7684\u57fa\u7840\u4e0a\uff0c\u4fee\u6539\u6700\u540e\u8f93\u51fa\u7ed3\u6784\uff0c\u5e76\u52a0\u8f7dA\u7684\u6a21\u578b\u53c2\u6570 2\u3001\u6839\u636e\u6570\u636e\u5927\u5c0f\u8c03\u6574 \u5982\u679cB\u4efb\u52a1\u6570\u636e\u91cf\u5c0f\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u9009\u62e9\u5c06A\u6a21\u578b\u7684\u6240\u6709\u7684\u5c42\u8fdb\u884cfreeze(\u53ef\u4ee5\u901a\u8fc7Tensorflow\u7684trainable=False\u53c2\u6570\u5b9e\u73b0)\uff0c\u800c\u5269\u4e0b\u7684\u8f93\u51fa\u5c42\u90e8\u5206\u53ef\u4ee5\u9009\u62e9\u8c03\u6574\u53c2\u6570\u8bad\u7ec3 \u5982\u679cB\u4efb\u52a1\u7684\u6570\u636e\u91cf\u5927\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u5c06A\u4e2d\u4e00\u534a\u6216\u8005\u5927\u90e8\u5206\u7684\u5c42\u8fdb\u884cfreeze,\u800c\u5269\u4e0b\u90e8\u5206\u7684layer\u53ef\u4ee5\u8fdb\u884c\u65b0\u4efb\u52a1\u6570\u636e\u57fa\u7840\u4e0a\u7684\u5fae\u8c03","title":"2.5.1.3 \u8fc7\u7a0b"},{"location":"tensorFlow/section4/#442","text":"tf.keras.applications \u4e2d\u6709\u4e00\u4e9b\u9884\u5b9a\u4e49\u597d\u7684\u7ecf\u5178\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u5982 VGG16 \u3001 VGG19 \u3001 ResNet \u3001 MobileNet \u7b49\u3002\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u8fd9\u4e9b\u7ecf\u5178\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff08\u751a\u81f3\u8f7d\u5165\u9884\u8bad\u7ec3\u7684\u53c2\u6570\uff09\uff0c\u800c\u65e0\u9700\u624b\u52a8\u5b9a\u4e49\u7f51\u7edc\u7ed3\u6784\u3002 \u652f\u6301\u4ee5\u4e0b\u7ed3\u6784\uff1a densenet module: DenseNet models for Keras. imagenet_utils module: Utilities for ImageNet data preprocessing & prediction decoding. inception_resnet_v2 module: Inception-ResNet V2 model for Keras. inception_v3 module: Inception V3 model for Keras. mobilenet module: MobileNet v1 models for Keras. mobilenet_v2 module: MobileNet v2 models for Keras. nasnet module: NASNet-A models for Keras. resnet module: ResNet models for Keras. resnet50 module: Public API for tf.keras.applications.resnet50 namespace. resnet_v2 module: ResNet v2 models for Keras. vgg16 module: VGG16 model for Keras. vgg19 module: VGG19 model for Keras. xception module: Xception V1 model for Keras. \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u6765\u5b9e\u4f8b\u5316\u4e00\u4e2a MobileNetV2 \u7f51\u7edc\u7ed3\u6784\uff1a model = tf.keras.applications.MobileNetV2() input_shape \uff1a\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\uff08\u4e0d\u542b\u7b2c\u4e00\u7ef4\u7684 Batch\uff09\uff0c\u5927\u591a\u9ed8\u8ba4\u4e3a 224 \u00d7 224 \u00d7 3 \u3002\u4e00\u822c\u800c\u8a00\uff0c\u6a21\u578b\u5bf9\u8f93\u5165\u5f20\u91cf\u7684\u5927\u5c0f\u6709\u4e0b\u9650\uff0c\u957f\u548c\u5bbd\u81f3\u5c11\u4e3a 32 \u00d7 32 \u6216 75 \u00d7 75 \uff1b include_top \uff1a\u5728\u7f51\u7edc\u7684\u6700\u540e\u662f\u5426\u5305\u542b\u5168\u8fde\u63a5\u5c42\uff0c\u9ed8\u8ba4\u4e3a True \uff1b weights \uff1a\u9884\u8bad\u7ec3\u6743\u503c\uff0c\u9ed8\u8ba4\u4e3a 'imagenet' \uff0c\u5373\u4e3a\u5f53\u524d\u6a21\u578b\u8f7d\u5165\u5728 ImageNet \u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\u3002\u5982\u9700\u968f\u673a\u521d\u59cb\u5316\u53d8\u91cf\u53ef\u8bbe\u4e3a None \uff1b classes \uff1a\u5206\u7c7b\u6570\uff0c\u9ed8\u8ba4\u4e3a 1000\u3002\u4fee\u6539\u8be5\u53c2\u6570\u9700\u8981 include_top \u53c2\u6570\u4e3a True \u4e14 weights \u53c2\u6570\u4e3a None \u3002 \u5f53\u6267\u884c\u4ee5\u4e0a\u4ee3\u7801\u65f6\uff0cTensorFlow \u4f1a\u81ea\u52a8\u4ece\u7f51\u7edc\u4e0a\u4e0b\u8f7d MobileNetV2 \u7f51\u7edc\u7ed3\u6784\uff0c\u56e0\u6b64\u5728\u7b2c\u4e00\u6b21\u6267\u884c\u4ee3\u7801\u65f6\u9700\u8981\u5177\u5907\u7f51\u7edc\u8fde\u63a5\u3002 \u53ef\u4ee5\u4f7f\u7528 MobileNetV2 \u7f51\u7edc\u5bf9\u76f8\u5173\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u770b\u770b\u6548\u679c model = tf . keras . applications . MobileNetV2 ( weights = None , classes = 5 )","title":"4.4.2 \u4f7f\u7528"},{"location":"tensorFlow/section4/#443","text":"\u638c\u63e1keras\u5377\u79ef\u7f51\u7edc\u76f8\u5173API \u5377\u673a\u7f51\u7edc\u7684\u6784\u5efa \u8fc1\u79fb\u5b66\u4e60\u4ee5\u53catf.keras.applications\u4f7f\u7528","title":"4.4.3 \u603b\u7ed3"},{"location":"tensorFlow/section5/","text":"4.5 Keras Pipline\u4e0e\u81ea\u5b9a\u4e49\u6a21\u578b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1keras pipline\u7684\u4f7f\u7528 \u638c\u63e1keras model\u8bad\u7ec3\u9a8c\u8bc1\u65b9\u6cd5\u4f7f\u7528 \u638c\u63e1keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528 \u5e94\u7528 \u65e0 \u4f7f\u7528\u4e86 Keras \u7684 Subclassing API \u5efa\u7acb\u6a21\u578b\uff0c\u5373\u5bf9 tf.keras.Model\u7c7b\u8fdb\u884c\u6269\u5c55\u4ee5\u5b9a\u4e49\u81ea\u5df1\u7684\u65b0\u6a21\u578b\uff0c\u540c\u65f6\u624b\u5de5\u7f16\u5199\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u7684\u6d41\u7a0b\u3002\u8fd9\u79cd\u65b9\u5f0f\u7075\u6d3b\u5ea6\u9ad8\uff0c\u4e14\u4e0e\u5176\u4ed6\u6d41\u884c\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff08\u5982 PyTorch\u3001Chainer\uff09\u5171\u901a\uff0c\u662f\u672c\u624b\u518c\u6240\u63a8\u8350\u7684\u65b9\u6cd5\u3002\u4e0d\u8fc7\u5728\u5f88\u591a\u65f6\u5019\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7ed3\u6784\u76f8\u5bf9\u7b80\u5355\u548c\u5178\u578b\u7684\u795e\u7ecf\u7f51\u7edc\uff08\u6bd4\u5982\u4e0a\u6587\u4e2d\u7684 MLP \u548c CNN\uff09\uff0c\u5e76\u4f7f\u7528\u5e38\u89c4\u7684\u624b\u6bb5\u8fdb\u884c\u8bad\u7ec3\u3002 Keras \u4e5f\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86\u53e6\u4e00\u5957\u66f4\u4e3a\u7b80\u5355\u9ad8\u6548\u7684\u5185\u7f6e\u65b9\u6cd5\u6765\u5efa\u7acb\u3001\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u3002 4.5.1 Keras Sequential/Functional API \u6a21\u5f0f\u5efa\u7acb\u6a21\u578b \u00b6 \u6700\u5178\u578b\u548c\u5e38\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u662f\u5c06\u4e00\u5806\u5c42\u6309\u7279\u5b9a\u987a\u5e8f\u53e0\u52a0\u8d77\u6765\uff0c\u90a3\u4e48\uff0c\u6211\u4eec\u662f\u4e0d\u662f\u53ea\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u7531 Keras \u5c06\u5b83\u4eec\u81ea\u52a8\u9996\u5c3e\u76f8\u8fde\uff0c\u5f62\u6210\u6a21\u578b\u5462\uff1fKeras \u7684 Sequential API \u6b63\u662f\u5982\u6b64\u3002 1\u3001tf.keras.models.Sequential() \u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u5feb\u901f\u5730\u5efa\u7acb\u4e00\u4e2a tf.keras.Model \u6a21\u578b\u5e76\u8fd4\u56de\uff1a model = tf . keras . models . Sequential ([ tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 100 , activation = tf . nn . relu ), tf . keras . layers . Dense ( 10 ), tf . keras . layers . Softmax () ]) \u4e0d\u8fc7\uff0c\u8fd9\u79cd\u5c42\u53e0\u7ed3\u6784\u5e76\u4e0d\u80fd\u8868\u793a\u4efb\u610f\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002 2\u3001\u4e3a\u6b64\uff0cKeras \u63d0\u4f9b\u4e86 Functional API\uff0c\u5e2e\u52a9\u6211\u4eec\u5efa\u7acb\u66f4\u4e3a\u590d\u6742\u7684\u6a21\u578b\uff0c\u6bd4\u5982\u8bf4\u9700\u8981**\u591a\u8f93\u5165 / \u8f93\u51fa\u6216\u5b58\u5728\u53c2\u6570\u5171\u4eab\u7684\u6a21\u578b**\u3002\u5176\u4f7f\u7528\u65b9\u6cd5\u662f\u5c06\u5c42\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u5e76\u8fd4\u56de\u5f20\u91cf\uff0c\u5e76\u5c06\u8f93\u5165\u5411\u91cf\u548c\u8f93\u51fa\u5411\u91cf\u63d0\u4f9b\u7ed9 tf.keras.Model \u7684 inputs \u548c outputs \u53c2\u6570\uff0c\u5982 inputs = tf . keras . Input ( shape = ( 28 , 28 , 1 )) x = tf . keras . layers . Flatten ()( inputs ) x = tf . keras . layers . Dense ( units = 100 , activation = tf . nn . relu )( x ) x = tf . keras . layers . Dense ( units = 10 )( x ) outputs = tf . keras . layers . Softmax ()( x ) model = tf . keras . Model ( inputs = inputs , outputs = outputs ) 4.5.2 \u4f7f\u7528 Keras Model \u7684 compile \u3001 fit \u548c evaluate \u65b9\u6cd5\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b \u00b6 1\u3001\u901a\u8fc7\u8c03\u7528model\u7684 compile \u65b9\u6cd5\u53bb\u914d\u7f6e\u8be5\u6a21\u578b\u6240\u9700\u8981\u7684\u8bad\u7ec3\u53c2\u6570\u4ee5\u53ca\u8bc4\u4f30\u65b9\u6cd5\u3002 model.compile(optimizer,loss=None,metrics=None, \u51c6\u786e\u7387\u8861):\u914d\u7f6e\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 optimizer:\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5668(\u5728keras.optimizers) from keras.optimizers import Adadelta from keras.optimizers import Adagrad from keras.optimizers import Adam from keras.optimizers import Adamax from keras.optimizers import Nadam from keras.optimizers import Optimizer from keras.optimizers import RMSprop from keras.optimizers import SGD from keras.optimizers import deserialize from keras.optimizers import get from keras.optimizers import serialize from keras.optimizers import AdamOptimizer () loss=None:\u635f\u5931\u7c7b\u578b,\u7c7b\u578b\u53ef\u4ee5\u662f\u5b57\u7b26\u4e32\u6216\u8005\u8be5function\u540d\u5b57\u53c2\u8003\uff1a ... from keras.losses import MAE as mae from keras.losses import MAE as mean_absolute_error from keras.losses import MAPE from keras.losses import binary_crossentropy from keras.losses import categorical_crossentropy from keras.losses import serialize ... metrics=None, ['accuracy'] model . compile ( optimizer = tf . keras . optimizers . Adam (), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) \u4e24\u4e2a\u76f8\u8fd1\u7684\u533a\u522b 1\u3001sparse_categorical_crossentropy:\u5bf9\u4e8e\u76ee\u6807\u503c\u662f\u6574\u578b\u7684\u8fdb\u884c\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97 2\u3001categorical_crossentropy:\u5bf9\u4e8e\u4e24\u4e2aoutput tensor and a target tensor\u8fdb\u884c\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97 \u4f7f\u7528\u5982\u4e0b model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) 2\u3001model.fit()\uff1a\u8fdb\u884c\u8bad\u7ec3 model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size) x:\u7279\u5f81\u503c: 1 \u3001 Numpy array ( or array - like ), or a list of arrays 2 \u3001 A TensorFlow tensor , or a list of tensors 3 \u3001 `tf.data` dataset or a dataset iterator . Should return a tuple of either `(inputs, targets)` or `(inputs, targets, sample_weights)` . 4 \u3001 A generator or `keras.utils.Sequence` returning `(inputs, targets)` or `(inputs, targets, sample weights)` . y:\u76ee\u6807\u503c batch_size=None\uff1a\u6279\u6b21\u5927\u5c0f epochs=1\uff1a\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570 validation_data \uff1a\u9a8c\u8bc1\u6570\u636e\uff0c\u53ef\u7528\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76d1\u63a7\u6a21\u578b\u7684\u6027\u80fd\u3002 callbacks=None\uff1a\u6dfb\u52a0\u56de\u8c03\u5217\u8868\uff08\u7528\u4e8e\u5982tensorboard\u663e\u793a\u7b49\uff09 model . fit ( train_images , train_labels , epochs = 5 , batch_size = 32 ) 3\u3001model.evaluate(test_images, test_labels) model.evaluate(test, test_label) \u9884\u6d4bmodel.predict(test)\uff1a \u5176\u5b83\u65b9\u6cd5\uff1a model.save_weights(filepath) \u5c06\u6a21\u578b\u7684\u6743\u91cd\u4fdd\u5b58\u4e3aHDF5\u6587\u4ef6\u6216\u8005ckpt\u6587\u4ef6 model.load_weights(filepath, by_name=False) \u4eceHDF5\u6587\u4ef6\uff08\u7531\u5176\u521b\u5efa save_weights \uff09\u52a0\u8f7d\u6a21\u578b\u7684\u6743\u91cd\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u67b6\u6784\u9884\u8ba1\u4e0d\u4f1a\u66f4\u6539\u3002\u8981\u5c06\u6743\u91cd\u52a0\u8f7d\u5230\u4e0d\u540c\u7684\u4f53\u7cfb\u7ed3\u6784\uff08\u5177\u6709\u4e00\u4e9b\u5171\u540c\u7684\u5c42\uff09\uff0c\u8bf7\u4f7f\u7528 by_name=True \u4ec5\u52a0\u8f7d\u5177\u6709\u76f8\u540c\u540d\u79f0\u7684\u90a3\u4e9b\u5c42\u3002 4.5.3 \u6848\u4f8b\uff1aCIFAR100\u6570\u636e\u96c6\u4ecb\u7ecd \u00b6 \u8fd9\u4e2a\u6570\u636e\u96c6\u5c31\u50cfCIFAR-10\uff0c\u9664\u4e86\u5b83\u6709100\u4e2a\u7c7b\uff0c\u6bcf\u4e2a\u7c7b\u5305\u542b600\u4e2a\u56fe\u50cf\u3002\uff0c\u6bcf\u7c7b\u5404\u6709500\u4e2a\u8bad\u7ec3\u56fe\u50cf\u548c100\u4e2a\u6d4b\u8bd5\u56fe\u50cf\u3002CIFAR-100\u4e2d\u7684100\u4e2a\u7c7b\u88ab\u5206\u621020\u4e2a\u8d85\u7c7b\u3002\u6bcf\u4e2a\u56fe\u50cf\u90fd\u5e26\u6709\u4e00\u4e2a\u201c\u7cbe\u7ec6\u201d\u6807\u7b7e\uff08\u5b83\u6240\u5c5e\u7684\u7c7b\uff09\u548c\u4e00\u4e2a\u201c\u7c97\u7cd9\u201d\u6807\u7b7e\uff08\u5b83\u6240\u5c5e\u7684\u8d85\u7c7b\uff09 \u4ee5\u4e0b\u662fCIFAR-100\u4e2d\u7684\u7c7b\u522b\u5217\u8868\uff1a \u7b49\u7b49... 4.4.2.1 API \u4f7f\u7528 \u00b6 \u7528\u4e8e\u6784\u5efaCNN\u6a21\u578b\u7684API Conv2D\uff1a\u5b9e\u73b0\u5377\u79ef\uff0ckernel_size,strides,padding,dataformat,'NHWC'\u548c'NCHW' MaxPool2D\uff1a\u6c60\u5316\u64cd\u4f5c keras.layers.Conv2D(32, kernel_size=5, strides=1, padding='same', data_format='channels_last', activation=tf.nn.relu), keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'), 4.4.2.2 \u6b65\u9aa4\u5206\u6790\u4ee5\u53ca\u4ee3\u7801\u5b9e\u73b0(\u7f29\u51cf\u7248LeNet5) \u00b6 \u8bfb\u53d6\u6570\u636e\u96c6: \u4ecedatasets\u4e2d\u83b7\u53d6\u76f8\u5e94\u7684\u6570\u636e\u96c6\uff0c\u76f4\u63a5\u6709\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 \u9700\u8981\u8fdb\u884c\u5f62\u72b6\u5904\u7406\u4ee5\u53ca\u5f52\u4e00\u5316 import tensorflow as tf import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" class CNNMnist ( object ): def __init__ ( self ): ( self . train , self . train_label ), ( self . test , self . test_label ) = \\ tf . keras . datasets . cifar100 . load_data () self . train = self . train . reshape ( - 1 , 32 , 32 , 3 ) / 255.0 self . test = self . test . reshape ( - 1 , 32 , 32 , 3 ) / 255.0 \u8fdb\u884c\u6a21\u578b\u7f16\u5199 \u4e24\u5c42\u5377\u79ef\u5c42+\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\u5c42 \u7f51\u7edc\u8bbe\u8ba1\uff1a \u7b2c\u4e00\u5c42 \u5377\u79ef\uff1a32\u4e2afilter\u3001\u5927\u5c0f5*5\u3001strides=1\u3001padding=\"SAME\" \u6fc0\u6d3b\uff1aRelu \u6c60\u5316\uff1a\u5927\u5c0f2x2\u3001strides2 \u7b2c\u4e00\u5c42 \u5377\u79ef\uff1a64\u4e2afilter\u3001\u5927\u5c0f5*5\u3001strides=1\u3001padding=\"SAME\" \u6fc0\u6d3b\uff1aRelu \u6c60\u5316\uff1a\u5927\u5c0f2x2\u3001strides2 \u5168\u8fde\u63a5\u5c42 \u7ecf\u8fc7\u6bcf\u4e00\u5c42\u56fe\u7247\u6570\u636e\u5927\u5c0f\u7684\u53d8\u5316\u9700\u8981\u786e\u5b9a\uff0cCIFAR100\u8f93\u5165\u7684\u6bcf\u6279\u6b21\u82e5\u5e72\u56fe\u7247\u6570\u636e\u5927\u5c0f\u4e3a[None, 32 * 32]\uff0c\u5982\u679c\u8981\u8fdb\u8fc7\u5377\u79ef\u8ba1\u7b97\uff0c\u9700\u8981\u53d8\u6210[None, 32, 32, 3] \u7b2c\u4e00\u5c42 \u5377\u79ef\uff1a[None, 32, 32, 3]\u2014\u2014\u2014>[None, 32, 32, 32] \u6743\u91cd\u6570\u91cf\uff1a[5, 5, 1 ,32] \u504f\u7f6e\u6570\u91cf\uff1a[32] \u6fc0\u6d3b\uff1a[None, 32, 32, 32]\u2014\u2014\u2014>[None, 32, 32, 32] \u6c60\u5316\uff1a[None, 32, 32, 32]\u2014\u2014\u2014>[None, 16, 16, 32] \u7b2c\u4e8c\u5c42 \u5377\u79ef\uff1a[None, 16, 16, 32]\u2014\u2014\u2014>[None, 16, 16, 64] \u6743\u91cd\u6570\u91cf\uff1a[5, 5, 32 ,64] \u504f\u7f6e\u6570\u91cf\uff1a[64] \u6fc0\u6d3b\uff1a[None, 16, 16, 64]\u2014\u2014\u2014>[None, 16, 16, 64] \u6c60\u5316\uff1a[None, 16, 16, 64]\u2014\u2014\u2014>[None, 8, 8, 64] \u5168\u8fde\u63a5\u5c42 [None, 8, 8, 64]\u2014\u2014>[None, 8 * 8 * 64] [None, 8 * 8 * 64] x [8 * 8 * 64, 1024] = [None, 1024] [None,1024] x [1024, 100]\u2014\u2014>[None, 100] \u6743\u91cd\u6570\u91cf\uff1a[8 * 8 * 64, 1024] + [1024, 100]\uff0c\u7531\u5206\u7c7b\u522b\u6570\u800c\u5b9a \u504f\u7f6e\u6570\u91cf\uff1a[1024] + [100]\uff0c\u7531\u5206\u7c7b\u522b\u6570\u800c\u5b9a model = tf . keras . Sequential ([ tf . keras . layers . Conv2D ( 32 , kernel_size = 5 , strides = 1 , padding = 'same' , data_format = 'channels_last' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 , padding = 'same' ), tf . keras . layers . Conv2D ( 64 , kernel_size = 5 , strides = 1 , padding = 'same' , data_format = 'channels_last' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 , padding = 'same' ), tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 1024 , activation = tf . nn . relu ), tf . keras . layers . Dense ( 100 , activation = tf . nn . softmax ), ]) \u5176\u5b83\u5b8c\u6574\u4ee3\u7801 def compile ( self ): CNNMnist . model . compile ( optimizer = tf . keras . optimizers . Adam (), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ 'accuracy' ]) return None def fit ( self ): CNNMnist . model . fit ( self . train , self . train_label , epochs = 1 , batch_size = 32 ) return None def evaluate ( self ): test_loss , test_acc = CNNMnist . model . evaluate ( self . test , self . test_label ) print ( test_loss , test_acc ) return None if __name__ == '__main__' : cnn = CNNMnist () cnn . compile () cnn . fit () cnn . predict () print ( CNNMnist . model . summary ()) \u8bad\u7ec3\u6548\u679c epoch 1: ...... 43168/50000 [========================>.....] - ETA: 35s - loss: 3.6360 - acc: 0.1547 43200/50000 [========================>.....] - ETA: 35s - loss: 3.6354 - acc: 0.1547 43232/50000 [========================>.....] - ETA: 35s - loss: 3.6352 - acc: 0.1548 43264/50000 [========================>.....] - ETA: 34s - loss: 3.6348 - acc: 0.1549 43296/50000 [========================>.....] - ETA: 34s - loss: 3.6346 - acc: 0.1549 4.5.3.3 \u624b\u52a8\u4fdd\u5b58\u548c\u6062\u590d\u6a21\u578b \u00b6 1\u3001\u624b\u52a8\u4fdd\u5b58\u6743\u91cd \u00b6 Model.save_weights \u65b9\u6cd5\u624b\u52a8\u4fdd\u5b58\u5b83\u4eec\u540c\u6837\u7b80\u5355\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c tf.keras \u548c save_weights \u7279\u522b\u4f7f\u7528 TensorFlow checkpoints \u683c\u5f0f .ckpt \u6269\u5c55\u540d\u3002 \u4ee3\u7801\u5c06\u6743\u91cd\u5b58\u50a8\u5230checkpoint\u2014\u2014 \u683c\u5f0f\u5316\u6587\u4ef6\u7684\u96c6\u5408\u4e2d\uff0c\u8fd9\u4e9b\u6587\u4ef6\u4ec5\u5305\u542b\u4e8c\u8fdb\u5236\u683c\u5f0f\u7684\u8bad\u7ec3\u6743\u91cd\u3002 Checkpoints \u5305\u542b\uff1a 1\u3001\u4e00\u4e2a\u6216\u591a\u4e2a\u5305\u542b\u6a21\u578b\u6743\u91cd\u7684\u3002 2\u3001\u7d22\u5f15\u6587\u4ef6\uff0c\u6307\u793a\u54ea\u4e9b\u6743\u91cd\u5b58\u50a8\u5728\u54ea\u4e2a\u5206\u7247\u4e2d\u3002 \u5982\u679c\u4f60\u53ea\u5728\u4e00\u53f0\u673a\u5668\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u4f60\u5c06\u6709\u4e00\u4e2a\u5e26\u6709\u540e\u7f00\u7684\u788e\u7247\uff1a .data-00000-of-00001 \u53ea\u5305\u542b\u82e5\u5e72 Variables \u5bf9\u8c61\u5e8f\u5217\u5316\u540e\u7684\u6570\u636e\uff0c\u4e0d\u5305\u542b\u56fe\u7ed3\u6784\uff0c\u6240\u4ee5\u53ea\u7ed9 checkpoint \u6a21\u578b\u4e0d\u63d0\u4f9b\u4ee3\u7801\u662f\u65e0\u6cd5\u91cd\u65b0\u6784\u5efa\u8ba1\u7b97\u56fe\u7684 \u4f7f\u7528\u4ecb\u7ecd # \u4fdd\u5b58\u6743\u91cd model . save_weights ( './checkpoints/my_checkpoint' ) # \u521b\u5efa\u6a21\u578b\u5b9e\u4f8b model = create_model () # \u52a0\u8f7d\u6743\u91cd model . load_weights ( './checkpoints/my_checkpoint' ) # \u8bc4\u4f30\u6a21\u578b loss , acc = model . evaluate ( test_images , test_labels , verbose = 2 ) print ( \"Restored model, accuracy: {:5.2f}%\" . format ( 100 * acc )) \u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\u8fdb\u884c\u4fdd\u5b58 \u4fdd\u5b58\u6210ckpt\u5f62\u5f0f model.save_weights('./weights/my_model') model.load_weights('./weights/my_model') SingleNN . model . save_weights ( \"./ckpt/SingleNN\" ) def predict ( self ): # \u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u8fc7\u540e\u7684\u6743\u91cd\u6d4b\u8bd5 if os . path . exists ( \"./ckpt/checkpoint\" ): SingleNN . model . load_weights ( \"./ckpt/SingleNN\" ) predictions = SingleNN . model . predict ( self . test ) # \u5bf9\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u5904\u7406 print ( np . argmax ( predictions , 1 )) return 2\u3001\u4fdd\u5b58\u6574\u4e2a\u6a21\u578b \u00b6 \u6a21\u578b\u548c\u4f18\u5316\u5668\u53ef\u4ee5\u4fdd\u5b58\u5230\u5305\u542b\u5176\u72b6\u6001\uff08\u6743\u91cd\u548c\u53d8\u91cf\uff09\u548c\u6a21\u578b\u53c2\u6570\u7684\u6587\u4ef6\u4e2d\u3002\u8fd9\u53ef\u4ee5\u5bfc\u51fa\u6a21\u578b\uff0c\u4ee5\u4fbf\u5728\u4e0d\u8bbf\u95ee\u539f\u59cb python \u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u4f7f\u7528\u5b83\u3002\u800c\u4e14\u60a8\u53ef\u4ee5\u901a\u8fc7\u6062\u590d\u4f18\u5316\u5668\u72b6\u6001\u7684\u65b9\u5f0f\uff0c\u4ece\u4e2d\u65ad\u7684\u4f4d\u7f6e\u6062\u590d\u8bad\u7ec3\u3002 \u4fdd\u5b58\u5b8c\u6574\u6a21\u578b\u4f1a\u975e\u5e38\u6709\u7528\uff0c\u53ef\u4ee5\u5728 TensorFlow.js (HDF5, Saved Model) \u52a0\u8f7d\u4ed6\u4eec\uff0c\u7136\u540e\u5728 web \u6d4f\u89c8\u5668\u4e2d\u8bad\u7ec3\u548c\u8fd0\u884c\u5b83\u4eec\uff0c\u6216\u8005\u4f7f\u7528 TensorFlow Lite \u5c06\u5b83\u4eec\u8f6c\u6362\u4e3a\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u8fd0\u884c(HDF5, Saved Model) \u5c06\u6a21\u578b\u4fdd\u5b58\u4e3aHDF5\u6587\u4ef6 SingleNN . model . save_weights ( \"./ckpt/SingleNN.h5\" ) def predict ( self ): # \u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u8fc7\u540e\u7684\u6743\u91cd\u6d4b\u8bd5 if os . path . exists ( \"./ckpt/SingleNN.h5\" ): SingleNN . model . load_weights ( \"./ckpt/SingleNN.h5\" ) predictions = SingleNN . model . predict ( self . test ) print ( np . argmax ( predictions , 1 )) return 4.5.4 \u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807 \u00b6 \u53ef\u80fd\u4f60\u8fd8\u4f1a\u95ee\uff0c\u5982\u679c\u73b0\u6709\u7684\u8fd9\u4e9b\u5c42\u65e0\u6cd5\u6ee1\u8db3\u6211\u7684\u8981\u6c42\uff0c\u6211\u9700\u8981\u5b9a\u4e49\u81ea\u5df1\u7684\u5c42\u600e\u4e48\u529e\uff1f\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u4e0d\u4ec5\u53ef\u4ee5\u7ee7\u627f tf.keras.Model \u7f16\u5199\u81ea\u5df1\u7684\u6a21\u578b\u7c7b\uff0c\u4e5f\u53ef\u4ee5\u7ee7\u627f tf.keras.layers.Layer \u7f16\u5199\u81ea\u5df1\u7684\u5c42\u3002 4.5.4.1 \u81ea\u5b9a\u4e49\u5c42 \u00b6 \u81ea\u5b9a\u4e49\u5c42\u9700\u8981\u7ee7\u627f tf.keras.layers.Layer \u7c7b\uff0c\u5e76\u91cd\u5199 init \u3001 build \u548c call \u4e09\u4e2a\u65b9\u6cd5\uff0c\u5982\u4e0b\u6240\u793a\uff1a class MyLayer ( tf . keras . layers . Layer ): def __init__ ( self ): super () . __init__ () # \u521d\u59cb\u5316\u4ee3\u7801 def build ( self , input_shape ): # input_shape \u662f\u4e00\u4e2a TensorShape \u7c7b\u578b\u5bf9\u8c61\uff0c\u63d0\u4f9b\u8f93\u5165\u7684\u5f62\u72b6 # \u5728\u7b2c\u4e00\u6b21\u4f7f\u7528\u8be5\u5c42\u7684\u65f6\u5019\u8c03\u7528\u8be5\u90e8\u5206\u4ee3\u7801\uff0c\u5728\u8fd9\u91cc\u521b\u5efa\u53d8\u91cf\u53ef\u4ee5\u4f7f\u5f97\u53d8\u91cf\u7684\u5f62\u72b6\u81ea\u9002\u5e94\u8f93\u5165\u7684\u5f62\u72b6 # \u800c\u4e0d\u9700\u8981\u4f7f\u7528\u8005\u989d\u5916\u6307\u5b9a\u53d8\u91cf\u5f62\u72b6\u3002 # \u5982\u679c\u5df2\u7ecf\u53ef\u4ee5\u5b8c\u5168\u786e\u5b9a\u53d8\u91cf\u7684\u5f62\u72b6\uff0c\u4e5f\u53ef\u4ee5\u5728__init__\u90e8\u5206\u521b\u5efa\u53d8\u91cf self . variable_0 = self . add_weight ( ... ) self . variable_1 = self . add_weight ( ... ) def call ( self , inputs ): # \u6a21\u578b\u8c03\u7528\u7684\u4ee3\u7801\uff08\u5904\u7406\u8f93\u5165\u5e76\u8fd4\u56de\u8f93\u51fa\uff09 return output \u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u8981\u81ea\u5df1\u5b9e\u73b0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff08 tf.keras.layers.Dense\uff09\uff0c\u53ef\u4ee5\u6309\u5982\u4e0b\u65b9\u5f0f\u7f16\u5199\u3002\u6b64\u4ee3\u7801\u5728 build\u65b9\u6cd5\u4e2d\u521b\u5efa\u4e24\u4e2a\u53d8\u91cf\uff0c\u5e76\u5728 call\u65b9\u6cd5\u4e2d\u4f7f\u7528\u521b\u5efa\u7684\u53d8\u91cf\u8fdb\u884c\u8fd0\u7b97\uff1a class LinearLayer ( tf . keras . layers . Layer ): def __init__ ( self , units ): super () . __init__ () self . units = units def build ( self , input_shape ): # \u8fd9\u91cc input_shape \u662f\u7b2c\u4e00\u6b21\u8fd0\u884ccall()\u65f6\u53c2\u6570inputs\u7684\u5f62\u72b6 self . w = self . add_variable ( name = 'w' , shape = [ input_shape [ - 1 ], self . units ], initializer = tf . zeros_initializer ()) self . b = self . add_variable ( name = 'b' , shape = [ self . units ], initializer = tf . zeros_initializer ()) def call ( self , inputs ): y_pred = tf . matmul ( inputs , self . w ) + self . b return y_pred \u5728\u5b9a\u4e49\u6a21\u578b\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4fbf\u53ef\u4ee5\u5982\u540c Keras \u4e2d\u7684\u5176\u4ed6\u5c42\u4e00\u6837\uff0c\u8c03\u7528\u6211\u4eec\u81ea\u5b9a\u4e49\u7684\u5c42 LinearLayer class LinearModel ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () self . layer = LinearLayer ( units = 1 ) def call ( self , inputs ): output = self . layer ( inputs ) return output 4.5.4.2 \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807 \u00b6 \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u9700\u8981\u7ee7\u627f tf.keras.losses.Loss \u7c7b\uff0c\u91cd\u5199 call \u65b9\u6cd5\u5373\u53ef\uff0c\u8f93\u5165\u771f\u5b9e\u503c y_true \u548c\u6a21\u578b\u9884\u6d4b\u503c y_pred \uff0c\u8f93\u51fa\u6a21\u578b\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u4e4b\u95f4\u901a\u8fc7\u81ea\u5b9a\u4e49\u7684\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u51fa\u7684\u635f\u5931\u503c\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u4e3a\u5747\u65b9\u5dee\u635f\u5931\u51fd\u6570\uff1a class MeanSquaredError ( tf . keras . losses . Loss ): def call ( self , y_true , y_pred ): return tf . reduce_mean ( tf . square ( y_pred - y_true )) \u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u9700\u8981\u7ee7\u627f tf.keras.metrics.Metric \u7c7b\uff0c\u5e76\u91cd\u5199 init \u3001 update_state \u548c result \u4e09\u4e2a\u65b9\u6cd5\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u5bf9\u524d\u9762\u7528\u5230\u7684 SparseCategoricalAccuracy \u8bc4\u4f30\u6307\u6807\u7c7b\u505a\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u91cd\u5b9e\u73b0\uff1a class SparseCategoricalAccuracy ( tf . keras . metrics . Metric ): def __init__ ( self ): super () . __init__ () self . total = self . add_weight ( name = 'total' , dtype = tf . int32 , initializer = tf . zeros_initializer ()) self . count = self . add_weight ( name = 'count' , dtype = tf . int32 , initializer = tf . zeros_initializer ()) def update_state ( self , y_true , y_pred , sample_weight = None ): values = tf . cast ( tf . equal ( y_true , tf . argmax ( y_pred , axis =- 1 , output_type = tf . int32 )), tf . int32 ) self . total . assign_add ( tf . shape ( y_true )[ 0 ]) self . count . assign_add ( tf . reduce_sum ( values )) def result ( self ): return self . count / self . total 4.5.5 \u603b\u7ed3 \u00b6 keras pipline\u7684\u4f7f\u7528 keras model\u8bad\u7ec3\u9a8c\u8bc1\u65b9\u6cd5\u4f7f\u7528 keras model \u6a21\u578b\u7684\u4fdd\u5b58\u548c\u52a0\u8f7d\u65b9\u6cd5 keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528","title":"4.5 Keras Pipline\u4e0e\u81ea\u5b9a\u4e49\u6a21\u578b"},{"location":"tensorFlow/section5/#45-keras-pipline","text":"","title":"4.5 Keras Pipline\u4e0e\u81ea\u5b9a\u4e49\u6a21\u578b"},{"location":"tensorFlow/section5/#_1","text":"\u76ee\u6807 \u638c\u63e1keras pipline\u7684\u4f7f\u7528 \u638c\u63e1keras model\u8bad\u7ec3\u9a8c\u8bc1\u65b9\u6cd5\u4f7f\u7528 \u638c\u63e1keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528 \u5e94\u7528 \u65e0 \u4f7f\u7528\u4e86 Keras \u7684 Subclassing API \u5efa\u7acb\u6a21\u578b\uff0c\u5373\u5bf9 tf.keras.Model\u7c7b\u8fdb\u884c\u6269\u5c55\u4ee5\u5b9a\u4e49\u81ea\u5df1\u7684\u65b0\u6a21\u578b\uff0c\u540c\u65f6\u624b\u5de5\u7f16\u5199\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u7684\u6d41\u7a0b\u3002\u8fd9\u79cd\u65b9\u5f0f\u7075\u6d3b\u5ea6\u9ad8\uff0c\u4e14\u4e0e\u5176\u4ed6\u6d41\u884c\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff08\u5982 PyTorch\u3001Chainer\uff09\u5171\u901a\uff0c\u662f\u672c\u624b\u518c\u6240\u63a8\u8350\u7684\u65b9\u6cd5\u3002\u4e0d\u8fc7\u5728\u5f88\u591a\u65f6\u5019\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7ed3\u6784\u76f8\u5bf9\u7b80\u5355\u548c\u5178\u578b\u7684\u795e\u7ecf\u7f51\u7edc\uff08\u6bd4\u5982\u4e0a\u6587\u4e2d\u7684 MLP \u548c CNN\uff09\uff0c\u5e76\u4f7f\u7528\u5e38\u89c4\u7684\u624b\u6bb5\u8fdb\u884c\u8bad\u7ec3\u3002 Keras \u4e5f\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86\u53e6\u4e00\u5957\u66f4\u4e3a\u7b80\u5355\u9ad8\u6548\u7684\u5185\u7f6e\u65b9\u6cd5\u6765\u5efa\u7acb\u3001\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u3002","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section5/#451-keras-sequentialfunctional-api","text":"\u6700\u5178\u578b\u548c\u5e38\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u662f\u5c06\u4e00\u5806\u5c42\u6309\u7279\u5b9a\u987a\u5e8f\u53e0\u52a0\u8d77\u6765\uff0c\u90a3\u4e48\uff0c\u6211\u4eec\u662f\u4e0d\u662f\u53ea\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u7531 Keras \u5c06\u5b83\u4eec\u81ea\u52a8\u9996\u5c3e\u76f8\u8fde\uff0c\u5f62\u6210\u6a21\u578b\u5462\uff1fKeras \u7684 Sequential API \u6b63\u662f\u5982\u6b64\u3002 1\u3001tf.keras.models.Sequential() \u63d0\u4f9b\u4e00\u4e2a\u5c42\u7684\u5217\u8868\uff0c\u5c31\u80fd\u5feb\u901f\u5730\u5efa\u7acb\u4e00\u4e2a tf.keras.Model \u6a21\u578b\u5e76\u8fd4\u56de\uff1a model = tf . keras . models . Sequential ([ tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 100 , activation = tf . nn . relu ), tf . keras . layers . Dense ( 10 ), tf . keras . layers . Softmax () ]) \u4e0d\u8fc7\uff0c\u8fd9\u79cd\u5c42\u53e0\u7ed3\u6784\u5e76\u4e0d\u80fd\u8868\u793a\u4efb\u610f\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002 2\u3001\u4e3a\u6b64\uff0cKeras \u63d0\u4f9b\u4e86 Functional API\uff0c\u5e2e\u52a9\u6211\u4eec\u5efa\u7acb\u66f4\u4e3a\u590d\u6742\u7684\u6a21\u578b\uff0c\u6bd4\u5982\u8bf4\u9700\u8981**\u591a\u8f93\u5165 / \u8f93\u51fa\u6216\u5b58\u5728\u53c2\u6570\u5171\u4eab\u7684\u6a21\u578b**\u3002\u5176\u4f7f\u7528\u65b9\u6cd5\u662f\u5c06\u5c42\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u5e76\u8fd4\u56de\u5f20\u91cf\uff0c\u5e76\u5c06\u8f93\u5165\u5411\u91cf\u548c\u8f93\u51fa\u5411\u91cf\u63d0\u4f9b\u7ed9 tf.keras.Model \u7684 inputs \u548c outputs \u53c2\u6570\uff0c\u5982 inputs = tf . keras . Input ( shape = ( 28 , 28 , 1 )) x = tf . keras . layers . Flatten ()( inputs ) x = tf . keras . layers . Dense ( units = 100 , activation = tf . nn . relu )( x ) x = tf . keras . layers . Dense ( units = 10 )( x ) outputs = tf . keras . layers . Softmax ()( x ) model = tf . keras . Model ( inputs = inputs , outputs = outputs )","title":"4.5.1 Keras Sequential/Functional API \u6a21\u5f0f\u5efa\u7acb\u6a21\u578b"},{"location":"tensorFlow/section5/#452-keras-model-compile-fit-evaluate","text":"1\u3001\u901a\u8fc7\u8c03\u7528model\u7684 compile \u65b9\u6cd5\u53bb\u914d\u7f6e\u8be5\u6a21\u578b\u6240\u9700\u8981\u7684\u8bad\u7ec3\u53c2\u6570\u4ee5\u53ca\u8bc4\u4f30\u65b9\u6cd5\u3002 model.compile(optimizer,loss=None,metrics=None, \u51c6\u786e\u7387\u8861):\u914d\u7f6e\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 optimizer:\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5668(\u5728keras.optimizers) from keras.optimizers import Adadelta from keras.optimizers import Adagrad from keras.optimizers import Adam from keras.optimizers import Adamax from keras.optimizers import Nadam from keras.optimizers import Optimizer from keras.optimizers import RMSprop from keras.optimizers import SGD from keras.optimizers import deserialize from keras.optimizers import get from keras.optimizers import serialize from keras.optimizers import AdamOptimizer () loss=None:\u635f\u5931\u7c7b\u578b,\u7c7b\u578b\u53ef\u4ee5\u662f\u5b57\u7b26\u4e32\u6216\u8005\u8be5function\u540d\u5b57\u53c2\u8003\uff1a ... from keras.losses import MAE as mae from keras.losses import MAE as mean_absolute_error from keras.losses import MAPE from keras.losses import binary_crossentropy from keras.losses import categorical_crossentropy from keras.losses import serialize ... metrics=None, ['accuracy'] model . compile ( optimizer = tf . keras . optimizers . Adam (), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) \u4e24\u4e2a\u76f8\u8fd1\u7684\u533a\u522b 1\u3001sparse_categorical_crossentropy:\u5bf9\u4e8e\u76ee\u6807\u503c\u662f\u6574\u578b\u7684\u8fdb\u884c\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97 2\u3001categorical_crossentropy:\u5bf9\u4e8e\u4e24\u4e2aoutput tensor and a target tensor\u8fdb\u884c\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97 \u4f7f\u7528\u5982\u4e0b model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = 0.001 ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) 2\u3001model.fit()\uff1a\u8fdb\u884c\u8bad\u7ec3 model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size) x:\u7279\u5f81\u503c: 1 \u3001 Numpy array ( or array - like ), or a list of arrays 2 \u3001 A TensorFlow tensor , or a list of tensors 3 \u3001 `tf.data` dataset or a dataset iterator . Should return a tuple of either `(inputs, targets)` or `(inputs, targets, sample_weights)` . 4 \u3001 A generator or `keras.utils.Sequence` returning `(inputs, targets)` or `(inputs, targets, sample weights)` . y:\u76ee\u6807\u503c batch_size=None\uff1a\u6279\u6b21\u5927\u5c0f epochs=1\uff1a\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570 validation_data \uff1a\u9a8c\u8bc1\u6570\u636e\uff0c\u53ef\u7528\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76d1\u63a7\u6a21\u578b\u7684\u6027\u80fd\u3002 callbacks=None\uff1a\u6dfb\u52a0\u56de\u8c03\u5217\u8868\uff08\u7528\u4e8e\u5982tensorboard\u663e\u793a\u7b49\uff09 model . fit ( train_images , train_labels , epochs = 5 , batch_size = 32 ) 3\u3001model.evaluate(test_images, test_labels) model.evaluate(test, test_label) \u9884\u6d4bmodel.predict(test)\uff1a \u5176\u5b83\u65b9\u6cd5\uff1a model.save_weights(filepath) \u5c06\u6a21\u578b\u7684\u6743\u91cd\u4fdd\u5b58\u4e3aHDF5\u6587\u4ef6\u6216\u8005ckpt\u6587\u4ef6 model.load_weights(filepath, by_name=False) \u4eceHDF5\u6587\u4ef6\uff08\u7531\u5176\u521b\u5efa save_weights \uff09\u52a0\u8f7d\u6a21\u578b\u7684\u6743\u91cd\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u67b6\u6784\u9884\u8ba1\u4e0d\u4f1a\u66f4\u6539\u3002\u8981\u5c06\u6743\u91cd\u52a0\u8f7d\u5230\u4e0d\u540c\u7684\u4f53\u7cfb\u7ed3\u6784\uff08\u5177\u6709\u4e00\u4e9b\u5171\u540c\u7684\u5c42\uff09\uff0c\u8bf7\u4f7f\u7528 by_name=True \u4ec5\u52a0\u8f7d\u5177\u6709\u76f8\u540c\u540d\u79f0\u7684\u90a3\u4e9b\u5c42\u3002","title":"4.5.2 \u4f7f\u7528 Keras Model \u7684 compile \u3001 fit \u548c evaluate \u65b9\u6cd5\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b"},{"location":"tensorFlow/section5/#453-cifar100","text":"\u8fd9\u4e2a\u6570\u636e\u96c6\u5c31\u50cfCIFAR-10\uff0c\u9664\u4e86\u5b83\u6709100\u4e2a\u7c7b\uff0c\u6bcf\u4e2a\u7c7b\u5305\u542b600\u4e2a\u56fe\u50cf\u3002\uff0c\u6bcf\u7c7b\u5404\u6709500\u4e2a\u8bad\u7ec3\u56fe\u50cf\u548c100\u4e2a\u6d4b\u8bd5\u56fe\u50cf\u3002CIFAR-100\u4e2d\u7684100\u4e2a\u7c7b\u88ab\u5206\u621020\u4e2a\u8d85\u7c7b\u3002\u6bcf\u4e2a\u56fe\u50cf\u90fd\u5e26\u6709\u4e00\u4e2a\u201c\u7cbe\u7ec6\u201d\u6807\u7b7e\uff08\u5b83\u6240\u5c5e\u7684\u7c7b\uff09\u548c\u4e00\u4e2a\u201c\u7c97\u7cd9\u201d\u6807\u7b7e\uff08\u5b83\u6240\u5c5e\u7684\u8d85\u7c7b\uff09 \u4ee5\u4e0b\u662fCIFAR-100\u4e2d\u7684\u7c7b\u522b\u5217\u8868\uff1a \u7b49\u7b49...","title":"4.5.3 \u6848\u4f8b\uff1aCIFAR100\u6570\u636e\u96c6\u4ecb\u7ecd"},{"location":"tensorFlow/section5/#4421-api","text":"\u7528\u4e8e\u6784\u5efaCNN\u6a21\u578b\u7684API Conv2D\uff1a\u5b9e\u73b0\u5377\u79ef\uff0ckernel_size,strides,padding,dataformat,'NHWC'\u548c'NCHW' MaxPool2D\uff1a\u6c60\u5316\u64cd\u4f5c keras.layers.Conv2D(32, kernel_size=5, strides=1, padding='same', data_format='channels_last', activation=tf.nn.relu), keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'),","title":"4.4.2.1  API \u4f7f\u7528"},{"location":"tensorFlow/section5/#4422-lenet5","text":"\u8bfb\u53d6\u6570\u636e\u96c6: \u4ecedatasets\u4e2d\u83b7\u53d6\u76f8\u5e94\u7684\u6570\u636e\u96c6\uff0c\u76f4\u63a5\u6709\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 \u9700\u8981\u8fdb\u884c\u5f62\u72b6\u5904\u7406\u4ee5\u53ca\u5f52\u4e00\u5316 import tensorflow as tf import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" class CNNMnist ( object ): def __init__ ( self ): ( self . train , self . train_label ), ( self . test , self . test_label ) = \\ tf . keras . datasets . cifar100 . load_data () self . train = self . train . reshape ( - 1 , 32 , 32 , 3 ) / 255.0 self . test = self . test . reshape ( - 1 , 32 , 32 , 3 ) / 255.0 \u8fdb\u884c\u6a21\u578b\u7f16\u5199 \u4e24\u5c42\u5377\u79ef\u5c42+\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\u5c42 \u7f51\u7edc\u8bbe\u8ba1\uff1a \u7b2c\u4e00\u5c42 \u5377\u79ef\uff1a32\u4e2afilter\u3001\u5927\u5c0f5*5\u3001strides=1\u3001padding=\"SAME\" \u6fc0\u6d3b\uff1aRelu \u6c60\u5316\uff1a\u5927\u5c0f2x2\u3001strides2 \u7b2c\u4e00\u5c42 \u5377\u79ef\uff1a64\u4e2afilter\u3001\u5927\u5c0f5*5\u3001strides=1\u3001padding=\"SAME\" \u6fc0\u6d3b\uff1aRelu \u6c60\u5316\uff1a\u5927\u5c0f2x2\u3001strides2 \u5168\u8fde\u63a5\u5c42 \u7ecf\u8fc7\u6bcf\u4e00\u5c42\u56fe\u7247\u6570\u636e\u5927\u5c0f\u7684\u53d8\u5316\u9700\u8981\u786e\u5b9a\uff0cCIFAR100\u8f93\u5165\u7684\u6bcf\u6279\u6b21\u82e5\u5e72\u56fe\u7247\u6570\u636e\u5927\u5c0f\u4e3a[None, 32 * 32]\uff0c\u5982\u679c\u8981\u8fdb\u8fc7\u5377\u79ef\u8ba1\u7b97\uff0c\u9700\u8981\u53d8\u6210[None, 32, 32, 3] \u7b2c\u4e00\u5c42 \u5377\u79ef\uff1a[None, 32, 32, 3]\u2014\u2014\u2014>[None, 32, 32, 32] \u6743\u91cd\u6570\u91cf\uff1a[5, 5, 1 ,32] \u504f\u7f6e\u6570\u91cf\uff1a[32] \u6fc0\u6d3b\uff1a[None, 32, 32, 32]\u2014\u2014\u2014>[None, 32, 32, 32] \u6c60\u5316\uff1a[None, 32, 32, 32]\u2014\u2014\u2014>[None, 16, 16, 32] \u7b2c\u4e8c\u5c42 \u5377\u79ef\uff1a[None, 16, 16, 32]\u2014\u2014\u2014>[None, 16, 16, 64] \u6743\u91cd\u6570\u91cf\uff1a[5, 5, 32 ,64] \u504f\u7f6e\u6570\u91cf\uff1a[64] \u6fc0\u6d3b\uff1a[None, 16, 16, 64]\u2014\u2014\u2014>[None, 16, 16, 64] \u6c60\u5316\uff1a[None, 16, 16, 64]\u2014\u2014\u2014>[None, 8, 8, 64] \u5168\u8fde\u63a5\u5c42 [None, 8, 8, 64]\u2014\u2014>[None, 8 * 8 * 64] [None, 8 * 8 * 64] x [8 * 8 * 64, 1024] = [None, 1024] [None,1024] x [1024, 100]\u2014\u2014>[None, 100] \u6743\u91cd\u6570\u91cf\uff1a[8 * 8 * 64, 1024] + [1024, 100]\uff0c\u7531\u5206\u7c7b\u522b\u6570\u800c\u5b9a \u504f\u7f6e\u6570\u91cf\uff1a[1024] + [100]\uff0c\u7531\u5206\u7c7b\u522b\u6570\u800c\u5b9a model = tf . keras . Sequential ([ tf . keras . layers . Conv2D ( 32 , kernel_size = 5 , strides = 1 , padding = 'same' , data_format = 'channels_last' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 , padding = 'same' ), tf . keras . layers . Conv2D ( 64 , kernel_size = 5 , strides = 1 , padding = 'same' , data_format = 'channels_last' , activation = tf . nn . relu ), tf . keras . layers . MaxPool2D ( pool_size = 2 , strides = 2 , padding = 'same' ), tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 1024 , activation = tf . nn . relu ), tf . keras . layers . Dense ( 100 , activation = tf . nn . softmax ), ]) \u5176\u5b83\u5b8c\u6574\u4ee3\u7801 def compile ( self ): CNNMnist . model . compile ( optimizer = tf . keras . optimizers . Adam (), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ 'accuracy' ]) return None def fit ( self ): CNNMnist . model . fit ( self . train , self . train_label , epochs = 1 , batch_size = 32 ) return None def evaluate ( self ): test_loss , test_acc = CNNMnist . model . evaluate ( self . test , self . test_label ) print ( test_loss , test_acc ) return None if __name__ == '__main__' : cnn = CNNMnist () cnn . compile () cnn . fit () cnn . predict () print ( CNNMnist . model . summary ()) \u8bad\u7ec3\u6548\u679c epoch 1: ...... 43168/50000 [========================>.....] - ETA: 35s - loss: 3.6360 - acc: 0.1547 43200/50000 [========================>.....] - ETA: 35s - loss: 3.6354 - acc: 0.1547 43232/50000 [========================>.....] - ETA: 35s - loss: 3.6352 - acc: 0.1548 43264/50000 [========================>.....] - ETA: 34s - loss: 3.6348 - acc: 0.1549 43296/50000 [========================>.....] - ETA: 34s - loss: 3.6346 - acc: 0.1549","title":"4.4.2.2 \u6b65\u9aa4\u5206\u6790\u4ee5\u53ca\u4ee3\u7801\u5b9e\u73b0(\u7f29\u51cf\u7248LeNet5)"},{"location":"tensorFlow/section5/#4533","text":"","title":"4.5.3.3 \u624b\u52a8\u4fdd\u5b58\u548c\u6062\u590d\u6a21\u578b"},{"location":"tensorFlow/section5/#1","text":"Model.save_weights \u65b9\u6cd5\u624b\u52a8\u4fdd\u5b58\u5b83\u4eec\u540c\u6837\u7b80\u5355\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c tf.keras \u548c save_weights \u7279\u522b\u4f7f\u7528 TensorFlow checkpoints \u683c\u5f0f .ckpt \u6269\u5c55\u540d\u3002 \u4ee3\u7801\u5c06\u6743\u91cd\u5b58\u50a8\u5230checkpoint\u2014\u2014 \u683c\u5f0f\u5316\u6587\u4ef6\u7684\u96c6\u5408\u4e2d\uff0c\u8fd9\u4e9b\u6587\u4ef6\u4ec5\u5305\u542b\u4e8c\u8fdb\u5236\u683c\u5f0f\u7684\u8bad\u7ec3\u6743\u91cd\u3002 Checkpoints \u5305\u542b\uff1a 1\u3001\u4e00\u4e2a\u6216\u591a\u4e2a\u5305\u542b\u6a21\u578b\u6743\u91cd\u7684\u3002 2\u3001\u7d22\u5f15\u6587\u4ef6\uff0c\u6307\u793a\u54ea\u4e9b\u6743\u91cd\u5b58\u50a8\u5728\u54ea\u4e2a\u5206\u7247\u4e2d\u3002 \u5982\u679c\u4f60\u53ea\u5728\u4e00\u53f0\u673a\u5668\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u4f60\u5c06\u6709\u4e00\u4e2a\u5e26\u6709\u540e\u7f00\u7684\u788e\u7247\uff1a .data-00000-of-00001 \u53ea\u5305\u542b\u82e5\u5e72 Variables \u5bf9\u8c61\u5e8f\u5217\u5316\u540e\u7684\u6570\u636e\uff0c\u4e0d\u5305\u542b\u56fe\u7ed3\u6784\uff0c\u6240\u4ee5\u53ea\u7ed9 checkpoint \u6a21\u578b\u4e0d\u63d0\u4f9b\u4ee3\u7801\u662f\u65e0\u6cd5\u91cd\u65b0\u6784\u5efa\u8ba1\u7b97\u56fe\u7684 \u4f7f\u7528\u4ecb\u7ecd # \u4fdd\u5b58\u6743\u91cd model . save_weights ( './checkpoints/my_checkpoint' ) # \u521b\u5efa\u6a21\u578b\u5b9e\u4f8b model = create_model () # \u52a0\u8f7d\u6743\u91cd model . load_weights ( './checkpoints/my_checkpoint' ) # \u8bc4\u4f30\u6a21\u578b loss , acc = model . evaluate ( test_images , test_labels , verbose = 2 ) print ( \"Restored model, accuracy: {:5.2f}%\" . format ( 100 * acc )) \u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\u8fdb\u884c\u4fdd\u5b58 \u4fdd\u5b58\u6210ckpt\u5f62\u5f0f model.save_weights('./weights/my_model') model.load_weights('./weights/my_model') SingleNN . model . save_weights ( \"./ckpt/SingleNN\" ) def predict ( self ): # \u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u8fc7\u540e\u7684\u6743\u91cd\u6d4b\u8bd5 if os . path . exists ( \"./ckpt/checkpoint\" ): SingleNN . model . load_weights ( \"./ckpt/SingleNN\" ) predictions = SingleNN . model . predict ( self . test ) # \u5bf9\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u5904\u7406 print ( np . argmax ( predictions , 1 )) return","title":"1\u3001\u624b\u52a8\u4fdd\u5b58\u6743\u91cd"},{"location":"tensorFlow/section5/#2","text":"\u6a21\u578b\u548c\u4f18\u5316\u5668\u53ef\u4ee5\u4fdd\u5b58\u5230\u5305\u542b\u5176\u72b6\u6001\uff08\u6743\u91cd\u548c\u53d8\u91cf\uff09\u548c\u6a21\u578b\u53c2\u6570\u7684\u6587\u4ef6\u4e2d\u3002\u8fd9\u53ef\u4ee5\u5bfc\u51fa\u6a21\u578b\uff0c\u4ee5\u4fbf\u5728\u4e0d\u8bbf\u95ee\u539f\u59cb python \u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u4f7f\u7528\u5b83\u3002\u800c\u4e14\u60a8\u53ef\u4ee5\u901a\u8fc7\u6062\u590d\u4f18\u5316\u5668\u72b6\u6001\u7684\u65b9\u5f0f\uff0c\u4ece\u4e2d\u65ad\u7684\u4f4d\u7f6e\u6062\u590d\u8bad\u7ec3\u3002 \u4fdd\u5b58\u5b8c\u6574\u6a21\u578b\u4f1a\u975e\u5e38\u6709\u7528\uff0c\u53ef\u4ee5\u5728 TensorFlow.js (HDF5, Saved Model) \u52a0\u8f7d\u4ed6\u4eec\uff0c\u7136\u540e\u5728 web \u6d4f\u89c8\u5668\u4e2d\u8bad\u7ec3\u548c\u8fd0\u884c\u5b83\u4eec\uff0c\u6216\u8005\u4f7f\u7528 TensorFlow Lite \u5c06\u5b83\u4eec\u8f6c\u6362\u4e3a\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u8fd0\u884c(HDF5, Saved Model) \u5c06\u6a21\u578b\u4fdd\u5b58\u4e3aHDF5\u6587\u4ef6 SingleNN . model . save_weights ( \"./ckpt/SingleNN.h5\" ) def predict ( self ): # \u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u8fc7\u540e\u7684\u6743\u91cd\u6d4b\u8bd5 if os . path . exists ( \"./ckpt/SingleNN.h5\" ): SingleNN . model . load_weights ( \"./ckpt/SingleNN.h5\" ) predictions = SingleNN . model . predict ( self . test ) print ( np . argmax ( predictions , 1 )) return","title":"2\u3001\u4fdd\u5b58\u6574\u4e2a\u6a21\u578b"},{"location":"tensorFlow/section5/#454","text":"\u53ef\u80fd\u4f60\u8fd8\u4f1a\u95ee\uff0c\u5982\u679c\u73b0\u6709\u7684\u8fd9\u4e9b\u5c42\u65e0\u6cd5\u6ee1\u8db3\u6211\u7684\u8981\u6c42\uff0c\u6211\u9700\u8981\u5b9a\u4e49\u81ea\u5df1\u7684\u5c42\u600e\u4e48\u529e\uff1f\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u4e0d\u4ec5\u53ef\u4ee5\u7ee7\u627f tf.keras.Model \u7f16\u5199\u81ea\u5df1\u7684\u6a21\u578b\u7c7b\uff0c\u4e5f\u53ef\u4ee5\u7ee7\u627f tf.keras.layers.Layer \u7f16\u5199\u81ea\u5df1\u7684\u5c42\u3002","title":"4.5.4 \u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807"},{"location":"tensorFlow/section5/#4541","text":"\u81ea\u5b9a\u4e49\u5c42\u9700\u8981\u7ee7\u627f tf.keras.layers.Layer \u7c7b\uff0c\u5e76\u91cd\u5199 init \u3001 build \u548c call \u4e09\u4e2a\u65b9\u6cd5\uff0c\u5982\u4e0b\u6240\u793a\uff1a class MyLayer ( tf . keras . layers . Layer ): def __init__ ( self ): super () . __init__ () # \u521d\u59cb\u5316\u4ee3\u7801 def build ( self , input_shape ): # input_shape \u662f\u4e00\u4e2a TensorShape \u7c7b\u578b\u5bf9\u8c61\uff0c\u63d0\u4f9b\u8f93\u5165\u7684\u5f62\u72b6 # \u5728\u7b2c\u4e00\u6b21\u4f7f\u7528\u8be5\u5c42\u7684\u65f6\u5019\u8c03\u7528\u8be5\u90e8\u5206\u4ee3\u7801\uff0c\u5728\u8fd9\u91cc\u521b\u5efa\u53d8\u91cf\u53ef\u4ee5\u4f7f\u5f97\u53d8\u91cf\u7684\u5f62\u72b6\u81ea\u9002\u5e94\u8f93\u5165\u7684\u5f62\u72b6 # \u800c\u4e0d\u9700\u8981\u4f7f\u7528\u8005\u989d\u5916\u6307\u5b9a\u53d8\u91cf\u5f62\u72b6\u3002 # \u5982\u679c\u5df2\u7ecf\u53ef\u4ee5\u5b8c\u5168\u786e\u5b9a\u53d8\u91cf\u7684\u5f62\u72b6\uff0c\u4e5f\u53ef\u4ee5\u5728__init__\u90e8\u5206\u521b\u5efa\u53d8\u91cf self . variable_0 = self . add_weight ( ... ) self . variable_1 = self . add_weight ( ... ) def call ( self , inputs ): # \u6a21\u578b\u8c03\u7528\u7684\u4ee3\u7801\uff08\u5904\u7406\u8f93\u5165\u5e76\u8fd4\u56de\u8f93\u51fa\uff09 return output \u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u8981\u81ea\u5df1\u5b9e\u73b0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff08 tf.keras.layers.Dense\uff09\uff0c\u53ef\u4ee5\u6309\u5982\u4e0b\u65b9\u5f0f\u7f16\u5199\u3002\u6b64\u4ee3\u7801\u5728 build\u65b9\u6cd5\u4e2d\u521b\u5efa\u4e24\u4e2a\u53d8\u91cf\uff0c\u5e76\u5728 call\u65b9\u6cd5\u4e2d\u4f7f\u7528\u521b\u5efa\u7684\u53d8\u91cf\u8fdb\u884c\u8fd0\u7b97\uff1a class LinearLayer ( tf . keras . layers . Layer ): def __init__ ( self , units ): super () . __init__ () self . units = units def build ( self , input_shape ): # \u8fd9\u91cc input_shape \u662f\u7b2c\u4e00\u6b21\u8fd0\u884ccall()\u65f6\u53c2\u6570inputs\u7684\u5f62\u72b6 self . w = self . add_variable ( name = 'w' , shape = [ input_shape [ - 1 ], self . units ], initializer = tf . zeros_initializer ()) self . b = self . add_variable ( name = 'b' , shape = [ self . units ], initializer = tf . zeros_initializer ()) def call ( self , inputs ): y_pred = tf . matmul ( inputs , self . w ) + self . b return y_pred \u5728\u5b9a\u4e49\u6a21\u578b\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4fbf\u53ef\u4ee5\u5982\u540c Keras \u4e2d\u7684\u5176\u4ed6\u5c42\u4e00\u6837\uff0c\u8c03\u7528\u6211\u4eec\u81ea\u5b9a\u4e49\u7684\u5c42 LinearLayer class LinearModel ( tf . keras . Model ): def __init__ ( self ): super () . __init__ () self . layer = LinearLayer ( units = 1 ) def call ( self , inputs ): output = self . layer ( inputs ) return output","title":"4.5.4.1 \u81ea\u5b9a\u4e49\u5c42"},{"location":"tensorFlow/section5/#4542","text":"\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u9700\u8981\u7ee7\u627f tf.keras.losses.Loss \u7c7b\uff0c\u91cd\u5199 call \u65b9\u6cd5\u5373\u53ef\uff0c\u8f93\u5165\u771f\u5b9e\u503c y_true \u548c\u6a21\u578b\u9884\u6d4b\u503c y_pred \uff0c\u8f93\u51fa\u6a21\u578b\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u4e4b\u95f4\u901a\u8fc7\u81ea\u5b9a\u4e49\u7684\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u51fa\u7684\u635f\u5931\u503c\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u4e3a\u5747\u65b9\u5dee\u635f\u5931\u51fd\u6570\uff1a class MeanSquaredError ( tf . keras . losses . Loss ): def call ( self , y_true , y_pred ): return tf . reduce_mean ( tf . square ( y_pred - y_true )) \u81ea\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u9700\u8981\u7ee7\u627f tf.keras.metrics.Metric \u7c7b\uff0c\u5e76\u91cd\u5199 init \u3001 update_state \u548c result \u4e09\u4e2a\u65b9\u6cd5\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u5bf9\u524d\u9762\u7528\u5230\u7684 SparseCategoricalAccuracy \u8bc4\u4f30\u6307\u6807\u7c7b\u505a\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u91cd\u5b9e\u73b0\uff1a class SparseCategoricalAccuracy ( tf . keras . metrics . Metric ): def __init__ ( self ): super () . __init__ () self . total = self . add_weight ( name = 'total' , dtype = tf . int32 , initializer = tf . zeros_initializer ()) self . count = self . add_weight ( name = 'count' , dtype = tf . int32 , initializer = tf . zeros_initializer ()) def update_state ( self , y_true , y_pred , sample_weight = None ): values = tf . cast ( tf . equal ( y_true , tf . argmax ( y_pred , axis =- 1 , output_type = tf . int32 )), tf . int32 ) self . total . assign_add ( tf . shape ( y_true )[ 0 ]) self . count . assign_add ( tf . reduce_sum ( values )) def result ( self ): return self . count / self . total","title":"4.5.4.2 \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807"},{"location":"tensorFlow/section5/#455","text":"keras pipline\u7684\u4f7f\u7528 keras model\u8bad\u7ec3\u9a8c\u8bc1\u65b9\u6cd5\u4f7f\u7528 keras model \u6a21\u578b\u7684\u4fdd\u5b58\u548c\u52a0\u8f7d\u65b9\u6cd5 keras\u81ea\u5b9a\u4e49\u5c42\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u7684\u4f7f\u7528","title":"4.5.5 \u603b\u7ed3"},{"location":"tensorFlow/section6/","text":"4.6 TF\u5e38\u7528\u529f\u80fd\u6a21\u5757 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1Checkpoint\u4f7f\u7528 \u638c\u63e1TensorBoard\u4f7f\u7528 \u638c\u63e1data\u6a21\u5757\u4f7f\u7528 \u638c\u63e1ImageDataGenerator\u7684\u4f7f\u7528 \u5e94\u7528 \u65e0 4.6.1 fit\u7684callbacks\u8be6\u89e3 \u00b6 \u56de\u8c03\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7ed9\u5b9a\u9636\u6bb5\u5e94\u7528\u7684\u4e00\u7ec4\u51fd\u6570\u3002\u53ef\u4ee5\u4f7f\u7528\u56de\u8c03\u6765\u83b7\u53d6\u57f9\u8bad\u671f\u95f4\u5185\u90e8\u72b6\u6001\u548c\u6a21\u578b\u7edf\u8ba1\u4fe1\u606f\u7684\u89c6\u56fe\u3002\u60a8\u53ef\u4ee5\u5c06\u56de\u8c03\u5217\u8868\uff08\u4f5c\u4e3a\u5173\u952e\u5b57\u53c2\u6570 callbacks \uff09\u4f20\u9012\u7ed9\u6216\u7c7b\u7684 fit() \u65b9\u6cd5\u3002\u7136\u540e\u5c06\u5728\u8bad\u7ec3\u7684\u6bcf\u4e2a\u9636\u6bb5\u8c03\u7528\u56de\u8c03\u7684\u76f8\u5173\u65b9\u6cd5\u3002 \u5b9a\u5236\u5316\u4fdd\u5b58\u6a21\u578b \u4fdd\u5b58events\u6587\u4ef6 4.6.1.1 ModelCheckpoint \u00b6 from tensorflow.python.keras.callbacks import ModelCheckpoint keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', save_best_only=False, save_weights_only=False, mode='auto', period=1) Save the model after every epoch\uff1a\u6bcf\u9694\u591a\u5c11\u6b21\u8fed\u4ee3\u4fdd\u5b58\u6a21\u578b filepath: \u4fdd\u5b58\u6a21\u578b\u5b57\u7b26\u4e32 \u5982\u679c\u8bbe\u7f6e weights.{epoch:02d}-{val_loss:.2f}.hdf5\u683c\u5f0f\uff0c\u5c06\u4f1a\u6bcf\u9694epoch number\u6570\u91cf\u5e76\u4e14\u5c06\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\u4fdd\u5b58\u5728\u8be5\u4f4d\u7f6e \u5982\u679c\u8bbe\u7f6eweights.{epoch:02d}-{val_acc:.2f}.hdf5\uff0c\u5c06\u4f1a\u6309\u7167val_acc\u7684\u503c\u8fdb\u884c\u4fdd\u5b58\u6a21\u578b monitor: quantity to monitor.\u8bbe\u7f6e\u4e3a'val_acc'\u6216\u8005'val_loss' save_best_only: if save_best_only=True, \u53ea\u4fdd\u7559\u6bd4\u4e0a\u6b21\u6a21\u578b\u66f4\u597d\u7684\u7ed3\u679c save_weights_only: if True, \u53ea\u4fdd\u5b58\u53bb\u90a3\u79cd(model.save_weights(filepath)), else the full model is saved (model.save(filepath)). mode: one of {auto, min, max}. \u5982\u679csave_best_only=True, \u5bf9\u4e8eval_acc, \u8981\u8bbe\u7f6emax, \u5bf9\u4e8eval_loss\u8981\u8bbe\u7f6emin period: \u8fed\u4ee3\u4fdd\u5b58checkpoints\u7684\u95f4\u9694 check = ModelCheckpoint ( './ckpt/singlenn_{epoch:02d}-{val_acc:.2f}.h5' , monitor = 'val_acc' , save_best_only = True , save_weights_only = True , mode = 'auto' , period = 1 ) SingleNN . model . fit ( self . train , self . train_label , epochs = 5 , callbacks = [ check ], validation_data = ( x , y )) \u6ce8\u610f\uff1a 1\u3001\u4f7f\u7528ModelCheckpoint\u4e00\u5b9a\u8981\u5728fit\u5f53\u4e2d\u6307\u5b9a\u9a8c\u8bc1\u96c6\u624d\u80fd\u4f7f\u7528\uff0c\u5426\u5219\u62a5\u9519\u8bef\u3002 2\u3001\u5176\u4e2dval_acc\u8fd8\u662fval_accuracy\u9700\u8981\u5728\u8fd9\u91cc\u6307\u5b9a model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy']) model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc']) 4.6.1.2 Tensorboard \u00b6 \u6dfb\u52a0Tensorboard\u89c2\u5bdf\u635f\u5931\u7b49\u60c5\u51b5 keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch') log_dir:\u4fdd\u5b58\u4e8b\u4ef6\u6587\u4ef6\u76ee\u5f55 write_graph=True\uff1a\u662f\u5426\u663e\u793a\u56fe\u7ed3\u6784 write_images=False\uff1a\u662f\u5426\u663e\u793a\u56fe\u7247 write_grads=True:\u662f\u5426\u663e\u793a\u68af\u5ea6 histogram_freq \u5fc5\u987b\u5927\u4e8e0 # \u6dfb\u52a0tensoboard\u89c2\u5bdf tensorboard = keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) SingleNN . model . fit ( self . train , self . train_label , epochs = 5 , callbacks = [ tensorboard ]) \u6253\u5f00\u7ec8\u7aef\u67e5\u770b\uff1a # \u6307\u5b9a\u5b58\u5728\u6587\u4ef6\u7684\u76ee\u5f55\uff0c\u6253\u5f00\u4e0b\u9762\u547d\u4ee4 tensorboard --logdir=\"./\" \u8fd9\u662fCNN mnist100\u6848\u4f8b\u4e2d\u7684\u6548\u679c\uff1a 1\u3001\u635f\u5931\u548c\u51c6\u786e\u7387 2\u3001\u56fe\u7ed3\u6784\u663e\u793a\uff1a 3\u3001\u6743\u91cd\u53c2\u6570\u663e\u793a 4.6.2 tf.data \uff1a\u6570\u636e\u96c6\u7684\u6784\u5efa\u4e0e\u9884\u5904\u7406 \u00b6 \u95ee\u9898\u5f15\u5165\uff1a \u5728\u5927\u90e8\u5206\u65f6\u5019\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u81ea\u5df1\u7684\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u6a21\u578b\u3002\u7136\u800c\uff0c\u9762\u5bf9\u4e00\u5806\u683c\u5f0f\u4e0d\u4e00\u7684\u539f\u59cb\u6570\u636e\u6587\u4ef6\uff0c\u5c06\u5176\u9884\u5904\u7406\u5e76\u8bfb\u5165\u7a0b\u5e8f\u7684\u8fc7\u7a0b\u5f80\u5f80\u5341\u5206\u7e41\u7410\uff0c\u751a\u81f3\u6bd4\u6a21\u578b\u7684\u8bbe\u8ba1\u8fd8\u8981\u8017\u8d39\u7cbe\u529b\u3002\u6bd4\u5982\uff0c\u4e3a\u4e86\u8bfb\u5165\u4e00\u6279\u56fe\u50cf\u6587\u4ef6\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\u7ea0\u7ed3\u4e8e python \u7684\u5404\u79cd\u56fe\u50cf\u5904\u7406\u5305\uff08\u6bd4\u5982 pillow \uff09\uff0c\u81ea\u5df1\u8bbe\u8ba1 Batch \u7684\u751f\u6210\u65b9\u5f0f\uff0c\u6700\u540e\u8fd8\u53ef\u80fd\u5728\u8fd0\u884c\u7684\u6548\u7387\u4e0a\u4e0d\u5c3d\u5982\u4eba\u610f\u3002\u4e3a\u6b64\uff0cTensorFlow \u63d0\u4f9b\u4e86 tf.data \u8fd9\u4e00\u6a21\u5757\uff0c\u5305\u62ec\u4e86\u4e00\u5957\u7075\u6d3b\u7684\u6570\u636e\u96c6\u6784\u5efa API\uff0c\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u5feb\u901f\u3001\u9ad8\u6548\u5730\u6784\u5efa\u6570\u636e\u8f93\u5165\u7684\u6d41\u6c34\u7ebf\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6570\u636e\u91cf\u5de8\u5927\u7684\u573a\u666f\u3002 4.6.2.1 \u6570\u636e\u96c6\u5bf9\u8c61\u7684\u5efa\u7acb \u00b6 tf.data \u7684\u6838\u5fc3\u662f tf.data.Dataset \u7c7b\uff0c\u63d0\u4f9b\u4e86\u5bf9\u6570\u636e\u96c6\u7684\u9ad8\u5c42\u5c01\u88c5\u3002 **tf.data.Dataset \u7531\u4e00\u7cfb\u5217\u7684\u53ef\u8fed\u4ee3\u8bbf\u95ee\u7684\u5143\u7d20\uff08element\uff09\u7ec4\u6210\uff0c\u6bcf\u4e2a\u5143\u7d20\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u5f20\u91cf\u3002**\u6bd4\u5982\u8bf4\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u7531\u56fe\u50cf\u7ec4\u6210\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u5143\u7d20\u53ef\u4ee5\u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a \u957f\u00d7\u5bbd\u00d7\u901a\u9053\u6570 \u7684\u56fe\u7247\u5f20\u91cf\uff0c\u4e5f\u53ef\u4ee5\u662f\u7531\u56fe\u7247\u5f20\u91cf\u548c\u56fe\u7247\u6807\u7b7e\u5f20\u91cf\u7ec4\u6210\u7684\u5143\u7ec4\uff08Tuple\uff09\u3002 1\u3001tf.data.Dataset.from_tensor_slices() \u00b6 \u6700\u57fa\u7840\u7684\u5efa\u7acb tf.data.Dataset \u7684\u65b9\u6cd5\u662f\u4f7f\u7528 tf.data.Dataset.from_tensor_slices() \uff0c\u9002\u7528\u4e8e\u6570\u636e\u91cf\u8f83\u5c0f\uff08\u80fd\u591f\u6574\u4e2a\u88c5\u8fdb\u5185\u5b58\uff09\u7684\u60c5\u51b5\u3002 import tensorflow as tf import numpy as np X = tf . constant ([ 2015 , 2016 , 2017 , 2018 , 2019 ]) Y = tf . constant ([ 12000 , 14000 , 15000 , 16500 , 17500 ]) # \u4e5f\u53ef\u4ee5\u4f7f\u7528NumPy\u6570\u7ec4\uff0c\u6548\u679c\u76f8\u540c # X = np.array([2015, 2016, 2017, 2018, 2019]) # Y = np.array([12000, 14000, 15000, 16500, 17500]) dataset = tf . data . Dataset . from_tensor_slices (( X , Y )) for x , y in dataset : print ( x . numpy (), y . numpy ()) \u8f93\u51fa 2013 12000 2014 14000 2015 15000 2016 16500 2017 17500 \u540c\u6837\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u53ef\u4ee5\u8f7d\u5165\u524d\u7ae0\u7684 MNIST \u6570\u636e\u96c6\uff1a import matplotlib.pyplot as plt ( train_data , train_label ), ( _ , _ ) = tf . keras . datasets . mnist . load_data () # [60000, 28, 28, 1] train_data = np . expand_dims ( train_data . astype ( np . float32 ) / 255.0 , axis =- 1 ) mnist_dataset = tf . data . Dataset . from_tensor_slices (( train_data , train_label )) for image , label in mnist_dataset : print ( label . numpy ()) print ( image . numpy ()) 4.6.2.2 \u6570\u636e\u96c6\u5bf9\u8c61\u7684\u9884\u5904\u7406 \u00b6 tf.data.Dataset \u7c7b\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u591a\u79cd\u6570\u636e\u96c6\u9884\u5904\u7406\u65b9\u6cd5\u3002\u6700\u5e38\u7528\u7684\u5982\uff1a 1\u3001Dataset.map(f) \uff1a \u5bf9\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u5e94\u7528\u51fd\u6570 f \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\uff08\u8fd9\u90e8\u5206\u5f80\u5f80\u7ed3\u5408 tf.io \u8fdb\u884c\u8bfb\u5199\u548c\u89e3\u7801\u6587\u4ef6\uff0c tf.image \u8fdb\u884c\u56fe\u50cf\u5904\u7406\uff09\uff1b 2\u3001Dataset.shuffle(buffer_size) \uff1a \u5c06\u6570\u636e\u96c6\u6253\u4e71\uff08\u8bbe\u5b9a\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u7f13\u51b2\u533a\uff08Buffer\uff09\uff0c\u53d6\u51fa\u524d buffer_size \u4e2a\u5143\u7d20\u653e\u5165\uff0c\u5e76\u4ece\u7f13\u51b2\u533a\u4e2d\u968f\u673a\u91c7\u6837\uff0c\u91c7\u6837\u540e\u7684\u6570\u636e\u7528\u540e\u7eed\u6570\u636e\u66ff\u6362\uff09\uff1b 3\u3001Dataset.batch(batch_size) \uff1a \u5c06\u6570\u636e\u96c6\u5206\u6210\u6279\u6b21\uff0c\u5373\u5bf9\u6bcf batch_size \u4e2a\u5143\u7d20\uff0c\u4f7f\u7528 tf.stack() \u5728\u7b2c 0 \u7ef4\u5408\u5e76\uff0c\u6210\u4e3a\u4e00\u4e2a\u5143\u7d20\u3002 4\u3001Dataset.prefetch() \uff1a \u9884\u53d6\u51fa\u6570\u636e\u96c6\u4e2d\u7684\u82e5\u5e72\u4e2a\u5143\u7d20 5\u3001\u9664\u6b64\u4ee5\u5916\uff0c\u8fd8\u6709 Dataset.repeat() \uff08\u91cd\u590d\u6570\u636e\u96c6\u7684\u5143\u7d20\uff09\u3001 Dataset.reduce() \uff08\u4e0e Map \u76f8\u5bf9\u7684\u805a\u5408\u64cd\u4f5c\uff09\u3001 Dataset.take ()\u7b49\uff0c\u53ef\u53c2\u8003 API \u6587\u6863 \u8fdb\u4e00\u6b65\u4e86\u89e3\u3002 4.6.4.3 \u4f7f\u7528\u6848\u4f8b \u00b6 1\u3001\u4f7f\u7528 Dataset.map() \u5c06\u6240\u6709\u56fe\u7247\u65cb\u8f6c 90 \u5ea6\uff1a def rot90 ( image , label ): image = tf . image . rot90 ( image ) return image , label mnist_dataset = mnist_dataset . map ( rot90 ) for image , label in mnist_dataset : plt . title ( label . numpy ()) plt . imshow ( image . numpy ()[:, :, 0 ]) plt . show () 2\u3001\u4f7f\u7528 Dataset.batch() \u5c06\u6570\u636e\u96c6\u5212\u5206\u6279\u6b21\uff0c\u6bcf\u4e2a\u6279\u6b21\u7684\u5927\u5c0f\u4e3a 4\uff1a # \u83b7\u53d6\u6279\u6b21\u6570\u636e mnist_dataset = mnist_dataset . batch ( 4 ) for images , labels in mnist_dataset : fig , axs = plt . subplots ( 1 , 4 ) for i in range ( 4 ): axs [ i ] . set_title ( labels . numpy ()[ i ]) axs [ i ] . imshow ( images . numpy ()[ i , :, :, 0 ]) plt . show () 3\u3001\u4f7f\u7528 Dataset.shuffle() \u5c06\u6570\u636e\u6253\u6563\u540e\u518d\u8bbe\u7f6e\u6279\u6b21\uff0c\u7f13\u5b58\u5927\u5c0f\u8bbe\u7f6e\u4e3a 10000 \u8bbe\u5b9a\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u4e3a buffer_size \u7684\u7f13\u51b2\u533a\uff08Buffer\uff09\uff1b\u521d\u59cb\u5316\u65f6\uff0c\u53d6\u51fa\u6570\u636e\u96c6\u4e2d\u7684\u524d buffer_size \u4e2a\u5143\u7d20\u653e\u5165\u7f13\u51b2\u533a\uff1b \u6bcf\u6b21\u9700\u8981\u4ece\u6570\u636e\u96c6\u4e2d\u53d6\u5143\u7d20\u65f6\uff0c\u5373\u4ece\u7f13\u51b2\u533a\u4e2d\u968f\u673a\u91c7\u6837\u4e00\u4e2a\u5143\u7d20\u5e76\u53d6\u51fa\uff0c\u7136\u540e\u4ece\u540e\u7eed\u7684\u5143\u7d20\u4e2d\u53d6\u51fa\u4e00\u4e2a\u653e\u56de\u5230\u4e4b\u524d\u88ab\u53d6\u51fa\u7684\u4f4d\u7f6e\uff0c\u4ee5\u7ef4\u6301\u7f13\u51b2\u533a\u7684\u5927\u5c0f\u3002 mnist_dataset = mnist_dataset . shuffle ( buffer_size = 10000 ) . batch ( 4 ) for images , labels in mnist_dataset : fig , axs = plt . subplots ( 1 , 4 ) for i in range ( 4 ): axs [ i ] . set_title ( labels . numpy ()[ i ]) axs [ i ] . imshow ( images . numpy ()[ i , :, :, 0 ]) plt . show () \u6ce8\uff1aDataset.shuffle() \u65f6\u7f13\u51b2\u533a\u5927\u5c0f buffer_size \u7684\u8bbe\u7f6e\uff0c\u6bcf\u6b21\u7684\u6570\u636e\u90fd\u4f1a\u88ab\u968f\u673a\u6253\u6563\u3002\u5f53 buffer_size \u8bbe\u7f6e\u4e3a 1 \u65f6\uff0c\u5176\u5b9e\u7b49\u4ef7\u4e8e\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u6253\u6563\u3002 \u5f53\u6570\u636e\u96c6\u7684\u6807\u7b7e\u987a\u5e8f\u5206\u5e03\u6781\u4e3a\u4e0d\u5747\u5300\uff08\u4f8b\u5982\u4e8c\u5143\u5206\u7c7b\u65f6\u6570\u636e\u96c6\u524d N \u4e2a\u7684\u6807\u7b7e\u4e3a 0\uff0c\u540e N \u4e2a\u7684\u6807\u7b7e\u4e3a 1\uff09\u65f6\uff0c\u8f83\u5c0f\u7684\u7f13\u51b2\u533a\u5927\u5c0f\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u65f6\u53d6\u51fa\u7684 Batch \u6570\u636e\u5f88\u53ef\u80fd\u5168\u4e3a\u540c\u4e00\u6807\u7b7e\uff0c\u4ece\u800c\u5f71\u54cd\u8bad\u7ec3\u6548\u679c\u3002\u4e00\u822c\u800c\u8a00\uff0c\u6570\u636e\u96c6\u7684\u987a\u5e8f\u5206\u5e03\u82e5\u8f83\u4e3a\u968f\u673a\uff0c\u5219\u7f13\u51b2\u533a\u7684\u5927\u5c0f\u53ef\u8f83\u5c0f\uff0c\u5426\u5219\u5219\u9700\u8981\u8bbe\u7f6e\u8f83\u5927\u7684\u7f13\u51b2\u533a\u3002 4.6.4.3 \u6570\u636e\u96c6\u5143\u7d20\u7684\u83b7\u53d6\u4e0e\u4f7f\u7528 \u00b6 1\u3001\u6784\u5efa\u597d\u6570\u636e\u5e76\u9884\u5904\u7406\u540e\uff0c\u6211\u4eec\u9700\u8981\u4ece\u5176\u4e2d\u8fed\u4ee3\u83b7\u53d6\u6570\u636e\u4ee5\u7528\u4e8e\u8bad\u7ec3\u3002tf.data.Dataset \u662f\u4e00\u4e2a Python \u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528 For \u5faa\u73af\u8fed\u4ee3\u83b7\u53d6\u6570\u636e\uff0c\u5373\uff1a dataset = tf . data . Dataset . from_tensor_slices (( A , B , C , ... )) for a , b , c , ... in dataset : # \u5bf9\u5f20\u91cfa, b, c\u7b49\u8fdb\u884c\u64cd\u4f5c\uff0c\u4f8b\u5982\u9001\u5165\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3 2\u3001\u53ef\u4ee5\u4f7f\u7528 iter() \u663e\u5f0f\u521b\u5efa\u4e00\u4e2a Python \u8fed\u4ee3\u5668\u5e76\u4f7f\u7528 next() \u83b7\u53d6\u4e0b\u4e00\u4e2a\u5143\u7d20\uff0c\u5373\uff1a dataset = tf . data . Dataset . from_tensor_slices (( A , B , C , ... )) it = iter ( dataset ) a_0 , b_0 , c_0 , ... = next ( it ) a_1 , b_1 , c_1 , ... = next ( it ) 3\u3001Keras \u652f\u6301\u4f7f\u7528 tf.data.Dataset \u76f4\u63a5\u4f5c\u4e3a\u8f93\u5165\u3002\u5f53\u8c03\u7528 tf.keras.Model \u7684 fit() \u548c evaluate() \u65b9\u6cd5\u65f6\uff0c\u53ef\u4ee5\u5c06\u53c2\u6570\u4e2d\u7684\u8f93\u5165\u6570\u636e x \u6307\u5b9a\u4e3a\u4e00\u4e2a\u5143\u7d20\u683c\u5f0f\u4e3a (\u8f93\u5165\u6570\u636e, \u6807\u7b7e\u6570\u636e) \u7684 Dataset \uff0c\u5e76\u5ffd\u7565\u6389\u53c2\u6570\u4e2d\u7684\u6807\u7b7e\u6570\u636e y \u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u4e0a\u8ff0\u7684 MNIST \u6570\u636e\u96c6\uff0c\u5e38\u89c4\u7684 Keras \u8bad\u7ec3\u65b9\u5f0f\u662f\uff1a model . fit ( x = train_data , y = train_label , epochs = num_epochs , batch_size = batch_size ) \u4f7f\u7528 tf.data.Dataset \u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f20\u5165 Dataset \uff1a model . fit ( mnist_dataset , epochs = num_epochs ) \u5982\u679c\u5df2\u7ecf\u901a\u8fc7 Dataset.batch() \u65b9\u6cd5\u5212\u5206\u4e86\u6570\u636e\u96c6\u7684\u6279\u6b21\uff0c\u6240\u4ee5\u8fd9\u91ccfit\u4e2d\u4e5f\u65e0\u9700\u63d0\u4f9b\u6279\u6b21\u7684\u5927\u5c0f\u3002 4.6.4.4 \u4f7f\u7528tf.data\u7684\u5e76\u884c\u5316\u7b56\u7565\u63d0\u9ad8\u8bad\u7ec3\u6d41\u7a0b\u6548\u7387 \u00b6 \u5f53\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u6211\u4eec\u5e0c\u671b\u5145\u5206\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\uff0c\u51cf\u5c11 CPU/GPU \u7684\u7a7a\u8f7d\u65f6\u95f4\u3002\u7136\u800c\u6709\u65f6\uff0c\u6570\u636e\u96c6\u7684\u51c6\u5907\u5904\u7406\u975e\u5e38\u8017\u65f6\uff0c\u4f7f\u5f97\u6211\u4eec\u5728\u6bcf\u8fdb\u884c\u4e00\u6b21\u8bad\u7ec3\u524d\u90fd\u9700\u8981\u82b1\u8d39\u5927\u91cf\u7684\u65f6\u95f4\u51c6\u5907\u5f85\u8bad\u7ec3\u7684\u6570\u636e\uff0c\u800c\u6b64\u65f6 GPU \u53ea\u80fd\u7a7a\u8f7d\u800c\u7b49\u5f85\u6570\u636e\uff0c\u9020\u6210\u4e86\u8ba1\u7b97\u8d44\u6e90\u7684\u6d6a\u8d39\u3002 tf.data \u7684\u6570\u636e\u96c6\u5bf9\u8c61\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86 Dataset.prefetch() \u65b9\u6cd5\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u8ba9\u6570\u636e\u96c6\u5bf9\u8c61 Dataset \u5728\u8bad\u7ec3\u65f6\u9884\u53d6\u51fa\u82e5\u5e72\u4e2a\u5143\u7d20\uff0c\u4f7f\u5f97\u5728 GPU \u8bad\u7ec3\u7684\u540c\u65f6 CPU \u53ef\u4ee5\u51c6\u5907\u6570\u636e\uff0c\u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u6d41\u7a0b\u7684\u6548\u7387 \u4f7f\u7528\uff1a mnist_dataset = mnist_dataset . prefetch ( buffer_size = tf . data . experimental . AUTOTUNE ) \u53c2\u6570 buffer_size \u65e2\u53ef\u624b\u5de5\u8bbe\u7f6e\uff0c\u4e5f\u53ef\u8bbe\u7f6e\u4e3a tf.data.experimental.AUTOTUNE \u4ece\u800c\u7531 TensorFlow \u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u6570\u503c\u3002 2\u3001\u8fd8\u6709\u4e00\u79cd\u65b9\u5f0f\u4e5f\u80fd\u591f\u63d0\u9ad8\u5229\u7528CPU\u8d44\u6e90 Dataset.map() \u4e5f\u53ef\u4ee5\u5229\u7528\u591a GPU \u8d44\u6e90\uff0c\u5e76\u884c\u5316\u5730\u5bf9\u6570\u636e\u9879\u8fdb\u884c\u53d8\u6362\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002 \u901a\u8fc7\u8bbe\u7f6e Dataset.map() \u7684 num_parallel_calls \u53c2\u6570\u5b9e\u73b0\u6570\u636e\u8f6c\u6362\u7684\u5e76\u884c\u5316\u3002\u4e0a\u9762\u7684\u662f\u672a\u5e76\u884c\u5316\u7684\u56fe\u793a\uff0c\u4e0b\u9762\u662f\u4e24\u6838\u5e76\u884c\u7684\u56fe\u793a\uff0c\u65f6\u95f4\u4f1a\u7f29\u5c0f # \u6dfb\u52a0\u53c2\u6570\u4f7f\u7528\uff0cnum_parallel_calls \u8bbe\u7f6e\u4e3a tf.data.experimental.AUTOTUNE \u4ee5\u8ba9 TensorFlow \u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u6570\u503c train_dataset = train_dataset . map ( map_func = _decode_and_resize , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \u901a\u8fc7 prefetch() \u7684\u4f7f\u7528\u548c\u5728 map() \u8fc7\u7a0b\u4e2d\u52a0\u5165 num_parallel_calls \u53c2\u6570\uff0c\u6a21\u578b\u8bad\u7ec3\u7684\u65f6\u95f4\u53ef\u7f29\u51cf\u81f3\u539f\u6765\u7684\u4e00\u534a\u751a\u81f3\u66f4\u4f4e\u3002 \u6ce8\uff1a\u7eb5\u8f74\u4e3a\u6bcf epoch \u8bad\u7ec3\u6240\u9700\u65f6\u95f4\uff0c\u5355\u4f4d\uff1a\u79d2 4.6.5 \u6848\u4f8b\uff1a\u5b9e\u73b0\u732b\u72d7\u56fe\u50cf\u5206\u7c7b \u00b6 \u6570\u636e\u96c6\u6765\u81ea kaggle \u4e0a\u7684\u4e00\u4e2a\u7ade\u8d5b\uff1a Dogs vs. Cats \uff0c\u8bad\u7ec3\u96c6\u670925000\u5f20\uff0c\u732b\u72d7\u5404\u5360\u4e00\u534a\u3002\u6d4b\u8bd5\u96c612500\u5f20\uff0c\u6ca1\u6709\u6807\u5b9a\u662f\u732b\u8fd8\u662f\u72d7\u3002 \u76ee\u7684\uff1a\u732b\u72d7\u56fe\u7247\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e3a\u793a\u4f8b \u4f7f\u7528 tf.data \u7ed3\u5408 tf.io \u548c tf.image \u5efa\u7acbDataset \u6570\u636e\u96c6 \u6570\u636e\u96c6\u53ef\u53d6\u8fd9\u91cc\u4e0b\u8f7d\uff1a https://www.floydhub.com/fastai/datasets/cats-vs-dogs \u6b65\u9aa4\uff1a 1\u3001\u6570\u636e\u96c6\u7684\u83b7\u53d6\u548c\u6784\u5efa 2\u3001\u6a21\u578b\u6784\u5efa\u548c\u5c01\u88c5 3\u3001\u8bad\u7ec3\u4ee5\u53ca\u6d4b\u8bd5\u8fc7\u7a0b\u5b9e\u73b0 1\u3001\u6570\u636e\u96c6\u7684\u83b7\u53d6\u548c\u6784\u5efa class CatOrDog ( object ): \"\"\"\u732b\u72d7\u5206\u7c7b \"\"\" num_epochs = 1 batch_size = 32 learning_rate = 0.001 # \u8bad\u7ec3\u76ee\u5f55 train_cats_dir = '/root/cv_project/tf_example/cats_vs_dogs/train/cats/' train_dogs_dir = '/root/cv_project/tf_example/cats_vs_dogs/train/dogs/' # \u9a8c\u8bc1\u76ee\u5f55 test_cats_dir = '/root/cv_project/tf_example/cats_vs_dogs/valid/cats/' test_dogs_dir = '/root/cv_project/tf_example/cats_vs_dogs/valid/dogs/' def __init__ ( self ): # 1\u3001\u8bfb\u53d6\u8bad\u7ec3\u96c6\u7684\u732b\u72d7\u6587\u4ef6 self . train_cat_filenames = tf . constant ([ CatOrDog . train_cats_dir + filename for filename in os . listdir ( CatOrDog . train_cats_dir )]) self . train_dog_filenames = tf . constant ([ CatOrDog . train_dogs_dir + filename for filename in os . listdir ( CatOrDog . train_dogs_dir )]) # 2\u3001\u732b\u72d7\u6587\u4ef6\u5217\u8868\u5408\u5e76\uff0c\u5e76\u4e14\u521d\u59cb\u5316\u732b\u72d7\u7684\u76ee\u6807\u503c\uff0c0\u4e3a\u732b\uff0c1\u4e3a\u72d7 self . train_filenames = tf . concat ([ self . train_cat_filenames , self . train_dog_filenames ], axis =- 1 ) self . train_labels = tf . concat ([ tf . zeros ( self . train_cat_filenames . shape , dtype = tf . int32 ), tf . ones ( self . train_dog_filenames . shape , dtype = tf . int32 )], axis =- 1 ) \u5b9a\u4e49\u6570\u636e\u7684\u83b7\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7tf.data\u6307\u5b9a def get_batch ( self ): \"\"\"\u83b7\u53d6dataset\u6279\u6b21\u6570\u636e :return: \"\"\" train_dataset = tf . data . Dataset . from_tensor_slices (( self . train_filenames , self . train_labels )) # \u8fdb\u884c\u6570\u636e\u7684map, \u968f\u673a\uff0c\u6279\u6b21\u548c\u9884\u5b58\u50a8 train_dataset = train_dataset . map ( map_func = _decode_and_resize , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_dataset = train_dataset . shuffle ( buffer_size = 20000 ) train_dataset = train_dataset . batch ( CatOrDog . batch_size ) train_dataset = train_dataset . prefetch ( tf . data . experimental . AUTOTUNE ) return train_dataset # \u56fe\u7247\u5904\u7406\u51fd\u6570\uff0c\u8bfb\u53d6\uff0c\u89e3\u7801\u5e76\u4e14\u8fdb\u884c\u8f93\u5165\u5f62\u72b6\u4fee\u6539 def _decode_and_resize ( filename , label ): image_string = tf . io . read_file ( filename ) image_decoded = tf . image . decode_jpeg ( image_string ) image_resized = tf . image . resize ( image_decoded , [ 256 , 256 ]) / 255.0 return image_resized , label 2\u3001\u6a21\u578b\u6784\u5efa\u548c\u5c01\u88c5 \u901a\u8fc7\u6784\u9020\u4e24\u5c42\u5377\u79ef+\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u7684\u7f51\u7edc self . model = tf . keras . Sequential ([ tf . keras . layers . Conv2D ( 32 , 3 , activation = 'relu' , input_shape = ( 256 , 256 , 3 )), tf . keras . layers . MaxPooling2D (), tf . keras . layers . Conv2D ( 32 , 5 , activation = 'relu' ), tf . keras . layers . MaxPooling2D (), tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 64 , activation = 'relu' ), tf . keras . layers . Dense ( 2 , activation = 'softmax' ) ]) 3\u3001\u8bad\u7ec3\u4ee5\u53ca\u6d4b\u8bd5\u8fc7\u7a0b\u5b9e\u73b0 \u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b,\u8fd9\u91cc\u5c31\u514d\u53bb\u6307\u5b9ackpt\u4ee5\u53catensorboard\u7684callbacks\u4e86\uff0c\u53ef\u4ee5\u81ea\u5df1\u53bb\u6307\u5b9a\u5b9e\u9a8c def train ( self , train_dataset ): \"\"\"\u8bad\u7ec3\u8fc7\u7a0b :return: \"\"\" self . model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = CatOrDog . learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) self . model . fit ( train_dataset , epochs = CatOrDog . num_epochs ) self . model . save_weights ( \"./ckpt/cat_or_dogs.h5\" ) \u6d4b\u8bd5\u8fc7\u7a0b 1\u3001\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u8bfb\u53d6\u6d4b\u8bd5\u6570\u636e\u53ca\u7684dataset\u6570\u636e\u96c6 2\u3001\u8fdb\u884cmodel\u7684\u9884\u6d4b\uff0c\u53ef\u4ee5\u5148\u8fdb\u884c\u6a21\u578b\u4fdd\u5b58\u4e4b\u540e\uff0c\u518d\u6b21\u8bfb\u53d6\u8fdb\u884c\u9884\u6d4b def test ( self ): # 1\u3001\u6784\u5efa\u6d4b\u8bd5\u6570\u636e\u96c6 test_cat_filenames = tf . constant ([ CatOrDog . test_cats_dir + filename for filename in os . listdir ( CatOrDog . test_cats_dir )]) test_dog_filenames = tf . constant ([ CatOrDog . test_dogs_dir + filename for filename in os . listdir ( CatOrDog . test_dogs_dir )]) test_filenames = tf . concat ([ test_cat_filenames , test_dog_filenames ], axis =- 1 ) test_labels = tf . concat ([ tf . zeros ( test_cat_filenames . shape , dtype = tf . int32 ), tf . ones ( test_dog_filenames . shape , dtype = tf . int32 )], axis =- 1 ) # 2\u3001\u6784\u5efadataset test_dataset = tf . data . Dataset . from_tensor_slices (( test_filenames , test_labels )) test_dataset = test_dataset . map ( _decode_and_resize ) test_dataset = test_dataset . batch ( batch_size ) # 3\u3001\u52a0\u8f7d\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30 if os . path . exists ( \"./ckpt/cat_or_dogs.h5\" ): self . model . load_weights ( \"./ckpt/cat_or_dogs.h5\" ) print ( self . model . metrics_names ) print ( self . model . evaluate ( test_dataset )) 4.6.6 ImageDataGenerator\u4ecb\u7ecd \u00b6 \u5f53\u6211\u4eec\u9700\u8981\u505a\u6570\u636e\u589e\u5f3a\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u901a\u8fc7\u5b9e\u65f6\u6570\u636e\u589e\u5f3a\u751f\u6210\u5f20\u91cf\u56fe\u50cf\u6570\u636e\u6279\u6b21\u3002\u6570\u636e\u5c06\u4e0d\u65ad\u5faa\u73af\uff08\u6309\u6279\u6b21\uff09\u3002\u4e0b\u9762\u5c31\u4ecb\u7ecd\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5bf9\u4e8e\u63d0\u4f9b\u8fc7\u6765\u7684\u672c\u5730\u56fe\u7247\u8bfb\u53d6\u7684\u6570\u636e\u8fd8\u662f\u5176\u4ed6\u5de5\u5177\u8bfb\u53d6\u7684\u56fe\u7247\u6570\u636e\u8fdb\u884c\u5728\u7ebf\u6570\u636e\u600e\u5f3a\u3002 1\u3001\u8bad\u7ec3\u7684\u65f6\u5019\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u4ee5\u53ca\u7c7b\u522b \u00b6 tf . keras . preprocessing . image . ImageDataGenerator ( featurewise_center = False , samplewise_center = False , featurewise_std_normalization = False , samplewise_std_normalization = False , zca_whitening = False , zca_epsilon = 1e-06 , rotation_range = 0 , width_shift_range = 0.0 , height_shift_range = 0.0 , brightness_range = None , shear_range = 0.0 , zoom_range = 0.0 , channel_shift_range = 0.0 , fill_mode = 'nearest' , cval = 0.0 , horizontal_flip = False , vertical_flip = False , rescale = None , preprocessing_function = None , data_format = None , validation_split = 0.0 , dtype = None ) \u5b8c\u6574\u53c2\u6570\u4ecb\u7ecd\u53c2\u8003TensorFlow\u5b98\u7f51\u6587\u6863\uff1a https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#view-aliases train_generator = ImageDataGenerator() \u751f\u4ea7\u56fe\u7247\u7684\u6279\u6b21\u5f20\u91cf\u503c\u5e76\u4e14\u63d0\u4f9b\u6570\u636e\u589e\u5f3a\u529f\u80fd rescale=1.0 / 255,:\u6807\u51c6\u5316 zca_whitening=False: # zca\u767d\u5316\u7684\u4f5c\u7528\u662f\u9488\u5bf9\u56fe\u7247\u8fdb\u884cPCA\u964d\u7ef4\u64cd\u4f5c\uff0c\u51cf\u5c11\u56fe\u7247\u7684\u5197\u4f59\u4fe1\u606f rotation_range=20:\u9ed8\u8ba40\uff0c \u65cb\u8f6c\u89d2\u5ea6\uff0c\u5728\u8fd9\u4e2a\u89d2\u5ea6\u8303\u56f4\u968f\u673a\u751f\u6210\u4e00\u4e2a\u503c width_shift_range=0.2,:\u9ed8\u8ba40\uff0c\u6c34\u5e73\u5e73\u79fb height_shift_range=0.2:\u9ed8\u8ba40\uff0c \u5782\u76f4\u5e73\u79fb shear_range=0.2:# \u5e73\u79fb\u53d8\u6362 horizontal_flip=True:\u6c34\u5e73\u7ffb\u8f6c zoom_range:\u968f\u673a\u7f29\u653e\u7684\u8303\u56f4 2\u3001\u4f7f\u7528\u65b9\u6cd5\u4ecb\u7ecd \u00b6 \u4f7f\u7528flow(x, y, batch_size) ( x_train , y_train ), ( x_test , y_test ) = cifar10 . load_data () datagen = ImageDataGenerator ( featurewise_center = True , featurewise_std_normalization = True , rotation_range = 20 , width_shift_range = 0.2 , height_shift_range = 0.2 , horizontal_flip = True ) for e in range ( epochs ): print ( 'Epoch' , e ) batches = 0 for x_batch , y_batch in datagen . flow ( x_train , y_train , batch_size = 32 ): model . fit ( x_batch , y_batch ) \u4f7f\u7528train_generator.flow_from_directory( directory=path,# \u8bfb\u53d6\u76ee\u5f55 target_size=(h,w),# \u76ee\u6807\u5f62\u72b6 batch_size=size,# \u6279\u6570\u91cf\u5927\u5c0f class_mode='binary', # \u76ee\u6807\u503c\u683c\u5f0f\uff0cOne of \"categorical\", \"binary\", \"sparse\", \"categorical\" \uff1a2D one-hot encoded labels \"binary\" will be 1D binary labels shuffle=True \u8fd9\u4e2aAPI\u56fa\u5b9a\u4e86\u8bfb\u53d6\u7684\u76ee\u5f55\u683c\u5f0f\uff0c\u53c2\u8003\uff1a python data/ train/ dogs/ dog001.jpg dog002.jpg ... cats/ cat001.jpg cat002.jpg ... validation/ dogs/ dog001.jpg dog002.jpg ... cats/ cat001.jpg cat002.jpg ... 4.6.7 \u6848\u4f8b\uff1aImageDataGenerator\u4e0e\u8fc1\u79fb\u5b66\u4e60\u7ed3\u5408\uff08\u57fa\u4e8eVGG\uff09 \u00b6 4.6.7.1 \u6848\u4f8b\u6548\u679c \u00b6 Epoch 1 / 2 1 / 13 [ =>............................ ] - ETA : 3 : 20 - loss : 1.6811 - acc : 0.1562 2 / 13 [ ===>.......................... ] - ETA : 3 : 01 - loss : 1.5769 - acc : 0.2500 3 / 13 [ =====>........................ ] - ETA : 2 : 44 - loss : 1.4728 - acc : 0.3958 4 / 13 [ ========>..................... ] - ETA : 2 : 27 - loss : 1.3843 - acc : 0.4531 5 / 13 [ ==========>................... ] - ETA : 2 : 14 - loss : 1.3045 - acc : 0.4938 6 / 13 [ ============>................. ] - ETA : 1 : 58 - loss : 1.2557 - acc : 0.5156 7 / 13 [ ===============>.............. ] - ETA : 1 : 33 - loss : 1.1790 - acc : 0.5759 8 / 13 [ =================>............ ] - ETA : 1 : 18 - loss : 1.1153 - acc : 0.6211 9 / 13 [ ===================>.......... ] - ETA : 1 : 02 - loss : 1.0567 - acc : 0.6562 10 / 13 [ ======================>....... ] - ETA : 46 s - loss : 1.0043 - acc : 0.6875 11 / 13 [ ========================>..... ] - ETA : 31 s - loss : 0.9580 - acc : 0.7159 12 / 13 [ ==========================>... ] - ETA : 15 s - loss : 0.9146 - acc : 0.7344 13 / 13 [ ============================== ] - 249 s 19 s / step - loss : 0.8743 - acc : 0.7519 - val_loss : 0.3906 - val_acc : 0.9000 Epoch 2 / 2 1 / 13 [ =>............................ ] - ETA : 2 : 56 - loss : 0.3862 - acc : 1.0000 2 / 13 [ ===>.......................... ] - ETA : 2 : 44 - loss : 0.3019 - acc : 1.0000 3 / 13 [ =====>........................ ] - ETA : 2 : 35 - loss : 0.2613 - acc : 1.0000 4 / 13 [ ========>..................... ] - ETA : 2 : 01 - loss : 0.2419 - acc : 0.9844 5 / 13 [ ==========>................... ] - ETA : 1 : 49 - loss : 0.2644 - acc : 0.9688 6 / 13 [ ============>................. ] - ETA : 1 : 36 - loss : 0.2494 - acc : 0.9688 7 / 13 [ ===============>.............. ] - ETA : 1 : 24 - loss : 0.2362 - acc : 0.9732 8 / 13 [ =================>............ ] - ETA : 1 : 10 - loss : 0.2234 - acc : 0.9766 9 / 13 [ ===================>.......... ] - ETA : 58 s - loss : 0.2154 - acc : 0.9757 10 / 13 [ ======================>....... ] - ETA : 44 s - loss : 0.2062 - acc : 0.9781 11 / 13 [ ========================>..... ] - ETA : 29 s - loss : 0.2007 - acc : 0.9801 12 / 13 [ ==========================>... ] - ETA : 14 s - loss : 0.1990 - acc : 0.9792 13 / 13 [ ============================== ] - 243 s 19 s / step - loss : 0.1923 - acc : 0.9809 - val_loss : 0.1929 - val_acc : 0.9300 4.6.7.2 \u6570\u636e\u96c6\u4ee5\u53ca\u8fc1\u79fb\u9700\u6c42 \u00b6 \u6570\u636e\u96c6\u662f\u67d0\u573a\u666f\u4e0b5\u4e2a\u7c7b\u522b\u56fe\u7247\u7684\u8bc6\u522b \u6211\u4eec\u5229\u7528\u73b0\u6709\u7684VGG\u6a21\u578b\u53bb\u8fdb\u884c\u5fae\u8c03 4.6.7.3 \u601d\u8def\u548c\u6b65\u9aa4 \u00b6 \u8bfb\u53d6\u672c\u5730\u7684\u56fe\u7247\u6570\u636e\u4ee5\u53ca\u7c7b\u522b keras.preprocessing.image import ImageDataGenerator\u63d0\u4f9b\u4e86\u8bfb\u53d6\u8f6c\u6362\u529f\u80fd \u6a21\u578b\u7684\u7ed3\u6784\u4fee\u6539\uff08\u6dfb\u52a0\u6211\u4eec\u81ea\u5b9a\u7684\u5206\u7c7b\u5c42\uff09 freeze\u6389\u539f\u59cbVGG\u6a21\u578b \u7f16\u8bd1\u4ee5\u53ca\u8bad\u7ec3\u548c\u4fdd\u5b58\u6a21\u578b\u65b9\u5f0f \u8f93\u5165\u6570\u636e\u8fdb\u884c\u9884\u6d4b 4.6.7.4 \u8bad\u7ec3\u7684\u65f6\u5019\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u4ee5\u53ca\u7c7b\u522b \u00b6 \u57fa\u4e8e\u4e0a\u9762\u5de5\u5177\u7684\u8bfb\u53d6\u4ee3\u7801 train_datagen = ImageDataGenerator ( rescale = 1. / 255 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( 'data/train' , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( 'data/validation' , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) # \u4f7f\u7528fit_generator model . fit_generator ( train_generator , steps_per_epoch = 2000 , epochs = 50 , validation_data = validation_generator , validation_steps = 800 ) \u4ee3\u7801\uff1a \u9996\u5148\u5bfc\u5165\u5305 import tensorflow as tf from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.applications.vgg16 import VGG16 import numpy as np import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" \u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u8fc1\u79fb\u5b66\u4e60\u7684\u7c7b\uff0c\u7136\u540e\u8fdb\u884c\u76f8\u5173\u5c5e\u6027\u8bbe\u7f6e\u548c\u8bfb\u53d6\u4ee3\u7801 class TransferModel ( object ): def __init__ ( self ): # \u5b9a\u4e49\u8bad\u7ec3\u548c\u6d4b\u8bd5\u56fe\u7247\u7684\u53d8\u5316\u65b9\u6cd5\uff0c\u6807\u51c6\u5316\u4ee5\u53ca\u6570\u636e\u589e\u5f3a self . train_generator = ImageDataGenerator ( rescale = 1.0 / 255.0 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ) self . test_generator = ImageDataGenerator ( rescale = 1.0 / 255.0 ) # \u6307\u5b9a\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u76ee\u5f55 self . train_dir = \"./data/train\" self . test_dir = \"./data/test\" # \u5b9a\u4e49\u56fe\u7247\u8bad\u7ec3\u76f8\u5173\u7f51\u7edc\u53c2\u6570 self . image_size = ( 224 , 224 ) self . batch_size = 32 def read_img_to_generator ( self ): \"\"\" \u8bfb\u53d6\u672c\u5730\u56fe\u7247\u4ee5\u53ca\u7c7b\u522b :return:\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u8fed\u4ee3\u5668 \"\"\" train_gen = self . train_generator . flow_from_directory ( directory = self . train_dir , target_size = self . model_size , batch_size = self . batch_size , class_mode = 'binary' , shuffle = True ) test_gen = self . test_generator . flow_from_directory ( directory = self . test_dir , target_size = self . model_size , batch_size = self . batch_size , class_mode = 'binary' , shuffle = True ) return train_gen , test_gen \u6253\u5370\u7ed3\u679c\u4e3a < keras_preprocessing . image . DirectoryIterator object at 0x12f52cf28 > 4.6.7.5 VGG\u6a21\u578b\u7684\u4fee\u6539\u6dfb\u52a0\u5168\u8fde\u63a5\u5c42-GlobalAveragePooling2D \u00b6 notop\u6a21\u578b\uff1a \u662f\u5426\u5305\u542b\u6700\u540e\u76843\u4e2a\u5168\u8fde\u63a5\u5c42\uff08whether to include the 3 fully-connected layers at the top of the network\uff09\u3002\u7528\u6765\u505afine-tuning\u4e13\u7528\uff0c\u4e13\u95e8\u5f00\u6e90\u4e86\u8fd9\u7c7b\u6a21\u578b\u3002 \u2018weights='imagenet'\u2019\uff0c\u610f\u601d\u662fVGG\u5728imagenet\u6bd4\u8d5b\u4e2d\u9884\u8bad\u7ec3\u7684\u6743\u91cd\uff0c\u4f7f\u7528resnet\u8bad\u7ec3 # \u5728__init__\u4e2d\u6dfb\u52a0 self . base_model = VGG16 ( weights = 'imagenet' , include_top = False ) base_model\u4f1a\u6709\u76f8\u5173\u5c5e\u6027\uff0c\u6a21\u578b\u7684\u8f93\u5165\u7ed3\u6784\uff1ainputs\uff0c\u6a21\u578b\u7684\u8f93\u51fa\u7ed3\u6784\uff0c\u6211\u4eec\u4fee\u6539\u9700\u8981\u5f97\u5230\u5df2\u6709VGG\u7684\u8f93\u5165\u548c\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u51fa\u6784\u5efa\u6210\u4e00\u4e2a\u65b0\u7684\u6a21\u578b\u3002 \u6a21\u578b\u6e90\u7801\uff1a if include_top : # Classification block x = layers . Flatten ( name = 'flatten' )( x ) x = layers . Dense ( 4096 , activation = 'relu' , name = 'fc1' )( x ) x = layers . Dense ( 4096 , activation = 'relu' , name = 'fc2' )( x ) x = layers . Dense ( classes , activation = 'softmax' , name = 'predictions' )( x ) else : if pooling == 'avg' : x = layers . GlobalAveragePooling2D ()( x ) elif pooling == 'max' : x = layers . GlobalMaxPooling2D ()( x ) \u4e00\u4e2aGlobalAveragePooling2D + \u4e24\u4e2a\u5168\u8fde\u63a5\u5c42 \u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u7ecf\u8fc7\u6700\u540eCNN\u5c42\u540e\u7684\u5c3a\u5bf8\u4e3a[bath_size, img_width, img_height, channels]\uff0c\u901a\u5e38\u7684\u505a\u6cd5\u662f\uff1a\u63a5\u4e00\u4e2aflatten layer\uff0c\u5c06\u5c3a\u5bf8\u53d8\u4e3a[batch_size, w * h * channels]\u518d\u81f3\u5c11\u63a5\u4e00\u4e2aFC layer\uff0c\u8fd9\u6837\u505a\u7684\u6700\u5927\u95ee\u9898\u662f\uff1a \u6a21\u578b\u53c2\u6570\u591a\uff0c\u4e14\u5bb9\u6613\u8fc7\u62df\u5408\u3002 \u5229\u7528pooling layer\u6765\u66ff\u4ee3\u6700\u540e\u7684FC layer \u89e3\u91ca\u5982\u4e0b\uff1a from keras.layers import Dense , Input , Conv2D from keras.layers import MaxPooling2D , GlobalAveragePooling2D x = Input ( shape = [ 8 , 8 , 2048 ]) # \u5047\u5b9a\u6700\u540e\u4e00\u5c42CNN\u7684\u5c42\u8f93\u51fa\u4e3a(None, 8, 8, 2048) x = GlobalAveragePooling2D ( name = 'avg_pool' )( x ) # shape=(?, 2048) # \u53d6\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5e73\u5747\u503c\u4f5c\u4e3a\u8f93\u51fa\uff0c\u7528\u4ee5\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42 x = Dense ( 1000 , activation = 'softmax' , name = 'predictions' )( x ) # shape=(?, 1000) # 1000\u4e3a\u7c7b\u522b 5\u7c7b\u56fe\u7247\u8bc6\u522b\u6a21\u578b\u4fee\u6539 \u6211\u4eec\u9700\u8981\u62ff\u5230\u57fa\u7840VGG\u6a21\u578b\uff0c\u5e76\u4e14VGG\u63d0\u4f9b\u6240\u6709\u5c42\u53c2\u6570\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u548c\u6ca1\u6709\u5168\u8fde\u63a5\u5c42\u53c2\u6570\u7684\u6a21\u578bnotop\u6a21\u578b from tensorflow.keras import Model def refine_base_model ( self ): \"\"\" \u5fae\u8c03VGG\u7ed3\u6784\uff0c5blocks\u540e\u9762+\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff08\u51cf\u5c11\u8fc1\u79fb\u5b66\u4e60\u7684\u53c2\u6570\u6570\u91cf\uff09+\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42 :return: \"\"\" # 1\u3001\u83b7\u53d6\u539fnotop\u6a21\u578b\u5f97\u51fa # [?, ?, ?, 512] x = self . base_model . outputs [ 0 ] # 2\u3001\u5728\u8f93\u51fa\u540e\u9762\u589e\u52a0\u6211\u4eec\u7ed3\u6784 # [?, ?, ?, 512]---->[?, 1 * 1 * 512] x = tf . keras . layers . GlobalAveragePooling2D ()( x ) # 3\u3001\u5b9a\u4e49\u65b0\u7684\u8fc1\u79fb\u6a21\u578b x = tf . keras . layers . Dense ( 1024 , activation = tf . nn . relu )( x ) y_predict = tf . keras . layers . Dense ( 5 , activation = tf . nn . softmax )( x ) # model\u5b9a\u4e49\u65b0\u6a21\u578b # VGG \u6a21\u578b\u7684\u8f93\u5165\uff0c \u8f93\u51fa\uff1ay_predict transfer_model = tf . keras . models . Model ( inputs = self . base_model . inputs , outputs = y_predict ) return transfer_model 4.6.7.6 freeze VGG\u6a21\u578b\u7ed3\u6784 \u00b6 \u76ee\u7684\uff1a\u8ba9VGG\u7ed3\u6784\u5f53\u4e2d\u7684\u6743\u91cd\u53c2\u6570\u4e0d\u53c2\u4e0e\u8bad\u7ec3,\u53ea\u8bad\u7ec3\u6211\u4eec\u6dfb\u52a0\u7684\u6700\u540e\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u6743\u91cd\u53c2\u6570 \u901a\u8fc7\u4f7f\u7528\u6bcf\u4e00\u5c42\u7684layer.trainable=False def freeze_vgg_model ( self ): \"\"\" freeze\u6389VGG\u7684\u7ed3\u6784 :return: \"\"\" for layer in self . base_model . layers : layer . trainable = False 4.6.7.7 \u7f16\u8bd1\u548c\u8bad\u7ec3 \u00b6 \u7f16\u8bd1 \u540c\u6837\u8fd8\u662f\u8fdb\u884c\u7f16\u8bd1\uff0c \u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7b97\u6cd5\uff1a\u5b66\u4e60\u7387\u521d\u59cb\u5316\u8f83\u5c0f\u7684\u503c\uff0c0.001,0.0001\uff0c\u56e0\u4e3a\u5df2\u7ecf\u5728\u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u57fa\u7840\u4e4b\u4e0a\u66f4\u65b0\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u592a\u5927\u5b66\u4e60\u7387\u53bb\u5b66\u4e60 def compile ( self , model ): \"\"\" \u7f16\u8bd1\u6a21\u578b :return: \"\"\" model . compile ( optimizer = tf . keras . optimizers . Adam (), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ 'accuracy' ]) return None def fit_generator ( self , model , train_gen , test_gen ): \"\"\" \u8bad\u7ec3\u6a21\u578b\uff0cmodel.fit_generator()\u4e0d\u662f\u9009\u62e9model.fit() :return: \"\"\" # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u51c6\u786e\u7387\u8bb0\u5f55\u7684h5\u6587\u4ef6 modelckpt = tf . keras . callbacks . ModelCheckpoint ( './ckpt/transfer_{epoch:02d}-{val_accuracy:.2f}.h5' , monitor = 'val_accuracy' , save_best_only = True , save_weights_only = False , mode = 'auto' , period = 1 ) model . fit_generator ( train_gen , epochs = 3 , validation_data = test_gen , callbacks = [ modelckpt ]) return None main\u51fd\u6570 if __name__ == '__main__' : tm = TransferModel () train_gen , test_gen = tm . read_img_to_generator () model = tm . refine_vgg_model () tm . freeze_vgg_model () tm . compile ( model ) tm . fit ( model , train_gen , test_gen ) 4.6.7.8 \u8fdb\u884c\u9884\u6d4b \u00b6 \u9884\u6d4b\u7684\u6b65\u9aa4\u5c31\u662f\u8bfb\u53d6\u56fe\u7247\u4ee5\u53ca\u5904\u7406\u5230\u6a21\u578b\u4e2d\u9884\u6d4b\uff0c\u52a0\u8f7d\u6211\u4eec\u8bad\u7ec3\u7684\u6a21\u578b def predict ( self , model ): \"\"\"\u9884\u6d4b\u8f93\u5165\u56fe\u7247\u7684\u7c7b\u522b :return: \"\"\" # 1\u3001\u52a0\u8f7d\u6a21\u578b\u8bad\u7ec3\u597d\u7684\u6743\u91cd model . load_weights ( \"./ckpt/transfer_01-0.84.h5\" ) # 2\u3001\u8bfb\u53d6\u56fe\u7247\u5904\u7406\u56fe\u7247\u6570\u636e\uff0c\u5f62\u72b6\uff0c\u6570\u636e\u5f52\u4e00\u5316 image = tf . io . read_file ( \"./data/test/dinosaurs/402.jpg\" ) image_decoded = tf . image . decode_jpeg ( image ) image_resized = tf . image . resize ( image_decoded , [ 224 , 224 ]) / 255.0 # 3\u7ef4-->4\u7ef4\u7684\u5f62\u72b6\u6539\u53d8 img = tf . reshape ( image_resized , ( 1 , image_resized . shape [ 0 ], image_resized . shape [ 1 ], image_resized . shape [ 2 ])) print ( \"\u4fee\u6539\u4e4b\u540e\u7684\u5f62\u72b6\uff1a\" , img . shape ) # 3\u3001\u8f93\u5165\u6570\u636e\u505a\u9884\u6d4b y_predict = model . predict ( img ) index = np . argmax ( y_predict , axis = 1 ) print ( self . label_dict [ str ( index [ 0 ])]) return None \u5efa\u7acb\u56fe\u7247\u7c7b\u522b\u7684\u5b57\u5178 self . label_dict = { '0' : 'bus' , '1' : 'dinosaurs' , '2' : 'elephants' , '3' : 'flowers' , '4' : 'horse' } 4.6.6 \u603b\u7ed3 \u00b6 Checkpoint\u4f7f\u7528 TensorBoard\u4f7f\u7528 tf.data\u6a21\u5757\u4f7f\u7528 ImageDataGenerator\u7684\u4f7f\u7528","title":"4.6 TF\u5e38\u7528\u529f\u80fd\u6a21\u5757"},{"location":"tensorFlow/section6/#46-tf","text":"","title":"4.6 TF\u5e38\u7528\u529f\u80fd\u6a21\u5757"},{"location":"tensorFlow/section6/#_1","text":"\u76ee\u6807 \u638c\u63e1Checkpoint\u4f7f\u7528 \u638c\u63e1TensorBoard\u4f7f\u7528 \u638c\u63e1data\u6a21\u5757\u4f7f\u7528 \u638c\u63e1ImageDataGenerator\u7684\u4f7f\u7528 \u5e94\u7528 \u65e0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section6/#461-fitcallbacks","text":"\u56de\u8c03\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7ed9\u5b9a\u9636\u6bb5\u5e94\u7528\u7684\u4e00\u7ec4\u51fd\u6570\u3002\u53ef\u4ee5\u4f7f\u7528\u56de\u8c03\u6765\u83b7\u53d6\u57f9\u8bad\u671f\u95f4\u5185\u90e8\u72b6\u6001\u548c\u6a21\u578b\u7edf\u8ba1\u4fe1\u606f\u7684\u89c6\u56fe\u3002\u60a8\u53ef\u4ee5\u5c06\u56de\u8c03\u5217\u8868\uff08\u4f5c\u4e3a\u5173\u952e\u5b57\u53c2\u6570 callbacks \uff09\u4f20\u9012\u7ed9\u6216\u7c7b\u7684 fit() \u65b9\u6cd5\u3002\u7136\u540e\u5c06\u5728\u8bad\u7ec3\u7684\u6bcf\u4e2a\u9636\u6bb5\u8c03\u7528\u56de\u8c03\u7684\u76f8\u5173\u65b9\u6cd5\u3002 \u5b9a\u5236\u5316\u4fdd\u5b58\u6a21\u578b \u4fdd\u5b58events\u6587\u4ef6","title":"4.6.1  fit\u7684callbacks\u8be6\u89e3"},{"location":"tensorFlow/section6/#4611-modelcheckpoint","text":"from tensorflow.python.keras.callbacks import ModelCheckpoint keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', save_best_only=False, save_weights_only=False, mode='auto', period=1) Save the model after every epoch\uff1a\u6bcf\u9694\u591a\u5c11\u6b21\u8fed\u4ee3\u4fdd\u5b58\u6a21\u578b filepath: \u4fdd\u5b58\u6a21\u578b\u5b57\u7b26\u4e32 \u5982\u679c\u8bbe\u7f6e weights.{epoch:02d}-{val_loss:.2f}.hdf5\u683c\u5f0f\uff0c\u5c06\u4f1a\u6bcf\u9694epoch number\u6570\u91cf\u5e76\u4e14\u5c06\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\u4fdd\u5b58\u5728\u8be5\u4f4d\u7f6e \u5982\u679c\u8bbe\u7f6eweights.{epoch:02d}-{val_acc:.2f}.hdf5\uff0c\u5c06\u4f1a\u6309\u7167val_acc\u7684\u503c\u8fdb\u884c\u4fdd\u5b58\u6a21\u578b monitor: quantity to monitor.\u8bbe\u7f6e\u4e3a'val_acc'\u6216\u8005'val_loss' save_best_only: if save_best_only=True, \u53ea\u4fdd\u7559\u6bd4\u4e0a\u6b21\u6a21\u578b\u66f4\u597d\u7684\u7ed3\u679c save_weights_only: if True, \u53ea\u4fdd\u5b58\u53bb\u90a3\u79cd(model.save_weights(filepath)), else the full model is saved (model.save(filepath)). mode: one of {auto, min, max}. \u5982\u679csave_best_only=True, \u5bf9\u4e8eval_acc, \u8981\u8bbe\u7f6emax, \u5bf9\u4e8eval_loss\u8981\u8bbe\u7f6emin period: \u8fed\u4ee3\u4fdd\u5b58checkpoints\u7684\u95f4\u9694 check = ModelCheckpoint ( './ckpt/singlenn_{epoch:02d}-{val_acc:.2f}.h5' , monitor = 'val_acc' , save_best_only = True , save_weights_only = True , mode = 'auto' , period = 1 ) SingleNN . model . fit ( self . train , self . train_label , epochs = 5 , callbacks = [ check ], validation_data = ( x , y )) \u6ce8\u610f\uff1a 1\u3001\u4f7f\u7528ModelCheckpoint\u4e00\u5b9a\u8981\u5728fit\u5f53\u4e2d\u6307\u5b9a\u9a8c\u8bc1\u96c6\u624d\u80fd\u4f7f\u7528\uff0c\u5426\u5219\u62a5\u9519\u8bef\u3002 2\u3001\u5176\u4e2dval_acc\u8fd8\u662fval_accuracy\u9700\u8981\u5728\u8fd9\u91cc\u6307\u5b9a model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy']) model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])","title":"4.6.1.1 ModelCheckpoint"},{"location":"tensorFlow/section6/#4612-tensorboard","text":"\u6dfb\u52a0Tensorboard\u89c2\u5bdf\u635f\u5931\u7b49\u60c5\u51b5 keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch') log_dir:\u4fdd\u5b58\u4e8b\u4ef6\u6587\u4ef6\u76ee\u5f55 write_graph=True\uff1a\u662f\u5426\u663e\u793a\u56fe\u7ed3\u6784 write_images=False\uff1a\u662f\u5426\u663e\u793a\u56fe\u7247 write_grads=True:\u662f\u5426\u663e\u793a\u68af\u5ea6 histogram_freq \u5fc5\u987b\u5927\u4e8e0 # \u6dfb\u52a0tensoboard\u89c2\u5bdf tensorboard = keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) SingleNN . model . fit ( self . train , self . train_label , epochs = 5 , callbacks = [ tensorboard ]) \u6253\u5f00\u7ec8\u7aef\u67e5\u770b\uff1a # \u6307\u5b9a\u5b58\u5728\u6587\u4ef6\u7684\u76ee\u5f55\uff0c\u6253\u5f00\u4e0b\u9762\u547d\u4ee4 tensorboard --logdir=\"./\" \u8fd9\u662fCNN mnist100\u6848\u4f8b\u4e2d\u7684\u6548\u679c\uff1a 1\u3001\u635f\u5931\u548c\u51c6\u786e\u7387 2\u3001\u56fe\u7ed3\u6784\u663e\u793a\uff1a 3\u3001\u6743\u91cd\u53c2\u6570\u663e\u793a","title":"4.6.1.2 Tensorboard"},{"location":"tensorFlow/section6/#462-tfdata","text":"\u95ee\u9898\u5f15\u5165\uff1a \u5728\u5927\u90e8\u5206\u65f6\u5019\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u81ea\u5df1\u7684\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u6a21\u578b\u3002\u7136\u800c\uff0c\u9762\u5bf9\u4e00\u5806\u683c\u5f0f\u4e0d\u4e00\u7684\u539f\u59cb\u6570\u636e\u6587\u4ef6\uff0c\u5c06\u5176\u9884\u5904\u7406\u5e76\u8bfb\u5165\u7a0b\u5e8f\u7684\u8fc7\u7a0b\u5f80\u5f80\u5341\u5206\u7e41\u7410\uff0c\u751a\u81f3\u6bd4\u6a21\u578b\u7684\u8bbe\u8ba1\u8fd8\u8981\u8017\u8d39\u7cbe\u529b\u3002\u6bd4\u5982\uff0c\u4e3a\u4e86\u8bfb\u5165\u4e00\u6279\u56fe\u50cf\u6587\u4ef6\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\u7ea0\u7ed3\u4e8e python \u7684\u5404\u79cd\u56fe\u50cf\u5904\u7406\u5305\uff08\u6bd4\u5982 pillow \uff09\uff0c\u81ea\u5df1\u8bbe\u8ba1 Batch \u7684\u751f\u6210\u65b9\u5f0f\uff0c\u6700\u540e\u8fd8\u53ef\u80fd\u5728\u8fd0\u884c\u7684\u6548\u7387\u4e0a\u4e0d\u5c3d\u5982\u4eba\u610f\u3002\u4e3a\u6b64\uff0cTensorFlow \u63d0\u4f9b\u4e86 tf.data \u8fd9\u4e00\u6a21\u5757\uff0c\u5305\u62ec\u4e86\u4e00\u5957\u7075\u6d3b\u7684\u6570\u636e\u96c6\u6784\u5efa API\uff0c\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u5feb\u901f\u3001\u9ad8\u6548\u5730\u6784\u5efa\u6570\u636e\u8f93\u5165\u7684\u6d41\u6c34\u7ebf\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6570\u636e\u91cf\u5de8\u5927\u7684\u573a\u666f\u3002","title":"4.6.2 tf.data \uff1a\u6570\u636e\u96c6\u7684\u6784\u5efa\u4e0e\u9884\u5904\u7406"},{"location":"tensorFlow/section6/#4621","text":"tf.data \u7684\u6838\u5fc3\u662f tf.data.Dataset \u7c7b\uff0c\u63d0\u4f9b\u4e86\u5bf9\u6570\u636e\u96c6\u7684\u9ad8\u5c42\u5c01\u88c5\u3002 **tf.data.Dataset \u7531\u4e00\u7cfb\u5217\u7684\u53ef\u8fed\u4ee3\u8bbf\u95ee\u7684\u5143\u7d20\uff08element\uff09\u7ec4\u6210\uff0c\u6bcf\u4e2a\u5143\u7d20\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u5f20\u91cf\u3002**\u6bd4\u5982\u8bf4\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u7531\u56fe\u50cf\u7ec4\u6210\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u5143\u7d20\u53ef\u4ee5\u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a \u957f\u00d7\u5bbd\u00d7\u901a\u9053\u6570 \u7684\u56fe\u7247\u5f20\u91cf\uff0c\u4e5f\u53ef\u4ee5\u662f\u7531\u56fe\u7247\u5f20\u91cf\u548c\u56fe\u7247\u6807\u7b7e\u5f20\u91cf\u7ec4\u6210\u7684\u5143\u7ec4\uff08Tuple\uff09\u3002","title":"4.6.2.1 \u6570\u636e\u96c6\u5bf9\u8c61\u7684\u5efa\u7acb"},{"location":"tensorFlow/section6/#1tfdatadatasetfrom_tensor_slices","text":"\u6700\u57fa\u7840\u7684\u5efa\u7acb tf.data.Dataset \u7684\u65b9\u6cd5\u662f\u4f7f\u7528 tf.data.Dataset.from_tensor_slices() \uff0c\u9002\u7528\u4e8e\u6570\u636e\u91cf\u8f83\u5c0f\uff08\u80fd\u591f\u6574\u4e2a\u88c5\u8fdb\u5185\u5b58\uff09\u7684\u60c5\u51b5\u3002 import tensorflow as tf import numpy as np X = tf . constant ([ 2015 , 2016 , 2017 , 2018 , 2019 ]) Y = tf . constant ([ 12000 , 14000 , 15000 , 16500 , 17500 ]) # \u4e5f\u53ef\u4ee5\u4f7f\u7528NumPy\u6570\u7ec4\uff0c\u6548\u679c\u76f8\u540c # X = np.array([2015, 2016, 2017, 2018, 2019]) # Y = np.array([12000, 14000, 15000, 16500, 17500]) dataset = tf . data . Dataset . from_tensor_slices (( X , Y )) for x , y in dataset : print ( x . numpy (), y . numpy ()) \u8f93\u51fa 2013 12000 2014 14000 2015 15000 2016 16500 2017 17500 \u540c\u6837\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u53ef\u4ee5\u8f7d\u5165\u524d\u7ae0\u7684 MNIST \u6570\u636e\u96c6\uff1a import matplotlib.pyplot as plt ( train_data , train_label ), ( _ , _ ) = tf . keras . datasets . mnist . load_data () # [60000, 28, 28, 1] train_data = np . expand_dims ( train_data . astype ( np . float32 ) / 255.0 , axis =- 1 ) mnist_dataset = tf . data . Dataset . from_tensor_slices (( train_data , train_label )) for image , label in mnist_dataset : print ( label . numpy ()) print ( image . numpy ())","title":"1\u3001tf.data.Dataset.from_tensor_slices()"},{"location":"tensorFlow/section6/#4622","text":"tf.data.Dataset \u7c7b\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u591a\u79cd\u6570\u636e\u96c6\u9884\u5904\u7406\u65b9\u6cd5\u3002\u6700\u5e38\u7528\u7684\u5982\uff1a 1\u3001Dataset.map(f) \uff1a \u5bf9\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u5e94\u7528\u51fd\u6570 f \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\uff08\u8fd9\u90e8\u5206\u5f80\u5f80\u7ed3\u5408 tf.io \u8fdb\u884c\u8bfb\u5199\u548c\u89e3\u7801\u6587\u4ef6\uff0c tf.image \u8fdb\u884c\u56fe\u50cf\u5904\u7406\uff09\uff1b 2\u3001Dataset.shuffle(buffer_size) \uff1a \u5c06\u6570\u636e\u96c6\u6253\u4e71\uff08\u8bbe\u5b9a\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u7f13\u51b2\u533a\uff08Buffer\uff09\uff0c\u53d6\u51fa\u524d buffer_size \u4e2a\u5143\u7d20\u653e\u5165\uff0c\u5e76\u4ece\u7f13\u51b2\u533a\u4e2d\u968f\u673a\u91c7\u6837\uff0c\u91c7\u6837\u540e\u7684\u6570\u636e\u7528\u540e\u7eed\u6570\u636e\u66ff\u6362\uff09\uff1b 3\u3001Dataset.batch(batch_size) \uff1a \u5c06\u6570\u636e\u96c6\u5206\u6210\u6279\u6b21\uff0c\u5373\u5bf9\u6bcf batch_size \u4e2a\u5143\u7d20\uff0c\u4f7f\u7528 tf.stack() \u5728\u7b2c 0 \u7ef4\u5408\u5e76\uff0c\u6210\u4e3a\u4e00\u4e2a\u5143\u7d20\u3002 4\u3001Dataset.prefetch() \uff1a \u9884\u53d6\u51fa\u6570\u636e\u96c6\u4e2d\u7684\u82e5\u5e72\u4e2a\u5143\u7d20 5\u3001\u9664\u6b64\u4ee5\u5916\uff0c\u8fd8\u6709 Dataset.repeat() \uff08\u91cd\u590d\u6570\u636e\u96c6\u7684\u5143\u7d20\uff09\u3001 Dataset.reduce() \uff08\u4e0e Map \u76f8\u5bf9\u7684\u805a\u5408\u64cd\u4f5c\uff09\u3001 Dataset.take ()\u7b49\uff0c\u53ef\u53c2\u8003 API \u6587\u6863 \u8fdb\u4e00\u6b65\u4e86\u89e3\u3002","title":"4.6.2.2 \u6570\u636e\u96c6\u5bf9\u8c61\u7684\u9884\u5904\u7406"},{"location":"tensorFlow/section6/#4643","text":"1\u3001\u4f7f\u7528 Dataset.map() \u5c06\u6240\u6709\u56fe\u7247\u65cb\u8f6c 90 \u5ea6\uff1a def rot90 ( image , label ): image = tf . image . rot90 ( image ) return image , label mnist_dataset = mnist_dataset . map ( rot90 ) for image , label in mnist_dataset : plt . title ( label . numpy ()) plt . imshow ( image . numpy ()[:, :, 0 ]) plt . show () 2\u3001\u4f7f\u7528 Dataset.batch() \u5c06\u6570\u636e\u96c6\u5212\u5206\u6279\u6b21\uff0c\u6bcf\u4e2a\u6279\u6b21\u7684\u5927\u5c0f\u4e3a 4\uff1a # \u83b7\u53d6\u6279\u6b21\u6570\u636e mnist_dataset = mnist_dataset . batch ( 4 ) for images , labels in mnist_dataset : fig , axs = plt . subplots ( 1 , 4 ) for i in range ( 4 ): axs [ i ] . set_title ( labels . numpy ()[ i ]) axs [ i ] . imshow ( images . numpy ()[ i , :, :, 0 ]) plt . show () 3\u3001\u4f7f\u7528 Dataset.shuffle() \u5c06\u6570\u636e\u6253\u6563\u540e\u518d\u8bbe\u7f6e\u6279\u6b21\uff0c\u7f13\u5b58\u5927\u5c0f\u8bbe\u7f6e\u4e3a 10000 \u8bbe\u5b9a\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u4e3a buffer_size \u7684\u7f13\u51b2\u533a\uff08Buffer\uff09\uff1b\u521d\u59cb\u5316\u65f6\uff0c\u53d6\u51fa\u6570\u636e\u96c6\u4e2d\u7684\u524d buffer_size \u4e2a\u5143\u7d20\u653e\u5165\u7f13\u51b2\u533a\uff1b \u6bcf\u6b21\u9700\u8981\u4ece\u6570\u636e\u96c6\u4e2d\u53d6\u5143\u7d20\u65f6\uff0c\u5373\u4ece\u7f13\u51b2\u533a\u4e2d\u968f\u673a\u91c7\u6837\u4e00\u4e2a\u5143\u7d20\u5e76\u53d6\u51fa\uff0c\u7136\u540e\u4ece\u540e\u7eed\u7684\u5143\u7d20\u4e2d\u53d6\u51fa\u4e00\u4e2a\u653e\u56de\u5230\u4e4b\u524d\u88ab\u53d6\u51fa\u7684\u4f4d\u7f6e\uff0c\u4ee5\u7ef4\u6301\u7f13\u51b2\u533a\u7684\u5927\u5c0f\u3002 mnist_dataset = mnist_dataset . shuffle ( buffer_size = 10000 ) . batch ( 4 ) for images , labels in mnist_dataset : fig , axs = plt . subplots ( 1 , 4 ) for i in range ( 4 ): axs [ i ] . set_title ( labels . numpy ()[ i ]) axs [ i ] . imshow ( images . numpy ()[ i , :, :, 0 ]) plt . show () \u6ce8\uff1aDataset.shuffle() \u65f6\u7f13\u51b2\u533a\u5927\u5c0f buffer_size \u7684\u8bbe\u7f6e\uff0c\u6bcf\u6b21\u7684\u6570\u636e\u90fd\u4f1a\u88ab\u968f\u673a\u6253\u6563\u3002\u5f53 buffer_size \u8bbe\u7f6e\u4e3a 1 \u65f6\uff0c\u5176\u5b9e\u7b49\u4ef7\u4e8e\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u6253\u6563\u3002 \u5f53\u6570\u636e\u96c6\u7684\u6807\u7b7e\u987a\u5e8f\u5206\u5e03\u6781\u4e3a\u4e0d\u5747\u5300\uff08\u4f8b\u5982\u4e8c\u5143\u5206\u7c7b\u65f6\u6570\u636e\u96c6\u524d N \u4e2a\u7684\u6807\u7b7e\u4e3a 0\uff0c\u540e N \u4e2a\u7684\u6807\u7b7e\u4e3a 1\uff09\u65f6\uff0c\u8f83\u5c0f\u7684\u7f13\u51b2\u533a\u5927\u5c0f\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u65f6\u53d6\u51fa\u7684 Batch \u6570\u636e\u5f88\u53ef\u80fd\u5168\u4e3a\u540c\u4e00\u6807\u7b7e\uff0c\u4ece\u800c\u5f71\u54cd\u8bad\u7ec3\u6548\u679c\u3002\u4e00\u822c\u800c\u8a00\uff0c\u6570\u636e\u96c6\u7684\u987a\u5e8f\u5206\u5e03\u82e5\u8f83\u4e3a\u968f\u673a\uff0c\u5219\u7f13\u51b2\u533a\u7684\u5927\u5c0f\u53ef\u8f83\u5c0f\uff0c\u5426\u5219\u5219\u9700\u8981\u8bbe\u7f6e\u8f83\u5927\u7684\u7f13\u51b2\u533a\u3002","title":"4.6.4.3 \u4f7f\u7528\u6848\u4f8b"},{"location":"tensorFlow/section6/#4643_1","text":"1\u3001\u6784\u5efa\u597d\u6570\u636e\u5e76\u9884\u5904\u7406\u540e\uff0c\u6211\u4eec\u9700\u8981\u4ece\u5176\u4e2d\u8fed\u4ee3\u83b7\u53d6\u6570\u636e\u4ee5\u7528\u4e8e\u8bad\u7ec3\u3002tf.data.Dataset \u662f\u4e00\u4e2a Python \u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528 For \u5faa\u73af\u8fed\u4ee3\u83b7\u53d6\u6570\u636e\uff0c\u5373\uff1a dataset = tf . data . Dataset . from_tensor_slices (( A , B , C , ... )) for a , b , c , ... in dataset : # \u5bf9\u5f20\u91cfa, b, c\u7b49\u8fdb\u884c\u64cd\u4f5c\uff0c\u4f8b\u5982\u9001\u5165\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3 2\u3001\u53ef\u4ee5\u4f7f\u7528 iter() \u663e\u5f0f\u521b\u5efa\u4e00\u4e2a Python \u8fed\u4ee3\u5668\u5e76\u4f7f\u7528 next() \u83b7\u53d6\u4e0b\u4e00\u4e2a\u5143\u7d20\uff0c\u5373\uff1a dataset = tf . data . Dataset . from_tensor_slices (( A , B , C , ... )) it = iter ( dataset ) a_0 , b_0 , c_0 , ... = next ( it ) a_1 , b_1 , c_1 , ... = next ( it ) 3\u3001Keras \u652f\u6301\u4f7f\u7528 tf.data.Dataset \u76f4\u63a5\u4f5c\u4e3a\u8f93\u5165\u3002\u5f53\u8c03\u7528 tf.keras.Model \u7684 fit() \u548c evaluate() \u65b9\u6cd5\u65f6\uff0c\u53ef\u4ee5\u5c06\u53c2\u6570\u4e2d\u7684\u8f93\u5165\u6570\u636e x \u6307\u5b9a\u4e3a\u4e00\u4e2a\u5143\u7d20\u683c\u5f0f\u4e3a (\u8f93\u5165\u6570\u636e, \u6807\u7b7e\u6570\u636e) \u7684 Dataset \uff0c\u5e76\u5ffd\u7565\u6389\u53c2\u6570\u4e2d\u7684\u6807\u7b7e\u6570\u636e y \u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u4e0a\u8ff0\u7684 MNIST \u6570\u636e\u96c6\uff0c\u5e38\u89c4\u7684 Keras \u8bad\u7ec3\u65b9\u5f0f\u662f\uff1a model . fit ( x = train_data , y = train_label , epochs = num_epochs , batch_size = batch_size ) \u4f7f\u7528 tf.data.Dataset \u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f20\u5165 Dataset \uff1a model . fit ( mnist_dataset , epochs = num_epochs ) \u5982\u679c\u5df2\u7ecf\u901a\u8fc7 Dataset.batch() \u65b9\u6cd5\u5212\u5206\u4e86\u6570\u636e\u96c6\u7684\u6279\u6b21\uff0c\u6240\u4ee5\u8fd9\u91ccfit\u4e2d\u4e5f\u65e0\u9700\u63d0\u4f9b\u6279\u6b21\u7684\u5927\u5c0f\u3002","title":"4.6.4.3 \u6570\u636e\u96c6\u5143\u7d20\u7684\u83b7\u53d6\u4e0e\u4f7f\u7528"},{"location":"tensorFlow/section6/#4644-tfdata","text":"\u5f53\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u6211\u4eec\u5e0c\u671b\u5145\u5206\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\uff0c\u51cf\u5c11 CPU/GPU \u7684\u7a7a\u8f7d\u65f6\u95f4\u3002\u7136\u800c\u6709\u65f6\uff0c\u6570\u636e\u96c6\u7684\u51c6\u5907\u5904\u7406\u975e\u5e38\u8017\u65f6\uff0c\u4f7f\u5f97\u6211\u4eec\u5728\u6bcf\u8fdb\u884c\u4e00\u6b21\u8bad\u7ec3\u524d\u90fd\u9700\u8981\u82b1\u8d39\u5927\u91cf\u7684\u65f6\u95f4\u51c6\u5907\u5f85\u8bad\u7ec3\u7684\u6570\u636e\uff0c\u800c\u6b64\u65f6 GPU \u53ea\u80fd\u7a7a\u8f7d\u800c\u7b49\u5f85\u6570\u636e\uff0c\u9020\u6210\u4e86\u8ba1\u7b97\u8d44\u6e90\u7684\u6d6a\u8d39\u3002 tf.data \u7684\u6570\u636e\u96c6\u5bf9\u8c61\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86 Dataset.prefetch() \u65b9\u6cd5\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u8ba9\u6570\u636e\u96c6\u5bf9\u8c61 Dataset \u5728\u8bad\u7ec3\u65f6\u9884\u53d6\u51fa\u82e5\u5e72\u4e2a\u5143\u7d20\uff0c\u4f7f\u5f97\u5728 GPU \u8bad\u7ec3\u7684\u540c\u65f6 CPU \u53ef\u4ee5\u51c6\u5907\u6570\u636e\uff0c\u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u6d41\u7a0b\u7684\u6548\u7387 \u4f7f\u7528\uff1a mnist_dataset = mnist_dataset . prefetch ( buffer_size = tf . data . experimental . AUTOTUNE ) \u53c2\u6570 buffer_size \u65e2\u53ef\u624b\u5de5\u8bbe\u7f6e\uff0c\u4e5f\u53ef\u8bbe\u7f6e\u4e3a tf.data.experimental.AUTOTUNE \u4ece\u800c\u7531 TensorFlow \u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u6570\u503c\u3002 2\u3001\u8fd8\u6709\u4e00\u79cd\u65b9\u5f0f\u4e5f\u80fd\u591f\u63d0\u9ad8\u5229\u7528CPU\u8d44\u6e90 Dataset.map() \u4e5f\u53ef\u4ee5\u5229\u7528\u591a GPU \u8d44\u6e90\uff0c\u5e76\u884c\u5316\u5730\u5bf9\u6570\u636e\u9879\u8fdb\u884c\u53d8\u6362\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002 \u901a\u8fc7\u8bbe\u7f6e Dataset.map() \u7684 num_parallel_calls \u53c2\u6570\u5b9e\u73b0\u6570\u636e\u8f6c\u6362\u7684\u5e76\u884c\u5316\u3002\u4e0a\u9762\u7684\u662f\u672a\u5e76\u884c\u5316\u7684\u56fe\u793a\uff0c\u4e0b\u9762\u662f\u4e24\u6838\u5e76\u884c\u7684\u56fe\u793a\uff0c\u65f6\u95f4\u4f1a\u7f29\u5c0f # \u6dfb\u52a0\u53c2\u6570\u4f7f\u7528\uff0cnum_parallel_calls \u8bbe\u7f6e\u4e3a tf.data.experimental.AUTOTUNE \u4ee5\u8ba9 TensorFlow \u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u6570\u503c train_dataset = train_dataset . map ( map_func = _decode_and_resize , num_parallel_calls = tf . data . experimental . AUTOTUNE ) \u901a\u8fc7 prefetch() \u7684\u4f7f\u7528\u548c\u5728 map() \u8fc7\u7a0b\u4e2d\u52a0\u5165 num_parallel_calls \u53c2\u6570\uff0c\u6a21\u578b\u8bad\u7ec3\u7684\u65f6\u95f4\u53ef\u7f29\u51cf\u81f3\u539f\u6765\u7684\u4e00\u534a\u751a\u81f3\u66f4\u4f4e\u3002 \u6ce8\uff1a\u7eb5\u8f74\u4e3a\u6bcf epoch \u8bad\u7ec3\u6240\u9700\u65f6\u95f4\uff0c\u5355\u4f4d\uff1a\u79d2","title":"4.6.4.4 \u4f7f\u7528tf.data\u7684\u5e76\u884c\u5316\u7b56\u7565\u63d0\u9ad8\u8bad\u7ec3\u6d41\u7a0b\u6548\u7387"},{"location":"tensorFlow/section6/#465","text":"\u6570\u636e\u96c6\u6765\u81ea kaggle \u4e0a\u7684\u4e00\u4e2a\u7ade\u8d5b\uff1a Dogs vs. Cats \uff0c\u8bad\u7ec3\u96c6\u670925000\u5f20\uff0c\u732b\u72d7\u5404\u5360\u4e00\u534a\u3002\u6d4b\u8bd5\u96c612500\u5f20\uff0c\u6ca1\u6709\u6807\u5b9a\u662f\u732b\u8fd8\u662f\u72d7\u3002 \u76ee\u7684\uff1a\u732b\u72d7\u56fe\u7247\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e3a\u793a\u4f8b \u4f7f\u7528 tf.data \u7ed3\u5408 tf.io \u548c tf.image \u5efa\u7acbDataset \u6570\u636e\u96c6 \u6570\u636e\u96c6\u53ef\u53d6\u8fd9\u91cc\u4e0b\u8f7d\uff1a https://www.floydhub.com/fastai/datasets/cats-vs-dogs \u6b65\u9aa4\uff1a 1\u3001\u6570\u636e\u96c6\u7684\u83b7\u53d6\u548c\u6784\u5efa 2\u3001\u6a21\u578b\u6784\u5efa\u548c\u5c01\u88c5 3\u3001\u8bad\u7ec3\u4ee5\u53ca\u6d4b\u8bd5\u8fc7\u7a0b\u5b9e\u73b0 1\u3001\u6570\u636e\u96c6\u7684\u83b7\u53d6\u548c\u6784\u5efa class CatOrDog ( object ): \"\"\"\u732b\u72d7\u5206\u7c7b \"\"\" num_epochs = 1 batch_size = 32 learning_rate = 0.001 # \u8bad\u7ec3\u76ee\u5f55 train_cats_dir = '/root/cv_project/tf_example/cats_vs_dogs/train/cats/' train_dogs_dir = '/root/cv_project/tf_example/cats_vs_dogs/train/dogs/' # \u9a8c\u8bc1\u76ee\u5f55 test_cats_dir = '/root/cv_project/tf_example/cats_vs_dogs/valid/cats/' test_dogs_dir = '/root/cv_project/tf_example/cats_vs_dogs/valid/dogs/' def __init__ ( self ): # 1\u3001\u8bfb\u53d6\u8bad\u7ec3\u96c6\u7684\u732b\u72d7\u6587\u4ef6 self . train_cat_filenames = tf . constant ([ CatOrDog . train_cats_dir + filename for filename in os . listdir ( CatOrDog . train_cats_dir )]) self . train_dog_filenames = tf . constant ([ CatOrDog . train_dogs_dir + filename for filename in os . listdir ( CatOrDog . train_dogs_dir )]) # 2\u3001\u732b\u72d7\u6587\u4ef6\u5217\u8868\u5408\u5e76\uff0c\u5e76\u4e14\u521d\u59cb\u5316\u732b\u72d7\u7684\u76ee\u6807\u503c\uff0c0\u4e3a\u732b\uff0c1\u4e3a\u72d7 self . train_filenames = tf . concat ([ self . train_cat_filenames , self . train_dog_filenames ], axis =- 1 ) self . train_labels = tf . concat ([ tf . zeros ( self . train_cat_filenames . shape , dtype = tf . int32 ), tf . ones ( self . train_dog_filenames . shape , dtype = tf . int32 )], axis =- 1 ) \u5b9a\u4e49\u6570\u636e\u7684\u83b7\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7tf.data\u6307\u5b9a def get_batch ( self ): \"\"\"\u83b7\u53d6dataset\u6279\u6b21\u6570\u636e :return: \"\"\" train_dataset = tf . data . Dataset . from_tensor_slices (( self . train_filenames , self . train_labels )) # \u8fdb\u884c\u6570\u636e\u7684map, \u968f\u673a\uff0c\u6279\u6b21\u548c\u9884\u5b58\u50a8 train_dataset = train_dataset . map ( map_func = _decode_and_resize , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_dataset = train_dataset . shuffle ( buffer_size = 20000 ) train_dataset = train_dataset . batch ( CatOrDog . batch_size ) train_dataset = train_dataset . prefetch ( tf . data . experimental . AUTOTUNE ) return train_dataset # \u56fe\u7247\u5904\u7406\u51fd\u6570\uff0c\u8bfb\u53d6\uff0c\u89e3\u7801\u5e76\u4e14\u8fdb\u884c\u8f93\u5165\u5f62\u72b6\u4fee\u6539 def _decode_and_resize ( filename , label ): image_string = tf . io . read_file ( filename ) image_decoded = tf . image . decode_jpeg ( image_string ) image_resized = tf . image . resize ( image_decoded , [ 256 , 256 ]) / 255.0 return image_resized , label 2\u3001\u6a21\u578b\u6784\u5efa\u548c\u5c01\u88c5 \u901a\u8fc7\u6784\u9020\u4e24\u5c42\u5377\u79ef+\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u7684\u7f51\u7edc self . model = tf . keras . Sequential ([ tf . keras . layers . Conv2D ( 32 , 3 , activation = 'relu' , input_shape = ( 256 , 256 , 3 )), tf . keras . layers . MaxPooling2D (), tf . keras . layers . Conv2D ( 32 , 5 , activation = 'relu' ), tf . keras . layers . MaxPooling2D (), tf . keras . layers . Flatten (), tf . keras . layers . Dense ( 64 , activation = 'relu' ), tf . keras . layers . Dense ( 2 , activation = 'softmax' ) ]) 3\u3001\u8bad\u7ec3\u4ee5\u53ca\u6d4b\u8bd5\u8fc7\u7a0b\u5b9e\u73b0 \u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b,\u8fd9\u91cc\u5c31\u514d\u53bb\u6307\u5b9ackpt\u4ee5\u53catensorboard\u7684callbacks\u4e86\uff0c\u53ef\u4ee5\u81ea\u5df1\u53bb\u6307\u5b9a\u5b9e\u9a8c def train ( self , train_dataset ): \"\"\"\u8bad\u7ec3\u8fc7\u7a0b :return: \"\"\" self . model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = CatOrDog . learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) self . model . fit ( train_dataset , epochs = CatOrDog . num_epochs ) self . model . save_weights ( \"./ckpt/cat_or_dogs.h5\" ) \u6d4b\u8bd5\u8fc7\u7a0b 1\u3001\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u8bfb\u53d6\u6d4b\u8bd5\u6570\u636e\u53ca\u7684dataset\u6570\u636e\u96c6 2\u3001\u8fdb\u884cmodel\u7684\u9884\u6d4b\uff0c\u53ef\u4ee5\u5148\u8fdb\u884c\u6a21\u578b\u4fdd\u5b58\u4e4b\u540e\uff0c\u518d\u6b21\u8bfb\u53d6\u8fdb\u884c\u9884\u6d4b def test ( self ): # 1\u3001\u6784\u5efa\u6d4b\u8bd5\u6570\u636e\u96c6 test_cat_filenames = tf . constant ([ CatOrDog . test_cats_dir + filename for filename in os . listdir ( CatOrDog . test_cats_dir )]) test_dog_filenames = tf . constant ([ CatOrDog . test_dogs_dir + filename for filename in os . listdir ( CatOrDog . test_dogs_dir )]) test_filenames = tf . concat ([ test_cat_filenames , test_dog_filenames ], axis =- 1 ) test_labels = tf . concat ([ tf . zeros ( test_cat_filenames . shape , dtype = tf . int32 ), tf . ones ( test_dog_filenames . shape , dtype = tf . int32 )], axis =- 1 ) # 2\u3001\u6784\u5efadataset test_dataset = tf . data . Dataset . from_tensor_slices (( test_filenames , test_labels )) test_dataset = test_dataset . map ( _decode_and_resize ) test_dataset = test_dataset . batch ( batch_size ) # 3\u3001\u52a0\u8f7d\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30 if os . path . exists ( \"./ckpt/cat_or_dogs.h5\" ): self . model . load_weights ( \"./ckpt/cat_or_dogs.h5\" ) print ( self . model . metrics_names ) print ( self . model . evaluate ( test_dataset ))","title":"4.6.5 \u6848\u4f8b\uff1a\u5b9e\u73b0\u732b\u72d7\u56fe\u50cf\u5206\u7c7b"},{"location":"tensorFlow/section6/#466-imagedatagenerator","text":"\u5f53\u6211\u4eec\u9700\u8981\u505a\u6570\u636e\u589e\u5f3a\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u901a\u8fc7\u5b9e\u65f6\u6570\u636e\u589e\u5f3a\u751f\u6210\u5f20\u91cf\u56fe\u50cf\u6570\u636e\u6279\u6b21\u3002\u6570\u636e\u5c06\u4e0d\u65ad\u5faa\u73af\uff08\u6309\u6279\u6b21\uff09\u3002\u4e0b\u9762\u5c31\u4ecb\u7ecd\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5bf9\u4e8e\u63d0\u4f9b\u8fc7\u6765\u7684\u672c\u5730\u56fe\u7247\u8bfb\u53d6\u7684\u6570\u636e\u8fd8\u662f\u5176\u4ed6\u5de5\u5177\u8bfb\u53d6\u7684\u56fe\u7247\u6570\u636e\u8fdb\u884c\u5728\u7ebf\u6570\u636e\u600e\u5f3a\u3002","title":"4.6.6 ImageDataGenerator\u4ecb\u7ecd"},{"location":"tensorFlow/section6/#1","text":"tf . keras . preprocessing . image . ImageDataGenerator ( featurewise_center = False , samplewise_center = False , featurewise_std_normalization = False , samplewise_std_normalization = False , zca_whitening = False , zca_epsilon = 1e-06 , rotation_range = 0 , width_shift_range = 0.0 , height_shift_range = 0.0 , brightness_range = None , shear_range = 0.0 , zoom_range = 0.0 , channel_shift_range = 0.0 , fill_mode = 'nearest' , cval = 0.0 , horizontal_flip = False , vertical_flip = False , rescale = None , preprocessing_function = None , data_format = None , validation_split = 0.0 , dtype = None ) \u5b8c\u6574\u53c2\u6570\u4ecb\u7ecd\u53c2\u8003TensorFlow\u5b98\u7f51\u6587\u6863\uff1a https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#view-aliases train_generator = ImageDataGenerator() \u751f\u4ea7\u56fe\u7247\u7684\u6279\u6b21\u5f20\u91cf\u503c\u5e76\u4e14\u63d0\u4f9b\u6570\u636e\u589e\u5f3a\u529f\u80fd rescale=1.0 / 255,:\u6807\u51c6\u5316 zca_whitening=False: # zca\u767d\u5316\u7684\u4f5c\u7528\u662f\u9488\u5bf9\u56fe\u7247\u8fdb\u884cPCA\u964d\u7ef4\u64cd\u4f5c\uff0c\u51cf\u5c11\u56fe\u7247\u7684\u5197\u4f59\u4fe1\u606f rotation_range=20:\u9ed8\u8ba40\uff0c \u65cb\u8f6c\u89d2\u5ea6\uff0c\u5728\u8fd9\u4e2a\u89d2\u5ea6\u8303\u56f4\u968f\u673a\u751f\u6210\u4e00\u4e2a\u503c width_shift_range=0.2,:\u9ed8\u8ba40\uff0c\u6c34\u5e73\u5e73\u79fb height_shift_range=0.2:\u9ed8\u8ba40\uff0c \u5782\u76f4\u5e73\u79fb shear_range=0.2:# \u5e73\u79fb\u53d8\u6362 horizontal_flip=True:\u6c34\u5e73\u7ffb\u8f6c zoom_range:\u968f\u673a\u7f29\u653e\u7684\u8303\u56f4","title":"1\u3001\u8bad\u7ec3\u7684\u65f6\u5019\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u4ee5\u53ca\u7c7b\u522b"},{"location":"tensorFlow/section6/#2","text":"\u4f7f\u7528flow(x, y, batch_size) ( x_train , y_train ), ( x_test , y_test ) = cifar10 . load_data () datagen = ImageDataGenerator ( featurewise_center = True , featurewise_std_normalization = True , rotation_range = 20 , width_shift_range = 0.2 , height_shift_range = 0.2 , horizontal_flip = True ) for e in range ( epochs ): print ( 'Epoch' , e ) batches = 0 for x_batch , y_batch in datagen . flow ( x_train , y_train , batch_size = 32 ): model . fit ( x_batch , y_batch ) \u4f7f\u7528train_generator.flow_from_directory( directory=path,# \u8bfb\u53d6\u76ee\u5f55 target_size=(h,w),# \u76ee\u6807\u5f62\u72b6 batch_size=size,# \u6279\u6570\u91cf\u5927\u5c0f class_mode='binary', # \u76ee\u6807\u503c\u683c\u5f0f\uff0cOne of \"categorical\", \"binary\", \"sparse\", \"categorical\" \uff1a2D one-hot encoded labels \"binary\" will be 1D binary labels shuffle=True \u8fd9\u4e2aAPI\u56fa\u5b9a\u4e86\u8bfb\u53d6\u7684\u76ee\u5f55\u683c\u5f0f\uff0c\u53c2\u8003\uff1a python data/ train/ dogs/ dog001.jpg dog002.jpg ... cats/ cat001.jpg cat002.jpg ... validation/ dogs/ dog001.jpg dog002.jpg ... cats/ cat001.jpg cat002.jpg ...","title":"2\u3001\u4f7f\u7528\u65b9\u6cd5\u4ecb\u7ecd"},{"location":"tensorFlow/section6/#467-imagedatageneratorvgg","text":"","title":"4.6.7 \u6848\u4f8b\uff1aImageDataGenerator\u4e0e\u8fc1\u79fb\u5b66\u4e60\u7ed3\u5408\uff08\u57fa\u4e8eVGG\uff09"},{"location":"tensorFlow/section6/#4671","text":"Epoch 1 / 2 1 / 13 [ =>............................ ] - ETA : 3 : 20 - loss : 1.6811 - acc : 0.1562 2 / 13 [ ===>.......................... ] - ETA : 3 : 01 - loss : 1.5769 - acc : 0.2500 3 / 13 [ =====>........................ ] - ETA : 2 : 44 - loss : 1.4728 - acc : 0.3958 4 / 13 [ ========>..................... ] - ETA : 2 : 27 - loss : 1.3843 - acc : 0.4531 5 / 13 [ ==========>................... ] - ETA : 2 : 14 - loss : 1.3045 - acc : 0.4938 6 / 13 [ ============>................. ] - ETA : 1 : 58 - loss : 1.2557 - acc : 0.5156 7 / 13 [ ===============>.............. ] - ETA : 1 : 33 - loss : 1.1790 - acc : 0.5759 8 / 13 [ =================>............ ] - ETA : 1 : 18 - loss : 1.1153 - acc : 0.6211 9 / 13 [ ===================>.......... ] - ETA : 1 : 02 - loss : 1.0567 - acc : 0.6562 10 / 13 [ ======================>....... ] - ETA : 46 s - loss : 1.0043 - acc : 0.6875 11 / 13 [ ========================>..... ] - ETA : 31 s - loss : 0.9580 - acc : 0.7159 12 / 13 [ ==========================>... ] - ETA : 15 s - loss : 0.9146 - acc : 0.7344 13 / 13 [ ============================== ] - 249 s 19 s / step - loss : 0.8743 - acc : 0.7519 - val_loss : 0.3906 - val_acc : 0.9000 Epoch 2 / 2 1 / 13 [ =>............................ ] - ETA : 2 : 56 - loss : 0.3862 - acc : 1.0000 2 / 13 [ ===>.......................... ] - ETA : 2 : 44 - loss : 0.3019 - acc : 1.0000 3 / 13 [ =====>........................ ] - ETA : 2 : 35 - loss : 0.2613 - acc : 1.0000 4 / 13 [ ========>..................... ] - ETA : 2 : 01 - loss : 0.2419 - acc : 0.9844 5 / 13 [ ==========>................... ] - ETA : 1 : 49 - loss : 0.2644 - acc : 0.9688 6 / 13 [ ============>................. ] - ETA : 1 : 36 - loss : 0.2494 - acc : 0.9688 7 / 13 [ ===============>.............. ] - ETA : 1 : 24 - loss : 0.2362 - acc : 0.9732 8 / 13 [ =================>............ ] - ETA : 1 : 10 - loss : 0.2234 - acc : 0.9766 9 / 13 [ ===================>.......... ] - ETA : 58 s - loss : 0.2154 - acc : 0.9757 10 / 13 [ ======================>....... ] - ETA : 44 s - loss : 0.2062 - acc : 0.9781 11 / 13 [ ========================>..... ] - ETA : 29 s - loss : 0.2007 - acc : 0.9801 12 / 13 [ ==========================>... ] - ETA : 14 s - loss : 0.1990 - acc : 0.9792 13 / 13 [ ============================== ] - 243 s 19 s / step - loss : 0.1923 - acc : 0.9809 - val_loss : 0.1929 - val_acc : 0.9300","title":"4.6.7.1 \u6848\u4f8b\u6548\u679c"},{"location":"tensorFlow/section6/#4672","text":"\u6570\u636e\u96c6\u662f\u67d0\u573a\u666f\u4e0b5\u4e2a\u7c7b\u522b\u56fe\u7247\u7684\u8bc6\u522b \u6211\u4eec\u5229\u7528\u73b0\u6709\u7684VGG\u6a21\u578b\u53bb\u8fdb\u884c\u5fae\u8c03","title":"4.6.7.2 \u6570\u636e\u96c6\u4ee5\u53ca\u8fc1\u79fb\u9700\u6c42"},{"location":"tensorFlow/section6/#4673","text":"\u8bfb\u53d6\u672c\u5730\u7684\u56fe\u7247\u6570\u636e\u4ee5\u53ca\u7c7b\u522b keras.preprocessing.image import ImageDataGenerator\u63d0\u4f9b\u4e86\u8bfb\u53d6\u8f6c\u6362\u529f\u80fd \u6a21\u578b\u7684\u7ed3\u6784\u4fee\u6539\uff08\u6dfb\u52a0\u6211\u4eec\u81ea\u5b9a\u7684\u5206\u7c7b\u5c42\uff09 freeze\u6389\u539f\u59cbVGG\u6a21\u578b \u7f16\u8bd1\u4ee5\u53ca\u8bad\u7ec3\u548c\u4fdd\u5b58\u6a21\u578b\u65b9\u5f0f \u8f93\u5165\u6570\u636e\u8fdb\u884c\u9884\u6d4b","title":"4.6.7.3 \u601d\u8def\u548c\u6b65\u9aa4"},{"location":"tensorFlow/section6/#4674","text":"\u57fa\u4e8e\u4e0a\u9762\u5de5\u5177\u7684\u8bfb\u53d6\u4ee3\u7801 train_datagen = ImageDataGenerator ( rescale = 1. / 255 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( 'data/train' , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( 'data/validation' , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) # \u4f7f\u7528fit_generator model . fit_generator ( train_generator , steps_per_epoch = 2000 , epochs = 50 , validation_data = validation_generator , validation_steps = 800 ) \u4ee3\u7801\uff1a \u9996\u5148\u5bfc\u5165\u5305 import tensorflow as tf from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.applications.vgg16 import VGG16 import numpy as np import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" \u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u8fc1\u79fb\u5b66\u4e60\u7684\u7c7b\uff0c\u7136\u540e\u8fdb\u884c\u76f8\u5173\u5c5e\u6027\u8bbe\u7f6e\u548c\u8bfb\u53d6\u4ee3\u7801 class TransferModel ( object ): def __init__ ( self ): # \u5b9a\u4e49\u8bad\u7ec3\u548c\u6d4b\u8bd5\u56fe\u7247\u7684\u53d8\u5316\u65b9\u6cd5\uff0c\u6807\u51c6\u5316\u4ee5\u53ca\u6570\u636e\u589e\u5f3a self . train_generator = ImageDataGenerator ( rescale = 1.0 / 255.0 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ) self . test_generator = ImageDataGenerator ( rescale = 1.0 / 255.0 ) # \u6307\u5b9a\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u76ee\u5f55 self . train_dir = \"./data/train\" self . test_dir = \"./data/test\" # \u5b9a\u4e49\u56fe\u7247\u8bad\u7ec3\u76f8\u5173\u7f51\u7edc\u53c2\u6570 self . image_size = ( 224 , 224 ) self . batch_size = 32 def read_img_to_generator ( self ): \"\"\" \u8bfb\u53d6\u672c\u5730\u56fe\u7247\u4ee5\u53ca\u7c7b\u522b :return:\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u8fed\u4ee3\u5668 \"\"\" train_gen = self . train_generator . flow_from_directory ( directory = self . train_dir , target_size = self . model_size , batch_size = self . batch_size , class_mode = 'binary' , shuffle = True ) test_gen = self . test_generator . flow_from_directory ( directory = self . test_dir , target_size = self . model_size , batch_size = self . batch_size , class_mode = 'binary' , shuffle = True ) return train_gen , test_gen \u6253\u5370\u7ed3\u679c\u4e3a < keras_preprocessing . image . DirectoryIterator object at 0x12f52cf28 >","title":"4.6.7.4  \u8bad\u7ec3\u7684\u65f6\u5019\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u4ee5\u53ca\u7c7b\u522b"},{"location":"tensorFlow/section6/#4675-vgg-globalaveragepooling2d","text":"notop\u6a21\u578b\uff1a \u662f\u5426\u5305\u542b\u6700\u540e\u76843\u4e2a\u5168\u8fde\u63a5\u5c42\uff08whether to include the 3 fully-connected layers at the top of the network\uff09\u3002\u7528\u6765\u505afine-tuning\u4e13\u7528\uff0c\u4e13\u95e8\u5f00\u6e90\u4e86\u8fd9\u7c7b\u6a21\u578b\u3002 \u2018weights='imagenet'\u2019\uff0c\u610f\u601d\u662fVGG\u5728imagenet\u6bd4\u8d5b\u4e2d\u9884\u8bad\u7ec3\u7684\u6743\u91cd\uff0c\u4f7f\u7528resnet\u8bad\u7ec3 # \u5728__init__\u4e2d\u6dfb\u52a0 self . base_model = VGG16 ( weights = 'imagenet' , include_top = False ) base_model\u4f1a\u6709\u76f8\u5173\u5c5e\u6027\uff0c\u6a21\u578b\u7684\u8f93\u5165\u7ed3\u6784\uff1ainputs\uff0c\u6a21\u578b\u7684\u8f93\u51fa\u7ed3\u6784\uff0c\u6211\u4eec\u4fee\u6539\u9700\u8981\u5f97\u5230\u5df2\u6709VGG\u7684\u8f93\u5165\u548c\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u8f93\u51fa\u6784\u5efa\u6210\u4e00\u4e2a\u65b0\u7684\u6a21\u578b\u3002 \u6a21\u578b\u6e90\u7801\uff1a if include_top : # Classification block x = layers . Flatten ( name = 'flatten' )( x ) x = layers . Dense ( 4096 , activation = 'relu' , name = 'fc1' )( x ) x = layers . Dense ( 4096 , activation = 'relu' , name = 'fc2' )( x ) x = layers . Dense ( classes , activation = 'softmax' , name = 'predictions' )( x ) else : if pooling == 'avg' : x = layers . GlobalAveragePooling2D ()( x ) elif pooling == 'max' : x = layers . GlobalMaxPooling2D ()( x ) \u4e00\u4e2aGlobalAveragePooling2D + \u4e24\u4e2a\u5168\u8fde\u63a5\u5c42 \u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u7ecf\u8fc7\u6700\u540eCNN\u5c42\u540e\u7684\u5c3a\u5bf8\u4e3a[bath_size, img_width, img_height, channels]\uff0c\u901a\u5e38\u7684\u505a\u6cd5\u662f\uff1a\u63a5\u4e00\u4e2aflatten layer\uff0c\u5c06\u5c3a\u5bf8\u53d8\u4e3a[batch_size, w * h * channels]\u518d\u81f3\u5c11\u63a5\u4e00\u4e2aFC layer\uff0c\u8fd9\u6837\u505a\u7684\u6700\u5927\u95ee\u9898\u662f\uff1a \u6a21\u578b\u53c2\u6570\u591a\uff0c\u4e14\u5bb9\u6613\u8fc7\u62df\u5408\u3002 \u5229\u7528pooling layer\u6765\u66ff\u4ee3\u6700\u540e\u7684FC layer \u89e3\u91ca\u5982\u4e0b\uff1a from keras.layers import Dense , Input , Conv2D from keras.layers import MaxPooling2D , GlobalAveragePooling2D x = Input ( shape = [ 8 , 8 , 2048 ]) # \u5047\u5b9a\u6700\u540e\u4e00\u5c42CNN\u7684\u5c42\u8f93\u51fa\u4e3a(None, 8, 8, 2048) x = GlobalAveragePooling2D ( name = 'avg_pool' )( x ) # shape=(?, 2048) # \u53d6\u6bcf\u4e00\u4e2a\u7279\u5f81\u56fe\u7684\u5e73\u5747\u503c\u4f5c\u4e3a\u8f93\u51fa\uff0c\u7528\u4ee5\u66ff\u4ee3\u5168\u8fde\u63a5\u5c42 x = Dense ( 1000 , activation = 'softmax' , name = 'predictions' )( x ) # shape=(?, 1000) # 1000\u4e3a\u7c7b\u522b 5\u7c7b\u56fe\u7247\u8bc6\u522b\u6a21\u578b\u4fee\u6539 \u6211\u4eec\u9700\u8981\u62ff\u5230\u57fa\u7840VGG\u6a21\u578b\uff0c\u5e76\u4e14VGG\u63d0\u4f9b\u6240\u6709\u5c42\u53c2\u6570\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u548c\u6ca1\u6709\u5168\u8fde\u63a5\u5c42\u53c2\u6570\u7684\u6a21\u578bnotop\u6a21\u578b from tensorflow.keras import Model def refine_base_model ( self ): \"\"\" \u5fae\u8c03VGG\u7ed3\u6784\uff0c5blocks\u540e\u9762+\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff08\u51cf\u5c11\u8fc1\u79fb\u5b66\u4e60\u7684\u53c2\u6570\u6570\u91cf\uff09+\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42 :return: \"\"\" # 1\u3001\u83b7\u53d6\u539fnotop\u6a21\u578b\u5f97\u51fa # [?, ?, ?, 512] x = self . base_model . outputs [ 0 ] # 2\u3001\u5728\u8f93\u51fa\u540e\u9762\u589e\u52a0\u6211\u4eec\u7ed3\u6784 # [?, ?, ?, 512]---->[?, 1 * 1 * 512] x = tf . keras . layers . GlobalAveragePooling2D ()( x ) # 3\u3001\u5b9a\u4e49\u65b0\u7684\u8fc1\u79fb\u6a21\u578b x = tf . keras . layers . Dense ( 1024 , activation = tf . nn . relu )( x ) y_predict = tf . keras . layers . Dense ( 5 , activation = tf . nn . softmax )( x ) # model\u5b9a\u4e49\u65b0\u6a21\u578b # VGG \u6a21\u578b\u7684\u8f93\u5165\uff0c \u8f93\u51fa\uff1ay_predict transfer_model = tf . keras . models . Model ( inputs = self . base_model . inputs , outputs = y_predict ) return transfer_model","title":"4.6.7.5 VGG\u6a21\u578b\u7684\u4fee\u6539\u6dfb\u52a0\u5168\u8fde\u63a5\u5c42-GlobalAveragePooling2D"},{"location":"tensorFlow/section6/#4676-freeze-vgg","text":"\u76ee\u7684\uff1a\u8ba9VGG\u7ed3\u6784\u5f53\u4e2d\u7684\u6743\u91cd\u53c2\u6570\u4e0d\u53c2\u4e0e\u8bad\u7ec3,\u53ea\u8bad\u7ec3\u6211\u4eec\u6dfb\u52a0\u7684\u6700\u540e\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u6743\u91cd\u53c2\u6570 \u901a\u8fc7\u4f7f\u7528\u6bcf\u4e00\u5c42\u7684layer.trainable=False def freeze_vgg_model ( self ): \"\"\" freeze\u6389VGG\u7684\u7ed3\u6784 :return: \"\"\" for layer in self . base_model . layers : layer . trainable = False","title":"4.6.7.6 freeze VGG\u6a21\u578b\u7ed3\u6784"},{"location":"tensorFlow/section6/#4677","text":"\u7f16\u8bd1 \u540c\u6837\u8fd8\u662f\u8fdb\u884c\u7f16\u8bd1\uff0c \u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7b97\u6cd5\uff1a\u5b66\u4e60\u7387\u521d\u59cb\u5316\u8f83\u5c0f\u7684\u503c\uff0c0.001,0.0001\uff0c\u56e0\u4e3a\u5df2\u7ecf\u5728\u5df2\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u57fa\u7840\u4e4b\u4e0a\u66f4\u65b0\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u592a\u5927\u5b66\u4e60\u7387\u53bb\u5b66\u4e60 def compile ( self , model ): \"\"\" \u7f16\u8bd1\u6a21\u578b :return: \"\"\" model . compile ( optimizer = tf . keras . optimizers . Adam (), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ 'accuracy' ]) return None def fit_generator ( self , model , train_gen , test_gen ): \"\"\" \u8bad\u7ec3\u6a21\u578b\uff0cmodel.fit_generator()\u4e0d\u662f\u9009\u62e9model.fit() :return: \"\"\" # \u6bcf\u4e00\u6b21\u8fed\u4ee3\u51c6\u786e\u7387\u8bb0\u5f55\u7684h5\u6587\u4ef6 modelckpt = tf . keras . callbacks . ModelCheckpoint ( './ckpt/transfer_{epoch:02d}-{val_accuracy:.2f}.h5' , monitor = 'val_accuracy' , save_best_only = True , save_weights_only = False , mode = 'auto' , period = 1 ) model . fit_generator ( train_gen , epochs = 3 , validation_data = test_gen , callbacks = [ modelckpt ]) return None main\u51fd\u6570 if __name__ == '__main__' : tm = TransferModel () train_gen , test_gen = tm . read_img_to_generator () model = tm . refine_vgg_model () tm . freeze_vgg_model () tm . compile ( model ) tm . fit ( model , train_gen , test_gen )","title":"4.6.7.7 \u7f16\u8bd1\u548c\u8bad\u7ec3"},{"location":"tensorFlow/section6/#4678","text":"\u9884\u6d4b\u7684\u6b65\u9aa4\u5c31\u662f\u8bfb\u53d6\u56fe\u7247\u4ee5\u53ca\u5904\u7406\u5230\u6a21\u578b\u4e2d\u9884\u6d4b\uff0c\u52a0\u8f7d\u6211\u4eec\u8bad\u7ec3\u7684\u6a21\u578b def predict ( self , model ): \"\"\"\u9884\u6d4b\u8f93\u5165\u56fe\u7247\u7684\u7c7b\u522b :return: \"\"\" # 1\u3001\u52a0\u8f7d\u6a21\u578b\u8bad\u7ec3\u597d\u7684\u6743\u91cd model . load_weights ( \"./ckpt/transfer_01-0.84.h5\" ) # 2\u3001\u8bfb\u53d6\u56fe\u7247\u5904\u7406\u56fe\u7247\u6570\u636e\uff0c\u5f62\u72b6\uff0c\u6570\u636e\u5f52\u4e00\u5316 image = tf . io . read_file ( \"./data/test/dinosaurs/402.jpg\" ) image_decoded = tf . image . decode_jpeg ( image ) image_resized = tf . image . resize ( image_decoded , [ 224 , 224 ]) / 255.0 # 3\u7ef4-->4\u7ef4\u7684\u5f62\u72b6\u6539\u53d8 img = tf . reshape ( image_resized , ( 1 , image_resized . shape [ 0 ], image_resized . shape [ 1 ], image_resized . shape [ 2 ])) print ( \"\u4fee\u6539\u4e4b\u540e\u7684\u5f62\u72b6\uff1a\" , img . shape ) # 3\u3001\u8f93\u5165\u6570\u636e\u505a\u9884\u6d4b y_predict = model . predict ( img ) index = np . argmax ( y_predict , axis = 1 ) print ( self . label_dict [ str ( index [ 0 ])]) return None \u5efa\u7acb\u56fe\u7247\u7c7b\u522b\u7684\u5b57\u5178 self . label_dict = { '0' : 'bus' , '1' : 'dinosaurs' , '2' : 'elephants' , '3' : 'flowers' , '4' : 'horse' }","title":"4.6.7.8 \u8fdb\u884c\u9884\u6d4b"},{"location":"tensorFlow/section6/#466","text":"Checkpoint\u4f7f\u7528 TensorBoard\u4f7f\u7528 tf.data\u6a21\u5757\u4f7f\u7528 ImageDataGenerator\u7684\u4f7f\u7528","title":"4.6.6 \u603b\u7ed3"},{"location":"tensorFlow/section7/","text":"4.7 Tensorflow\u6267\u884c\u6a21\u5f0f \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b \u5e94\u7528 \u65e0 4.7.1 Eager Execution\u4e0eGraph Execution \u00b6 4.7.1.1 Graph Execution\uff08\u56fe\u6a21\u5f0f\uff09 \u00b6 \u7279\u70b9: \u9884\u5148\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u8fd0\u884c\u65f6\u53cd\u590d\u4f7f\u7528\uff0c\u4e0d\u80fd\u6539\u53d8 \u901f\u5ea6\u66f4\u5feb\uff0c\u9002\u5408\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u5e73\u53f0 TensorFlow \u7684\u56fe\u6267\u884c\u6a21\u5f0f\u662f\u4e00\u4e2a\u7b26\u53f7\u5f0f\u7684\uff08\u57fa\u4e8e\u8ba1\u7b97\u56fe\u7684\uff09\u8ba1\u7b97\u6846\u67b6\u3002\u7b80\u800c\u8a00\u4e4b\uff0c\u5982\u679c\u4f60\u9700\u8981\u8fdb\u884c\u4e00\u7cfb\u5217\u8ba1\u7b97\uff0c\u5219\u9700\u8981\u4f9d\u6b21\u8fdb\u884c\u5982\u4e0b\u4e24\u6b65\uff1a 1\u3001\u5efa\u7acb\u4e00\u4e2a \u201c\u8ba1\u7b97\u56fe\u201d\uff0c\u8fd9\u4e2a\u56fe\u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u8f93\u5165\u6570\u636e\u901a\u8fc7\u4e00\u7cfb\u5217\u8ba1\u7b97\u800c\u5f97\u5230\u8f93\u51fa\uff1b 2\u3001\u5efa\u7acb\u4e00\u4e2a\u4f1a\u8bdd\uff0c\u5e76\u5728\u4f1a\u8bdd\u4e2d\u4e0e\u8ba1\u7b97\u56fe\u8fdb\u884c\u4ea4\u4e92\uff0c\u5373\u5411\u8ba1\u7b97\u56fe\u4f20\u5165\u8ba1\u7b97\u6240\u9700\u7684\u6570\u636e\uff0c\u5e76\u4ece\u8ba1\u7b97\u56fe\u4e2d\u83b7\u53d6\u7ed3\u679c\u3002 Session \u7528\u6765**\u7ed9\u5b9a Graph \u7684\u8f93\u5165\uff0c\u6307\u5b9a Graph \u4e2d\u7684\u7ed3\u679c\u83b7\u53d6\u65b9\u5f0f\uff0c \u5e76\u542f\u52a8\u6570\u636e\u5728 Graph \u4e2d\u7684\u6d41\u52a8** \u62e5\u6709\u5e76\u7ba1\u7406 Tensorflow \u7a0b\u5e8f\u8fd0\u884c\u65f6\u7684\u6240\u6709\u8d44\u6e90\uff0c\u8d44\u6e90\u5305\u62ec:\u786c\u4ef6(CPU,GPU)\uff0c\u6570\u636e \u4f7f\u7528\u8ba1\u7b97\u56fe\u4e0e\u4f1a\u8bdd\u8fdb\u884c\u57fa\u672c\u8fd0\u7b97\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u6700\u57fa\u672c\u7684\u8fd0\u7b97\u793a\u4f8b\u3002 import tensorflow.compat.v1 as tf tf . disable_eager_execution () # 1\u3001\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u201c\u8ba1\u7b97\u56fe\u201d a = tf . constant ( 1 ) b = tf . constant ( 1 ) # \u7b49\u4ef7\u4e8e c = tf.add(a, b)\uff0cc\u662f\u5f20\u91cfa\u548c\u5f20\u91cfb\u901a\u8fc7 tf.add \u8fd9\u4e00\u64cd\u4f5c\uff08Operation\uff09\u6240\u5f62\u6210\u7684\u65b0\u5f20\u91cf c = a + b # 2\u3001# \u5b9e\u4f8b\u5316\u4e00\u4e2a\u4f1a\u8bdd\uff08Session\uff09 # \u901a\u8fc7\u4f1a\u8bdd\u7684 run() \u65b9\u6cd5\u5bf9\u8ba1\u7b97\u56fe\u91cc\u7684\u8282\u70b9\uff08\u5f20\u91cf\uff09\u8fdb\u884c\u5b9e\u9645\u7684\u8ba1\u7b97 sess = tf . Session () c_ = sess . run ( c ) print ( c_ ) \u6ce8\uff1a\u4e3a\u4e86\u4f7f\u7528\u56fe\u6267\u884c\u6a21\u5f0f\uff0c\u9700\u8981\u4f7f\u7528 TensorFlow 1.X \u7684 API \u8fdb\u884c\u64cd\u4f5c\uff0c\u6240\u4ee5\u4f7f\u7528 import tensorflow.compat.v1 as tf \u5bfc\u5165 TensorFlow\uff0c\u5e76\u901a\u8fc7 tf.disable_eager_execution() \u7981\u7528\u9ed8\u8ba4\u7684\u5373\u65f6\u6267\u884c\u6a21\u5f0f\u3002 4.7.1.2 Eager Execution\uff08\u52a8\u6001\u56fe\u6a21\u5f0f\uff09 \u00b6 eager \u6a21\u5f0f\u662f\u5728 TF 1.4 \u7248\u672c\u4e4b\u540e\u5f15\u5165\u7684\uff0c\u5728 TF 2.0\u4e4b\u540e\u5c06\u4f1a\u628a eager \u6a21\u5f0f\u53d8\u4e3a\u9ed8\u8ba4\u6267\u884c\u6a21\u5f0f\u3002TensorFlow 2.0 \u4e2d\u7684 Eager Execution \u662f\u4e00\u79cd\u547d\u4ee4\u5f0f\u7f16\u7a0b\u73af\u5883\uff0c\u53ef\u7acb\u5373\u8bc4\u4f30\u64cd\u4f5c\uff0c\u65e0\u9700\u6784\u5efa\u56fe\uff1a\u64cd\u4f5c\u4f1a\u8fd4\u56de\u5177\u4f53\u7684\u503c\uff0c\u800c\u4e0d\u662f\u6784\u5efa\u4ee5\u540e\u518d\u8fd0\u884c\u7684\u8ba1\u7b97\u56fe\u3002 Eager Execution \u7684\u4f18\u70b9\u5982\u4e0b\uff1a 1\u3001\u5feb\u901f\u8c03\u8bd5\u5373\u523b\u7684\u8fd0\u884c\u9519\u8bef\u5e76\u901a\u8fc7 Python \u5de5\u5177\u8fdb\u884c\u6574\u5408 2\u3001\u501f\u52a9\u6613\u4e8e\u4f7f\u7528\u7684 Python \u63a7\u5236\u6d41\u652f\u6301\u52a8\u6001\u6a21\u578b 3\u3001\u4e3a\u81ea\u5b9a\u4e49\u548c\u9ad8\u9636\u68af\u5ea6\u63d0\u4f9b\u5f3a\u5927\u652f\u6301 4\u3001\u9002\u7528\u4e8e\u51e0\u4e4e\u6240\u6709\u53ef\u7528\u7684 TensorFlow \u8fd0\u7b97 TensorFlow 2.0\u5f15\u5165\u7684eager\u63d0\u9ad8\u4e86\u4ee3\u7801\u7684\u7b80\u6d01\u6027\uff0c\u800c\u4e14\u66f4\u5bb9\u6613debug\u3002**\u4f46\u662f\u5bf9\u4e8e\u6027\u80fd\u6765\u8bf4\uff0ceager\u6267\u884c\u76f8\u6bd4Graph\u6a21\u5f0f\u4f1a\u6709\u4e00\u5b9a\u7684\u635f\u5931\u3002\u6bd5\u7adf\u539f\u751f\u7684Graph\u6a21\u5f0f\u662f\u5148\u6784\u5efa\u597d\u9759\u6001\u56fe\uff0c\u7136\u540e\u624d\u771f\u6b63\u6267\u884c\u3002\u8fd9\u5bf9\u4e8e \u5728\u5206\u5e03\u5f0f\u8bad\u7ec3\u3001\u6027\u80fd\u4f18\u5316\u548c\u751f\u4ea7\u90e8\u7f72\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002**\u4f46\u662f\u597d\u5728\uff0cTensorFlow 2.0\u5f15\u5165\u4e86tf.function\u548cAutoGraph\u6765\u7f29\u5c0feager\u6267\u884c\u548cGraph\u6a21\u5f0f\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5176\u6838\u5fc3\u662f\u5c06\u4e00\u7cfb\u5217\u7684Python\u8bed\u6cd5\u8f6c\u5316\u4e3a\u9ad8\u6027\u80fd\u7684graph\u64cd\u4f5c\u3002 \u6ce8\uff1a\u5b9e\u9645\u4e0a\uff0cEager Execution \u5728 1.x \u7684\u540e\u671f\u7248\u672c\u4e2d\u4e5f\u5b58\u5728\uff0c\u4f46\u9700\u8981\u5355\u72ec\u6267\u884c tf.enable_eager_execution() \u8fdb\u884c\u624b\u52a8\u542f\u7528\u3002 4.7.2 @tf.function\u5b9e\u73b0Graph Execution \u6a21\u5f0f \u00b6 \u5728 TensorFlow 2.0 \u4e2d\uff0c\u63a8\u8350\u4f7f\u7528 @tf.function \uff08\u800c\u975e 1.X \u4e2d\u7684 tf.Session \uff09\u5b9e\u73b0 Graph Execution\uff0c\u4ece\u800c\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u6613\u4e8e\u90e8\u7f72\u4e14\u9ad8\u6027\u80fd\u7684 TensorFlow \u56fe\u6a21\u578b\u3002\u53ea\u9700\u8981\u5c06\u6211\u4eec\u5e0c\u671b\u4ee5 Graph Execution \u6a21\u5f0f\u8fd0\u884c\u7684\u4ee3\u7801\u5c01\u88c5\u5728\u4e00\u4e2a\u51fd\u6570\u5185\uff0c\u5e76\u5728\u51fd\u6570\u524d\u52a0\u4e0a @tf.function \u5373\u53ef\u3002 \u4e0a\u9762\u4f8b\u5b50\u4ee3\u7801\uff0c\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e tf.function \u7684\u4ee3\u7801\u7b49\u4ef7\u53bb\u6267\u884c\u56fe\u6a21\u5f0f\uff1a import tensorflow as tf @tf.function def graph (): a = tf . constant ( 1 ) # \u5b9a\u4e49\u4e00\u4e2a\u5e38\u91cf\u5f20\u91cf\uff08Tensor\uff09 b = tf . constant ( 1 ) c = a + b return c c_ = graph () print ( c_ . numpy ()) \u5e76\u4e0d\u662f\u4efb\u4f55\u51fd\u6570\u90fd\u53ef\u4ee5\u88ab @tf.function \u4fee\u9970\uff01@tf.function \u4f7f\u7528\u9759\u6001\u7f16\u8bd1\u5c06\u51fd\u6570\u5185\u7684\u4ee3\u7801\u8f6c\u6362\u6210\u8ba1\u7b97\u56fe\uff0c\u56e0\u6b64\u5bf9\u51fd\u6570\u5185\u53ef\u4f7f\u7528\u7684\u8bed\u53e5\u6709\u4e00\u5b9a\u9650\u5236\uff0c\u4e14\u9700\u8981\u51fd\u6570\u5185\u7684\u64cd\u4f5c\u672c\u8eab\u80fd\u591f\u88ab\u6784\u5efa\u4e3a\u8ba1\u7b97\u56fe\u3002 \u5efa\u8bae\u5728\u51fd\u6570\u5185\u53ea\u4f7f\u7528TensorFlow \u7684\u539f\u751f\u64cd\u4f5c\uff0c\u4e0d\u8981\u4f7f\u7528\u8fc7\u4e8e\u590d\u6742\u7684 Python \u8bed\u53e5\uff0c\u51fd\u6570\u53c2\u6570\u53ea\u5305\u62ec TensorFlow \u5f20\u91cf\u6216 NumPy \u6570\u7ec4\uff0c\u5e76\u6700\u597d\u662f\u80fd\u591f\u6309\u7167\u8ba1\u7b97\u56fe\u7684\u601d\u60f3\u53bb\u6784\u5efa\u51fd\u6570\u3002 import tensorflow as tf @tf.function def train_one_step ( X , y ): with tf . GradientTape () as tape : y_pred = model ( X ) loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y , y_pred = y_pred ) loss = tf . reduce_mean ( loss ) # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u4e86TensorFlow\u5185\u7f6e\u7684tf.print() # @tf.function\u4e0d\u652f\u6301Python\u5185\u7f6e\u7684print\u65b9\u6cd5\u53bb\u5f53\u505a\u8ba1\u7b97\u8282\u70b9 tf . print ( \"loss\" , loss ) grads = tape . gradient ( loss , model . variables ) optimizer . apply_gradients ( grads_and_vars = zip ( grads , model . variables )) if __name__ == '__main__' : model = CNN () optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ) start_time = time . time () for batch_index in range ( num_batches ): X , y = data_loader . get_batch ( batch_size ) train_one_step ( X , y ) end_time = time . time () print ( end_time - start_time ) 4.7.2.2 @tf.function \u673a\u5236\u539f\u7406 \u00b6 \u5f53\u88ab @tf.function \u4fee\u9970\u7684\u51fd\u6570\u7b2c\u4e00\u6b21\u88ab\u8c03\u7528\u7684\u65f6\u5019\uff0c\u8fdb\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a 1\u3001\u5728 Eager Execution \u6a21\u5f0f\u5173\u95ed\u7684\u73af\u5883\u4e0b\uff0c\u51fd\u6570\u5185\u7684\u4ee3\u7801\u4f9d\u6b21\u8fd0\u884c\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u6bcf\u4e2a tf. \u65b9\u6cd5\u90fd\u53ea\u662f\u5b9a\u4e49\u4e86\u8ba1\u7b97\u8282\u70b9\uff0c\u800c\u5e76\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u5b9e\u8d28\u7684\u8ba1\u7b97\u3002\u8fd9\u4e0e TensorFlow 1.X \u7684 Graph Execution \u662f\u4e00\u81f4\u7684\uff1b 2\u3001\u4f7f\u7528 AutoGraph \u5c06\u51fd\u6570\u4e2d\u7684 Python \u63a7\u5236\u6d41\u8bed\u53e5\u8f6c\u6362\u6210 TensorFlow \u8ba1\u7b97\u56fe\u4e2d\u7684\u5bf9\u5e94\u8282\u70b9\uff08\u6bd4\u5982\u8bf4 while \u548c for \u8bed\u53e5\u8f6c\u6362\u4e3a tf.while \uff0c if \u8bed\u53e5\u8f6c\u6362\u4e3a tf.cond \u7b49\u7b49\uff1b 3\u3001\u57fa\u4e8e\u4e0a\u9762\u7684\u4e24\u6b65\uff0c\u5efa\u7acb\u51fd\u6570\u5185\u4ee3\u7801\u7684\u8ba1\u7b97\u56fe\u8868\u793a\uff1b\u7136\u540e\u8fd0\u884c\u4e00\u6b21\u8fd9\u4e2a\u8ba1\u7b97\u56fe\uff1b \u57fa\u4e8e\u51fd\u6570\u7684\u540d\u5b57\u548c\u8f93\u5165\u7684\u51fd\u6570\u53c2\u6570\u7684\u7c7b\u578b\u751f\u6210\u4e00\u4e2a\u54c8\u5e0c\u503c\uff0c\u5e76\u5c06\u5efa\u7acb\u7684\u8ba1\u7b97\u56fe\u7f13\u5b58\u5230\u4e00\u4e2a\u54c8\u5e0c\u8868\u4e2d\u3002 \u5982\u679c\u5728\u88ab @tf.function \u4fee\u9970\u7684\u51fd\u6570\u4e4b\u540e\u518d\u6b21\u88ab\u8c03\u7528\u7684\u65f6\u5019\uff0c\u6839\u636e\u51fd\u6570\u540d\u548c\u8f93\u5165\u7684\u51fd\u6570\u53c2\u6570\u7684\u7c7b\u578b\u8ba1\u7b97\u54c8\u5e0c\u503c\uff0c\u68c0\u67e5\u54c8\u5e0c\u8868\u4e2d\u662f\u5426\u5df2\u7ecf\u6709\u4e86\u5bf9\u5e94\u8ba1\u7b97\u56fe\u7684\u7f13\u5b58\u3002\u5982\u679c\u662f\uff0c\u5219\u76f4\u63a5\u4f7f\u7528\u5df2\u7f13\u5b58\u7684\u8ba1\u7b97\u56fe\uff0c\u5426\u5219\u91cd\u65b0\u6309\u4e0a\u8ff0\u6b65\u9aa4\u5efa\u7acb\u8ba1\u7b97\u56fe\u3002 1\u3001\u4f7f\u7528\u4e0b\u9762\u4f8b\u5b50\u4f53\u73b0tf.function\u6574\u4e2a\u8ba1\u7b97\u6b65\u9aa4\uff1a \u00b6 import tensorflow as tf import numpy as np @tf.function def f ( x ): # \u6ce8\u610f\u8fd9\u91cc\u662fprint\uff0c\u4e0d\u662ftf.print print ( \"The function is running in Python\" ) tf . print ( x ) # \u8fd0\u884c\u8fc7\u7a0b a = tf . constant ( 1 , dtype = tf . int32 ) f ( a ) b = tf . constant ( 2 , dtype = tf . int32 ) f ( b ) b_array = np . array ( 2 , dtype = np . int32 ) f ( b_array ) c = tf . constant ( 0.1 , dtype = tf . float32 ) f ( c ) d = tf . constant ( 0.2 , dtype = tf . float32 ) f ( d ) # \u5bf9\u4e8ePython\u7684\u7c7b\u578b f ( 1 ) f ( 2 ) f ( 1 ) \u4e0a\u8ff0\u7a0b\u5e8f\u7684\u8ba1\u7b97\u7ed3\u679c\u662f\uff1f\u7b54\u6848\u662f: # Tensor\u7c7b\u578b The function is running in Python 1 2 2 The function is running in Python 0.1 0.2 # Python\u7c7b\u578b The function is running in Python 1 The function is running in Python 2 1 \u5f53\u8ba1\u7b97 f(a) \u65f6\uff0c\u7531\u4e8e\u662f\u7b2c\u4e00\u6b21\u8c03\u7528\u8be5\u51fd\u6570\uff0cTensorFlow \u8fdb\u884c\u4e86\u4ee5\u4e0b\u64cd\u4f5c\uff1a 1\u3001\u5c06\u51fd\u6570\u5185\u7684\u4ee3\u7801\u4f9d\u6b21\u8fd0\u884c\u4e86\u4e00\u904d\uff1b 2\u3001\u6784\u5efa\u4e86\u8ba1\u7b97\u56fe\uff0c\u7136\u540e\u8fd0\u884c\u4e86\u4e00\u6b21\u8be5\u8ba1\u7b97\u56fe\uff08\u56e0\u6b64\u8f93\u51fa\u4e86 1\uff09\u3002\u8fd9\u91cc tf.print(x) \u53ef\u4ee5\u4f5c\u4e3a\u8ba1\u7b97\u56fe\u7684\u8282\u70b9\uff0c\u4f46 Python \u5185\u7f6e\u7684 print \u5219\u4e0d\u80fd\u88ab\u8f6c\u6362\u6210\u8ba1\u7b97\u56fe\u7684\u8282\u70b9\u3002 3\u3001\u5c06\u8be5\u8ba1\u7b97\u56fe\u7f13\u5b58\u5230\u4e86\u4e00\u4e2a\u54c8\u5e0c\u8868\u4e2d\uff08\u5982\u679c\u4e4b\u540e\u518d\u6709\u7c7b\u578b\u4e3a tf.int32 \uff0cshape \u4e3a\u7a7a\u7684\u5f20\u91cf\u8f93\u5165\uff0c\u5219\u91cd\u590d\u4f7f\u7528\u5df2\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\uff09\u3002 \u63a5\u4e0b\u6765\u7b2c\u4e8c\u6b21\u8ba1\u7b97\u4e4b\u540e \u4e00\u3001\u8ba1\u7b97 f(b) \u65f6\uff0c\u7531\u4e8e b \u7684\u7c7b\u578b\u4e0e a \u76f8\u540c\uff0c\u6240\u4ee5 TensorFlow \u91cd\u590d\u4f7f\u7528\u4e86\u4e4b\u524d\u5df2\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\u5e76\u8fd0\u884c\uff08\u56e0\u6b64\u8f93\u51fa\u4e86 2\uff09\u3002\u8fd9\u91cc\u7531\u4e8e\u5e76\u6ca1\u6709\u771f\u6b63\u5730\u9010\u884c\u8fd0\u884c\u51fd\u6570\u4e2d\u7684\u4ee3\u7801\uff0c\u6240\u4ee5\u51fd\u6570\u7b2c\u4e00\u884c\u7684\u6587\u672c\u8f93\u51fa\u4ee3\u7801\u6ca1\u6709\u8fd0\u884c\u3002\u8ba1\u7b97 f(b_array) \u65f6\uff0cTensorFlow \u81ea\u52a8\u5c06 numpy \u7684\u6570\u636e\u7ed3\u6784\u8f6c\u6362\u6210\u4e86 TensorFlow \u4e2d\u7684\u5f20\u91cf\uff0c\u56e0\u6b64\u4f9d\u7136\u80fd\u591f\u590d\u7528\u4e4b\u524d\u5df2\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\u3002 \u4e8c\u3001\u8ba1\u7b97 f\u00a9 \u65f6\uff0c\u867d\u7136\u5f20\u91cf c \u7684 shape \u548c a \u3001 b \u5747\u76f8\u540c\uff0c\u4f46\u7c7b\u578b\u4e3a tf.float32 \uff0c\u56e0\u6b64 TensorFlow \u91cd\u65b0\u8fd0\u884c\u4e86\u51fd\u6570\u5185\u4ee3\u7801\uff08\u4ece\u800c\u518d\u6b21\u8f93\u51fa\u4e86\u6587\u672c\uff09\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u8f93\u5165\u4e3a tf.float32 \u7c7b\u578b\u7684\u8ba1\u7b97\u56fe\u3002 \u4e09\u3001\u8ba1\u7b97 f(d) \u65f6\uff0c\u7531\u4e8e d \u548c c \u7684\u7c7b\u578b\u76f8\u540c\uff0c\u6240\u4ee5 TensorFlow \u590d\u7528\u4e86\u8ba1\u7b97\u56fe\uff0c\u540c\u7406\u6ca1\u6709\u8f93\u51fa\u6587\u672c\u3002 \u95ee\u9898\uff1a\u5982\u679c\u6253\u5370\u5b57\u7b26\u4e32\u7684print()\u66ff\u6362\u6210tf.print()\uff0c\u7ed3\u679c\u4f1a\u662f\uff1f \u00b6 \u6b63\u5e38\u7684\u6309\u7167\u987a\u5e8f\u8f93\u51fa\uff1a The function is running in Python 1 The function is running in Python 2 The function is running in Python 2 The function is running in Python 0.1 The function is running in Python 0.2 The function is running in Python 1 The function is running in Python 2 The function is running in Python 1 \u603b\u7ed3\uff1a\u4e4b\u540e\u7684\u8ba1\u7b97\u7ed3\u679c\u5219\u663e\u793a\u51fa @tf.function \u5bf9 Python \u5185\u7f6e\u7684\u6574\u6570\u548c\u6d6e\u70b9\u6570\u7c7b\u578b\u7684\u5904\u7406\u65b9\u5f0f\u3002**\u53ea\u6709\u5f53\u503c\u5b8c\u5168\u4e00\u81f4\u7684\u65f6\u5019\uff0c @tf.function \u624d\u4f1a\u590d\u7528\u4e4b\u524d\u5efa\u7acb\u7684\u8ba1\u7b97\u56fe\uff0c\u800c\u5e76\u4e0d\u4f1a\u81ea\u52a8\u5c06 Python \u5185\u7f6e\u7684\u6574\u6570\u6216\u6d6e\u70b9\u6570\u7b49\u8f6c\u6362\u6210\u5f20\u91cf\u3002**\u4e00\u822c\u800c\u8a00\uff0c\u5e94\u5f53\u53ea\u5728\u6307\u5b9a\u8d85\u53c2\u6570\u7b49\u5c11\u6570\u573a\u5408\u4f7f\u7528 Python \u5185\u7f6e\u7c7b\u578b\u4f5c\u4e3a\u88ab @tf.function \u4fee\u9970\u7684\u51fd\u6570\u7684\u53c2\u6570\u3002 4.7.3 \u4f7f\u7528\u4f20\u7edf\u7684 tf.Session\uff08\u4e86\u89e3\uff09 \u00b6 TensorFlow 2.0 \u63d0\u4f9b\u4e86 tf.compat.v1 \u6a21\u5757\u4ee5\u652f\u6301 TensorFlow 1.X \u7248\u672c\u7684 API\u3002\u540c\u65f6\uff0c\u53ea\u8981\u5728\u7f16\u5199\u6a21\u578b\u7684\u65f6\u5019\u7a0d\u52a0\u6ce8\u610f\uff0cKeras \u7684\u6a21\u578b\u662f\u53ef\u4ee5\u540c\u65f6\u517c\u5bb9 Eager Execution \u6a21\u5f0f\u548c Graph Execution \u6a21\u5f0f\u7684\u3002 \u4f8b\u5982\uff0c\u4e4b\u524d\u7684MLP \u6216 CNN \u6a21\u578b\u53bb\u8bad\u7ec3MNIST\u6570\u636e\u7684\u4ee3\u7801\u5982\u4e0b\uff1a optimizer = tf . compat . v1 . train . AdamOptimizer ( learning_rate = learning_rate ) num_batches = int ( data_loader . num_train_data // batch_size * num_epochs ) # 1\u3001\u5efa\u7acb\u8ba1\u7b97\u56fe X_placeholder = tf . compat . v1 . placeholder ( name = 'X' , shape = [ None , 28 , 28 , 1 ], dtype = tf . float32 ) y_placeholder = tf . compat . v1 . placeholder ( name = 'y' , shape = [ None ], dtype = tf . int32 ) y_pred = model ( X_placeholder ) loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y_placeholder , y_pred = y_pred ) loss = tf . reduce_mean ( loss ) train_op = optimizer . minimize ( loss ) sparse_categorical_accuracy = tf . keras . metrics . SparseCategoricalAccuracy () # 2\u3001\u5efa\u7acbSession\uff0c\u5e76\u8fd0\u884c\u56fe\u8ba1\u7b97 with tf . compat . v1 . Session () as sess : sess . run ( tf . compat . v1 . global_variables_initializer ()) for batch_index in range ( num_batches ): X , y = data_loader . get_batch ( batch_size ) # \u4f7f\u7528Session.run()\u5c06\u6570\u636e\u9001\u5165\u8ba1\u7b97\u56fe\u8282\u70b9\uff0c\u8fdb\u884c\u8bad\u7ec3\u4ee5\u53ca\u8ba1\u7b97\u635f\u5931\u51fd\u6570 _ , loss_value = sess . run ([ train_op , loss ], feed_dict = { X_placeholder : X , y_placeholder : y }) print ( \"batch %d : loss %f \" % ( batch_index , loss_value )) num_batches = int ( data_loader . num_test_data // batch_size ) for batch_index in range ( num_batches ): start_index , end_index = batch_index * batch_size , ( batch_index + 1 ) * batch_size y_pred = model . predict ( data_loader . test_data [ start_index : end_index ]) # \u8fd0\u884c\u9884\u6d4b\u7ed3\u679c sess . run ( sparse_categorical_accuracy . update ( y_true = data_loader . test_label [ start_index : end_index ], y_pred = y_pred )) print ( \"test accuracy: %f \" % sess . run ( sparse_categorical_accuracy . result ())) 4.7.4 \u603b\u7ed3 \u00b6 tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b tf.function\u7684\u4f5c\u7528\u548c\u539f\u7406","title":"4.7 Tensorflow\u6267\u884c\u6a21\u5f0f"},{"location":"tensorFlow/section7/#47-tensorflow","text":"","title":"4.7 Tensorflow\u6267\u884c\u6a21\u5f0f"},{"location":"tensorFlow/section7/#_1","text":"\u76ee\u6807 \u638c\u63e1tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b \u5e94\u7528 \u65e0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section7/#471-eager-executiongraph-execution","text":"","title":"4.7.1 Eager Execution\u4e0eGraph Execution"},{"location":"tensorFlow/section7/#4711-graph-execution","text":"\u7279\u70b9: \u9884\u5148\u5b9a\u4e49\u8ba1\u7b97\u56fe\uff0c\u8fd0\u884c\u65f6\u53cd\u590d\u4f7f\u7528\uff0c\u4e0d\u80fd\u6539\u53d8 \u901f\u5ea6\u66f4\u5feb\uff0c\u9002\u5408\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u5e73\u53f0 TensorFlow \u7684\u56fe\u6267\u884c\u6a21\u5f0f\u662f\u4e00\u4e2a\u7b26\u53f7\u5f0f\u7684\uff08\u57fa\u4e8e\u8ba1\u7b97\u56fe\u7684\uff09\u8ba1\u7b97\u6846\u67b6\u3002\u7b80\u800c\u8a00\u4e4b\uff0c\u5982\u679c\u4f60\u9700\u8981\u8fdb\u884c\u4e00\u7cfb\u5217\u8ba1\u7b97\uff0c\u5219\u9700\u8981\u4f9d\u6b21\u8fdb\u884c\u5982\u4e0b\u4e24\u6b65\uff1a 1\u3001\u5efa\u7acb\u4e00\u4e2a \u201c\u8ba1\u7b97\u56fe\u201d\uff0c\u8fd9\u4e2a\u56fe\u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u8f93\u5165\u6570\u636e\u901a\u8fc7\u4e00\u7cfb\u5217\u8ba1\u7b97\u800c\u5f97\u5230\u8f93\u51fa\uff1b 2\u3001\u5efa\u7acb\u4e00\u4e2a\u4f1a\u8bdd\uff0c\u5e76\u5728\u4f1a\u8bdd\u4e2d\u4e0e\u8ba1\u7b97\u56fe\u8fdb\u884c\u4ea4\u4e92\uff0c\u5373\u5411\u8ba1\u7b97\u56fe\u4f20\u5165\u8ba1\u7b97\u6240\u9700\u7684\u6570\u636e\uff0c\u5e76\u4ece\u8ba1\u7b97\u56fe\u4e2d\u83b7\u53d6\u7ed3\u679c\u3002 Session \u7528\u6765**\u7ed9\u5b9a Graph \u7684\u8f93\u5165\uff0c\u6307\u5b9a Graph \u4e2d\u7684\u7ed3\u679c\u83b7\u53d6\u65b9\u5f0f\uff0c \u5e76\u542f\u52a8\u6570\u636e\u5728 Graph \u4e2d\u7684\u6d41\u52a8** \u62e5\u6709\u5e76\u7ba1\u7406 Tensorflow \u7a0b\u5e8f\u8fd0\u884c\u65f6\u7684\u6240\u6709\u8d44\u6e90\uff0c\u8d44\u6e90\u5305\u62ec:\u786c\u4ef6(CPU,GPU)\uff0c\u6570\u636e \u4f7f\u7528\u8ba1\u7b97\u56fe\u4e0e\u4f1a\u8bdd\u8fdb\u884c\u57fa\u672c\u8fd0\u7b97\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u6700\u57fa\u672c\u7684\u8fd0\u7b97\u793a\u4f8b\u3002 import tensorflow.compat.v1 as tf tf . disable_eager_execution () # 1\u3001\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u201c\u8ba1\u7b97\u56fe\u201d a = tf . constant ( 1 ) b = tf . constant ( 1 ) # \u7b49\u4ef7\u4e8e c = tf.add(a, b)\uff0cc\u662f\u5f20\u91cfa\u548c\u5f20\u91cfb\u901a\u8fc7 tf.add \u8fd9\u4e00\u64cd\u4f5c\uff08Operation\uff09\u6240\u5f62\u6210\u7684\u65b0\u5f20\u91cf c = a + b # 2\u3001# \u5b9e\u4f8b\u5316\u4e00\u4e2a\u4f1a\u8bdd\uff08Session\uff09 # \u901a\u8fc7\u4f1a\u8bdd\u7684 run() \u65b9\u6cd5\u5bf9\u8ba1\u7b97\u56fe\u91cc\u7684\u8282\u70b9\uff08\u5f20\u91cf\uff09\u8fdb\u884c\u5b9e\u9645\u7684\u8ba1\u7b97 sess = tf . Session () c_ = sess . run ( c ) print ( c_ ) \u6ce8\uff1a\u4e3a\u4e86\u4f7f\u7528\u56fe\u6267\u884c\u6a21\u5f0f\uff0c\u9700\u8981\u4f7f\u7528 TensorFlow 1.X \u7684 API \u8fdb\u884c\u64cd\u4f5c\uff0c\u6240\u4ee5\u4f7f\u7528 import tensorflow.compat.v1 as tf \u5bfc\u5165 TensorFlow\uff0c\u5e76\u901a\u8fc7 tf.disable_eager_execution() \u7981\u7528\u9ed8\u8ba4\u7684\u5373\u65f6\u6267\u884c\u6a21\u5f0f\u3002","title":"4.7.1.1 Graph Execution\uff08\u56fe\u6a21\u5f0f\uff09"},{"location":"tensorFlow/section7/#4712-eager-execution","text":"eager \u6a21\u5f0f\u662f\u5728 TF 1.4 \u7248\u672c\u4e4b\u540e\u5f15\u5165\u7684\uff0c\u5728 TF 2.0\u4e4b\u540e\u5c06\u4f1a\u628a eager \u6a21\u5f0f\u53d8\u4e3a\u9ed8\u8ba4\u6267\u884c\u6a21\u5f0f\u3002TensorFlow 2.0 \u4e2d\u7684 Eager Execution \u662f\u4e00\u79cd\u547d\u4ee4\u5f0f\u7f16\u7a0b\u73af\u5883\uff0c\u53ef\u7acb\u5373\u8bc4\u4f30\u64cd\u4f5c\uff0c\u65e0\u9700\u6784\u5efa\u56fe\uff1a\u64cd\u4f5c\u4f1a\u8fd4\u56de\u5177\u4f53\u7684\u503c\uff0c\u800c\u4e0d\u662f\u6784\u5efa\u4ee5\u540e\u518d\u8fd0\u884c\u7684\u8ba1\u7b97\u56fe\u3002 Eager Execution \u7684\u4f18\u70b9\u5982\u4e0b\uff1a 1\u3001\u5feb\u901f\u8c03\u8bd5\u5373\u523b\u7684\u8fd0\u884c\u9519\u8bef\u5e76\u901a\u8fc7 Python \u5de5\u5177\u8fdb\u884c\u6574\u5408 2\u3001\u501f\u52a9\u6613\u4e8e\u4f7f\u7528\u7684 Python \u63a7\u5236\u6d41\u652f\u6301\u52a8\u6001\u6a21\u578b 3\u3001\u4e3a\u81ea\u5b9a\u4e49\u548c\u9ad8\u9636\u68af\u5ea6\u63d0\u4f9b\u5f3a\u5927\u652f\u6301 4\u3001\u9002\u7528\u4e8e\u51e0\u4e4e\u6240\u6709\u53ef\u7528\u7684 TensorFlow \u8fd0\u7b97 TensorFlow 2.0\u5f15\u5165\u7684eager\u63d0\u9ad8\u4e86\u4ee3\u7801\u7684\u7b80\u6d01\u6027\uff0c\u800c\u4e14\u66f4\u5bb9\u6613debug\u3002**\u4f46\u662f\u5bf9\u4e8e\u6027\u80fd\u6765\u8bf4\uff0ceager\u6267\u884c\u76f8\u6bd4Graph\u6a21\u5f0f\u4f1a\u6709\u4e00\u5b9a\u7684\u635f\u5931\u3002\u6bd5\u7adf\u539f\u751f\u7684Graph\u6a21\u5f0f\u662f\u5148\u6784\u5efa\u597d\u9759\u6001\u56fe\uff0c\u7136\u540e\u624d\u771f\u6b63\u6267\u884c\u3002\u8fd9\u5bf9\u4e8e \u5728\u5206\u5e03\u5f0f\u8bad\u7ec3\u3001\u6027\u80fd\u4f18\u5316\u548c\u751f\u4ea7\u90e8\u7f72\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002**\u4f46\u662f\u597d\u5728\uff0cTensorFlow 2.0\u5f15\u5165\u4e86tf.function\u548cAutoGraph\u6765\u7f29\u5c0feager\u6267\u884c\u548cGraph\u6a21\u5f0f\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5176\u6838\u5fc3\u662f\u5c06\u4e00\u7cfb\u5217\u7684Python\u8bed\u6cd5\u8f6c\u5316\u4e3a\u9ad8\u6027\u80fd\u7684graph\u64cd\u4f5c\u3002 \u6ce8\uff1a\u5b9e\u9645\u4e0a\uff0cEager Execution \u5728 1.x \u7684\u540e\u671f\u7248\u672c\u4e2d\u4e5f\u5b58\u5728\uff0c\u4f46\u9700\u8981\u5355\u72ec\u6267\u884c tf.enable_eager_execution() \u8fdb\u884c\u624b\u52a8\u542f\u7528\u3002","title":"4.7.1.2 Eager Execution\uff08\u52a8\u6001\u56fe\u6a21\u5f0f\uff09"},{"location":"tensorFlow/section7/#472-tffunctiongraph-execution","text":"\u5728 TensorFlow 2.0 \u4e2d\uff0c\u63a8\u8350\u4f7f\u7528 @tf.function \uff08\u800c\u975e 1.X \u4e2d\u7684 tf.Session \uff09\u5b9e\u73b0 Graph Execution\uff0c\u4ece\u800c\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u6613\u4e8e\u90e8\u7f72\u4e14\u9ad8\u6027\u80fd\u7684 TensorFlow \u56fe\u6a21\u578b\u3002\u53ea\u9700\u8981\u5c06\u6211\u4eec\u5e0c\u671b\u4ee5 Graph Execution \u6a21\u5f0f\u8fd0\u884c\u7684\u4ee3\u7801\u5c01\u88c5\u5728\u4e00\u4e2a\u51fd\u6570\u5185\uff0c\u5e76\u5728\u51fd\u6570\u524d\u52a0\u4e0a @tf.function \u5373\u53ef\u3002 \u4e0a\u9762\u4f8b\u5b50\u4ee3\u7801\uff0c\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e tf.function \u7684\u4ee3\u7801\u7b49\u4ef7\u53bb\u6267\u884c\u56fe\u6a21\u5f0f\uff1a import tensorflow as tf @tf.function def graph (): a = tf . constant ( 1 ) # \u5b9a\u4e49\u4e00\u4e2a\u5e38\u91cf\u5f20\u91cf\uff08Tensor\uff09 b = tf . constant ( 1 ) c = a + b return c c_ = graph () print ( c_ . numpy ()) \u5e76\u4e0d\u662f\u4efb\u4f55\u51fd\u6570\u90fd\u53ef\u4ee5\u88ab @tf.function \u4fee\u9970\uff01@tf.function \u4f7f\u7528\u9759\u6001\u7f16\u8bd1\u5c06\u51fd\u6570\u5185\u7684\u4ee3\u7801\u8f6c\u6362\u6210\u8ba1\u7b97\u56fe\uff0c\u56e0\u6b64\u5bf9\u51fd\u6570\u5185\u53ef\u4f7f\u7528\u7684\u8bed\u53e5\u6709\u4e00\u5b9a\u9650\u5236\uff0c\u4e14\u9700\u8981\u51fd\u6570\u5185\u7684\u64cd\u4f5c\u672c\u8eab\u80fd\u591f\u88ab\u6784\u5efa\u4e3a\u8ba1\u7b97\u56fe\u3002 \u5efa\u8bae\u5728\u51fd\u6570\u5185\u53ea\u4f7f\u7528TensorFlow \u7684\u539f\u751f\u64cd\u4f5c\uff0c\u4e0d\u8981\u4f7f\u7528\u8fc7\u4e8e\u590d\u6742\u7684 Python \u8bed\u53e5\uff0c\u51fd\u6570\u53c2\u6570\u53ea\u5305\u62ec TensorFlow \u5f20\u91cf\u6216 NumPy \u6570\u7ec4\uff0c\u5e76\u6700\u597d\u662f\u80fd\u591f\u6309\u7167\u8ba1\u7b97\u56fe\u7684\u601d\u60f3\u53bb\u6784\u5efa\u51fd\u6570\u3002 import tensorflow as tf @tf.function def train_one_step ( X , y ): with tf . GradientTape () as tape : y_pred = model ( X ) loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y , y_pred = y_pred ) loss = tf . reduce_mean ( loss ) # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u4e86TensorFlow\u5185\u7f6e\u7684tf.print() # @tf.function\u4e0d\u652f\u6301Python\u5185\u7f6e\u7684print\u65b9\u6cd5\u53bb\u5f53\u505a\u8ba1\u7b97\u8282\u70b9 tf . print ( \"loss\" , loss ) grads = tape . gradient ( loss , model . variables ) optimizer . apply_gradients ( grads_and_vars = zip ( grads , model . variables )) if __name__ == '__main__' : model = CNN () optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ) start_time = time . time () for batch_index in range ( num_batches ): X , y = data_loader . get_batch ( batch_size ) train_one_step ( X , y ) end_time = time . time () print ( end_time - start_time )","title":"4.7.2 @tf.function\u5b9e\u73b0Graph Execution \u6a21\u5f0f"},{"location":"tensorFlow/section7/#4722-tffunction","text":"\u5f53\u88ab @tf.function \u4fee\u9970\u7684\u51fd\u6570\u7b2c\u4e00\u6b21\u88ab\u8c03\u7528\u7684\u65f6\u5019\uff0c\u8fdb\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a 1\u3001\u5728 Eager Execution \u6a21\u5f0f\u5173\u95ed\u7684\u73af\u5883\u4e0b\uff0c\u51fd\u6570\u5185\u7684\u4ee3\u7801\u4f9d\u6b21\u8fd0\u884c\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u6bcf\u4e2a tf. \u65b9\u6cd5\u90fd\u53ea\u662f\u5b9a\u4e49\u4e86\u8ba1\u7b97\u8282\u70b9\uff0c\u800c\u5e76\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u5b9e\u8d28\u7684\u8ba1\u7b97\u3002\u8fd9\u4e0e TensorFlow 1.X \u7684 Graph Execution \u662f\u4e00\u81f4\u7684\uff1b 2\u3001\u4f7f\u7528 AutoGraph \u5c06\u51fd\u6570\u4e2d\u7684 Python \u63a7\u5236\u6d41\u8bed\u53e5\u8f6c\u6362\u6210 TensorFlow \u8ba1\u7b97\u56fe\u4e2d\u7684\u5bf9\u5e94\u8282\u70b9\uff08\u6bd4\u5982\u8bf4 while \u548c for \u8bed\u53e5\u8f6c\u6362\u4e3a tf.while \uff0c if \u8bed\u53e5\u8f6c\u6362\u4e3a tf.cond \u7b49\u7b49\uff1b 3\u3001\u57fa\u4e8e\u4e0a\u9762\u7684\u4e24\u6b65\uff0c\u5efa\u7acb\u51fd\u6570\u5185\u4ee3\u7801\u7684\u8ba1\u7b97\u56fe\u8868\u793a\uff1b\u7136\u540e\u8fd0\u884c\u4e00\u6b21\u8fd9\u4e2a\u8ba1\u7b97\u56fe\uff1b \u57fa\u4e8e\u51fd\u6570\u7684\u540d\u5b57\u548c\u8f93\u5165\u7684\u51fd\u6570\u53c2\u6570\u7684\u7c7b\u578b\u751f\u6210\u4e00\u4e2a\u54c8\u5e0c\u503c\uff0c\u5e76\u5c06\u5efa\u7acb\u7684\u8ba1\u7b97\u56fe\u7f13\u5b58\u5230\u4e00\u4e2a\u54c8\u5e0c\u8868\u4e2d\u3002 \u5982\u679c\u5728\u88ab @tf.function \u4fee\u9970\u7684\u51fd\u6570\u4e4b\u540e\u518d\u6b21\u88ab\u8c03\u7528\u7684\u65f6\u5019\uff0c\u6839\u636e\u51fd\u6570\u540d\u548c\u8f93\u5165\u7684\u51fd\u6570\u53c2\u6570\u7684\u7c7b\u578b\u8ba1\u7b97\u54c8\u5e0c\u503c\uff0c\u68c0\u67e5\u54c8\u5e0c\u8868\u4e2d\u662f\u5426\u5df2\u7ecf\u6709\u4e86\u5bf9\u5e94\u8ba1\u7b97\u56fe\u7684\u7f13\u5b58\u3002\u5982\u679c\u662f\uff0c\u5219\u76f4\u63a5\u4f7f\u7528\u5df2\u7f13\u5b58\u7684\u8ba1\u7b97\u56fe\uff0c\u5426\u5219\u91cd\u65b0\u6309\u4e0a\u8ff0\u6b65\u9aa4\u5efa\u7acb\u8ba1\u7b97\u56fe\u3002","title":"4.7.2.2 @tf.function \u673a\u5236\u539f\u7406"},{"location":"tensorFlow/section7/#1tffunction","text":"import tensorflow as tf import numpy as np @tf.function def f ( x ): # \u6ce8\u610f\u8fd9\u91cc\u662fprint\uff0c\u4e0d\u662ftf.print print ( \"The function is running in Python\" ) tf . print ( x ) # \u8fd0\u884c\u8fc7\u7a0b a = tf . constant ( 1 , dtype = tf . int32 ) f ( a ) b = tf . constant ( 2 , dtype = tf . int32 ) f ( b ) b_array = np . array ( 2 , dtype = np . int32 ) f ( b_array ) c = tf . constant ( 0.1 , dtype = tf . float32 ) f ( c ) d = tf . constant ( 0.2 , dtype = tf . float32 ) f ( d ) # \u5bf9\u4e8ePython\u7684\u7c7b\u578b f ( 1 ) f ( 2 ) f ( 1 ) \u4e0a\u8ff0\u7a0b\u5e8f\u7684\u8ba1\u7b97\u7ed3\u679c\u662f\uff1f\u7b54\u6848\u662f: # Tensor\u7c7b\u578b The function is running in Python 1 2 2 The function is running in Python 0.1 0.2 # Python\u7c7b\u578b The function is running in Python 1 The function is running in Python 2 1 \u5f53\u8ba1\u7b97 f(a) \u65f6\uff0c\u7531\u4e8e\u662f\u7b2c\u4e00\u6b21\u8c03\u7528\u8be5\u51fd\u6570\uff0cTensorFlow \u8fdb\u884c\u4e86\u4ee5\u4e0b\u64cd\u4f5c\uff1a 1\u3001\u5c06\u51fd\u6570\u5185\u7684\u4ee3\u7801\u4f9d\u6b21\u8fd0\u884c\u4e86\u4e00\u904d\uff1b 2\u3001\u6784\u5efa\u4e86\u8ba1\u7b97\u56fe\uff0c\u7136\u540e\u8fd0\u884c\u4e86\u4e00\u6b21\u8be5\u8ba1\u7b97\u56fe\uff08\u56e0\u6b64\u8f93\u51fa\u4e86 1\uff09\u3002\u8fd9\u91cc tf.print(x) \u53ef\u4ee5\u4f5c\u4e3a\u8ba1\u7b97\u56fe\u7684\u8282\u70b9\uff0c\u4f46 Python \u5185\u7f6e\u7684 print \u5219\u4e0d\u80fd\u88ab\u8f6c\u6362\u6210\u8ba1\u7b97\u56fe\u7684\u8282\u70b9\u3002 3\u3001\u5c06\u8be5\u8ba1\u7b97\u56fe\u7f13\u5b58\u5230\u4e86\u4e00\u4e2a\u54c8\u5e0c\u8868\u4e2d\uff08\u5982\u679c\u4e4b\u540e\u518d\u6709\u7c7b\u578b\u4e3a tf.int32 \uff0cshape \u4e3a\u7a7a\u7684\u5f20\u91cf\u8f93\u5165\uff0c\u5219\u91cd\u590d\u4f7f\u7528\u5df2\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\uff09\u3002 \u63a5\u4e0b\u6765\u7b2c\u4e8c\u6b21\u8ba1\u7b97\u4e4b\u540e \u4e00\u3001\u8ba1\u7b97 f(b) \u65f6\uff0c\u7531\u4e8e b \u7684\u7c7b\u578b\u4e0e a \u76f8\u540c\uff0c\u6240\u4ee5 TensorFlow \u91cd\u590d\u4f7f\u7528\u4e86\u4e4b\u524d\u5df2\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\u5e76\u8fd0\u884c\uff08\u56e0\u6b64\u8f93\u51fa\u4e86 2\uff09\u3002\u8fd9\u91cc\u7531\u4e8e\u5e76\u6ca1\u6709\u771f\u6b63\u5730\u9010\u884c\u8fd0\u884c\u51fd\u6570\u4e2d\u7684\u4ee3\u7801\uff0c\u6240\u4ee5\u51fd\u6570\u7b2c\u4e00\u884c\u7684\u6587\u672c\u8f93\u51fa\u4ee3\u7801\u6ca1\u6709\u8fd0\u884c\u3002\u8ba1\u7b97 f(b_array) \u65f6\uff0cTensorFlow \u81ea\u52a8\u5c06 numpy \u7684\u6570\u636e\u7ed3\u6784\u8f6c\u6362\u6210\u4e86 TensorFlow \u4e2d\u7684\u5f20\u91cf\uff0c\u56e0\u6b64\u4f9d\u7136\u80fd\u591f\u590d\u7528\u4e4b\u524d\u5df2\u6784\u5efa\u7684\u8ba1\u7b97\u56fe\u3002 \u4e8c\u3001\u8ba1\u7b97 f\u00a9 \u65f6\uff0c\u867d\u7136\u5f20\u91cf c \u7684 shape \u548c a \u3001 b \u5747\u76f8\u540c\uff0c\u4f46\u7c7b\u578b\u4e3a tf.float32 \uff0c\u56e0\u6b64 TensorFlow \u91cd\u65b0\u8fd0\u884c\u4e86\u51fd\u6570\u5185\u4ee3\u7801\uff08\u4ece\u800c\u518d\u6b21\u8f93\u51fa\u4e86\u6587\u672c\uff09\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u8f93\u5165\u4e3a tf.float32 \u7c7b\u578b\u7684\u8ba1\u7b97\u56fe\u3002 \u4e09\u3001\u8ba1\u7b97 f(d) \u65f6\uff0c\u7531\u4e8e d \u548c c \u7684\u7c7b\u578b\u76f8\u540c\uff0c\u6240\u4ee5 TensorFlow \u590d\u7528\u4e86\u8ba1\u7b97\u56fe\uff0c\u540c\u7406\u6ca1\u6709\u8f93\u51fa\u6587\u672c\u3002","title":"1\u3001\u4f7f\u7528\u4e0b\u9762\u4f8b\u5b50\u4f53\u73b0tf.function\u6574\u4e2a\u8ba1\u7b97\u6b65\u9aa4\uff1a"},{"location":"tensorFlow/section7/#printtfprint","text":"\u6b63\u5e38\u7684\u6309\u7167\u987a\u5e8f\u8f93\u51fa\uff1a The function is running in Python 1 The function is running in Python 2 The function is running in Python 2 The function is running in Python 0.1 The function is running in Python 0.2 The function is running in Python 1 The function is running in Python 2 The function is running in Python 1 \u603b\u7ed3\uff1a\u4e4b\u540e\u7684\u8ba1\u7b97\u7ed3\u679c\u5219\u663e\u793a\u51fa @tf.function \u5bf9 Python \u5185\u7f6e\u7684\u6574\u6570\u548c\u6d6e\u70b9\u6570\u7c7b\u578b\u7684\u5904\u7406\u65b9\u5f0f\u3002**\u53ea\u6709\u5f53\u503c\u5b8c\u5168\u4e00\u81f4\u7684\u65f6\u5019\uff0c @tf.function \u624d\u4f1a\u590d\u7528\u4e4b\u524d\u5efa\u7acb\u7684\u8ba1\u7b97\u56fe\uff0c\u800c\u5e76\u4e0d\u4f1a\u81ea\u52a8\u5c06 Python \u5185\u7f6e\u7684\u6574\u6570\u6216\u6d6e\u70b9\u6570\u7b49\u8f6c\u6362\u6210\u5f20\u91cf\u3002**\u4e00\u822c\u800c\u8a00\uff0c\u5e94\u5f53\u53ea\u5728\u6307\u5b9a\u8d85\u53c2\u6570\u7b49\u5c11\u6570\u573a\u5408\u4f7f\u7528 Python \u5185\u7f6e\u7c7b\u578b\u4f5c\u4e3a\u88ab @tf.function \u4fee\u9970\u7684\u51fd\u6570\u7684\u53c2\u6570\u3002","title":"\u95ee\u9898\uff1a\u5982\u679c\u6253\u5370\u5b57\u7b26\u4e32\u7684print()\u66ff\u6362\u6210tf.print()\uff0c\u7ed3\u679c\u4f1a\u662f\uff1f"},{"location":"tensorFlow/section7/#473-tfsession","text":"TensorFlow 2.0 \u63d0\u4f9b\u4e86 tf.compat.v1 \u6a21\u5757\u4ee5\u652f\u6301 TensorFlow 1.X \u7248\u672c\u7684 API\u3002\u540c\u65f6\uff0c\u53ea\u8981\u5728\u7f16\u5199\u6a21\u578b\u7684\u65f6\u5019\u7a0d\u52a0\u6ce8\u610f\uff0cKeras \u7684\u6a21\u578b\u662f\u53ef\u4ee5\u540c\u65f6\u517c\u5bb9 Eager Execution \u6a21\u5f0f\u548c Graph Execution \u6a21\u5f0f\u7684\u3002 \u4f8b\u5982\uff0c\u4e4b\u524d\u7684MLP \u6216 CNN \u6a21\u578b\u53bb\u8bad\u7ec3MNIST\u6570\u636e\u7684\u4ee3\u7801\u5982\u4e0b\uff1a optimizer = tf . compat . v1 . train . AdamOptimizer ( learning_rate = learning_rate ) num_batches = int ( data_loader . num_train_data // batch_size * num_epochs ) # 1\u3001\u5efa\u7acb\u8ba1\u7b97\u56fe X_placeholder = tf . compat . v1 . placeholder ( name = 'X' , shape = [ None , 28 , 28 , 1 ], dtype = tf . float32 ) y_placeholder = tf . compat . v1 . placeholder ( name = 'y' , shape = [ None ], dtype = tf . int32 ) y_pred = model ( X_placeholder ) loss = tf . keras . losses . sparse_categorical_crossentropy ( y_true = y_placeholder , y_pred = y_pred ) loss = tf . reduce_mean ( loss ) train_op = optimizer . minimize ( loss ) sparse_categorical_accuracy = tf . keras . metrics . SparseCategoricalAccuracy () # 2\u3001\u5efa\u7acbSession\uff0c\u5e76\u8fd0\u884c\u56fe\u8ba1\u7b97 with tf . compat . v1 . Session () as sess : sess . run ( tf . compat . v1 . global_variables_initializer ()) for batch_index in range ( num_batches ): X , y = data_loader . get_batch ( batch_size ) # \u4f7f\u7528Session.run()\u5c06\u6570\u636e\u9001\u5165\u8ba1\u7b97\u56fe\u8282\u70b9\uff0c\u8fdb\u884c\u8bad\u7ec3\u4ee5\u53ca\u8ba1\u7b97\u635f\u5931\u51fd\u6570 _ , loss_value = sess . run ([ train_op , loss ], feed_dict = { X_placeholder : X , y_placeholder : y }) print ( \"batch %d : loss %f \" % ( batch_index , loss_value )) num_batches = int ( data_loader . num_test_data // batch_size ) for batch_index in range ( num_batches ): start_index , end_index = batch_index * batch_size , ( batch_index + 1 ) * batch_size y_pred = model . predict ( data_loader . test_data [ start_index : end_index ]) # \u8fd0\u884c\u9884\u6d4b\u7ed3\u679c sess . run ( sparse_categorical_accuracy . update ( y_true = data_loader . test_label [ start_index : end_index ], y_pred = y_pred )) print ( \"test accuracy: %f \" % sess . run ( sparse_categorical_accuracy . result ()))","title":"4.7.3 \u4f7f\u7528\u4f20\u7edf\u7684 tf.Session\uff08\u4e86\u89e3\uff09"},{"location":"tensorFlow/section7/#474","text":"tf\u7684\u56fe\u6267\u884c\u6a21\u5f0f\u539f\u7406\u4e0e\u4f1a\u8bdd\u6a21\u5f0f\u7684\u533a\u522b tf.function\u7684\u4f5c\u7528\u548c\u539f\u7406","title":"4.7.4 \u603b\u7ed3"},{"location":"tensorFlow/section8/","text":"4.8 \u5206\u5e03\u5f0f\u8bad\u7ec3 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u638c\u63e1TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528 \u5e94\u7528 \u65e0 \u5f53\u6211\u4eec\u62e5\u6709\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u65f6\uff0c\u901a\u8fc7\u4f7f\u7528\u5408\u9002\u7684\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u6211\u4eec\u53ef\u4ee5\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ece\u800c\u5927\u5e45\u538b\u7f29\u6a21\u578b\u8bad\u7ec3\u7684\u65f6\u95f4\u3002\u9488\u5bf9\u4e0d\u540c\u7684\u4f7f\u7528\u573a\u666f\uff0cTensorFlow \u5728 tf.distribute.Strategy`\u4e2d\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u82e5\u5e72\u79cd\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u4f7f\u5f97\u6211\u4eec\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u8bad\u7ec3\u6a21\u578b\u3002 4.8.1 TensorFlow \u5206\u5e03\u5f0f\u7684\u5206\u7c7b \u00b6 \u56fe\u95f4\u5e76\u884c\uff08\u53c8\u79f0\u6570\u636e\u5e76\u884c\uff09 \u6bcf\u4e2a\u673a\u5668\u4e0a\u90fd\u4f1a\u6709\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\uff0c\u5c06\u6570\u636e\u5206\u6563\u5230\u5404\u4e2a\u673a\u5668\uff0c\u5206\u522b\u8ba1\u7b97\u68af\u5ea6\u3002 \u56fe\u5185\u5e76\u884c\uff08\u53c8\u79f0\u6a21\u578b\u5e76\u884c\uff09 \u6bcf\u4e2a\u673a\u5668\u5206\u522b\u8d1f\u8d23\u6574\u4e2a\u6a21\u578b\u7684\u4e00\u90e8\u5206\u8ba1\u7b97\u4efb\u52a1\u3002 1\u3001\u56fe\u95f4\u5e76\u884c\u7528\u7684\u975e\u5e38\u591a\uff0c\u4f1a\u5305\u542b\u4e24\u79cd\u65b9\u5f0f\u8fdb\u884c\u66f4\u65b0 \u00b6 \u540c\u6b65\uff1a\u6536\u96c6\u5230\u8db3\u591f\u6570\u91cf\u7684\u68af\u5ea6\uff0c\u4e00\u540c\u66f4\u65b0\uff0c\u4e0b\u56fe\u4e0a\u65b9 \u5f02\u6b65\uff1a\u5373\u540c\u6b65\u65b9\u5f0f\u4e0b\uff0c\u66f4\u65b0\u9700\u6c42\u7684\u68af\u5ea6\u6570\u91cf\u4e3a1\uff0c\u4e0b\u56fe\u4e0b\u65b9 \u6ce8\uff1aPS(parameter server):\u7ef4\u62a4\u5168\u5c40\u5171\u4eab\u7684\u6a21\u578b\u53c2\u6570\u7684\u670d\u52a1\u5668 2\u3001\u5b9e\u73b0\u65b9\u5f0f \u00b6 \u5355\u673a\u591a\u5361 \u591a\u673a\u5355\u5361 TensorFlow\u591a\u673a\u591a\u5361\u5b9e\u73b0\u601d\u8def \u3002\u591a\u7ea7\u591a\u5361\u7684\u5206\u5e03\u5f0f\u6709\u5f88\u591a\u5b9e\u73b0\u65b9\u5f0f\uff0c\u6bd4\u5982\uff1a 1. \u5c06\u6bcf\u4e2a GPU\u5f53\u505a\u4e00\u4e2aworker 2. \u540c\u4e00\u4e2a\u673a\u5668\u7684\u5404\u4e2a GPU\u8fdb\u884c\u56fe\u5185\u5e76\u884c 3. \u540c\u4e00\u4e2a\u673a\u5668\u7684\u5404\u4e2a GPU\u8fdb\u884c\u56fe\u95f4\u5e76\u884c \u6bd4\u5982\u8bf4\u7b2c\u4e09\u79cd\uff1a\u6a21\u578b\u5b9e\u73b0\u5c01\u88c5\u6210\u51fd\u6570\u3001\u5c06\u6570\u636e\u5206\u6210 GPU\u6570\u91cf\u7684\u4efd\u6570 \u3001\u5728\u6bcf\u4e2a GPU\u4e0b \uff0c\u8fdb\u884c\u4e00\u6b21\u6a21\u578b forward\u8ba1\u7b97 \uff0c\u5e76\u4f7f\u7528\u4f18\u5316\u5668\u7b97\u51fa\u68af\u5ea6\u3001 reduce\u6bcf\u4e2aGPU\u4e0b\u7684\u68af\u5ea6 \uff0c\u5e76\u5c06\u68af\u5ea6\u4f20\u5165\u5230\u5206\u5e03\u5f0f\u4e2d\u7684\u4f18\u5316\u5668\u4e2d 4.8.1 \u5355\u673a\u591a\u5361\u8bad\u7ec3\uff1a MirroredStrategy \u00b6 tf.distribute.MirroredStrategy \u662f\u4e00\u79cd\u7b80\u5355\u4e14\u9ad8\u6027\u80fd\u7684\uff0c\u6570\u636e\u5e76\u884c\u7684\u540c\u6b65\u5f0f\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u4e3b\u8981\u652f\u6301\u591a\u4e2a GPU \u5728\u540c\u4e00\u53f0\u4e3b\u673a\u4e0a\u8bad\u7ec3\u3002 1\u3001MirroredStrategy\u8fd0\u884c\u539f\u7406\uff1a 1\u3001\u8bad\u7ec3\u5f00\u59cb\u524d\uff0c\u8be5\u7b56\u7565\u5728\u6240\u6709 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\uff08GPU\uff09\u4e0a\u5747\u5404\u590d\u5236\u4e00\u4efd\u5b8c\u6574\u7684\u6a21\u578b 2\u3001\u6bcf\u6b21\u8bad\u7ec3\u4f20\u5165\u4e00\u4e2a\u6279\u6b21\u7684\u6570\u636e\u65f6\uff0c\u5c06\u6570\u636e\u5206\u6210 N \u4efd\uff0c\u5206\u522b\u4f20\u5165 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\uff08\u5373\u6570\u636e\u5e76\u884c\uff09 3\u3001\u4f7f\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684 All-reduce \u64cd\u4f5c\uff0c\u5728\u8ba1\u7b97\u8bbe\u5907\u95f4\u9ad8\u6548\u4ea4\u6362\u68af\u5ea6\u6570\u636e\u5e76\u8fdb\u884c\u6c42\u548c\uff0c\u4f7f\u5f97\u6700\u7ec8\u6bcf\u4e2a\u8bbe\u5907\u90fd\u6709\u4e86\u6240\u6709\u8bbe\u5907\u7684\u68af\u5ea6\u4e4b\u548c\uff0c\u4f7f\u7528\u68af\u5ea6\u6c42\u548c\u7684\u7ed3\u679c\u66f4\u65b0\u672c\u5730\u53d8\u91cf \u5f53\u6240\u6709\u8bbe\u5907\u5747\u66f4\u65b0\u672c\u5730\u53d8\u91cf\u540e\uff0c\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8bad\u7ec3\uff08\u5373\u8be5\u5e76\u884c\u7b56\u7565\u662f\u540c\u6b65\u7684\uff09\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cTensorFlow \u4e2d\u7684 MirroredStrategy \u7b56\u7565\u4f7f\u7528 NVIDIA NCCL \u8fdb\u884c All-reduce \u64cd\u4f5c\u3002 2\u3001\u6784\u5efa\u4ee3\u7801\u6b65\u9aa4\uff1a 1\u3001\u4f7f\u7528\u8fd9\u79cd\u7b56\u7565\u65f6\uff0c\u6211\u4eec\u53ea\u9700\u5b9e\u4f8b\u5316\u4e00\u4e2a MirroredStrategy \u7b56\u7565: strategy = tf . distribute . MirroredStrategy () 2\u3001\u5e76\u5c06\u6a21\u578b\u6784\u5efa\u7684\u4ee3\u7801\u653e\u5165 strategy.scope() \u7684\u4e0a\u4e0b\u6587\u73af\u5883\u4e2d: with strategy . scope (): # \u6a21\u578b\u6784\u5efa\u4ee3\u7801 \u6216\u8005\u53ef\u4ee5\u5728\u53c2\u6570\u4e2d\u6307\u5b9a\u8bbe\u5907\uff0c\u5982: strategy = tf . distribute . MirroredStrategy ( devices = [ \"/gpu:0\" , \"/gpu:1\" ]) \u5373\u6307\u5b9a\u53ea\u4f7f\u7528\u7b2c 0\u30011 \u53f7 GPU \u53c2\u4e0e\u5206\u5e03\u5f0f\u7b56\u7565\u3002 4.8.1.1 MirroredStrategy\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u8bad\u7ec3 \u00b6 \u4ee5\u4e0b\u4ee3\u7801\u5c55\u793a\u4e86\u4f7f\u7528 MirroredStrategy \u7b56\u7565\uff0c\u5728 TensorFlow Datasets \u4e2d\u7684\u90e8\u5206\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u4f7f\u7528 Keras \u8bad\u7ec3 MobileNetV2 \u7684\u8fc7\u7a0b\uff1a import tensorflow as tf import tensorflow_datasets as tfds num_epochs = 5 batch_size_per_replica = 64 learning_rate = 0.001 strategy = tf . distribute . MirroredStrategy () print ( 'Number of devices: %d ' % strategy . num_replicas_in_sync ) # \u8f93\u51fa\u8bbe\u5907\u6570\u91cf batch_size = batch_size_per_replica * strategy . num_replicas_in_sync # \u8f7d\u5165\u6570\u636e\u96c6\u5e76\u9884\u5904\u7406 def resize ( image , label ): image = tf . image . resize ( image , [ 224 , 224 ]) / 255.0 return image , label # \u5f53as_supervised\u4e3aTrue\u65f6\uff0c\u8fd4\u56deimage\u548clabel\u4e24\u4e2a\u952e\u503c dataset = tfds . load ( \"cats_vs_dogs\" , split = tfds . Split . TRAIN , as_supervised = True ) dataset = dataset . map ( resize ) . shuffle ( 1024 ) . batch ( batch_size ) with strategy . scope (): model = tf . keras . applications . MobileNetV2 () model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) model . fit ( dataset , epochs = num_epochs ) \u8fd9\u4e2a\u662f\u5728\u7ebf\u4e0b\u6d4b\u8bd5\u7684\u7ed3\u679c epoch=5,batch_size=64 2\u5757 NVIDIA GeForce GTX 1080 Ti \u663e\u5361\u8fdb\u884c\u5355\u673a\u591a\u5361\u7684\u6a21\u578b\u8bad\u7ec3\u3002 \u6570\u636e\u96c6 \u5355\u673a\u65e0\u5206\u5e03\u5f0f\uff08Batch Size \u4e3a 64\uff09 \u5355\u673a\u591a\u5361\uff08\u603b Batch Size \u4e3a 64\uff09 \u5355\u673a\u591a\u5361\uff08\u603b Batch Size \u4e3a 256\uff09 cats_vs_dogs 150s/epoch 36s/epoch 30s/epoch 4.8.2 \u591a\u673a\u8bad\u7ec3\uff1a MultiWorkerMirroredStrategy \u00b6 \u591a\u673a\u8bad\u7ec3\u7684\u65b9\u6cd5\u548c\u5355\u673a\u591a\u5361\u7c7b\u4f3c\uff0c\u5c06 MirroredStrategy \u66f4\u6362\u4e3a\u9002\u5408\u591a\u673a\u8bad\u7ec3\u7684 MultiWorkerMirroredStrategy \u5373\u53ef\u3002\u4e0d\u8fc7\uff0c\u7531\u4e8e\u6d89\u53ca\u5230\u591a\u53f0\u8ba1\u7b97\u673a\u4e4b\u95f4\u7684\u901a\u8baf\uff0c\u8fd8\u9700\u8981\u8fdb\u884c\u4e00\u4e9b\u989d\u5916\u7684\u8bbe\u7f6e\u3002 1\u3001\u9700\u8981\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf TF_CONFIG \uff0c\u793a\u4f8b\u5982\u4e0b: os . environ [ 'TF_CONFIG' ] = json . dumps ({ 'cluster' : { 'worker' : [ \"localhost:8888\" , \"localhost:9999\" ] }, 'task' : { 'type' : 'worker' , 'index' : 0 } }) 2\u3001TF_CONFIG \u7531 cluster \u548c task \u4e24\u90e8\u5206\u7ec4\u6210\uff1a cluster \u8bf4\u660e\u4e86\u6574\u4e2a\u591a\u673a\u96c6\u7fa4\u7684\u7ed3\u6784\u548c\u6bcf\u53f0\u673a\u5668\u7684\u7f51\u7edc\u5730\u5740\uff08IP + \u7aef\u53e3\u53f7\uff09\u3002\u5bf9\u4e8e\u6bcf\u4e00\u53f0\u673a\u5668\uff0ccluster \u7684\u503c\u90fd\u662f\u76f8\u540c\u7684\u3002 task \u8bf4\u660e\u4e86\u5f53\u524d\u673a\u5668\u7684\u89d2\u8272\u3002\u4f8b\u5982\uff0c {'type': 'worker', 'index': 0} \u8bf4\u660e\u5f53\u524d\u673a\u5668\u662f cluster \u4e2d\u7684\u7b2c 0 \u4e2a worker\uff08\u5373 localhost:20000 \uff09\u3002\u6bcf\u4e00\u53f0\u673a\u5668\u7684 task \u503c\u90fd\u9700\u8981\u9488\u5bf9\u5f53\u524d\u4e3b\u673a\u8fdb\u884c\u5206\u522b\u7684\u8bbe\u7f6e\u3002 3\u3001\u8fd0\u884c\u8fc7\u7a0b 1\u3001\u5728\u6240\u6709\u7684\u673a\u5668\u4e0a\u9010\u4e2a\u8fd0\u884c\u8bad\u7ec3\u4ee3\u7801\u5373\u53ef\u3002\u5148\u8fd0\u884c\u7684\u4ee3\u7801\u5728\u5c1a\u672a\u4e0e\u5176\u4ed6\u4e3b\u673a\u8fde\u63a5\u65f6\u4f1a\u8fdb\u5165\u76d1\u542c\u72b6\u6001\uff0c\u5f85\u6574\u4e2a\u96c6\u7fa4\u7684\u8fde\u63a5\u5efa\u7acb\u5b8c\u6bd5\u540e\uff0c\u6240\u6709\u7684\u673a\u5668\u5373\u4f1a\u540c\u65f6\u5f00\u59cb\u8bad\u7ec3\u3002 2\u3001\u5047\u8bbe\u6709\u4e24\u53f0\u673a\u5668\uff0c\u5373\u9996\u5148\u5728\u4e24\u53f0\u673a\u5668\u4e0a\u5747\u90e8\u7f72\u8fd9\u4e2a\u7a0b\u5e8f\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f task \u90e8\u5206\uff0c\u7b2c\u4e00\u53f0\u673a\u5668\u8bbe\u7f6e\u4e3a {'type': 'worker', 'index': 0} \uff0c\u7b2c\u4e8c\u53f0\u673a\u5668\u8bbe\u7f6e\u4e3a {'type': 'worker', 'index': 1} \u3002\u63a5\u4e0b\u6765\uff0c\u5728\u4e24\u53f0\u673a\u5668\u4e0a\u4f9d\u6b21\u8fd0\u884c\u7a0b\u5e8f\uff0c\u5f85\u901a\u8baf\u6210\u529f\u540e\uff0c\u5373\u4f1a\u81ea\u52a8\u5f00\u59cb\u8bad\u7ec3\u6d41\u7a0b\u3002 \u591a\u673a\u8bad\u7ec3\u4ee3\u7801 \u00b6 \u540c\u6837\u5bf9\u4e8e\u540c\u4e00\u4e2a\u6570\u636e\u53ca\u8fdb\u884c\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6307\u5b9a\u591a\u673a\u4ee3\u7801\uff1a import tensorflow_datasets as tfds import os import json num_epochs = 5 batch_size_per_replica = 64 learning_rate = 0.001 num_workers = 2 # 1\u3001\u6307\u5b9a\u96c6\u7fa4\u73af\u5883 os . environ [ 'TF_CONFIG' ] = json . dumps ({ 'cluster' : { 'worker' : [ \"localhost:20000\" , \"localhost:20001\" ] }, 'task' : { 'type' : 'worker' , 'index' : 0 } }) batch_size = batch_size_per_replica * num_workers def resize ( image , label ): image = tf . image . resize ( image , [ 224 , 224 ]) / 255.0 return image , label dataset = tfds . load ( \"cats_vs_dogs\" , split = tfds . Split . TRAIN , as_supervised = True ) dataset = dataset . map ( resize ) . shuffle ( 1024 ) . batch ( batch_size ) # 2\u3001\u521d\u59cb\u5316\u96c6\u7fa4 strategy = tf . distribute . experimental . MultiWorkerMirroredStrategy () # 3\u3001\u4e0a\u4e0b\u6587\u73af\u5883\u5b9a\u4e49\u6a21\u578b with strategy . scope (): model = tf . keras . applications . MobileNetV2 () model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) model . fit ( dataset , epochs = num_epochs ) \u6d4b\u8bd5\u7ed3\u679c\u6bd4\u8f83\uff1a\u5355\u5f20 NVIDIA Tesla K80 \u663e\u5361\uff0c\u4f7f\u7528\u5355\u673a\u5355\u5361\u65f6\uff0cBatch Size \u8bbe\u7f6e\u4e3a 64\uff1b\u4f7f\u7528\u53cc\u673a\u5355\u5361\u65f6\uff0c\u6d4b\u8bd5\u603b Batch Size \u4e3a 64\uff08\u5206\u53d1\u5230\u5355\u53f0\u673a\u5668\u7684 Batch Size \u4e3a 32\uff09\u548c\u603b Batch Size \u4e3a 128\uff08\u5206\u53d1\u5230\u5355\u53f0\u673a\u5668\u7684 Batch Size \u4e3a 64\uff09\u4e24\u79cd\u60c5\u51b5\u3002 \u6570\u636e\u96c6 \u5355\u673a\u5355\u5361\uff08Batch Size \u4e3a 64\uff09 \u53cc\u673a\u5355\u5361\uff08\u603b Batch Size \u4e3a 64\uff09 \u53cc\u673a\u5355\u5361\uff08\u603b Batch Size \u4e3a 128\uff09 cats_vs_dogs 1622s 858s 755s 4.8.3 \u603b\u7ed3 \u00b6 TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528","title":"4.8 \u5206\u5e03\u5f0f\u8bad\u7ec3"},{"location":"tensorFlow/section8/#48","text":"","title":"4.8 \u5206\u5e03\u5f0f\u8bad\u7ec3"},{"location":"tensorFlow/section8/#_1","text":"\u76ee\u6807 \u638c\u63e1TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528 \u5e94\u7528 \u65e0 \u5f53\u6211\u4eec\u62e5\u6709\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u65f6\uff0c\u901a\u8fc7\u4f7f\u7528\u5408\u9002\u7684\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u6211\u4eec\u53ef\u4ee5\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ece\u800c\u5927\u5e45\u538b\u7f29\u6a21\u578b\u8bad\u7ec3\u7684\u65f6\u95f4\u3002\u9488\u5bf9\u4e0d\u540c\u7684\u4f7f\u7528\u573a\u666f\uff0cTensorFlow \u5728 tf.distribute.Strategy`\u4e2d\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u82e5\u5e72\u79cd\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u4f7f\u5f97\u6211\u4eec\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u8bad\u7ec3\u6a21\u578b\u3002","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section8/#481-tensorflow","text":"\u56fe\u95f4\u5e76\u884c\uff08\u53c8\u79f0\u6570\u636e\u5e76\u884c\uff09 \u6bcf\u4e2a\u673a\u5668\u4e0a\u90fd\u4f1a\u6709\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\uff0c\u5c06\u6570\u636e\u5206\u6563\u5230\u5404\u4e2a\u673a\u5668\uff0c\u5206\u522b\u8ba1\u7b97\u68af\u5ea6\u3002 \u56fe\u5185\u5e76\u884c\uff08\u53c8\u79f0\u6a21\u578b\u5e76\u884c\uff09 \u6bcf\u4e2a\u673a\u5668\u5206\u522b\u8d1f\u8d23\u6574\u4e2a\u6a21\u578b\u7684\u4e00\u90e8\u5206\u8ba1\u7b97\u4efb\u52a1\u3002","title":"4.8.1 TensorFlow \u5206\u5e03\u5f0f\u7684\u5206\u7c7b"},{"location":"tensorFlow/section8/#1","text":"\u540c\u6b65\uff1a\u6536\u96c6\u5230\u8db3\u591f\u6570\u91cf\u7684\u68af\u5ea6\uff0c\u4e00\u540c\u66f4\u65b0\uff0c\u4e0b\u56fe\u4e0a\u65b9 \u5f02\u6b65\uff1a\u5373\u540c\u6b65\u65b9\u5f0f\u4e0b\uff0c\u66f4\u65b0\u9700\u6c42\u7684\u68af\u5ea6\u6570\u91cf\u4e3a1\uff0c\u4e0b\u56fe\u4e0b\u65b9 \u6ce8\uff1aPS(parameter server):\u7ef4\u62a4\u5168\u5c40\u5171\u4eab\u7684\u6a21\u578b\u53c2\u6570\u7684\u670d\u52a1\u5668","title":"1\u3001\u56fe\u95f4\u5e76\u884c\u7528\u7684\u975e\u5e38\u591a\uff0c\u4f1a\u5305\u542b\u4e24\u79cd\u65b9\u5f0f\u8fdb\u884c\u66f4\u65b0"},{"location":"tensorFlow/section8/#2","text":"\u5355\u673a\u591a\u5361 \u591a\u673a\u5355\u5361 TensorFlow\u591a\u673a\u591a\u5361\u5b9e\u73b0\u601d\u8def \u3002\u591a\u7ea7\u591a\u5361\u7684\u5206\u5e03\u5f0f\u6709\u5f88\u591a\u5b9e\u73b0\u65b9\u5f0f\uff0c\u6bd4\u5982\uff1a 1. \u5c06\u6bcf\u4e2a GPU\u5f53\u505a\u4e00\u4e2aworker 2. \u540c\u4e00\u4e2a\u673a\u5668\u7684\u5404\u4e2a GPU\u8fdb\u884c\u56fe\u5185\u5e76\u884c 3. \u540c\u4e00\u4e2a\u673a\u5668\u7684\u5404\u4e2a GPU\u8fdb\u884c\u56fe\u95f4\u5e76\u884c \u6bd4\u5982\u8bf4\u7b2c\u4e09\u79cd\uff1a\u6a21\u578b\u5b9e\u73b0\u5c01\u88c5\u6210\u51fd\u6570\u3001\u5c06\u6570\u636e\u5206\u6210 GPU\u6570\u91cf\u7684\u4efd\u6570 \u3001\u5728\u6bcf\u4e2a GPU\u4e0b \uff0c\u8fdb\u884c\u4e00\u6b21\u6a21\u578b forward\u8ba1\u7b97 \uff0c\u5e76\u4f7f\u7528\u4f18\u5316\u5668\u7b97\u51fa\u68af\u5ea6\u3001 reduce\u6bcf\u4e2aGPU\u4e0b\u7684\u68af\u5ea6 \uff0c\u5e76\u5c06\u68af\u5ea6\u4f20\u5165\u5230\u5206\u5e03\u5f0f\u4e2d\u7684\u4f18\u5316\u5668\u4e2d","title":"2\u3001\u5b9e\u73b0\u65b9\u5f0f"},{"location":"tensorFlow/section8/#481-mirroredstrategy","text":"tf.distribute.MirroredStrategy \u662f\u4e00\u79cd\u7b80\u5355\u4e14\u9ad8\u6027\u80fd\u7684\uff0c\u6570\u636e\u5e76\u884c\u7684\u540c\u6b65\u5f0f\u5206\u5e03\u5f0f\u7b56\u7565\uff0c\u4e3b\u8981\u652f\u6301\u591a\u4e2a GPU \u5728\u540c\u4e00\u53f0\u4e3b\u673a\u4e0a\u8bad\u7ec3\u3002 1\u3001MirroredStrategy\u8fd0\u884c\u539f\u7406\uff1a 1\u3001\u8bad\u7ec3\u5f00\u59cb\u524d\uff0c\u8be5\u7b56\u7565\u5728\u6240\u6709 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\uff08GPU\uff09\u4e0a\u5747\u5404\u590d\u5236\u4e00\u4efd\u5b8c\u6574\u7684\u6a21\u578b 2\u3001\u6bcf\u6b21\u8bad\u7ec3\u4f20\u5165\u4e00\u4e2a\u6279\u6b21\u7684\u6570\u636e\u65f6\uff0c\u5c06\u6570\u636e\u5206\u6210 N \u4efd\uff0c\u5206\u522b\u4f20\u5165 N \u4e2a\u8ba1\u7b97\u8bbe\u5907\uff08\u5373\u6570\u636e\u5e76\u884c\uff09 3\u3001\u4f7f\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684 All-reduce \u64cd\u4f5c\uff0c\u5728\u8ba1\u7b97\u8bbe\u5907\u95f4\u9ad8\u6548\u4ea4\u6362\u68af\u5ea6\u6570\u636e\u5e76\u8fdb\u884c\u6c42\u548c\uff0c\u4f7f\u5f97\u6700\u7ec8\u6bcf\u4e2a\u8bbe\u5907\u90fd\u6709\u4e86\u6240\u6709\u8bbe\u5907\u7684\u68af\u5ea6\u4e4b\u548c\uff0c\u4f7f\u7528\u68af\u5ea6\u6c42\u548c\u7684\u7ed3\u679c\u66f4\u65b0\u672c\u5730\u53d8\u91cf \u5f53\u6240\u6709\u8bbe\u5907\u5747\u66f4\u65b0\u672c\u5730\u53d8\u91cf\u540e\uff0c\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8bad\u7ec3\uff08\u5373\u8be5\u5e76\u884c\u7b56\u7565\u662f\u540c\u6b65\u7684\uff09\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cTensorFlow \u4e2d\u7684 MirroredStrategy \u7b56\u7565\u4f7f\u7528 NVIDIA NCCL \u8fdb\u884c All-reduce \u64cd\u4f5c\u3002 2\u3001\u6784\u5efa\u4ee3\u7801\u6b65\u9aa4\uff1a 1\u3001\u4f7f\u7528\u8fd9\u79cd\u7b56\u7565\u65f6\uff0c\u6211\u4eec\u53ea\u9700\u5b9e\u4f8b\u5316\u4e00\u4e2a MirroredStrategy \u7b56\u7565: strategy = tf . distribute . MirroredStrategy () 2\u3001\u5e76\u5c06\u6a21\u578b\u6784\u5efa\u7684\u4ee3\u7801\u653e\u5165 strategy.scope() \u7684\u4e0a\u4e0b\u6587\u73af\u5883\u4e2d: with strategy . scope (): # \u6a21\u578b\u6784\u5efa\u4ee3\u7801 \u6216\u8005\u53ef\u4ee5\u5728\u53c2\u6570\u4e2d\u6307\u5b9a\u8bbe\u5907\uff0c\u5982: strategy = tf . distribute . MirroredStrategy ( devices = [ \"/gpu:0\" , \"/gpu:1\" ]) \u5373\u6307\u5b9a\u53ea\u4f7f\u7528\u7b2c 0\u30011 \u53f7 GPU \u53c2\u4e0e\u5206\u5e03\u5f0f\u7b56\u7565\u3002","title":"4.8.1 \u5355\u673a\u591a\u5361\u8bad\u7ec3\uff1a MirroredStrategy"},{"location":"tensorFlow/section8/#4811-mirroredstrategy","text":"\u4ee5\u4e0b\u4ee3\u7801\u5c55\u793a\u4e86\u4f7f\u7528 MirroredStrategy \u7b56\u7565\uff0c\u5728 TensorFlow Datasets \u4e2d\u7684\u90e8\u5206\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u4f7f\u7528 Keras \u8bad\u7ec3 MobileNetV2 \u7684\u8fc7\u7a0b\uff1a import tensorflow as tf import tensorflow_datasets as tfds num_epochs = 5 batch_size_per_replica = 64 learning_rate = 0.001 strategy = tf . distribute . MirroredStrategy () print ( 'Number of devices: %d ' % strategy . num_replicas_in_sync ) # \u8f93\u51fa\u8bbe\u5907\u6570\u91cf batch_size = batch_size_per_replica * strategy . num_replicas_in_sync # \u8f7d\u5165\u6570\u636e\u96c6\u5e76\u9884\u5904\u7406 def resize ( image , label ): image = tf . image . resize ( image , [ 224 , 224 ]) / 255.0 return image , label # \u5f53as_supervised\u4e3aTrue\u65f6\uff0c\u8fd4\u56deimage\u548clabel\u4e24\u4e2a\u952e\u503c dataset = tfds . load ( \"cats_vs_dogs\" , split = tfds . Split . TRAIN , as_supervised = True ) dataset = dataset . map ( resize ) . shuffle ( 1024 ) . batch ( batch_size ) with strategy . scope (): model = tf . keras . applications . MobileNetV2 () model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) model . fit ( dataset , epochs = num_epochs ) \u8fd9\u4e2a\u662f\u5728\u7ebf\u4e0b\u6d4b\u8bd5\u7684\u7ed3\u679c epoch=5,batch_size=64 2\u5757 NVIDIA GeForce GTX 1080 Ti \u663e\u5361\u8fdb\u884c\u5355\u673a\u591a\u5361\u7684\u6a21\u578b\u8bad\u7ec3\u3002 \u6570\u636e\u96c6 \u5355\u673a\u65e0\u5206\u5e03\u5f0f\uff08Batch Size \u4e3a 64\uff09 \u5355\u673a\u591a\u5361\uff08\u603b Batch Size \u4e3a 64\uff09 \u5355\u673a\u591a\u5361\uff08\u603b Batch Size \u4e3a 256\uff09 cats_vs_dogs 150s/epoch 36s/epoch 30s/epoch","title":"4.8.1.1 MirroredStrategy\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u8bad\u7ec3"},{"location":"tensorFlow/section8/#482-multiworkermirroredstrategy","text":"\u591a\u673a\u8bad\u7ec3\u7684\u65b9\u6cd5\u548c\u5355\u673a\u591a\u5361\u7c7b\u4f3c\uff0c\u5c06 MirroredStrategy \u66f4\u6362\u4e3a\u9002\u5408\u591a\u673a\u8bad\u7ec3\u7684 MultiWorkerMirroredStrategy \u5373\u53ef\u3002\u4e0d\u8fc7\uff0c\u7531\u4e8e\u6d89\u53ca\u5230\u591a\u53f0\u8ba1\u7b97\u673a\u4e4b\u95f4\u7684\u901a\u8baf\uff0c\u8fd8\u9700\u8981\u8fdb\u884c\u4e00\u4e9b\u989d\u5916\u7684\u8bbe\u7f6e\u3002 1\u3001\u9700\u8981\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf TF_CONFIG \uff0c\u793a\u4f8b\u5982\u4e0b: os . environ [ 'TF_CONFIG' ] = json . dumps ({ 'cluster' : { 'worker' : [ \"localhost:8888\" , \"localhost:9999\" ] }, 'task' : { 'type' : 'worker' , 'index' : 0 } }) 2\u3001TF_CONFIG \u7531 cluster \u548c task \u4e24\u90e8\u5206\u7ec4\u6210\uff1a cluster \u8bf4\u660e\u4e86\u6574\u4e2a\u591a\u673a\u96c6\u7fa4\u7684\u7ed3\u6784\u548c\u6bcf\u53f0\u673a\u5668\u7684\u7f51\u7edc\u5730\u5740\uff08IP + \u7aef\u53e3\u53f7\uff09\u3002\u5bf9\u4e8e\u6bcf\u4e00\u53f0\u673a\u5668\uff0ccluster \u7684\u503c\u90fd\u662f\u76f8\u540c\u7684\u3002 task \u8bf4\u660e\u4e86\u5f53\u524d\u673a\u5668\u7684\u89d2\u8272\u3002\u4f8b\u5982\uff0c {'type': 'worker', 'index': 0} \u8bf4\u660e\u5f53\u524d\u673a\u5668\u662f cluster \u4e2d\u7684\u7b2c 0 \u4e2a worker\uff08\u5373 localhost:20000 \uff09\u3002\u6bcf\u4e00\u53f0\u673a\u5668\u7684 task \u503c\u90fd\u9700\u8981\u9488\u5bf9\u5f53\u524d\u4e3b\u673a\u8fdb\u884c\u5206\u522b\u7684\u8bbe\u7f6e\u3002 3\u3001\u8fd0\u884c\u8fc7\u7a0b 1\u3001\u5728\u6240\u6709\u7684\u673a\u5668\u4e0a\u9010\u4e2a\u8fd0\u884c\u8bad\u7ec3\u4ee3\u7801\u5373\u53ef\u3002\u5148\u8fd0\u884c\u7684\u4ee3\u7801\u5728\u5c1a\u672a\u4e0e\u5176\u4ed6\u4e3b\u673a\u8fde\u63a5\u65f6\u4f1a\u8fdb\u5165\u76d1\u542c\u72b6\u6001\uff0c\u5f85\u6574\u4e2a\u96c6\u7fa4\u7684\u8fde\u63a5\u5efa\u7acb\u5b8c\u6bd5\u540e\uff0c\u6240\u6709\u7684\u673a\u5668\u5373\u4f1a\u540c\u65f6\u5f00\u59cb\u8bad\u7ec3\u3002 2\u3001\u5047\u8bbe\u6709\u4e24\u53f0\u673a\u5668\uff0c\u5373\u9996\u5148\u5728\u4e24\u53f0\u673a\u5668\u4e0a\u5747\u90e8\u7f72\u8fd9\u4e2a\u7a0b\u5e8f\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f task \u90e8\u5206\uff0c\u7b2c\u4e00\u53f0\u673a\u5668\u8bbe\u7f6e\u4e3a {'type': 'worker', 'index': 0} \uff0c\u7b2c\u4e8c\u53f0\u673a\u5668\u8bbe\u7f6e\u4e3a {'type': 'worker', 'index': 1} \u3002\u63a5\u4e0b\u6765\uff0c\u5728\u4e24\u53f0\u673a\u5668\u4e0a\u4f9d\u6b21\u8fd0\u884c\u7a0b\u5e8f\uff0c\u5f85\u901a\u8baf\u6210\u529f\u540e\uff0c\u5373\u4f1a\u81ea\u52a8\u5f00\u59cb\u8bad\u7ec3\u6d41\u7a0b\u3002","title":"4.8.2 \u591a\u673a\u8bad\u7ec3\uff1a MultiWorkerMirroredStrategy"},{"location":"tensorFlow/section8/#_2","text":"\u540c\u6837\u5bf9\u4e8e\u540c\u4e00\u4e2a\u6570\u636e\u53ca\u8fdb\u884c\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6307\u5b9a\u591a\u673a\u4ee3\u7801\uff1a import tensorflow_datasets as tfds import os import json num_epochs = 5 batch_size_per_replica = 64 learning_rate = 0.001 num_workers = 2 # 1\u3001\u6307\u5b9a\u96c6\u7fa4\u73af\u5883 os . environ [ 'TF_CONFIG' ] = json . dumps ({ 'cluster' : { 'worker' : [ \"localhost:20000\" , \"localhost:20001\" ] }, 'task' : { 'type' : 'worker' , 'index' : 0 } }) batch_size = batch_size_per_replica * num_workers def resize ( image , label ): image = tf . image . resize ( image , [ 224 , 224 ]) / 255.0 return image , label dataset = tfds . load ( \"cats_vs_dogs\" , split = tfds . Split . TRAIN , as_supervised = True ) dataset = dataset . map ( resize ) . shuffle ( 1024 ) . batch ( batch_size ) # 2\u3001\u521d\u59cb\u5316\u96c6\u7fa4 strategy = tf . distribute . experimental . MultiWorkerMirroredStrategy () # 3\u3001\u4e0a\u4e0b\u6587\u73af\u5883\u5b9a\u4e49\u6a21\u578b with strategy . scope (): model = tf . keras . applications . MobileNetV2 () model . compile ( optimizer = tf . keras . optimizers . Adam ( learning_rate = learning_rate ), loss = tf . keras . losses . sparse_categorical_crossentropy , metrics = [ tf . keras . metrics . sparse_categorical_accuracy ] ) model . fit ( dataset , epochs = num_epochs ) \u6d4b\u8bd5\u7ed3\u679c\u6bd4\u8f83\uff1a\u5355\u5f20 NVIDIA Tesla K80 \u663e\u5361\uff0c\u4f7f\u7528\u5355\u673a\u5355\u5361\u65f6\uff0cBatch Size \u8bbe\u7f6e\u4e3a 64\uff1b\u4f7f\u7528\u53cc\u673a\u5355\u5361\u65f6\uff0c\u6d4b\u8bd5\u603b Batch Size \u4e3a 64\uff08\u5206\u53d1\u5230\u5355\u53f0\u673a\u5668\u7684 Batch Size \u4e3a 32\uff09\u548c\u603b Batch Size \u4e3a 128\uff08\u5206\u53d1\u5230\u5355\u53f0\u673a\u5668\u7684 Batch Size \u4e3a 64\uff09\u4e24\u79cd\u60c5\u51b5\u3002 \u6570\u636e\u96c6 \u5355\u673a\u5355\u5361\uff08Batch Size \u4e3a 64\uff09 \u53cc\u673a\u5355\u5361\uff08\u603b Batch Size \u4e3a 64\uff09 \u53cc\u673a\u5355\u5361\uff08\u603b Batch Size \u4e3a 128\uff09 cats_vs_dogs 1622s 858s 755s","title":"\u591a\u673a\u8bad\u7ec3\u4ee3\u7801"},{"location":"tensorFlow/section8/#483","text":"TensorFlow\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63a5\u53e3\u4f7f\u7528","title":"4.8.3 \u603b\u7ed3"},{"location":"tensorFlow/section9/","text":"4.9 \u7efc\u5408\u6848\u4f8b\uff1a\u5783\u573e\u5206\u7c7b\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u76ee\u6807 \u77e5\u9053\u5783\u573e\u5206\u7c7b\u76f8\u5173\u6bd4\u8d5b\u95ee\u9898 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u5e38\u89c1\u4f18\u5316(tricks) \u638c\u63e1\u5e38\u7528\u5206\u7c7b\u95ee\u9898\u7684\u6570\u636e\u589e\u5f3a\u65b9\u5f0f mixup\u7b49 \u638c\u63e1\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316 \u4e86\u89e3\u5206\u7c7b\u5e38\u89c1\u6a21\u578b\u4ee5\u53ca\u6a21\u578b\u7b97\u6cd5\u4f18\u5316 \u5e94\u7528 \u5e94\u7528Tensorflow\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u6570\u636e\u7684\u8bfb\u53d6\u4ee5\u53ca\u5904\u7406\u8981\u6c42 4.9.1 \u5783\u573e\u5206\u7c7b\u4ecb\u7ecd \u00b6 \u5783\u573e\u5206\u7c7b\u95ee\u9898\u662f2019\u5e74\u7684\u793e\u4f1a\u70ed\u70b9\u95ee\u9898\uff0c2019\u5e746\u670825\u65e5\uff0c\u751f\u6d3b\u5783\u573e\u5206\u7c7b\u5236\u5ea6\u5c06\u5165\u6cd5\u3002\u4e0a\u6d77\u6210\u4e3a\u7b2c\u4e00\u4e2a\u4e2d\u56fd\u5783\u573e\u5206\u7c7b\u8bd5\u70b9\u57ce\u5e02\u3002 \u4e00\u822c\u662f\u6307\u6309\u4e00\u5b9a\u89c4\u5b9a\u6216\u6807\u51c6\u5c06\u5783\u573e\u5206\u7c7b\u50a8\u5b58\u3001\u5206\u7c7b\u6295\u653e\u548c\u5206\u7c7b\u642c\u8fd0\uff0c\u4ece\u800c\u8f6c\u53d8\u6210\u516c\u5171\u8d44\u6e90\u7684\u4e00\u7cfb\u5217\u6d3b\u52a8\u7684\u603b\u79f0\u3002\u5206\u7c7b\u7684\u76ee\u7684\u662f\u63d0\u9ad8\u5783\u573e\u7684\u8d44\u6e90\u4ef7\u503c\u548c\u7ecf\u6d4e\u4ef7\u503c\uff0c\u529b\u4e89\u7269\u5c3d\u5176\u7528\u3002 1\u3001\u5783\u573e\u5206\u7c7b\u95ee\u9898\u7684\u9700\u6c42 \uff1a \u00b6 \u5c0f\u732a\u4f69\u5947\u7248\u672c\uff1a \u6ce8\uff1a\u6e7f\u5783\u573e\uff08\u53a8\u4f59\u5783\u573e\uff09\uff0c\u5e72\u5783\u573e\uff08\u5176\u4ed6\u5783\u573e\uff09 \u5206\u7c7b\u77e5\u8bc6\u5c0f\u62d3\u5c55\uff1a\u53ef\u56de\u6536\u7269\u6307\u9002\u5b9c\u56de\u6536\u548c\u8d44\u6e90\u5229\u7528\u7684\u5e9f\u5f03\u7269\uff0c\u5305\u62ec\u5e9f\u5f03\u7684\u73bb\u7483\u3001\u91d1\u5c5e\u3001\u5851\u6599\u3001\u7eb8\u7c7b\u3001\u7ec7\u7269\u3001\u5bb6\u5177\u3001\u7535\u5668\u7535\u5b50\u4ea7\u54c1\u548c\u5e74\u82b1\u5e74\u6854\u7b49\u3002\u53a8\u4f59\u5783\u573e\u6307\u5bb6\u5ead\u3001\u4e2a\u4eba\u4ea7\u751f\u7684\u6613\u8150\u6027\u5783\u573e\uff0c\u5305\u62ec\u5269\u83dc\u3001\u5269\u996d\u3001\u83dc\u53f6\u3001\u679c\u76ae\u3001\u86cb\u58f3\u3001\u8336\u6e23\u3001\u6c64\u6e23\u3001\u9aa8\u5934\u3001\u5e9f\u5f03\u98df\u7269\u4ee5\u53ca\u53a8\u623f\u4e0b\u811a\u6599\u7b49\u3002\u6709\u5bb3\u5783\u573e\u6307\u5bf9\u4eba\u4f53\u5065\u5eb7\u6216\u8005\u81ea\u7136\u73af\u5883\u9020\u6210\u76f4\u63a5\u6216\u8005\u6f5c\u5728\u5371\u5bb3\u4e14\u5e94\u5f53\u4e13\u95e8\u5904\u7406\u7684\u5e9f\u5f03\u7269\uff0c\u5305\u62ec\u5e9f\u7535\u6c60\u3001\u5e9f\u8367\u5149\u706f\u7ba1\u7b49\u3002\u5176\u4ed6\u5783\u573e\u6307\u9664\u4ee5\u4e0a\u4e09\u7c7b\u5783\u573e\u4e4b\u5916\u7684\u5176\u4ed6\u751f\u6d3b\u5783\u573e\uff0c\u6bd4\u5982\u7eb8\u5c3f\u88e4\u3001\u5c18\u571f\u3001\u70df\u5934\u3001\u4e00\u6b21\u6027\u5feb\u9910\u76d2\u3001\u7834\u635f\u82b1\u76c6\u53ca\u7897\u789f\u3001\u5899\u7eb8\u7b49\u3002 2\u3001\u5783\u573e\u5206\u7c7b\u610f\u4e49 \u00b6 \u51cf\u5c11\u5360\u5730\u3001\u51cf\u5c11\u6c61\u67d3\u3001\u53d8\u5e9f\u4e3a\u5b9d 3\u3001\u5783\u573e\u5206\u7c7b\u96be\u70b9 \u00b6 \u79cd\u7c7b\u591a\uff0c\u6613\u5206\u9519\uff1a\u5982\u53e3\u9999\u7cd6\uff1f\u6e7f\u7eb8\u5dfe\uff1f\u74dc\u5b50\u76ae\uff1f\u5851\u6599\u888b\uff1f \u5e72\uff0c\u5e72\uff0c\u6e7f\uff0c\u53ef\u56de\u6536 \u81ea\u52a8\u5206\u6361 \u4eba\u4eec\u901a\u8fc7\u624b\u673a\u62cd\u7167\uff0c\u7528\u7a0b\u5e8f\u81ea\u52a8\u8bc6\u522b\u51fa\u5783\u573e\u7684\u7c7b\u522b\uff0c\u4e0d\u4ec5\u7b80\u5316\u4eba\u4eec\u5bf9\u5783\u573e\u5206\u7c7b\u7684\u5904\u7406\uff0c\u800c\u4e14\u63d0\u9ad8\u5783\u573e\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3002 4.9.1.1 \u5783\u573e\u5206\u7c7b\u6bd4\u8d5b \u00b6 1\u3001\u534e\u4e3a\u4e91\u4eba\u5de5\u667a\u80fd\u5927\u8d5b\u00b7\u5783\u573e\u5206\u7c7b\u6311\u6218\u676f \u5b98\u7f51\uff1a https://competition.huaweicloud.com/information/1000007620/introduction 1\u3001\u5783\u573e\u79cd\u7c7b40\u7c7b \u00b6 { \"0\": \"\u5176\u4ed6\u5783\u573e/\u4e00\u6b21\u6027\u5feb\u9910\u76d2\", \"1\": \"\u5176\u4ed6\u5783\u573e/\u6c61\u635f\u5851\u6599\", \"2\": \"\u5176\u4ed6\u5783\u573e/\u70df\u8482\", \"3\": \"\u5176\u4ed6\u5783\u573e/\u7259\u7b7e\", \"4\": \"\u5176\u4ed6\u5783\u573e/\u7834\u788e\u82b1\u76c6\u53ca\u789f\u7897\", \"5\": \"\u5176\u4ed6\u5783\u573e/\u7af9\u7b77\", \"6\": \"\u53a8\u4f59\u5783\u573e/\u5269\u996d\u5269\u83dc\", \"7\": \"\u53a8\u4f59\u5783\u573e/\u5927\u9aa8\u5934\", \"8\": \"\u53a8\u4f59\u5783\u573e/\u6c34\u679c\u679c\u76ae\", \"9\": \"\u53a8\u4f59\u5783\u573e/\u6c34\u679c\u679c\u8089\", \"10\": \"\u53a8\u4f59\u5783\u573e/\u8336\u53f6\u6e23\", \"11\": \"\u53a8\u4f59\u5783\u573e/\u83dc\u53f6\u83dc\u6839\", \"12\": \"\u53a8\u4f59\u5783\u573e/\u86cb\u58f3\", \"13\": \"\u53a8\u4f59\u5783\u573e/\u9c7c\u9aa8\", \"14\": \"\u53ef\u56de\u6536\u7269/\u5145\u7535\u5b9d\", \"15\": \"\u53ef\u56de\u6536\u7269/\u5305\", \"16\": \"\u53ef\u56de\u6536\u7269/\u5316\u5986\u54c1\u74f6\", \"17\": \"\u53ef\u56de\u6536\u7269/\u5851\u6599\u73a9\u5177\", \"18\": \"\u53ef\u56de\u6536\u7269/\u5851\u6599\u7897\u76c6\", \"19\": \"\u53ef\u56de\u6536\u7269/\u5851\u6599\u8863\u67b6\", \"20\": \"\u53ef\u56de\u6536\u7269/\u5feb\u9012\u7eb8\u888b\", \"21\": \"\u53ef\u56de\u6536\u7269/\u63d2\u5934\u7535\u7ebf\", \"22\": \"\u53ef\u56de\u6536\u7269/\u65e7\u8863\u670d\", \"23\": \"\u53ef\u56de\u6536\u7269/\u6613\u62c9\u7f50\", \"24\": \"\u53ef\u56de\u6536\u7269/\u6795\u5934\", \"25\": \"\u53ef\u56de\u6536\u7269/\u6bdb\u7ed2\u73a9\u5177\", \"26\": \"\u53ef\u56de\u6536\u7269/\u6d17\u53d1\u6c34\u74f6\", \"27\": \"\u53ef\u56de\u6536\u7269/\u73bb\u7483\u676f\", \"28\": \"\u53ef\u56de\u6536\u7269/\u76ae\u978b\", \"29\": \"\u53ef\u56de\u6536\u7269/\u7827\u677f\", \"30\": \"\u53ef\u56de\u6536\u7269/\u7eb8\u677f\u7bb1\", \"31\": \"\u53ef\u56de\u6536\u7269/\u8c03\u6599\u74f6\", \"32\": \"\u53ef\u56de\u6536\u7269/\u9152\u74f6\", \"33\": \"\u53ef\u56de\u6536\u7269/\u91d1\u5c5e\u98df\u54c1\u7f50\", \"34\": \"\u53ef\u56de\u6536\u7269/\u9505\", \"35\": \"\u53ef\u56de\u6536\u7269/\u98df\u7528\u6cb9\u6876\", \"36\": \"\u53ef\u56de\u6536\u7269/\u996e\u6599\u74f6\", \"37\": \"\u6709\u5bb3\u5783\u573e/\u5e72\u7535\u6c60\", \"38\": \"\u6709\u5bb3\u5783\u573e/\u8f6f\u818f\", \"39\": \"\u6709\u5bb3\u5783\u573e/\u8fc7\u671f\u836f\u7269\" } 2\u3001\u5176\u4ed6\u6bd4\u8d5b Apache Flink\u6781\u5ba2\u6311\u6218\u8d5b\u2014\u2014\u5783\u573e\u56fe\u7247\u5206\u7c7b \u5b98\u65b9\uff1a https://tianchi.aliyun.com/competition/entrance/231743/information 4.9.2 \u534e\u4e3a\u5783\u573e\u5206\u7c7b\u6bd4\u8d5b\u4ecb\u7ecd \u00b6 \u672c\u6b21\u6bd4\u8d5b\u9009\u53d640\u79cd\u751f\u6d3b\u4e2d\u5e38\u89c1\u7684\u5783\u573e\uff0c\u9009\u624b\u6839\u636e\u516c\u5e03\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53d1\u5e03\u5230\u534e\u4e3aModelArts\u5e73\u53f0\u4e0a\uff0c\u5728\u7ebf\u9884\u6d4b\u534e\u4e3a\u7684\u79c1\u6709\u6570\u636e\u96c6\uff0c\u91c7\u7528\u8bc6\u522b\u51c6\u786e\u7387\u4f5c\u4e3a\u8bc4\u4ef7\u6307\u6807\u3002 \u8fd9\u6b21\u6bd4\u8d5b\u4e2d\u6709\u5f88\u591a\u5bb9\u6613\u6df7\u6dc6\u7684\u7c7b\uff0c\u6bd4\u5982\u996e\u6599\u74f6\u548c\u8c03\u6599\u74f6\u3001\u7b77\u5b50\u548c\u7259\u7b7e\u3001\u679c\u76ae\u548c\u679c\u8089\u7b49\u5916\u5f62\u6781\u4e3a\u76f8\u4f3c\u7684\u5783\u573e\uff0c\u56e0\u6b64\u6b64\u6b21\u7ade\u8d5b\u4e5f\u53ef\u770b\u4f5c\u662f\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u3002 \u91cd\u8981\uff1a\u6bd4\u8d5b\u6216\u8005\u9879\u76ee\u89e3\u9898\u601d\u8def \u00b6 1\u3001\u62ff\u5230\u6570\u636e\u540e\uff0c\u9996\u5148\u505a\u6570\u636e\u5206\u6790\u3002\u7edf\u8ba1\u6570\u636e\u6837\u672c\u5206\u5e03\uff0c\u5c3a\u5bf8\u5206\u5e03\uff0c\u56fe\u7247\u5f62\u6001\u7b49\uff0c\u57fa\u4e8e\u5206\u6790\u53ef\u4ee5\u505a\u4e00\u4e9b\u9488\u5bf9\u6027\u7684\u6570\u636e\u9884\u5904\u7406\u7b97\u6cd5\uff0c\u5bf9\u540e\u671f\u7684\u6a21\u578b\u8bad\u7ec3\u4f1a\u6709\u5f88\u5927\u7684\u5e2e\u52a9 2\u3001\u9009\u62e9\u597d\u7684baseline\u3002\u9700\u8981\u4e0d\u65ad\u7684\u5c1d\u8bd5\u5404\u79cd\u73b0\u6709\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u8fdb\u884c\u7ed3\u679c\u5bf9\u6bd4\uff0c\u6311\u9009\u51fa\u9002\u5408\u8be5\u7f51\u7edc\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u7136\u540e\u57fa\u4e8e\u8be5\u6a21\u578b\u8fdb\u884c\u4e0d\u65ad\u7684\u8c03\u53c2\uff0c\u8c03\u8bd5\u51fa\u6027\u80fd\u8f83\u597d\u7684\u53c2\u6570 3\u3001\u505a\u7ed3\u679c\u9a8c\u8bc1\uff0c\u5c06\u4e0a\u8ff0\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u505a\u7ed3\u679c\u9a8c\u8bc1\uff0c\u627e\u51fa\u9519\u8bef\u6837\u672c\uff0c\u5206\u6790\u51fa\u9519\u539f\u56e0\uff0c\u7136\u540e\u9488\u5bf9\u6027\u7684\u8c03\u6574\u7f51\u7edc\u548c\u6570\u636e\u3002 3\u3001\u57fa\u4e8e\u65b0\u6570\u636e\u548c\u6a21\u578b\uff0c\u518d\u6b21\u8fdb\u884c\u6a21\u578b\u8c03\u4f18 \u6bd4\u8d5b\u8868\u73b0\u524d5\u56e2\u961f\u6548\u679c \u00b6 \u540d\u6b21 \u51c6\u786e\u7387 \u63a8\u7406(inference)\u65f6\u95f4(ms) \u7b2c\u4e00\u540d 0.969636 102.8 \u7b2c\u4e8c\u540d 0.96251 95.43 \u7b2c\u4e09\u540d 0.962045 97.25 \u7b2c\u56db\u540d 0.961735 82.99 \u7b2c\u4e94\u540d 0.957397 108.49 4.9.2.1 \u8d5b\u9898\u5206\u6790 \u00b6 1\u3001\u95ee\u9898\u63cf\u8ff0: \u00b6 \u7ecf\u5178\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u3002\u91c7\u7528\u6df1\u5733\u5e02\u5783\u573e\u5206\u7c7b\u6807\u51c6\uff0c\u8f93\u51fa\u8be5\u7269\u54c1\u5c5e\u4e8e\u53ef\u56de\u6536\u7269\u3001 \u53a8\u4f59\u5783\u573e\u3001\u6709\u5bb3\u5783\u573e\u548c\u5176\u4ed6\u5783\u573e\u4e2d\u7684\u4e8c\u7ea7\u5206\u7c7b\uff0c\u517143\u4e2a\u7c7b\u522b\u3002 2\u3001\u8bc4\u4ef7\u6307\u6807: \u00b6 \u8bc6\u522b\u51c6\u786e\u7387 = \u8bc6\u522b\u6b63\u786e\u7684\u56fe\u7247\u6570 / \u56fe\u7247\u603b\u6570 3\u3001\u6311\u6218: \u00b6 \u5b98\u65b9\u8bad\u7ec3\u96c6\u670919459\u5f20\u56fe\u7247\uff0c\u6570\u636e\u91cf\u5c0f; \u7c7b\u522b\u8f83\u591a(40)\uff0c\u4e14\u5404\u7c7b\u6837\u672c\u4e0d\u5e73\u8861; \u56fe\u7247\u5927\u5c0f\u3001\u5206\u8fa8\u7387\u4e0d\u4e00\uff0c\u5783\u573e\u7269\u54c1\u6709\u591a\u79cd\u5c3a\u5ea6; \u5783\u573e\u5206\u7c7b\u662f\u7ec6\u7c92\u5ea6\u3001\u7c97\u7c92\u5ea6\u517c\u6709\u7684\u4e00\u79cd\u5206\u7c7b\u95ee\u9898\uff0c\u8f6e\u5ed3\u3001\u7eb9\u7406\u3001\u5bf9\u8c61\u4f4d\u7f6e\u5206 \u5e03\u90fd\u9700\u8981\u8003\u5bdf 4.9.2.2 \u5bf9\u7b56 \u00b6 1\u3001\u6570\u636e\u96c6\u5206\u6790\u548c\u9009\u62e9 2\u3001\u6a21\u578b\u9009\u62e9 3\u3001\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u5e38\u89c1trick\uff08\u4f18\u5316\uff09 1\u3001\u6570\u636e\u96c6\u60c5\u51b5 \u00b6 \u6570\u636e\u96c6\u4e0b\u8f7d\u4ee5\u53ca\u7ec4\u6210 \u7ec4\u6210\u6709train_data\uff0c\u7136\u540e\u540c\u76ee\u5f55\u4e0b\u6709\u56fe\u7247\u4ee5\u53ca\u5bf9\u5e94txt txt\u4e2d\u7684\u683c\u5f0f\uff1aimg_1.jpg, 0-\u4e3a\u56fe\u7247\u4ee5\u53ca\u5bf9\u5e94\u76ee\u6807 \u6ce8\uff1a\u5b98\u65b9\u8fd8\u6709V2\u7248\u672c\u7684\u6570\u636e\uff0c\u62d3\u5c55\u4e86\u7c7b\u522b\u517143\u7c7b\uff08\u6211\u4eec\u540e\u9762\u7684\u9879\u76ee\u662f\u5728\u7b2c\u4e00\u4e2a\u7248\u672c\u7684\u6570\u636e\u4e2d\u505a\u8bad\u7ec3\uff09 2\u3001\u5206\u7c7b\u6a21\u578b\u9009\u62e9 \u00b6 \u6570\u636e\u91cf\u5c0f\u3001\u7c7b\u522b\u591a\u3001\u63a8\u7406\u65f6\u95f4\u77ed->\u7efc\u5408\u8003\u5bdf\u8ba1 \u7b97\u91cf\u3001\u4f53\u79ef\u3001\u7cbe\u5ea6\uff0c\u9009\u62e9\u8fd1\u671f\u624d\u53d1\u5e03\u7684\u9ad8\u8d28\u91cf \u9884\u8bad\u7ec3\u6a21\u578b(EfficientNet B5/B4)\u8fdb\u884c\u8fc1\u79fb \u5b66\u4e60 \uff081\uff09\u73b0\u6709\u6a21\u578b\u4ee5\u53ca\u51c6\u786e\u7387\u5bf9\u6bd4 \u00b6 Top-1 \u51c6\u786e\u7387\u548c Top-5 \u51c6\u786e\u7387\u90fd\u662f\u5728 ImageNet \u9a8c\u8bc1\u96c6\u4e0a\u7684\u7ed3\u679c\u3002 Architecture @top1* @top5* Weights EfficientNetB0 0.7668 0.9312 + EfficientNetB1 0.7863 0.9418 + EfficientNetB2 0.7968 0.9475 + EfficientNetB3 0.8083 0.9531 + Tensorflow\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u8fc7\u7684\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b\uff08TFAPI\u6587\u6863\uff0c\u5b98\u7f51\u4f1a\u63a8\u8350\u5b89\u88c5\uff09\uff1a # \u8f93\u5165\u5927\u5c0f EfficientNetB0 - ( 224 , 224 , 3 ) EfficientNetB1 - ( 240 , 240 , 3 ) EfficientNetB2 - ( 260 , 260 , 3 ) EfficientNetB3 - ( 300 , 300 , 3 ) EfficientNetB4 - ( 380 , 380 , 3 ) EfficientNetB5 - ( 456 , 456 , 3 ) EfficientNetB6 - ( 528 , 528 , 3 ) EfficientNetB7 - ( 600 , 600 , 3 ) \u6ce8\uff1a\u9879\u76ee\u964d\u5230\u6a21\u578b\u90e8\u5206\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\u6a21\u578b 3\u3001 \u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u5e38\u89c1trick\uff08\u4f18\u5316\uff09 \u00b6 \uff081\uff09\u6570\u636e\u65b9\u9762 \u00b6 \u5206\u6790\uff1a\u4e0b\u56fe\u6a2a\u5750\u6807\u662f\u7c7b\u6807\u53f7\uff0c\u7eb5\u5750\u6807\u662f\u6bcf\u4e2a\u7c7b\u7684\u6837\u672c\u6570\u91cf\u3002 \u5f88\u5bb9\u6613\u770b\u51fa\uff0c\u6bcf\u4e2a\u7c7b\u4e4b\u95f4\u7684\u6837\u672c\u91cf\u5dee\u5f02\u5f88\u5927\uff0c\u5982\u679c\u4e0d\u505a\u7c7b\u5747\u8861\u5904\u7406\uff0c\u5f88\u6709\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6837\u672c\u91cf\u591a\u7684\u7c7b\u8fc7\u62df\u5408\uff0c\u6837\u672c\u91cf\u5c11\u7684\u7c7b\u6b20\u62df\u5408\u3002 \u5e38\u89c1\u7684\u7c7b\u5747\u8861\u65b9\u6cd5\u6709\uff1a\u591a\u6570\u7c7b\u6b20\u91c7\u6837\uff0c\u5c11\u6570\u7c7b\u8fc7\u91c7\u6837\uff1b\u6570\u636e\u589e\u5f3a\uff1b\u6807\u7b7e\u5e73\u6ed1\uff1b \u56fe\u7247\u957f\u5bbd\u6bd4\u6709\u4e00\u5b9a\u7684\u5dee\u5f02\u6027\uff0c\u957f\u5bbd\u6bd4\u5927\u591a\u6570\u96c6\u4e2d\u4e8e1\uff0c\u56e0\u6b64\u4e5f\u9002\u5408\u4e00\u4e9b\u6a21\u578b\u8f93\u5165\u5c3a\u5bf8\u8bbe\u4e3a1\uff1a1 1\u3001\u6570\u636e\u589e\u5f3a \uff081\uff09\u5e76\u975e\u6240\u6709\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u90fd\u6709\u6548\uff0c\u8981\u4fdd\u8bc1\u6570\u636e\u589e\u5f3a\u540e\u76ee\u6807\u4ecd\u53ef\u8089\u773c\u5206\u8fa8\uff0c\u4e14\u4e0d\u6539\u53d8\u56fe\u50cf\u6240\u5c5e\u7c7b\u522b\u3002 \uff082\uff09\u8fc7\u591a\u7684\u6570\u636e\u589e\u5f3a\u4e5f\u4f1a\u5ef6\u957f\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\uff0c\u901a\u5e38\u7ffb\u8f6c\u7684\u6548\u679c\u4e0d\u9519\uff08\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\u3001\u968f\u673a\u5782\u76f4\u7ffb\u8f6c\u3001\u4ee5\u4e00\u5b9a\u6982\u7387\u968f\u673a\u65cb\u8f6c90\u00b0\u3001180\u00b0\u3001270\u00b0\u3001\u968f\u673acrop(0-10%)\u7b49\uff09 \u5176\u4ed6\u5982\u4e0b\uff1a Color Jittering:\u5bf9\u989c\u8272\u7684\u6570\u636e\u589e\u5f3a:\u56fe\u50cf\u4eae\u5ea6\u3001\u9971\u548c\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u53d8\u5316 Random Scale:\u5c3a\u5ea6\u53d8\u6362; Random Crop:\u91c7\u7528\u968f\u673a\u56fe\u50cf\u5dee\u503c\u65b9\u5f0f\uff0c\u5bf9\u56fe\u50cf\u8fdb\u884c\u88c1\u526a\u3001\u7f29\u653e Horizontal/Vertical Flip:\u6c34\u5e73/\u5782\u76f4\u7ffb\u8f6c; Shift:\u5e73\u79fb\u53d8\u6362; Rotation/Reflection:\u65cb\u8f6c/\u4eff\u5c04\u53d8\u6362; Noise:\u9ad8\u65af\u566a\u58f0\u3001\u6a21\u7cca\u5904\u7406; 2\u3001\u5916\u90e8\u6570\u636e\uff1a\u6bd4\u8d5b\u4e0d\u9650\u5236\u4f7f\u7528\u5916\u90e8\u6570\u636e\uff0c\u4e5f\u5c31\u662f\u8bf4\u53ef\u4ee5\u901a\u8fc7\u81ea\u5df1\u62cd\u7167\u3001\u7f51\u4e0a\u722c\u53d6\u7b49\u65b9\u5f0f\u83b7\u5f97\u66f4\u591a\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u6bd4\u8f83\u8d39\u65f6\u8017\u529b\u3002\u901a\u5e38\u81ea\u5df1\u627e\u7684\u6570\u636e\u96c6\u8d28\u91cf\u4e5f\u4e0d\u591f\u597d\uff0c\u4e0e\u534e\u4e3a\u516c\u5e03\u7684\u6570\u636e\u96c6\u5206\u5e03\u4e0d\u540c\uff0c\u6709\u4e9b\u56e2\u961f\u722c\u53d6\u4e00\u4e9b\u989d\u5916\u6570\u636e\uff0c\u6700\u7ec8\u6548\u679c\u90fd\u4e0d\u597d\uff0c\u751a\u81f3\u964d\u4f4e\u4e86\u5206\u6570\uff0c\u56e0\u6b64\u653e\u5f03\u4e86\u8fd9\u79cd\u65b9\u6cd5\u3002\u6240\u4ee5\u5728\u4e00\u5f00\u59cb\u6784\u9020\u597d\u6570\u636e\u5206\u5e03\u5f88\u91cd\u8981\u3002\uff08\u6bd4\u8d5b\u4e0e\u9879\u76ee\u4f1a\u6709\u4e9b\u5dee\u5f02\uff0c\u771f\u6b63\u9879\u76ee\u5176\u5b9e\u8fd8\u662f\u66f4\u591a\u8986\u76d6\u6570\u636e\u5206\u5e03\u8d8a\u597d\uff0c\u6bd4\u8d5b\u53ef\u80fd\u53ea\u662f\u534e\u4e3a\u516c\u5f00\u7684\u6570\u636e\u96c6\u5305\u62ec\u6d4b\u8bd5\u7684\u6570\u636e\u5206\u5e03\u4e00\u6837\u7684\uff0c\u5bfc\u81f4\u4e0d\u80fd\u62ff\u8fc7\u591a\u7684\u5916\u90e8\u6570\u636e\uff08\u5bb9\u6613\u8fc7\u62df\u5408\uff09\uff09 3\u3001\u6570\u636e\u5f52\u4e00\u5316 4\u3001\u6807\u7b7e\u5e73\u6ed1 5\u3001mixup \uff082\uff09\u53d1\u6398\u4e0e\u8bad\u7ec3\u6a21\u578b\u7684\u6f5c\u529b\uff1a \u00b6 1\u3001\u4f7f\u7528\u591a\u79cd\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c 2\u3001\u9009\u62e9\u6539\u8fdb\u7684Adam\u4f18\u5316\u65b9\u6cd5 \uff1aAdam with warm up\u4f18\u5316\u5668 3\u3001\u81ea\u5b9a\u4e49\u5b66\u4e60\u7387-\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387 \u81ea\u5e26warmup\u7684\u5b66\u4e60\u7387\u63a7\u5236\u5bf9\u8fed\u4ee3\u6b21\u6570\u6bd4\u8f83\u7a33\u5065(\u53ea\u8981\u8fbe\u5230\u8db3\u591f\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u6700\u7ec8\u7ed3\u679c\u90fd\u6bd4 \u8f83\u63a5\u8fd1)\uff0c\u5927\u5927\u964d\u4f4e\u8c03\u53c2\u590d\u6742\u6027\uff0c\u7f29\u77ed\u5b9e\u9a8c\u5468\u671f 4.9.3 \u9879\u76ee\u6784\u5efa\uff08\u6a21\u5757\u5206\u6790\uff09 \u00b6 4.9.3.1 \u9879\u76ee\u6a21\u5757\u56fe \u00b6 data:\u5b58\u653e\u6570\u636e\u7684\u76ee\u5f55 data_gen\u76ee\u5f55\uff1a\u6279\u6b21\u6570\u636e\u9884\u5904\u7406\u4ee3\u7801\uff0c\u5305\u62ec\u6570\u636e\u589e\u5f3a\u3001\u6807\u7b7e\u5e73\u6ed1\u3001mixup\u529f\u80fd deploy\uff1a\u6a21\u578b\u5bfc\u51fa\u4ee5\u53ca\u90e8\u7f72\u6a21\u5757 efficientnet:efficientnet\u6a21\u578b\u6e90\u7801\u5b58\u653e\u4f4d\u7f6e utils:\u5c01\u88c5\u7684\u5de5\u5177\u7c7b\uff0c\u5982warmup\u4ee5\u53ca\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387 train.y\u4e0eeval.py\uff1a\u8bad\u7ec3\u7f51\u7edc\u90e8\u5206\u5305\u62ec\u6570\u636e\u6d41\u83b7\u53d6\u3001\u7f51\u7edc\u6784\u5efa\u3001\u4f18\u5316\u5668 \u9879\u76ee\u8fd0\u884c\u8fc7\u7a0b\u6570\u636e\u8bb0\u5f55\u4ee5\u53ca\u6700\u7ec8\u6548\u679c \u00b6 \u572816\u6838\u3001\u5185\u5b5816G\u7684\u673a\u5668\u4e0a\uff0c\u53ea\u7528CPU\u8ba1\u7b971 epoch\u8017\u65f61.83\u5c0f\u65f6\uff081\u5c0f\u65f650\u5206\u949f\uff09 Epoch 1/30 76/787 [=>............................] - ETA: 1:49:16 - loss: 3.7690 - accuracy: 0.0189 303/787 [==========>...................] - ETA: 1:07:05 - loss: 3.7383 - accuracy: 0.025 468/787 [================>.............] - ETA: 43:30 - loss: 3.7253 - accuracy: 0.0262 470/787 [================>.............] - ETA: 43:13 - loss: 3.7251 - accuracy: 0.0261 499/787 [==================>...........] - ETA: 39:12 - loss: 3.7232 - accuracy: 0.0270 576/787 [====================>.........] - ETA: 28:35 - loss: 3.7188 - accuracy: 0.0290 577/787 [====================>.........] - ETA: 28:26 - loss: 3.7187 - accuracy: 0.0290 602/787 [=====================>........] - ETA: 25:01 - loss: 3.7170 - accuracy: 0.0295 612/787 [======================>.......] - ETA: 23:39 - loss: 3.7163 - accuracy: 0.0298 ... 786/787 [============================>.] - ETA: 8s - loss: 3.7085 - accuracy: 0.0319 \u9879\u76ee\u8bad\u7ec3\u4ee3\u7801\u521d\u59cb-\u8bad\u7ec3\u6d41\u7a0b \u00b6 \u4e0b\u9762\u7b80\u5355\u7684\u4ecb\u7ecd\u4e00\u4e0b\u6574\u4e2a\u5de5\u7a0b\u4e2d\u6700\u5173\u952e\u7684\u8bad\u7ec3\u90e8\u5206\u4ee3\u7801 import multiprocessing import numpy as np import argparse import tensorflow as tf from tensorflow.keras.callbacks import ReduceLROnPlateau from tensorflow.keras.callbacks import TensorBoard , Callback from tensorflow.keras.layers import Dense , GlobalAveragePooling2D from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam , RMSprop from efficientnet import model as EfficientNet from efficientnet import preprocess_input from data_gen import data_flow from utils.warmup_cosine_decay_scheduler import WarmUpCosineDecayScheduler import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" # efficientnet\u6e90\u7801\u5b9e\u73b0\u7528TF1.X\u7248\u672c\uff0c\u6240\u4ee5\u8981\u5173\u95ed\u9ed8\u8ba4\u7684eager\u6a21\u5f0f tf . compat . v1 . disable_eager_execution () parser = argparse . ArgumentParser () parser . add_argument ( \"data_url\" , type = str , default = './data/garbage_classify/train_data' , help = \"data dir\" , nargs = '?' ) parser . add_argument ( \"train_url\" , type = str , default = './garbage_ckpt/' , help = \"save model dir\" , nargs = '?' ) parser . add_argument ( \"num_classes\" , type = int , default = 40 , help = \"num_classes\" , nargs = '?' ) parser . add_argument ( \"input_size\" , type = int , default = 300 , help = \"input_size\" , nargs = '?' ) parser . add_argument ( \"batch_size\" , type = int , default = 16 , help = \"batch_size\" , nargs = '?' ) parser . add_argument ( \"learning_rate\" , type = float , default = 0.0001 , help = \"learning_rate\" , nargs = '?' ) parser . add_argument ( \"max_epochs\" , type = int , default = 30 , help = \"max_epochs\" , nargs = '?' ) parser . add_argument ( \"deploy_script_path\" , type = str , default = '' , help = \"deploy_script_path\" , nargs = '?' ) parser . add_argument ( \"test_data_url\" , type = str , default = '' , help = \"test_data_url\" , nargs = '?' ) def model_fn ( param ): \"\"\"\u8fc1\u79fb\u5b66\u4e60\u4fee\u6539\u6a21\u578b\u51fd\u6570 :param param: :return: \"\"\" base_model = EfficientNet . EfficientNetB3 ( include_top = False , input_shape = ( param . input_size , param . input_size , 3 ), classes = param . num_classes ) x = base_model . output x = GlobalAveragePooling2D ( name = 'avg_pool' )( x ) predictions = Dense ( param . num_classes , activation = 'softmax' )( x ) model = Model ( inputs = base_model . input , outputs = predictions ) return model def train_model ( param ): \"\"\"\u8bad\u7ec3\u6a21\u578b :param param: \u4f20\u5165\u7684\u547d\u4ee4\u53c2\u6570 :return: \"\"\" # 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence train_sequence , validation_sequence = data_flow ( param . data_url , param . batch_size , param . num_classes , param . input_size , preprocess_input ) # 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 model = model_fn ( param ) optimizer = Adam ( lr = param . learning_rate ) objective = 'categorical_crossentropy' metrics = [ 'accuracy' ] # \u6a21\u578b\u4fee\u6539 # \u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u5668\u6307\u5b9a model . compile ( loss = objective , optimizer = optimizer , metrics = metrics ) model . summary () # \u5224\u65ad\u6a21\u578b\u662f\u5426\u52a0\u8f7d\u5386\u53f2\u6a21\u578b if os . path . exists ( param . train_url ): filenames = os . listdir ( param . train_url ) model . load_weights ( filenames [ - 1 ]) print ( \"\u52a0\u8f7d\u5b8c\u6210!!!\" ) # 3\u3001\u6307\u5b9a\u8bad\u7ec3\u7684callbacks\uff0c\u5e76\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3 # \uff081\uff09Tensorboard tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) # \uff082\uff09\u81ea\u5b9a\u4e49warm up\u548c\u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf sample_count = len ( train_sequence ) * param . batch_size epochs = param . max_epochs warmup_epoch = 5 batch_size = param . batch_size learning_rate_base = param . learning_rate total_steps = int ( epochs * sample_count / batch_size ) warmup_steps = int ( warmup_epoch * sample_count / batch_size ) warm_up_lr = WarmUpCosineDecayScheduler ( learning_rate_base = learning_rate_base , total_steps = total_steps , warmup_learning_rate = 0 , warmup_steps = warmup_steps , hold_base_rate_steps = 0 , ) #\uff083\uff09\u6a21\u578b\u4fdd\u5b58\u76f8\u5173\u53c2\u6570 check = tf . keras . callbacks . ModelCheckpoint ( param . train_url + 'weights_{epoch:02d}-{val_acc:.2f}.h5' , monitor = 'val_acc' , save_best_only = True , save_weights_only = False , mode = 'auto' , period = 1 ) # \uff084\uff09\u8bad\u7ec3 model . fit_generator ( train_sequence , steps_per_epoch = len ( train_sequence ), epochs = param . max_epochs , verbose = 1 , callbacks = [ check , tensorboard , warm_up_lr ], validation_data = validation_sequence , max_queue_size = 10 , workers = int ( multiprocessing . cpu_count () * 0.7 ), use_multiprocessing = True , shuffle = True ) print ( '\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f!' ) 4.9.3.2 \u6b65\u9aa4\u4ee5\u53ca\u77e5\u8bc6\u70b9\u5e94\u7528\u5206\u6790 \u00b6 1\u3001\u6570\u636e\u8bfb\u53d6\u4ee5\u53ca\u9884\u5904\u7406\u6a21\u5757 \u6570\u636e\u83b7\u53d6 \u6570\u636e\u589e\u5f3a \u5f52\u4e00\u5316 \u968f\u673a\u64e6\u9664 Mixup 2\u3001\u6a21\u578b\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0 efficientnet\u6a21\u578b\u4ecb\u7ecd \u5783\u573e\u5206\u7c7b\u6a21\u578b\u4fee\u6539 \u6a21\u578b\u5b66\u4e60\u7387\u4f18\u5316-warmup\u4e0e\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387 \u6a21\u578b\u4f18\u5316\u5668-Adam\u4f18\u5316\u5668\u6539\u8fdbRAdam/NRdam 3\u3001\u6a21\u578b\u8bad\u7ec3\u4fdd\u5b58\u4e0e\u9884\u6d4b \u6a21\u578b\u5b8c\u6574\u8bad\u7ec3\u8fc7\u7a0b\u5b9e\u73b0 \u9884\u4f30\u6d41\u7a0b\u5b9e\u73b0 4\u3001\u6a21\u578b\u5bfc\u51fa\u4ee5\u53ca\u90e8\u7f72 tf.saved_model\u6a21\u5757\u4f7f\u7528 TensorFlow serving\u6a21\u5757\u4f7f\u7528 \u4e0a\u9762\u662f\u5783\u573e\u5206\u7c7b\u9879\u76ee\u8981\u638c\u63e1\u7684\u77e5\u8bc6\u70b9\uff0c\u4e5f\u662f\u8981\u53bb\u5b9e\u73b0\u9879\u76ee\u8bad\u7ec3\u7684\u5173\u952e 4.9.4 \u6570\u636e\u8bfb\u53d6\u4e0e\u9884\u5904\u7406 \u00b6 4.9.4.1 \u9879\u76ee\u9884\u5904\u7406\u6a21\u4ee3\u7801\u6d41\u7a0b\u4ecb\u7ecd \u00b6 \u4ee3\u7801\u6d41\u7a0b\u4ecb\u7ecd \u00b6 1\u3001\u672c\u5730\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u8fdb\u884c\u56fe\u7247\u8def\u5f84\u8bfb\u53d6\uff0c\u6807\u7b7e\u8bfb\u53d6\uff0c\u5bf9\u6807\u7b7e\u8fdb\u884c\u5e73\u6ed1\u5904\u7406 2\u3001tf.keras.Sequence\u7c7b\u5c01\u88c5\uff0c\u8fd4\u56de\u5e8f\u5217\u6570\u636e \u5b8c\u6574\u6d41\u7a0b\uff1a def data_from_sequence ( train_data_dir , batch_size , num_classes , input_size ): \"\"\"\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u548c\u6807\u7b7e\u6570\u636e\uff0c\u5904\u7406\u6210sequence\u6570\u636e\u7c7b\u578b :param train_data_dir: \u8bad\u7ec3\u6570\u636e\u76ee\u5f55 :param batch_size: \u6279\u6b21\u5927\u5c0f :param num_classes: \u5783\u573e\u5206\u7c7b\u603b\u7c7b\u522b\u6570 :param input_size: \u8f93\u5165\u6a21\u578b\u7684\u56fe\u7247\u5927\u5c0f(300, 300) :return: \"\"\" # 1\u3001\u83b7\u53d6txt\u6587\u4ef6\uff0c\u6253\u4e71\u4e00\u6b21\u6587\u4ef6 label_files = [ os . path . join ( train_data_dir , filename ) for filename in os . listdir ( train_data_dir ) if filename . endswith ( '.txt' )] print ( label_files ) random . shuffle ( label_files ) # 2\u3001\u8bfb\u53d6txt\u6587\u4ef6\uff0c\u89e3\u6790\u51fa img_paths = [] labels = [] for index , file_path in enumerate ( label_files ): with open ( file_path , 'r' ) as f : line = f . readline () line_split = line . strip () . split ( ', ' ) if len ( line_split ) != 2 : print ( ' %s \u6587\u4ef6\u4e2d\u683c\u5f0f\u9519\u8bef' % ( file_path )) continue # \u83b7\u53d6\u56fe\u7247\u540d\u79f0\u548c\u6807\u7b7e\uff0c\u8f6c\u6362\u683c\u5f0f img_name = line_split [ 0 ] label = int ( line_split [ 1 ]) # \u56fe\u7247\u5b8c\u6574\u8def\u5f84\u62fc\u63a5\uff0c\u5e76\u83b7\u53d6\u5230\u56fe\u7247\u548c\u6807\u7b7e\u5217\u8868\u4e2d\uff08\u987a\u5e8f\u4e00\u4e00\u5bf9\u5e94\uff09 img_paths . append ( os . path . join ( train_data_dir , img_name )) labels . append ( label ) # 3\u3001\u8fdb\u884c\u6807\u7b7e\u7c7b\u522b\u5904\u7406\uff0c\u4ee5\u53ca\u6807\u7b7e\u5e73\u6ed1 labels = to_categorical ( labels , num_classes ) labels = smooth_labels ( labels ) # 4\u3001\u8fdb\u884c\u6240\u6709\u6570\u636e\u7684\u5206\u5272\uff0c\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 train_img_paths , validation_img_paths , train_labels , validation_labels = \\ train_test_split ( img_paths , labels , test_size = 0.15 , random_state = 0 ) print ( '\u603b\u5171\u6837\u672c\u6570: %d , \u8bad\u7ec3\u6837\u672c\u6570: %d , \u9a8c\u8bc1\u6837\u672c\u6570\u636e: %d ' % ( len ( img_paths ), len ( train_img_paths ), len ( validation_img_paths ))) # 5\u3001sequence\u5e8f\u5217\u6570\u636e\u5236\u4f5c train_sequence = GarbageDataSequence ( train_img_paths , train_labels , batch_size , [ input_size , input_size ], use_aug = True ) validation_sequence = GarbageDataSequence ( validation_img_paths , validation_labels , batch_size , [ input_size , input_size ], use_aug = False ) return train_sequence , validation_sequence 1\u3001\u672c\u5730\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u8fdb\u884c\u56fe\u7247\u8def\u5f84\u8bfb\u53d6\uff0c\u6807\u7b7e\u8bfb\u53d6\uff0c\u5bf9\u6807\u7b7e\u8fdb\u884c\u5e73\u6ed1\u5904\u7406 \u00b6 \u65b0\u5efa\u4e00\u4e2adata_gen\u7684\u76ee\u5f55\uff0c\u65b0\u5efaprocessing_data.py\uff0c\u5b9e\u73b0\u4e0b\u9762\u8fd9\u4e2a\u5c06\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u8c03\u7528\u7684\u6570\u636e\u5904\u7406\u4e3b\u51fd\u6570 import math import os import random import numpy as np from PIL import Image from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.utils import to_categorical , Sequence from sklearn.model_selection import train_test_split from data_gen.random_eraser import get_random_eraser def data_from_sequence ( train_data_dir , batch_size , num_classes , input_size ): \"\"\"\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u548c\u6807\u7b7e\u6570\u636e\uff0c\u5904\u7406\u6210sequence\u6570\u636e\u7c7b\u578b :param train_data_dir: \u8bad\u7ec3\u6570\u636e\u76ee\u5f55 :param batch_size: \u6279\u6b21\u5927\u5c0f :param num_classes: \u5783\u573e\u5206\u7c7b\u603b\u7c7b\u522b\u6570 :param input_size: \u8f93\u5165\u6a21\u578b\u7684\u56fe\u7247\u5927\u5c0f(300, 300) :return: \"\"\" # 1\u3001\u83b7\u53d6txt\u6587\u4ef6\uff0c\u6253\u4e71\u4e00\u6b21\u6587\u4ef6 label_files = [ os . path . join ( train_data_dir , filename ) for filename in os . listdir ( train_data_dir ) if filename . endswith ( '.txt' )] print ( label_files ) random . shuffle ( label_files ) # 2\u3001\u8bfb\u53d6txt\u6587\u4ef6\uff0c\u89e3\u6790\u51fa img_paths = [] labels = [] for index , file_path in enumerate ( label_files ): with open ( file_path , 'r' ) as f : line = f . readline () line_split = line . strip () . split ( ', ' ) if len ( line_split ) != 2 : print ( ' %s \u6587\u4ef6\u4e2d\u683c\u5f0f\u9519\u8bef' % ( file_path )) continue # \u83b7\u53d6\u56fe\u7247\u540d\u79f0\u548c\u6807\u7b7e\uff0c\u8f6c\u6362\u683c\u5f0f img_name = line_split [ 0 ] label = int ( line_split [ 1 ]) # \u56fe\u7247\u5b8c\u6574\u8def\u5f84\u62fc\u63a5\uff0c\u5e76\u83b7\u53d6\u5230\u56fe\u7247\u548c\u6807\u7b7e\u5217\u8868\u4e2d\uff08\u987a\u5e8f\u4e00\u4e00\u5bf9\u5e94\uff09 img_paths . append ( os . path . join ( train_data_dir , img_name )) labels . append ( label ) # 3\u3001\u8fdb\u884c\u6807\u7b7e\u7c7b\u522b\u5904\u7406\uff0c\u4ee5\u53ca\u6807\u7b7e\u5e73\u6ed1 labels = to_categorical ( labels , num_classes ) labels = smooth_labels ( labels ) return None (1) \u6570\u636e\u8bfb\u53d6\u548c\u7c7b\u522b\u8f6c\u6362\u4ee5\u53ca\u6807\u7b7e\u5e73\u6ed1 \u00b6 to_categorical\u4f7f\u7528\u4ecb\u7ecd\uff1a In [5]: tf.keras.utils.to_categorical([1,2,3,4,5], num_classes=10) Out[5]: array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32) 1\u3001\u6807\u7b7e\u5e73\u6ed1-Label Smoothing Regularization \u00b6 Label Smoothing\u5c31\u662f\u4e00\u79cd\u6291\u5236\u8fc7\u62df\u5408\u7684\u624b\u6bb5\u3002 \u601d\u60f3\uff1a\u5728\u8bad\u7ec3\u65f6\u5373\u5047\u8bbe\u6807\u7b7e\u53ef\u80fd\u5b58\u5728\u9519\u8bef\uff0c\u907f\u514d\u201c\u8fc7\u5206\u201d\u76f8\u4fe1\u8bad\u7ec3\u6837\u672c\u7684\u6807\u7b7e\u3002\u5c31\u662f\u8981\u544a\u8bc9\u6a21\u578b\uff0c\u6837\u672c\u7684\u6807\u7b7e\u4e0d\u4e00\u5b9a\u6b63\u786e\uff0c\u90a3\u4e48\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u5bf9\u4e8e\u5c11\u91cf\u7684\u6837\u672c\u9519\u8bef\u5c31\u4f1a\u9c81\u68d2\u6027\u66f4\u5f3a\u3002 \u8fc7\u7a0b\uff1a \u5728\u6bcf\u6b21\u8fed\u4ee3\u65f6\uff0c\u5e76\u4e0d\u76f4\u63a5\u5c06(xi,yi)\u653e\u5165\u8bad\u7ec3\u96c6\uff0c\u800c\u662f\u8bbe\u7f6e\u4e00\u4e2a\u9519\u8bef\u7387\u03b5\uff0c\u4ee51-\u03b5\u7684\u6982\u7387\u5c06(xi,yi)\u4ee3\u5165\u8bad\u7ec3\uff0c\u4ee5\u03b5\u7684\u6982\u7387\u5c06(xi,1-yi)\u4ee3\u5165\u8bad\u7ec3 $$ q_i=\\begin{cases}1-\\varepsilon, \\text{if i=y,} \\\\\\\\\\frac{\\varepsilon}{K-1}, \\text{others} \\end{cases} $$ \u6bd4\u5982\uff1a\u6211\u4eec\u7684\u4e8c\u5206\u7c7b\u732b/\u72d7\u793a\u4f8b\uff0c0.1 \u7684\u6807\u7b7e\u5e73\u6ed1\u610f\u5473\u7740\u76ee\u6807\u7b54\u6848\u5c06\u662f 0.90(90%\u786e\u4fe1)\u8fd9\u662f\u4e00\u4e2a\u72d7\u7684\u56fe\u50cf\uff0c\u800c 0.10(10%\u786e\u4fe1)\u8fd9\u662f\u4e00\u53ea\u732b\uff0c\u800c\u4e0d\u662f\u5148\u524d\u7684\u5411 1 \u6216 0 \u79fb\u52a8\u7684\u7ed3\u679c\u3002\u7531\u4e8e\u4e0d\u592a\u786e\u5b9a\uff0c\u5b83\u4f5c\u4e3a\u4e00\u79cd\u6b63\u5219\u5316\u5f62\u5f0f\uff0c\u63d0\u9ad8\u4e86\u5b83\u5bf9\u65b0\u6570\u636e\u7684\u9884\u6d4b\u80fd\u529b\u3002 Label Smoothing\u7684\u5de5\u4f5c\u539f\u7406\u662f\u5bf9\u539f\u6765\u7684[0 1]\u8fd9\u79cd\u6807\u6ce8\u505a\u4e00\u4e2a\u6539\u52a8\uff0c\u5047\u8bbe\u6211\u4eec\u7ed9\u5b9aLabel Smoothing\u7684\u503c\u4e3a0.1\uff1a[0,1]\u00d7(1\u22120.1)+0.\u00bd=[0.05,0.95] \u516c\u5f0f\u539f\u7406\u8bb2\u89e3\uff1a \u6b63\u5e38\u4ea4\u53c9\u71b5\u53ef\u4ee5\u5199\u4f5c\uff1a $$ H(y, p) = \\sum_{k=1}^{K}{-y_{k}}log(p_{k}) $$ \u6807\u7b7e\u5e73\u6ed1\u5316\u540e\u53d8\u6210\uff1a y_{k}^{LS} = y_{k}(1 - \\alpha) + \\alpha / K y_{k}^{LS} = y_{k}(1 - \\alpha) + \\alpha / K \u7406\u89e3\uff1a \u6ca1\u6709\u6807\u7b7e\u5e73\u6ed1\u8ba1\u7b97\u7684\u635f\u5931\u53ea\u8003\u8651\u6b63\u786e\u6807\u7b7e\u4f4d\u7f6e\u7684\u635f\u5931\uff0c\u800c\u4e0d\u8003\u8651\u5176\u4ed6\u6807\u7b7e\u4f4d\u7f6e\u7684\u635f\u5931\uff0c\u8fd9\u5c31\u4f1a\u4f7f\u5f97\u6a21\u578b\u8fc7\u4e8e\u5173\u6ce8\u589e\u5927\u9884\u6d4b\u6b63\u786e\u6807\u7b7e\u7684\u6982\u7387\uff0c\u800c\u4e0d\u5173\u6ce8\u51cf \u5c11\u9884\u6d4b\u9519\u8bef\u6807\u7b7e\u7684\u6982\u7387\uff0c\u6700\u540e\u5bfc\u81f4\u7684\u7ed3\u679c\u662f\u6a21\u578b\u5728\u81ea\u5df1\u7684\u8bad\u7ec3\u96c6\u4e0a\u62df\u5408\u6548\u679c \u975e\u5e38\u826f\u597d\uff0c\u800c\u5728\u5176\u4ed6\u7684\u6d4b\u8bd5\u96c6\u7ed3\u679c\u8868\u73b0\u4e0d\u597d\uff0c\u5373\u8fc7\u62df\u5408\u3002 \u5e73\u6ed1\u8fc7\u540e\u7684\u6837\u672c\u4ea4\u53c9\u71b5\u635f\u5931\u5c31\u4e0d\u4ec5\u8003\u8651\u5230\u4e86\u8bad\u7ec3\u6837\u672c\u4e2d\u6b63\u786e\u7684\u6807\u7b7e\u4f4d\u7f6e (one-hot\u6807\u7b7e\u4e3a1\u7684\u4f4d\u7f6e)\u7684\u635f\u5931\uff0c\u4e5f\u7a0d\u5fae\u8003\u8651\u5230\u5176\u4ed6\u9519\u8bef\u6807\u7b7e\u4f4d\u7f6e(one- hot\u6807\u7b7e\u4e3a0\u7684\u4f4d\u7f6e)\u7684\u635f\u5931\uff0c\u5bfc\u81f4\u6700\u540e\u7684\u635f\u5931\u589e\u5927\uff0c\u5bfc\u81f4\u6a21\u578b\u7684\u5b66\u4e60\u80fd\u529b\u63d0 \u9ad8\uff0c\u5373\u8981\u4e0b\u964d\u5230\u539f\u6765\u7684\u635f\u5931\uff0c\u5c31\u5f97\u5b66\u4e60\u7684\u66f4\u597d\uff0c\u4e5f\u5c31\u662f\u8feb\u4f7f\u6a21\u578b\u5f80\u589e\u5927\u6b63\u786e \u5206\u7c7b\u6982\u7387\u5e76\u4e14\u540c\u65f6\u51cf\u5c0f\u9519\u8bef\u5206\u7c7b\u6982\u7387\u7684\u65b9\u5411\u524d\u8fdb\u3002 \u6765\u81ea\u4e8e\u8bba\u6587\uff1a\u8bba\u6587:Rethinking the Inception Architecture for ComputerVision \u6ce8\uff1a\u524d\u4e24\u5217\u7684\u6a21\u578b\u672a\u8fdb\u884c\u6807\u7b7e\u5e73\u6ed1\u5904\u7406\uff0c\u540e\u4e24 \u5217\u4f7f\u7528\u4e86\u6807\u7b7e\u5e73\u6ed1\u6280\u672f \u73b0\u8c61\uff1a\u53ef\u89c1\u6807\u7b7e\u5e73\u6ed1\u6280\u672f\u53ef\u4ee5\u4f7f\u5f97\u7f51\u7edc\u5012\u6570\u7b2c\u4e8c\u5c42\u6fc0\u6d3b\u51fd\u6570\u7684\u8868\u793a\u7684\u805a\u7c7b\u66f4\u52a0\u7d27\u5bc6\u3002 \u6807\u7b7e\u5e73\u6ed1\u63d0\u9ad8\u4e86\u6700\u7ec8\u7684\u7cbe\u5ea6 \u901a\u5e38\u7528\u4e8e\uff1a\u56fe\u7247\u5206\u7c7b\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u8bed\u97f3\u8bc6\u522b\u3002 \u4ee3\u7801\u5b9e\u73b0 \u00b6 def smooth_labels ( y , smooth_factor = 0.1 ): assert len ( y . shape ) == 2 if 0 <= smooth_factor <= 1 : y *= 1 - smooth_factor y += smooth_factor / y . shape [ 1 ] else : raise Exception ( 'Invalid label smoothing factor: ' + str ( smooth_factor )) return y 2\u3001tf.keras.Sequence\u7c7b\u5c01\u88c5\uff0c\u8fd4\u56de\u5e8f\u5217\u6570\u636e \u00b6 \u9996\u5148\u4ecb\u7ecd\u4e00\u4e0bSequence\u4ee5\u53ca\u5176\u4ed6\u76f8\u5173\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u4e4b\u524d\u63a5\u89e6\u8fc7\u6709tf.data\u4ee5\u53catf.keras.preprocessing.image\u4e2d\u7684ImageDataGenerator\uff0c\u524d\u9762\u53ef\u4ee5\u6784\u9020\u81ea\u5b9a\u4e49\u6279\u6b21\u7b49\u7b49\uff0c\u540e\u8005\u63d0\u4f9b\u4e86\u9ed8\u8ba4\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5b9e\u73b0\u6279\u6b21\u6570\u636e\u8fed\u4ee3\u8fd4\u56de\u3002\u4f46\u662f\u5bf9\u4e8e\u5f88\u591a\u4efb\u52a1\u6765\u8bf4\u6211\u4eec\u9700\u8981\u505a\u66f4\u591a\u7684\u6709\u4e9b\u81ea\u5b9a\u4e49\u9884\u5904\u7406\uff0c\u5982\u6807\u7b7e\u5e73\u6ed1\uff0c\u968f\u673a\u64e6\u51fa\u7b49\u7b49\uff0c\u5728\u4e00\u4e2aAPI\u4e2d\u65e0\u6cd5\u5b8c\u5168\u5b9e\u73b0\uff0c\u73b0\u5728\u6211\u4eec\u4f1a\u4ecb\u7ecd\u4e00\u4e2a\u80fd\u5b9e\u73b0\u66f4\u81ea\u7531\u7684\u5404\u4e2a\u65f6\u95f4\u5185\u4fee\u6539\u6570\u636e\u96c6\u7684\u5de5\u5177Sequence tf.keras.utils.Sequence 1\u3001\u6bcf\u4e2a\u4eba\u90fd Sequence \u5fc5\u987b\u5b9e\u73b0 __getitem__ \u548c __len__ \u65b9\u6cd5\u3002\u5982\u679c\u60a8\u60f3\u5728\u5404\u4e2a\u65f6\u671f\u4e4b\u95f4\u4fee\u6539\u6570\u636e\u96c6\uff0c\u5219\u53ef\u4ee5\u5b9e\u73b0 on_epoch_end \u3002\u8be5\u65b9\u6cd5 __getitem__ \u5e94\u8fd4\u56de\u5b8c\u6574\u7684\u6279\u6b21\u3002\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u5176\u4ed6\u65b9\u6cd5\u4f9b\u4f7f\u7528 2\u3001\u7279\u70b9\uff1a Sequence \u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\uff0c\u800c\u751f\u6210\u5668\u5219\u4e0d\u4f1a\u3002 \u5b98\u7f51\u4f7f\u7528\u6848\u4f8b\uff1a from skimage.io import imread from skimage.transform import resize import numpy as np import math # Here, `x_set` is list of path to the images # and `y_set` are the associated classes. class CIFAR10Sequence ( Sequence ): def __init__ ( self , x_set , y_set , batch_size ): self . x , self . y = x_set , y_set self . batch_size = batch_size def __len__ ( self ): return math . ceil ( len ( self . x ) / self . batch_size ) def __getitem__ ( self , idx ): batch_x = self . x [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] batch_y = self . y [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] return np . array ([ resize ( imread ( file_name ), ( 200 , 200 )) for file_name in batch_x ]), np . array ( batch_y ) GarbageDataSequence-\u5783\u573e\u5206\u7c7b\u7684Sequence\u4ee3\u7801\u89e3\u6790 \u00b6 \u6784\u5efa\u4e86\u4e00\u4e2aGarbageDataSequence\u7c7b\u522b\uff0c \u7ee7\u627f\u57fa\u7c7bSequence class GarbageDataSequence ( Sequence ): \"\"\"\u6570\u636e\u6d41\u751f\u6210\u5668\uff0c\u6bcf\u6b21\u8fed\u4ee3\u8fd4\u56de\u4e00\u4e2abatch \u53ef\u76f4\u63a5\u7528\u4e8efit_generator\u7684generator\u53c2\u6570\uff0c\u80fd\u4fdd\u8bc1\u5728\u591a\u8fdb\u7a0b\u4e0b\u7684\u4e00\u4e2aepoch\u4e2d\u4e0d\u4f1a\u91cd\u590d\u53d6\u76f8\u540c\u7684\u6837\u672c \"\"\" def __init__ ( self , img_paths , labels , batch_size , img_size , use_aug ): # \u5f02\u5e38\u5224\u65ad self . x_y = np . hstack (( np . array ( img_paths ) . reshape ( len ( img_paths ), 1 ), np . array ( labels ))) self . batch_size = batch_size self . img_size = img_size self . alpha = 0.2 self . use_aug = use_aug self . eraser = get_random_eraser ( s_h = 0.3 , pixel_level = True ) def __len__ ( self ): return math . ceil ( len ( self . x_y ) / self . batch_size ) @staticmethod def center_img ( img , size = None , fill_value = 255 ): \"\"\"\u6539\u53d8\u56fe\u7247\u5c3a\u5bf8\u5230300x300\uff0c\u5e76\u4e14\u505a\u586b\u5145\u4f7f\u5f97\u56fe\u50cf\u5904\u4e8e\u4e2d\u95f4\u4f4d\u7f6e \"\"\" h , w = img . shape [: 2 ] if size is None : size = max ( h , w ) shape = ( size , size ) + img . shape [ 2 :] background = np . full ( shape , fill_value , np . uint8 ) center_x = ( size - w ) // 2 center_y = ( size - h ) // 2 background [ center_y : center_y + h , center_x : center_x + w ] = img return background def preprocess_img ( self , img_path ): \"\"\"\u56fe\u7247\u7684\u5904\u7406\u6d41\u7a0b\u51fd\u6570\uff0c\u6570\u636e\u589e\u5f3a\u3001center_img\u5904\u7406 \"\"\" # 1\u3001\u56fe\u50cf\u8bfb\u53d6\uff0c[180 , 200]-> \uff08200\uff09max(180, 200)->[300/200 * 180, 300/200 * 200] # \u8fd9\u6837\u505a\u4e3a\u4e86\u4e0d\u4f7f\u56fe\u5f62\u76f4\u63a5\u53d8\u5f62\uff0c\u540e\u7eed\u5728\u7edf\u4e00\u957f\u5bbd img = Image . open ( img_path ) resize_scale = self . img_size [ 0 ] / max ( img . size [: 2 ]) img = img . resize (( int ( img . size [ 0 ] * resize_scale ), int ( img . size [ 1 ] * resize_scale ))) img = img . convert ( 'RGB' ) img = np . array ( img ) # 2\u3001\u6570\u636e\u589e\u5f3a\uff1a\u5982\u679c\u662f\u8bad\u7ec3\u96c6\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u64cd\u4f5c # \u5148\u968f\u673a\u64e6\u9664\uff0c\u7136\u540e\u7ffb\u8f6c if self . use_aug : img = self . eraser ( img ) datagen = ImageDataGenerator ( width_shift_range = 0.05 , height_shift_range = 0.05 , horizontal_flip = True , vertical_flip = True , ) img = datagen . random_transform ( img ) # 3\u3001\u628a\u56fe\u7247\u5927\u5c0f\u8c03\u6574\u5230[300, 300, 3]\uff0c\u8c03\u6574\u7684\u65b9\u5f0f\u4e3a\u76f4\u63a5\u586b\u5145\u5c0f\u7684\u5750\u6807\u3002\u4e3a\u4e86\u6a21\u578b\u9700\u8981 img = self . center_img ( img , self . img_size [ 0 ]) return img def __getitem__ ( self , idx ): # 1\u3001\u5904\u7406\u56fe\u7247\u5927\u5c0f\u3001\u6570\u636e\u589e\u5f3a\u7b49\u8fc7\u7a0b print ( self . x_y ) batch_x = self . x_y [ idx * self . batch_size : ( idx + 1 ) * self . batch_size , 0 ] batch_y = self . x_y [ idx * self . batch_size : ( idx + 1 ) * self . batch_size , 1 :] batch_x = np . array ([ self . preprocess_img ( img_path ) for img_path in batch_x ]) batch_y = np . array ( batch_y ) . astype ( np . float32 ) # print(batch_y[1]) # 2\u3001mixup\u8fdb\u884c\u6784\u9020\u65b0\u7684\u6837\u672c\u5206\u5e03\u6570\u636e # batch_x, batch_y = self.mixup(batch_x, batch_y) # 3\u3001\u8f93\u5165\u6a21\u578b\u7684\u5f52\u4e00\u5316\u6570\u636e batch_x = self . preprocess_input ( batch_x ) return batch_x , batch_y def on_epoch_end ( self ): np . random . shuffle ( self . x_y ) def preprocess_input ( self , x ): \"\"\"\u5f52\u4e00\u5316\u5904\u7406\u6837\u672c\u7279\u5f81\u503c :param x: :return: \"\"\" assert x . ndim in ( 3 , 4 ) assert x . shape [ - 1 ] == 3 MEAN_RGB = [ 0.485 * 255 , 0.456 * 255 , 0.406 * 255 ] STDDEV_RGB = [ 0.229 * 255 , 0.224 * 255 , 0.225 * 255 ] x = x - np . array ( MEAN_RGB ) x = x / np . array ( STDDEV_RGB ) return x def mixup ( self , batch_x , batch_y ): \"\"\" \u6570\u636e\u6df7\u5408mixup :param batch_x: \u8981mixup\u7684batch_X :param batch_y: \u8981mixup\u7684batch_y :return: mixup\u540e\u7684\u6570\u636e \"\"\" size = self . batch_size l = np . random . beta ( self . alpha , self . alpha , size ) X_l = l . reshape ( size , 1 , 1 , 1 ) y_l = l . reshape ( size , 1 ) X1 = batch_x Y1 = batch_y X2 = batch_x [:: - 1 ] Y2 = batch_y [:: - 1 ] X = X1 * X_l + X2 * ( 1 - X_l ) Y = Y1 * y_l + Y2 * ( 1 - y_l ) return X , Y if __name__ == '__main__' : train_data_dir = '../data/garbage_classify/train_data' batch_size = 32 train_sequence , validation_sequence = data_from_sequence ( train_data_dir , batch_size , num_classes = 40 , input_size = 300 ) for i in range ( 100 ): print ( \"\u7b2c %d \u6279\u6b21\u6570\u636e\" % i ) batch_data , bacth_label = train_sequence . __getitem__ ( i ) print ( batch_data . shape , bacth_label . shape ) batch_data , bacth_label = validation_sequence . __getitem__ ( i ) \uff081\uff09\u6570\u636e\u589e\u5f3a\u9009\u62e9\u65b9\u6cd5 \u00b6 \u6784\u5efa\u4e86\u4e00\u5957\u590d\u6742\u4e14\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u6db5\u76d6\u51e0\u4f55\u53d8\u6362\u3001\u968f\u673a\u64e6\u9664\u3001Mixup\u7b56\u7565\u3002 \u7ec4\u5408\u7b56\u7565\u4ec5\u9700\u5c11\u91cf\u53c2\u6570\u8c03\u8282\u5373\u53ef\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u96c6\uff0c\u6548\u679c\u8d85\u8fc7\u8c37\u6b4c\u5728Imagenet\u4e0a\u641c\u7d22\u5f97\u5230\u7684Auto-augment\u7b56\u7565 \u66f4\u6709\u6548\u7684\u6355\u6349\u591a\u79cd\u5206\u8fa8\u7387\u3001\u591a\u5c3a\u5ea6\u3001\u591a\u7c92\u5ea6\u56fe\u7247\u7684\u8f6e\u5ed3\u3001\u7eb9 \u7406\u3001\u4f4d\u7f6e\u5206\u5e03\u7b49\u7279\u5f81 1\u3001\u6df7\u5408\u8bad\u7ec3\uff08Mixup Training\uff09 \u00b6 Mixup\u662f\u4e00\u79cd\u975e\u5e38\u89c4\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e00\u4e2a\u548c\u6570\u636e\u65e0\u5173\u7684\u7b80\u5355\u6570\u636e\u589e\u5f3a\u539f\u5219\uff0c\u5176\u4ee5\u7ebf\u6027\u63d2\u503c\u7684\u65b9\u5f0f\u6765\u6784\u5efa\u65b0\u7684\u8bad\u7ec3\u6837\u672c\u548c\u6807\u7b7e\u3002 \u968f\u673a\u53d6\u4e24\u4e2a\u6837\u672c\uff0c\u901a\u8fc7\u52a0\u6743\u7ebf\u6027\u63d2\u503c\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u6837\u672c\u3002 \u65b0\u7684\u6837\u672c\u7684\u8f93\u5165\u548c\u771f\u5b9e\u6982\u7387\u5206\u5e03\u4e3a\uff1a \\hat{x} = \\lambda x_i + (1-\\lambda)x_j, \\hat{y} = \\lambda y_i + (1-\\lambda)y_j \\hat{x} = \\lambda x_i + (1-\\lambda)x_j, \\hat{y} = \\lambda y_i + (1-\\lambda)y_j mixup\u7b56\u7565\u5b9e\u73b0\uff0c\u5c01\u88c5\u5728 def mixup(self, batch_x, batch_y): \"\"\" \u6570\u636e\u6df7\u5408mixup :param batch_x: \u8981mixup\u7684batch_X :param batch_y: \u8981mixup\u7684batch_y :return: mixup\u540e\u7684\u6570\u636e \"\"\" size = self.batch_size l = np.random.beta(self.alpha, self.alpha, size) X_l = l.reshape(size, 1, 1, 1) y_l = l.reshape(size, 1) X1 = batch_x Y1 = batch_y X2 = batch_x[::-1] Y2 = batch_y[::-1] X = X1 * X_l + X2 * (1 - X_l) Y = Y1 * y_l + Y2 * (1 - y_l) return X, Y 2\u3001Random Erasing\u539f\u7406: \u00b6 \u8bad\u7ec3\u65f6\uff0c\u968f\u673a\u64e6\u9664\u65b9\u6cd5\u4f1a\u5728\u539f\u56fe\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u77e9 \u5f62\u533a\u57df\uff0c\u5c06\u8be5\u533a\u57df\u7684\u50cf\u7d20\u66ff\u6362\u4e3a\u968f\u673a\u503c\u3002\u8fd9\u4e2a\u8fc7 \u7a0b\u4e2d\uff0c\u53c2\u4e0e\u8bad\u7ec3\u7684\u56fe\u7247\u4f1a\u505a\u4e0d\u540c\u7a0b\u5ea6\u7684\u906e\u6321\uff0c\u8fd9 \u6837\u53ef\u4ee5\u964d\u4f4e\u8fc7\u62df\u5408\u7684\u98ce\u9669\u5e76\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002 \u968f\u673a\u64e6\u9664\u662f\u72ec\u7acb\u4e8e\u53c2\u6570\u5b66\u4e60\u8fc7\u7a0b\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u6574 \u5408\u5230\u4efb\u4f55\u57fa\u4e8eCNN\u7684\u8bc6\u522b\u6a21\u578b\u4e2d\u3002 \u5c01\u88c5\u5728random_eraser.py\u6587\u4ef6\u4e2d\u3002 import numpy as np import tensorflow as tf def get_random_eraser ( p = 0.5 , s_l = 0.02 , s_h = 0.4 , r_1 = 0.3 , r_2 = 1 / 0.3 , v_l = 0 , v_h = 255 , pixel_level = False ): def eraser ( input_img ): img_h , img_w , img_c = input_img . shape p_1 = np . random . rand () if p_1 > p : return input_img while True : s = np . random . uniform ( s_l , s_h ) * img_h * img_w r = np . random . uniform ( r_1 , r_2 ) w = int ( np . sqrt ( s / r )) h = int ( np . sqrt ( s * r )) left = np . random . randint ( 0 , img_w ) top = np . random . randint ( 0 , img_h ) if left + w <= img_w and top + h <= img_h : break if pixel_level : c = np . random . uniform ( v_l , v_h , ( h , w , img_c )) else : c = np . random . uniform ( v_l , v_h ) input_img [ top : top + h , left : left + w , :] = c return input_img return eraser \u6ce8\uff1a\u8fd9\u4e9b\u4ee3\u7801\u4e0d\u9700\u8981\u53bb\u5b9e\u73b0\uff0c\u6709\u5f88\u591a\u73b0\u6210\u5b9e\u73b0\u597d\u7684\u65b9\u6cd5 3\u3001ImageDataGenerator-\u63d0\u4f9b\u4e3b\u8981\u7ffb\u8f6c\u65b9\u6cd5 \u00b6 \u5982\u4e0b\u4f7f\u7528\uff0c\u8fdb\u884c\u968f\u673a\u6c34\u5e73/\u5782\u76f4\u7ffb\u8f6c\u3002 datagen = ImageDataGenerator ( horizontal_flip = True , vertical_flip = True , ) \u6700\u540e\u5b9e\u73b0\u6d4b\u8bd5\u7ed3\u679c\uff1a ... \u7b2c 10 \u6279\u6b21\u6570\u636e ( 32 , 300 , 300 , 3 ) [[ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] ... [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ]] 4.9.5 \u603b\u7ed3 \u00b6 \u77e5\u9053\u5783\u573e\u5206\u7c7b\u76f8\u5173\u6bd4\u8d5b\u95ee\u9898 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u5e38\u89c1\u4f18\u5316(tricks) \u5e38\u7528\u5206\u7c7b\u95ee\u9898\u7684\u6570\u636e\u589e\u5f3a\u65b9\u5f0f mixup \u968f\u673a\u64e6\u9664 \u7ffb\u8f6c \u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316 \u5206\u7c7b\u5e38\u89c1\u6a21\u578b\u4ee5\u53ca\u6a21\u578b\u7b97\u6cd5\u4f18\u5316","title":"4.9 \u7efc\u5408\u6848\u4f8b\uff1a\u5783\u573e\u5206\u7c7b\u4ecb\u7ecd"},{"location":"tensorFlow/section9/#49","text":"","title":"4.9 \u7efc\u5408\u6848\u4f8b\uff1a\u5783\u573e\u5206\u7c7b\u4ecb\u7ecd"},{"location":"tensorFlow/section9/#_1","text":"\u76ee\u6807 \u77e5\u9053\u5783\u573e\u5206\u7c7b\u76f8\u5173\u6bd4\u8d5b\u95ee\u9898 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u5e38\u89c1\u4f18\u5316(tricks) \u638c\u63e1\u5e38\u7528\u5206\u7c7b\u95ee\u9898\u7684\u6570\u636e\u589e\u5f3a\u65b9\u5f0f mixup\u7b49 \u638c\u63e1\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316 \u4e86\u89e3\u5206\u7c7b\u5e38\u89c1\u6a21\u578b\u4ee5\u53ca\u6a21\u578b\u7b97\u6cd5\u4f18\u5316 \u5e94\u7528 \u5e94\u7528Tensorflow\u5b8c\u6210\u5783\u573e\u5206\u7c7b\u6570\u636e\u7684\u8bfb\u53d6\u4ee5\u53ca\u5904\u7406\u8981\u6c42","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"tensorFlow/section9/#491","text":"\u5783\u573e\u5206\u7c7b\u95ee\u9898\u662f2019\u5e74\u7684\u793e\u4f1a\u70ed\u70b9\u95ee\u9898\uff0c2019\u5e746\u670825\u65e5\uff0c\u751f\u6d3b\u5783\u573e\u5206\u7c7b\u5236\u5ea6\u5c06\u5165\u6cd5\u3002\u4e0a\u6d77\u6210\u4e3a\u7b2c\u4e00\u4e2a\u4e2d\u56fd\u5783\u573e\u5206\u7c7b\u8bd5\u70b9\u57ce\u5e02\u3002 \u4e00\u822c\u662f\u6307\u6309\u4e00\u5b9a\u89c4\u5b9a\u6216\u6807\u51c6\u5c06\u5783\u573e\u5206\u7c7b\u50a8\u5b58\u3001\u5206\u7c7b\u6295\u653e\u548c\u5206\u7c7b\u642c\u8fd0\uff0c\u4ece\u800c\u8f6c\u53d8\u6210\u516c\u5171\u8d44\u6e90\u7684\u4e00\u7cfb\u5217\u6d3b\u52a8\u7684\u603b\u79f0\u3002\u5206\u7c7b\u7684\u76ee\u7684\u662f\u63d0\u9ad8\u5783\u573e\u7684\u8d44\u6e90\u4ef7\u503c\u548c\u7ecf\u6d4e\u4ef7\u503c\uff0c\u529b\u4e89\u7269\u5c3d\u5176\u7528\u3002","title":"4.9.1 \u5783\u573e\u5206\u7c7b\u4ecb\u7ecd"},{"location":"tensorFlow/section9/#1","text":"\u5c0f\u732a\u4f69\u5947\u7248\u672c\uff1a \u6ce8\uff1a\u6e7f\u5783\u573e\uff08\u53a8\u4f59\u5783\u573e\uff09\uff0c\u5e72\u5783\u573e\uff08\u5176\u4ed6\u5783\u573e\uff09 \u5206\u7c7b\u77e5\u8bc6\u5c0f\u62d3\u5c55\uff1a\u53ef\u56de\u6536\u7269\u6307\u9002\u5b9c\u56de\u6536\u548c\u8d44\u6e90\u5229\u7528\u7684\u5e9f\u5f03\u7269\uff0c\u5305\u62ec\u5e9f\u5f03\u7684\u73bb\u7483\u3001\u91d1\u5c5e\u3001\u5851\u6599\u3001\u7eb8\u7c7b\u3001\u7ec7\u7269\u3001\u5bb6\u5177\u3001\u7535\u5668\u7535\u5b50\u4ea7\u54c1\u548c\u5e74\u82b1\u5e74\u6854\u7b49\u3002\u53a8\u4f59\u5783\u573e\u6307\u5bb6\u5ead\u3001\u4e2a\u4eba\u4ea7\u751f\u7684\u6613\u8150\u6027\u5783\u573e\uff0c\u5305\u62ec\u5269\u83dc\u3001\u5269\u996d\u3001\u83dc\u53f6\u3001\u679c\u76ae\u3001\u86cb\u58f3\u3001\u8336\u6e23\u3001\u6c64\u6e23\u3001\u9aa8\u5934\u3001\u5e9f\u5f03\u98df\u7269\u4ee5\u53ca\u53a8\u623f\u4e0b\u811a\u6599\u7b49\u3002\u6709\u5bb3\u5783\u573e\u6307\u5bf9\u4eba\u4f53\u5065\u5eb7\u6216\u8005\u81ea\u7136\u73af\u5883\u9020\u6210\u76f4\u63a5\u6216\u8005\u6f5c\u5728\u5371\u5bb3\u4e14\u5e94\u5f53\u4e13\u95e8\u5904\u7406\u7684\u5e9f\u5f03\u7269\uff0c\u5305\u62ec\u5e9f\u7535\u6c60\u3001\u5e9f\u8367\u5149\u706f\u7ba1\u7b49\u3002\u5176\u4ed6\u5783\u573e\u6307\u9664\u4ee5\u4e0a\u4e09\u7c7b\u5783\u573e\u4e4b\u5916\u7684\u5176\u4ed6\u751f\u6d3b\u5783\u573e\uff0c\u6bd4\u5982\u7eb8\u5c3f\u88e4\u3001\u5c18\u571f\u3001\u70df\u5934\u3001\u4e00\u6b21\u6027\u5feb\u9910\u76d2\u3001\u7834\u635f\u82b1\u76c6\u53ca\u7897\u789f\u3001\u5899\u7eb8\u7b49\u3002","title":"1\u3001\u5783\u573e\u5206\u7c7b\u95ee\u9898\u7684\u9700\u6c42 \uff1a"},{"location":"tensorFlow/section9/#2","text":"\u51cf\u5c11\u5360\u5730\u3001\u51cf\u5c11\u6c61\u67d3\u3001\u53d8\u5e9f\u4e3a\u5b9d","title":"2\u3001\u5783\u573e\u5206\u7c7b\u610f\u4e49"},{"location":"tensorFlow/section9/#3","text":"\u79cd\u7c7b\u591a\uff0c\u6613\u5206\u9519\uff1a\u5982\u53e3\u9999\u7cd6\uff1f\u6e7f\u7eb8\u5dfe\uff1f\u74dc\u5b50\u76ae\uff1f\u5851\u6599\u888b\uff1f \u5e72\uff0c\u5e72\uff0c\u6e7f\uff0c\u53ef\u56de\u6536 \u81ea\u52a8\u5206\u6361 \u4eba\u4eec\u901a\u8fc7\u624b\u673a\u62cd\u7167\uff0c\u7528\u7a0b\u5e8f\u81ea\u52a8\u8bc6\u522b\u51fa\u5783\u573e\u7684\u7c7b\u522b\uff0c\u4e0d\u4ec5\u7b80\u5316\u4eba\u4eec\u5bf9\u5783\u573e\u5206\u7c7b\u7684\u5904\u7406\uff0c\u800c\u4e14\u63d0\u9ad8\u5783\u573e\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3002","title":"3\u3001\u5783\u573e\u5206\u7c7b\u96be\u70b9"},{"location":"tensorFlow/section9/#4911","text":"1\u3001\u534e\u4e3a\u4e91\u4eba\u5de5\u667a\u80fd\u5927\u8d5b\u00b7\u5783\u573e\u5206\u7c7b\u6311\u6218\u676f \u5b98\u7f51\uff1a https://competition.huaweicloud.com/information/1000007620/introduction","title":"4.9.1.1 \u5783\u573e\u5206\u7c7b\u6bd4\u8d5b"},{"location":"tensorFlow/section9/#140","text":"{ \"0\": \"\u5176\u4ed6\u5783\u573e/\u4e00\u6b21\u6027\u5feb\u9910\u76d2\", \"1\": \"\u5176\u4ed6\u5783\u573e/\u6c61\u635f\u5851\u6599\", \"2\": \"\u5176\u4ed6\u5783\u573e/\u70df\u8482\", \"3\": \"\u5176\u4ed6\u5783\u573e/\u7259\u7b7e\", \"4\": \"\u5176\u4ed6\u5783\u573e/\u7834\u788e\u82b1\u76c6\u53ca\u789f\u7897\", \"5\": \"\u5176\u4ed6\u5783\u573e/\u7af9\u7b77\", \"6\": \"\u53a8\u4f59\u5783\u573e/\u5269\u996d\u5269\u83dc\", \"7\": \"\u53a8\u4f59\u5783\u573e/\u5927\u9aa8\u5934\", \"8\": \"\u53a8\u4f59\u5783\u573e/\u6c34\u679c\u679c\u76ae\", \"9\": \"\u53a8\u4f59\u5783\u573e/\u6c34\u679c\u679c\u8089\", \"10\": \"\u53a8\u4f59\u5783\u573e/\u8336\u53f6\u6e23\", \"11\": \"\u53a8\u4f59\u5783\u573e/\u83dc\u53f6\u83dc\u6839\", \"12\": \"\u53a8\u4f59\u5783\u573e/\u86cb\u58f3\", \"13\": \"\u53a8\u4f59\u5783\u573e/\u9c7c\u9aa8\", \"14\": \"\u53ef\u56de\u6536\u7269/\u5145\u7535\u5b9d\", \"15\": \"\u53ef\u56de\u6536\u7269/\u5305\", \"16\": \"\u53ef\u56de\u6536\u7269/\u5316\u5986\u54c1\u74f6\", \"17\": \"\u53ef\u56de\u6536\u7269/\u5851\u6599\u73a9\u5177\", \"18\": \"\u53ef\u56de\u6536\u7269/\u5851\u6599\u7897\u76c6\", \"19\": \"\u53ef\u56de\u6536\u7269/\u5851\u6599\u8863\u67b6\", \"20\": \"\u53ef\u56de\u6536\u7269/\u5feb\u9012\u7eb8\u888b\", \"21\": \"\u53ef\u56de\u6536\u7269/\u63d2\u5934\u7535\u7ebf\", \"22\": \"\u53ef\u56de\u6536\u7269/\u65e7\u8863\u670d\", \"23\": \"\u53ef\u56de\u6536\u7269/\u6613\u62c9\u7f50\", \"24\": \"\u53ef\u56de\u6536\u7269/\u6795\u5934\", \"25\": \"\u53ef\u56de\u6536\u7269/\u6bdb\u7ed2\u73a9\u5177\", \"26\": \"\u53ef\u56de\u6536\u7269/\u6d17\u53d1\u6c34\u74f6\", \"27\": \"\u53ef\u56de\u6536\u7269/\u73bb\u7483\u676f\", \"28\": \"\u53ef\u56de\u6536\u7269/\u76ae\u978b\", \"29\": \"\u53ef\u56de\u6536\u7269/\u7827\u677f\", \"30\": \"\u53ef\u56de\u6536\u7269/\u7eb8\u677f\u7bb1\", \"31\": \"\u53ef\u56de\u6536\u7269/\u8c03\u6599\u74f6\", \"32\": \"\u53ef\u56de\u6536\u7269/\u9152\u74f6\", \"33\": \"\u53ef\u56de\u6536\u7269/\u91d1\u5c5e\u98df\u54c1\u7f50\", \"34\": \"\u53ef\u56de\u6536\u7269/\u9505\", \"35\": \"\u53ef\u56de\u6536\u7269/\u98df\u7528\u6cb9\u6876\", \"36\": \"\u53ef\u56de\u6536\u7269/\u996e\u6599\u74f6\", \"37\": \"\u6709\u5bb3\u5783\u573e/\u5e72\u7535\u6c60\", \"38\": \"\u6709\u5bb3\u5783\u573e/\u8f6f\u818f\", \"39\": \"\u6709\u5bb3\u5783\u573e/\u8fc7\u671f\u836f\u7269\" } 2\u3001\u5176\u4ed6\u6bd4\u8d5b Apache Flink\u6781\u5ba2\u6311\u6218\u8d5b\u2014\u2014\u5783\u573e\u56fe\u7247\u5206\u7c7b \u5b98\u65b9\uff1a https://tianchi.aliyun.com/competition/entrance/231743/information","title":"1\u3001\u5783\u573e\u79cd\u7c7b40\u7c7b"},{"location":"tensorFlow/section9/#492","text":"\u672c\u6b21\u6bd4\u8d5b\u9009\u53d640\u79cd\u751f\u6d3b\u4e2d\u5e38\u89c1\u7684\u5783\u573e\uff0c\u9009\u624b\u6839\u636e\u516c\u5e03\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53d1\u5e03\u5230\u534e\u4e3aModelArts\u5e73\u53f0\u4e0a\uff0c\u5728\u7ebf\u9884\u6d4b\u534e\u4e3a\u7684\u79c1\u6709\u6570\u636e\u96c6\uff0c\u91c7\u7528\u8bc6\u522b\u51c6\u786e\u7387\u4f5c\u4e3a\u8bc4\u4ef7\u6307\u6807\u3002 \u8fd9\u6b21\u6bd4\u8d5b\u4e2d\u6709\u5f88\u591a\u5bb9\u6613\u6df7\u6dc6\u7684\u7c7b\uff0c\u6bd4\u5982\u996e\u6599\u74f6\u548c\u8c03\u6599\u74f6\u3001\u7b77\u5b50\u548c\u7259\u7b7e\u3001\u679c\u76ae\u548c\u679c\u8089\u7b49\u5916\u5f62\u6781\u4e3a\u76f8\u4f3c\u7684\u5783\u573e\uff0c\u56e0\u6b64\u6b64\u6b21\u7ade\u8d5b\u4e5f\u53ef\u770b\u4f5c\u662f\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u3002","title":"4.9.2 \u534e\u4e3a\u5783\u573e\u5206\u7c7b\u6bd4\u8d5b\u4ecb\u7ecd"},{"location":"tensorFlow/section9/#_2","text":"1\u3001\u62ff\u5230\u6570\u636e\u540e\uff0c\u9996\u5148\u505a\u6570\u636e\u5206\u6790\u3002\u7edf\u8ba1\u6570\u636e\u6837\u672c\u5206\u5e03\uff0c\u5c3a\u5bf8\u5206\u5e03\uff0c\u56fe\u7247\u5f62\u6001\u7b49\uff0c\u57fa\u4e8e\u5206\u6790\u53ef\u4ee5\u505a\u4e00\u4e9b\u9488\u5bf9\u6027\u7684\u6570\u636e\u9884\u5904\u7406\u7b97\u6cd5\uff0c\u5bf9\u540e\u671f\u7684\u6a21\u578b\u8bad\u7ec3\u4f1a\u6709\u5f88\u5927\u7684\u5e2e\u52a9 2\u3001\u9009\u62e9\u597d\u7684baseline\u3002\u9700\u8981\u4e0d\u65ad\u7684\u5c1d\u8bd5\u5404\u79cd\u73b0\u6709\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u8fdb\u884c\u7ed3\u679c\u5bf9\u6bd4\uff0c\u6311\u9009\u51fa\u9002\u5408\u8be5\u7f51\u7edc\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u7136\u540e\u57fa\u4e8e\u8be5\u6a21\u578b\u8fdb\u884c\u4e0d\u65ad\u7684\u8c03\u53c2\uff0c\u8c03\u8bd5\u51fa\u6027\u80fd\u8f83\u597d\u7684\u53c2\u6570 3\u3001\u505a\u7ed3\u679c\u9a8c\u8bc1\uff0c\u5c06\u4e0a\u8ff0\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u505a\u7ed3\u679c\u9a8c\u8bc1\uff0c\u627e\u51fa\u9519\u8bef\u6837\u672c\uff0c\u5206\u6790\u51fa\u9519\u539f\u56e0\uff0c\u7136\u540e\u9488\u5bf9\u6027\u7684\u8c03\u6574\u7f51\u7edc\u548c\u6570\u636e\u3002 3\u3001\u57fa\u4e8e\u65b0\u6570\u636e\u548c\u6a21\u578b\uff0c\u518d\u6b21\u8fdb\u884c\u6a21\u578b\u8c03\u4f18","title":"\u91cd\u8981\uff1a\u6bd4\u8d5b\u6216\u8005\u9879\u76ee\u89e3\u9898\u601d\u8def"},{"location":"tensorFlow/section9/#5","text":"\u540d\u6b21 \u51c6\u786e\u7387 \u63a8\u7406(inference)\u65f6\u95f4(ms) \u7b2c\u4e00\u540d 0.969636 102.8 \u7b2c\u4e8c\u540d 0.96251 95.43 \u7b2c\u4e09\u540d 0.962045 97.25 \u7b2c\u56db\u540d 0.961735 82.99 \u7b2c\u4e94\u540d 0.957397 108.49","title":"\u6bd4\u8d5b\u8868\u73b0\u524d5\u56e2\u961f\u6548\u679c"},{"location":"tensorFlow/section9/#4921","text":"","title":"4.9.2.1 \u8d5b\u9898\u5206\u6790"},{"location":"tensorFlow/section9/#1_1","text":"\u7ecf\u5178\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u3002\u91c7\u7528\u6df1\u5733\u5e02\u5783\u573e\u5206\u7c7b\u6807\u51c6\uff0c\u8f93\u51fa\u8be5\u7269\u54c1\u5c5e\u4e8e\u53ef\u56de\u6536\u7269\u3001 \u53a8\u4f59\u5783\u573e\u3001\u6709\u5bb3\u5783\u573e\u548c\u5176\u4ed6\u5783\u573e\u4e2d\u7684\u4e8c\u7ea7\u5206\u7c7b\uff0c\u517143\u4e2a\u7c7b\u522b\u3002","title":"1\u3001\u95ee\u9898\u63cf\u8ff0:"},{"location":"tensorFlow/section9/#2_1","text":"\u8bc6\u522b\u51c6\u786e\u7387 = \u8bc6\u522b\u6b63\u786e\u7684\u56fe\u7247\u6570 / \u56fe\u7247\u603b\u6570","title":"2\u3001\u8bc4\u4ef7\u6307\u6807:"},{"location":"tensorFlow/section9/#3_1","text":"\u5b98\u65b9\u8bad\u7ec3\u96c6\u670919459\u5f20\u56fe\u7247\uff0c\u6570\u636e\u91cf\u5c0f; \u7c7b\u522b\u8f83\u591a(40)\uff0c\u4e14\u5404\u7c7b\u6837\u672c\u4e0d\u5e73\u8861; \u56fe\u7247\u5927\u5c0f\u3001\u5206\u8fa8\u7387\u4e0d\u4e00\uff0c\u5783\u573e\u7269\u54c1\u6709\u591a\u79cd\u5c3a\u5ea6; \u5783\u573e\u5206\u7c7b\u662f\u7ec6\u7c92\u5ea6\u3001\u7c97\u7c92\u5ea6\u517c\u6709\u7684\u4e00\u79cd\u5206\u7c7b\u95ee\u9898\uff0c\u8f6e\u5ed3\u3001\u7eb9\u7406\u3001\u5bf9\u8c61\u4f4d\u7f6e\u5206 \u5e03\u90fd\u9700\u8981\u8003\u5bdf","title":"3\u3001\u6311\u6218:"},{"location":"tensorFlow/section9/#4922","text":"1\u3001\u6570\u636e\u96c6\u5206\u6790\u548c\u9009\u62e9 2\u3001\u6a21\u578b\u9009\u62e9 3\u3001\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u5e38\u89c1trick\uff08\u4f18\u5316\uff09","title":"4.9.2.2 \u5bf9\u7b56"},{"location":"tensorFlow/section9/#1_2","text":"\u6570\u636e\u96c6\u4e0b\u8f7d\u4ee5\u53ca\u7ec4\u6210 \u7ec4\u6210\u6709train_data\uff0c\u7136\u540e\u540c\u76ee\u5f55\u4e0b\u6709\u56fe\u7247\u4ee5\u53ca\u5bf9\u5e94txt txt\u4e2d\u7684\u683c\u5f0f\uff1aimg_1.jpg, 0-\u4e3a\u56fe\u7247\u4ee5\u53ca\u5bf9\u5e94\u76ee\u6807 \u6ce8\uff1a\u5b98\u65b9\u8fd8\u6709V2\u7248\u672c\u7684\u6570\u636e\uff0c\u62d3\u5c55\u4e86\u7c7b\u522b\u517143\u7c7b\uff08\u6211\u4eec\u540e\u9762\u7684\u9879\u76ee\u662f\u5728\u7b2c\u4e00\u4e2a\u7248\u672c\u7684\u6570\u636e\u4e2d\u505a\u8bad\u7ec3\uff09","title":"1\u3001\u6570\u636e\u96c6\u60c5\u51b5"},{"location":"tensorFlow/section9/#2_2","text":"\u6570\u636e\u91cf\u5c0f\u3001\u7c7b\u522b\u591a\u3001\u63a8\u7406\u65f6\u95f4\u77ed->\u7efc\u5408\u8003\u5bdf\u8ba1 \u7b97\u91cf\u3001\u4f53\u79ef\u3001\u7cbe\u5ea6\uff0c\u9009\u62e9\u8fd1\u671f\u624d\u53d1\u5e03\u7684\u9ad8\u8d28\u91cf \u9884\u8bad\u7ec3\u6a21\u578b(EfficientNet B5/B4)\u8fdb\u884c\u8fc1\u79fb \u5b66\u4e60","title":"2\u3001\u5206\u7c7b\u6a21\u578b\u9009\u62e9"},{"location":"tensorFlow/section9/#1_3","text":"Top-1 \u51c6\u786e\u7387\u548c Top-5 \u51c6\u786e\u7387\u90fd\u662f\u5728 ImageNet \u9a8c\u8bc1\u96c6\u4e0a\u7684\u7ed3\u679c\u3002 Architecture @top1* @top5* Weights EfficientNetB0 0.7668 0.9312 + EfficientNetB1 0.7863 0.9418 + EfficientNetB2 0.7968 0.9475 + EfficientNetB3 0.8083 0.9531 + Tensorflow\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u8fc7\u7684\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b\uff08TFAPI\u6587\u6863\uff0c\u5b98\u7f51\u4f1a\u63a8\u8350\u5b89\u88c5\uff09\uff1a # \u8f93\u5165\u5927\u5c0f EfficientNetB0 - ( 224 , 224 , 3 ) EfficientNetB1 - ( 240 , 240 , 3 ) EfficientNetB2 - ( 260 , 260 , 3 ) EfficientNetB3 - ( 300 , 300 , 3 ) EfficientNetB4 - ( 380 , 380 , 3 ) EfficientNetB5 - ( 456 , 456 , 3 ) EfficientNetB6 - ( 528 , 528 , 3 ) EfficientNetB7 - ( 600 , 600 , 3 ) \u6ce8\uff1a\u9879\u76ee\u964d\u5230\u6a21\u578b\u90e8\u5206\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\u6a21\u578b","title":"\uff081\uff09\u73b0\u6709\u6a21\u578b\u4ee5\u53ca\u51c6\u786e\u7387\u5bf9\u6bd4"},{"location":"tensorFlow/section9/#3-trick","text":"","title":"3\u3001 \u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u5e38\u89c1trick\uff08\u4f18\u5316\uff09"},{"location":"tensorFlow/section9/#1_4","text":"\u5206\u6790\uff1a\u4e0b\u56fe\u6a2a\u5750\u6807\u662f\u7c7b\u6807\u53f7\uff0c\u7eb5\u5750\u6807\u662f\u6bcf\u4e2a\u7c7b\u7684\u6837\u672c\u6570\u91cf\u3002 \u5f88\u5bb9\u6613\u770b\u51fa\uff0c\u6bcf\u4e2a\u7c7b\u4e4b\u95f4\u7684\u6837\u672c\u91cf\u5dee\u5f02\u5f88\u5927\uff0c\u5982\u679c\u4e0d\u505a\u7c7b\u5747\u8861\u5904\u7406\uff0c\u5f88\u6709\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6837\u672c\u91cf\u591a\u7684\u7c7b\u8fc7\u62df\u5408\uff0c\u6837\u672c\u91cf\u5c11\u7684\u7c7b\u6b20\u62df\u5408\u3002 \u5e38\u89c1\u7684\u7c7b\u5747\u8861\u65b9\u6cd5\u6709\uff1a\u591a\u6570\u7c7b\u6b20\u91c7\u6837\uff0c\u5c11\u6570\u7c7b\u8fc7\u91c7\u6837\uff1b\u6570\u636e\u589e\u5f3a\uff1b\u6807\u7b7e\u5e73\u6ed1\uff1b \u56fe\u7247\u957f\u5bbd\u6bd4\u6709\u4e00\u5b9a\u7684\u5dee\u5f02\u6027\uff0c\u957f\u5bbd\u6bd4\u5927\u591a\u6570\u96c6\u4e2d\u4e8e1\uff0c\u56e0\u6b64\u4e5f\u9002\u5408\u4e00\u4e9b\u6a21\u578b\u8f93\u5165\u5c3a\u5bf8\u8bbe\u4e3a1\uff1a1 1\u3001\u6570\u636e\u589e\u5f3a \uff081\uff09\u5e76\u975e\u6240\u6709\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u90fd\u6709\u6548\uff0c\u8981\u4fdd\u8bc1\u6570\u636e\u589e\u5f3a\u540e\u76ee\u6807\u4ecd\u53ef\u8089\u773c\u5206\u8fa8\uff0c\u4e14\u4e0d\u6539\u53d8\u56fe\u50cf\u6240\u5c5e\u7c7b\u522b\u3002 \uff082\uff09\u8fc7\u591a\u7684\u6570\u636e\u589e\u5f3a\u4e5f\u4f1a\u5ef6\u957f\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\uff0c\u901a\u5e38\u7ffb\u8f6c\u7684\u6548\u679c\u4e0d\u9519\uff08\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\u3001\u968f\u673a\u5782\u76f4\u7ffb\u8f6c\u3001\u4ee5\u4e00\u5b9a\u6982\u7387\u968f\u673a\u65cb\u8f6c90\u00b0\u3001180\u00b0\u3001270\u00b0\u3001\u968f\u673acrop(0-10%)\u7b49\uff09 \u5176\u4ed6\u5982\u4e0b\uff1a Color Jittering:\u5bf9\u989c\u8272\u7684\u6570\u636e\u589e\u5f3a:\u56fe\u50cf\u4eae\u5ea6\u3001\u9971\u548c\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u53d8\u5316 Random Scale:\u5c3a\u5ea6\u53d8\u6362; Random Crop:\u91c7\u7528\u968f\u673a\u56fe\u50cf\u5dee\u503c\u65b9\u5f0f\uff0c\u5bf9\u56fe\u50cf\u8fdb\u884c\u88c1\u526a\u3001\u7f29\u653e Horizontal/Vertical Flip:\u6c34\u5e73/\u5782\u76f4\u7ffb\u8f6c; Shift:\u5e73\u79fb\u53d8\u6362; Rotation/Reflection:\u65cb\u8f6c/\u4eff\u5c04\u53d8\u6362; Noise:\u9ad8\u65af\u566a\u58f0\u3001\u6a21\u7cca\u5904\u7406; 2\u3001\u5916\u90e8\u6570\u636e\uff1a\u6bd4\u8d5b\u4e0d\u9650\u5236\u4f7f\u7528\u5916\u90e8\u6570\u636e\uff0c\u4e5f\u5c31\u662f\u8bf4\u53ef\u4ee5\u901a\u8fc7\u81ea\u5df1\u62cd\u7167\u3001\u7f51\u4e0a\u722c\u53d6\u7b49\u65b9\u5f0f\u83b7\u5f97\u66f4\u591a\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u6bd4\u8f83\u8d39\u65f6\u8017\u529b\u3002\u901a\u5e38\u81ea\u5df1\u627e\u7684\u6570\u636e\u96c6\u8d28\u91cf\u4e5f\u4e0d\u591f\u597d\uff0c\u4e0e\u534e\u4e3a\u516c\u5e03\u7684\u6570\u636e\u96c6\u5206\u5e03\u4e0d\u540c\uff0c\u6709\u4e9b\u56e2\u961f\u722c\u53d6\u4e00\u4e9b\u989d\u5916\u6570\u636e\uff0c\u6700\u7ec8\u6548\u679c\u90fd\u4e0d\u597d\uff0c\u751a\u81f3\u964d\u4f4e\u4e86\u5206\u6570\uff0c\u56e0\u6b64\u653e\u5f03\u4e86\u8fd9\u79cd\u65b9\u6cd5\u3002\u6240\u4ee5\u5728\u4e00\u5f00\u59cb\u6784\u9020\u597d\u6570\u636e\u5206\u5e03\u5f88\u91cd\u8981\u3002\uff08\u6bd4\u8d5b\u4e0e\u9879\u76ee\u4f1a\u6709\u4e9b\u5dee\u5f02\uff0c\u771f\u6b63\u9879\u76ee\u5176\u5b9e\u8fd8\u662f\u66f4\u591a\u8986\u76d6\u6570\u636e\u5206\u5e03\u8d8a\u597d\uff0c\u6bd4\u8d5b\u53ef\u80fd\u53ea\u662f\u534e\u4e3a\u516c\u5f00\u7684\u6570\u636e\u96c6\u5305\u62ec\u6d4b\u8bd5\u7684\u6570\u636e\u5206\u5e03\u4e00\u6837\u7684\uff0c\u5bfc\u81f4\u4e0d\u80fd\u62ff\u8fc7\u591a\u7684\u5916\u90e8\u6570\u636e\uff08\u5bb9\u6613\u8fc7\u62df\u5408\uff09\uff09 3\u3001\u6570\u636e\u5f52\u4e00\u5316 4\u3001\u6807\u7b7e\u5e73\u6ed1 5\u3001mixup","title":"\uff081\uff09\u6570\u636e\u65b9\u9762"},{"location":"tensorFlow/section9/#2_3","text":"1\u3001\u4f7f\u7528\u591a\u79cd\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c 2\u3001\u9009\u62e9\u6539\u8fdb\u7684Adam\u4f18\u5316\u65b9\u6cd5 \uff1aAdam with warm up\u4f18\u5316\u5668 3\u3001\u81ea\u5b9a\u4e49\u5b66\u4e60\u7387-\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387 \u81ea\u5e26warmup\u7684\u5b66\u4e60\u7387\u63a7\u5236\u5bf9\u8fed\u4ee3\u6b21\u6570\u6bd4\u8f83\u7a33\u5065(\u53ea\u8981\u8fbe\u5230\u8db3\u591f\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u6700\u7ec8\u7ed3\u679c\u90fd\u6bd4 \u8f83\u63a5\u8fd1)\uff0c\u5927\u5927\u964d\u4f4e\u8c03\u53c2\u590d\u6742\u6027\uff0c\u7f29\u77ed\u5b9e\u9a8c\u5468\u671f","title":"\uff082\uff09\u53d1\u6398\u4e0e\u8bad\u7ec3\u6a21\u578b\u7684\u6f5c\u529b\uff1a"},{"location":"tensorFlow/section9/#493","text":"","title":"4.9.3 \u9879\u76ee\u6784\u5efa\uff08\u6a21\u5757\u5206\u6790\uff09"},{"location":"tensorFlow/section9/#4931","text":"data:\u5b58\u653e\u6570\u636e\u7684\u76ee\u5f55 data_gen\u76ee\u5f55\uff1a\u6279\u6b21\u6570\u636e\u9884\u5904\u7406\u4ee3\u7801\uff0c\u5305\u62ec\u6570\u636e\u589e\u5f3a\u3001\u6807\u7b7e\u5e73\u6ed1\u3001mixup\u529f\u80fd deploy\uff1a\u6a21\u578b\u5bfc\u51fa\u4ee5\u53ca\u90e8\u7f72\u6a21\u5757 efficientnet:efficientnet\u6a21\u578b\u6e90\u7801\u5b58\u653e\u4f4d\u7f6e utils:\u5c01\u88c5\u7684\u5de5\u5177\u7c7b\uff0c\u5982warmup\u4ee5\u53ca\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387 train.y\u4e0eeval.py\uff1a\u8bad\u7ec3\u7f51\u7edc\u90e8\u5206\u5305\u62ec\u6570\u636e\u6d41\u83b7\u53d6\u3001\u7f51\u7edc\u6784\u5efa\u3001\u4f18\u5316\u5668","title":"4.9.3.1 \u9879\u76ee\u6a21\u5757\u56fe"},{"location":"tensorFlow/section9/#_3","text":"\u572816\u6838\u3001\u5185\u5b5816G\u7684\u673a\u5668\u4e0a\uff0c\u53ea\u7528CPU\u8ba1\u7b971 epoch\u8017\u65f61.83\u5c0f\u65f6\uff081\u5c0f\u65f650\u5206\u949f\uff09 Epoch 1/30 76/787 [=>............................] - ETA: 1:49:16 - loss: 3.7690 - accuracy: 0.0189 303/787 [==========>...................] - ETA: 1:07:05 - loss: 3.7383 - accuracy: 0.025 468/787 [================>.............] - ETA: 43:30 - loss: 3.7253 - accuracy: 0.0262 470/787 [================>.............] - ETA: 43:13 - loss: 3.7251 - accuracy: 0.0261 499/787 [==================>...........] - ETA: 39:12 - loss: 3.7232 - accuracy: 0.0270 576/787 [====================>.........] - ETA: 28:35 - loss: 3.7188 - accuracy: 0.0290 577/787 [====================>.........] - ETA: 28:26 - loss: 3.7187 - accuracy: 0.0290 602/787 [=====================>........] - ETA: 25:01 - loss: 3.7170 - accuracy: 0.0295 612/787 [======================>.......] - ETA: 23:39 - loss: 3.7163 - accuracy: 0.0298 ... 786/787 [============================>.] - ETA: 8s - loss: 3.7085 - accuracy: 0.0319","title":"\u9879\u76ee\u8fd0\u884c\u8fc7\u7a0b\u6570\u636e\u8bb0\u5f55\u4ee5\u53ca\u6700\u7ec8\u6548\u679c"},{"location":"tensorFlow/section9/#-","text":"\u4e0b\u9762\u7b80\u5355\u7684\u4ecb\u7ecd\u4e00\u4e0b\u6574\u4e2a\u5de5\u7a0b\u4e2d\u6700\u5173\u952e\u7684\u8bad\u7ec3\u90e8\u5206\u4ee3\u7801 import multiprocessing import numpy as np import argparse import tensorflow as tf from tensorflow.keras.callbacks import ReduceLROnPlateau from tensorflow.keras.callbacks import TensorBoard , Callback from tensorflow.keras.layers import Dense , GlobalAveragePooling2D from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam , RMSprop from efficientnet import model as EfficientNet from efficientnet import preprocess_input from data_gen import data_flow from utils.warmup_cosine_decay_scheduler import WarmUpCosineDecayScheduler import os os . environ [ \"TF_CPP_MIN_LOG_LEVEL\" ] = \"2\" # efficientnet\u6e90\u7801\u5b9e\u73b0\u7528TF1.X\u7248\u672c\uff0c\u6240\u4ee5\u8981\u5173\u95ed\u9ed8\u8ba4\u7684eager\u6a21\u5f0f tf . compat . v1 . disable_eager_execution () parser = argparse . ArgumentParser () parser . add_argument ( \"data_url\" , type = str , default = './data/garbage_classify/train_data' , help = \"data dir\" , nargs = '?' ) parser . add_argument ( \"train_url\" , type = str , default = './garbage_ckpt/' , help = \"save model dir\" , nargs = '?' ) parser . add_argument ( \"num_classes\" , type = int , default = 40 , help = \"num_classes\" , nargs = '?' ) parser . add_argument ( \"input_size\" , type = int , default = 300 , help = \"input_size\" , nargs = '?' ) parser . add_argument ( \"batch_size\" , type = int , default = 16 , help = \"batch_size\" , nargs = '?' ) parser . add_argument ( \"learning_rate\" , type = float , default = 0.0001 , help = \"learning_rate\" , nargs = '?' ) parser . add_argument ( \"max_epochs\" , type = int , default = 30 , help = \"max_epochs\" , nargs = '?' ) parser . add_argument ( \"deploy_script_path\" , type = str , default = '' , help = \"deploy_script_path\" , nargs = '?' ) parser . add_argument ( \"test_data_url\" , type = str , default = '' , help = \"test_data_url\" , nargs = '?' ) def model_fn ( param ): \"\"\"\u8fc1\u79fb\u5b66\u4e60\u4fee\u6539\u6a21\u578b\u51fd\u6570 :param param: :return: \"\"\" base_model = EfficientNet . EfficientNetB3 ( include_top = False , input_shape = ( param . input_size , param . input_size , 3 ), classes = param . num_classes ) x = base_model . output x = GlobalAveragePooling2D ( name = 'avg_pool' )( x ) predictions = Dense ( param . num_classes , activation = 'softmax' )( x ) model = Model ( inputs = base_model . input , outputs = predictions ) return model def train_model ( param ): \"\"\"\u8bad\u7ec3\u6a21\u578b :param param: \u4f20\u5165\u7684\u547d\u4ee4\u53c2\u6570 :return: \"\"\" # 1\u3001\u5efa\u7acb\u8bfb\u53d6\u6570\u636e\u7684sequence train_sequence , validation_sequence = data_flow ( param . data_url , param . batch_size , param . num_classes , param . input_size , preprocess_input ) # 2\u3001\u5efa\u7acb\u6a21\u578b\uff0c\u6307\u5b9a\u6a21\u578b\u8bad\u7ec3\u76f8\u5173\u53c2\u6570 model = model_fn ( param ) optimizer = Adam ( lr = param . learning_rate ) objective = 'categorical_crossentropy' metrics = [ 'accuracy' ] # \u6a21\u578b\u4fee\u6539 # \u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u5668\u6307\u5b9a model . compile ( loss = objective , optimizer = optimizer , metrics = metrics ) model . summary () # \u5224\u65ad\u6a21\u578b\u662f\u5426\u52a0\u8f7d\u5386\u53f2\u6a21\u578b if os . path . exists ( param . train_url ): filenames = os . listdir ( param . train_url ) model . load_weights ( filenames [ - 1 ]) print ( \"\u52a0\u8f7d\u5b8c\u6210!!!\" ) # 3\u3001\u6307\u5b9a\u8bad\u7ec3\u7684callbacks\uff0c\u5e76\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3 # \uff081\uff09Tensorboard tensorboard = tf . keras . callbacks . TensorBoard ( log_dir = './graph' , histogram_freq = 1 , write_graph = True , write_images = True ) # \uff082\uff09\u81ea\u5b9a\u4e49warm up\u548c\u4f59\u5f26\u5b66\u4e60\u7387\u8870\u51cf sample_count = len ( train_sequence ) * param . batch_size epochs = param . max_epochs warmup_epoch = 5 batch_size = param . batch_size learning_rate_base = param . learning_rate total_steps = int ( epochs * sample_count / batch_size ) warmup_steps = int ( warmup_epoch * sample_count / batch_size ) warm_up_lr = WarmUpCosineDecayScheduler ( learning_rate_base = learning_rate_base , total_steps = total_steps , warmup_learning_rate = 0 , warmup_steps = warmup_steps , hold_base_rate_steps = 0 , ) #\uff083\uff09\u6a21\u578b\u4fdd\u5b58\u76f8\u5173\u53c2\u6570 check = tf . keras . callbacks . ModelCheckpoint ( param . train_url + 'weights_{epoch:02d}-{val_acc:.2f}.h5' , monitor = 'val_acc' , save_best_only = True , save_weights_only = False , mode = 'auto' , period = 1 ) # \uff084\uff09\u8bad\u7ec3 model . fit_generator ( train_sequence , steps_per_epoch = len ( train_sequence ), epochs = param . max_epochs , verbose = 1 , callbacks = [ check , tensorboard , warm_up_lr ], validation_data = validation_sequence , max_queue_size = 10 , workers = int ( multiprocessing . cpu_count () * 0.7 ), use_multiprocessing = True , shuffle = True ) print ( '\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f!' )","title":"\u9879\u76ee\u8bad\u7ec3\u4ee3\u7801\u521d\u59cb-\u8bad\u7ec3\u6d41\u7a0b"},{"location":"tensorFlow/section9/#4932","text":"1\u3001\u6570\u636e\u8bfb\u53d6\u4ee5\u53ca\u9884\u5904\u7406\u6a21\u5757 \u6570\u636e\u83b7\u53d6 \u6570\u636e\u589e\u5f3a \u5f52\u4e00\u5316 \u968f\u673a\u64e6\u9664 Mixup 2\u3001\u6a21\u578b\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0 efficientnet\u6a21\u578b\u4ecb\u7ecd \u5783\u573e\u5206\u7c7b\u6a21\u578b\u4fee\u6539 \u6a21\u578b\u5b66\u4e60\u7387\u4f18\u5316-warmup\u4e0e\u4f59\u5f26\u9000\u706b\u5b66\u4e60\u7387 \u6a21\u578b\u4f18\u5316\u5668-Adam\u4f18\u5316\u5668\u6539\u8fdbRAdam/NRdam 3\u3001\u6a21\u578b\u8bad\u7ec3\u4fdd\u5b58\u4e0e\u9884\u6d4b \u6a21\u578b\u5b8c\u6574\u8bad\u7ec3\u8fc7\u7a0b\u5b9e\u73b0 \u9884\u4f30\u6d41\u7a0b\u5b9e\u73b0 4\u3001\u6a21\u578b\u5bfc\u51fa\u4ee5\u53ca\u90e8\u7f72 tf.saved_model\u6a21\u5757\u4f7f\u7528 TensorFlow serving\u6a21\u5757\u4f7f\u7528 \u4e0a\u9762\u662f\u5783\u573e\u5206\u7c7b\u9879\u76ee\u8981\u638c\u63e1\u7684\u77e5\u8bc6\u70b9\uff0c\u4e5f\u662f\u8981\u53bb\u5b9e\u73b0\u9879\u76ee\u8bad\u7ec3\u7684\u5173\u952e","title":"4.9.3.2  \u6b65\u9aa4\u4ee5\u53ca\u77e5\u8bc6\u70b9\u5e94\u7528\u5206\u6790"},{"location":"tensorFlow/section9/#494","text":"","title":"4.9.4 \u6570\u636e\u8bfb\u53d6\u4e0e\u9884\u5904\u7406"},{"location":"tensorFlow/section9/#4941","text":"","title":"4.9.4.1 \u9879\u76ee\u9884\u5904\u7406\u6a21\u4ee3\u7801\u6d41\u7a0b\u4ecb\u7ecd"},{"location":"tensorFlow/section9/#_4","text":"1\u3001\u672c\u5730\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u8fdb\u884c\u56fe\u7247\u8def\u5f84\u8bfb\u53d6\uff0c\u6807\u7b7e\u8bfb\u53d6\uff0c\u5bf9\u6807\u7b7e\u8fdb\u884c\u5e73\u6ed1\u5904\u7406 2\u3001tf.keras.Sequence\u7c7b\u5c01\u88c5\uff0c\u8fd4\u56de\u5e8f\u5217\u6570\u636e \u5b8c\u6574\u6d41\u7a0b\uff1a def data_from_sequence ( train_data_dir , batch_size , num_classes , input_size ): \"\"\"\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u548c\u6807\u7b7e\u6570\u636e\uff0c\u5904\u7406\u6210sequence\u6570\u636e\u7c7b\u578b :param train_data_dir: \u8bad\u7ec3\u6570\u636e\u76ee\u5f55 :param batch_size: \u6279\u6b21\u5927\u5c0f :param num_classes: \u5783\u573e\u5206\u7c7b\u603b\u7c7b\u522b\u6570 :param input_size: \u8f93\u5165\u6a21\u578b\u7684\u56fe\u7247\u5927\u5c0f(300, 300) :return: \"\"\" # 1\u3001\u83b7\u53d6txt\u6587\u4ef6\uff0c\u6253\u4e71\u4e00\u6b21\u6587\u4ef6 label_files = [ os . path . join ( train_data_dir , filename ) for filename in os . listdir ( train_data_dir ) if filename . endswith ( '.txt' )] print ( label_files ) random . shuffle ( label_files ) # 2\u3001\u8bfb\u53d6txt\u6587\u4ef6\uff0c\u89e3\u6790\u51fa img_paths = [] labels = [] for index , file_path in enumerate ( label_files ): with open ( file_path , 'r' ) as f : line = f . readline () line_split = line . strip () . split ( ', ' ) if len ( line_split ) != 2 : print ( ' %s \u6587\u4ef6\u4e2d\u683c\u5f0f\u9519\u8bef' % ( file_path )) continue # \u83b7\u53d6\u56fe\u7247\u540d\u79f0\u548c\u6807\u7b7e\uff0c\u8f6c\u6362\u683c\u5f0f img_name = line_split [ 0 ] label = int ( line_split [ 1 ]) # \u56fe\u7247\u5b8c\u6574\u8def\u5f84\u62fc\u63a5\uff0c\u5e76\u83b7\u53d6\u5230\u56fe\u7247\u548c\u6807\u7b7e\u5217\u8868\u4e2d\uff08\u987a\u5e8f\u4e00\u4e00\u5bf9\u5e94\uff09 img_paths . append ( os . path . join ( train_data_dir , img_name )) labels . append ( label ) # 3\u3001\u8fdb\u884c\u6807\u7b7e\u7c7b\u522b\u5904\u7406\uff0c\u4ee5\u53ca\u6807\u7b7e\u5e73\u6ed1 labels = to_categorical ( labels , num_classes ) labels = smooth_labels ( labels ) # 4\u3001\u8fdb\u884c\u6240\u6709\u6570\u636e\u7684\u5206\u5272\uff0c\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 train_img_paths , validation_img_paths , train_labels , validation_labels = \\ train_test_split ( img_paths , labels , test_size = 0.15 , random_state = 0 ) print ( '\u603b\u5171\u6837\u672c\u6570: %d , \u8bad\u7ec3\u6837\u672c\u6570: %d , \u9a8c\u8bc1\u6837\u672c\u6570\u636e: %d ' % ( len ( img_paths ), len ( train_img_paths ), len ( validation_img_paths ))) # 5\u3001sequence\u5e8f\u5217\u6570\u636e\u5236\u4f5c train_sequence = GarbageDataSequence ( train_img_paths , train_labels , batch_size , [ input_size , input_size ], use_aug = True ) validation_sequence = GarbageDataSequence ( validation_img_paths , validation_labels , batch_size , [ input_size , input_size ], use_aug = False ) return train_sequence , validation_sequence","title":"\u4ee3\u7801\u6d41\u7a0b\u4ecb\u7ecd"},{"location":"tensorFlow/section9/#1_5","text":"\u65b0\u5efa\u4e00\u4e2adata_gen\u7684\u76ee\u5f55\uff0c\u65b0\u5efaprocessing_data.py\uff0c\u5b9e\u73b0\u4e0b\u9762\u8fd9\u4e2a\u5c06\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u8c03\u7528\u7684\u6570\u636e\u5904\u7406\u4e3b\u51fd\u6570 import math import os import random import numpy as np from PIL import Image from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.utils import to_categorical , Sequence from sklearn.model_selection import train_test_split from data_gen.random_eraser import get_random_eraser def data_from_sequence ( train_data_dir , batch_size , num_classes , input_size ): \"\"\"\u8bfb\u53d6\u672c\u5730\u56fe\u7247\u548c\u6807\u7b7e\u6570\u636e\uff0c\u5904\u7406\u6210sequence\u6570\u636e\u7c7b\u578b :param train_data_dir: \u8bad\u7ec3\u6570\u636e\u76ee\u5f55 :param batch_size: \u6279\u6b21\u5927\u5c0f :param num_classes: \u5783\u573e\u5206\u7c7b\u603b\u7c7b\u522b\u6570 :param input_size: \u8f93\u5165\u6a21\u578b\u7684\u56fe\u7247\u5927\u5c0f(300, 300) :return: \"\"\" # 1\u3001\u83b7\u53d6txt\u6587\u4ef6\uff0c\u6253\u4e71\u4e00\u6b21\u6587\u4ef6 label_files = [ os . path . join ( train_data_dir , filename ) for filename in os . listdir ( train_data_dir ) if filename . endswith ( '.txt' )] print ( label_files ) random . shuffle ( label_files ) # 2\u3001\u8bfb\u53d6txt\u6587\u4ef6\uff0c\u89e3\u6790\u51fa img_paths = [] labels = [] for index , file_path in enumerate ( label_files ): with open ( file_path , 'r' ) as f : line = f . readline () line_split = line . strip () . split ( ', ' ) if len ( line_split ) != 2 : print ( ' %s \u6587\u4ef6\u4e2d\u683c\u5f0f\u9519\u8bef' % ( file_path )) continue # \u83b7\u53d6\u56fe\u7247\u540d\u79f0\u548c\u6807\u7b7e\uff0c\u8f6c\u6362\u683c\u5f0f img_name = line_split [ 0 ] label = int ( line_split [ 1 ]) # \u56fe\u7247\u5b8c\u6574\u8def\u5f84\u62fc\u63a5\uff0c\u5e76\u83b7\u53d6\u5230\u56fe\u7247\u548c\u6807\u7b7e\u5217\u8868\u4e2d\uff08\u987a\u5e8f\u4e00\u4e00\u5bf9\u5e94\uff09 img_paths . append ( os . path . join ( train_data_dir , img_name )) labels . append ( label ) # 3\u3001\u8fdb\u884c\u6807\u7b7e\u7c7b\u522b\u5904\u7406\uff0c\u4ee5\u53ca\u6807\u7b7e\u5e73\u6ed1 labels = to_categorical ( labels , num_classes ) labels = smooth_labels ( labels ) return None","title":"1\u3001\u672c\u5730\u6570\u636e\u7684\u8bfb\u53d6\uff0c\u8fdb\u884c\u56fe\u7247\u8def\u5f84\u8bfb\u53d6\uff0c\u6807\u7b7e\u8bfb\u53d6\uff0c\u5bf9\u6807\u7b7e\u8fdb\u884c\u5e73\u6ed1\u5904\u7406"},{"location":"tensorFlow/section9/#1_6","text":"to_categorical\u4f7f\u7528\u4ecb\u7ecd\uff1a In [5]: tf.keras.utils.to_categorical([1,2,3,4,5], num_classes=10) Out[5]: array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)","title":"(1) \u6570\u636e\u8bfb\u53d6\u548c\u7c7b\u522b\u8f6c\u6362\u4ee5\u53ca\u6807\u7b7e\u5e73\u6ed1"},{"location":"tensorFlow/section9/#1-label-smoothing-regularization","text":"Label Smoothing\u5c31\u662f\u4e00\u79cd\u6291\u5236\u8fc7\u62df\u5408\u7684\u624b\u6bb5\u3002 \u601d\u60f3\uff1a\u5728\u8bad\u7ec3\u65f6\u5373\u5047\u8bbe\u6807\u7b7e\u53ef\u80fd\u5b58\u5728\u9519\u8bef\uff0c\u907f\u514d\u201c\u8fc7\u5206\u201d\u76f8\u4fe1\u8bad\u7ec3\u6837\u672c\u7684\u6807\u7b7e\u3002\u5c31\u662f\u8981\u544a\u8bc9\u6a21\u578b\uff0c\u6837\u672c\u7684\u6807\u7b7e\u4e0d\u4e00\u5b9a\u6b63\u786e\uff0c\u90a3\u4e48\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u5bf9\u4e8e\u5c11\u91cf\u7684\u6837\u672c\u9519\u8bef\u5c31\u4f1a\u9c81\u68d2\u6027\u66f4\u5f3a\u3002 \u8fc7\u7a0b\uff1a \u5728\u6bcf\u6b21\u8fed\u4ee3\u65f6\uff0c\u5e76\u4e0d\u76f4\u63a5\u5c06(xi,yi)\u653e\u5165\u8bad\u7ec3\u96c6\uff0c\u800c\u662f\u8bbe\u7f6e\u4e00\u4e2a\u9519\u8bef\u7387\u03b5\uff0c\u4ee51-\u03b5\u7684\u6982\u7387\u5c06(xi,yi)\u4ee3\u5165\u8bad\u7ec3\uff0c\u4ee5\u03b5\u7684\u6982\u7387\u5c06(xi,1-yi)\u4ee3\u5165\u8bad\u7ec3 $$ q_i=\\begin{cases}1-\\varepsilon, \\text{if i=y,} \\\\\\\\\\frac{\\varepsilon}{K-1}, \\text{others} \\end{cases} $$ \u6bd4\u5982\uff1a\u6211\u4eec\u7684\u4e8c\u5206\u7c7b\u732b/\u72d7\u793a\u4f8b\uff0c0.1 \u7684\u6807\u7b7e\u5e73\u6ed1\u610f\u5473\u7740\u76ee\u6807\u7b54\u6848\u5c06\u662f 0.90(90%\u786e\u4fe1)\u8fd9\u662f\u4e00\u4e2a\u72d7\u7684\u56fe\u50cf\uff0c\u800c 0.10(10%\u786e\u4fe1)\u8fd9\u662f\u4e00\u53ea\u732b\uff0c\u800c\u4e0d\u662f\u5148\u524d\u7684\u5411 1 \u6216 0 \u79fb\u52a8\u7684\u7ed3\u679c\u3002\u7531\u4e8e\u4e0d\u592a\u786e\u5b9a\uff0c\u5b83\u4f5c\u4e3a\u4e00\u79cd\u6b63\u5219\u5316\u5f62\u5f0f\uff0c\u63d0\u9ad8\u4e86\u5b83\u5bf9\u65b0\u6570\u636e\u7684\u9884\u6d4b\u80fd\u529b\u3002 Label Smoothing\u7684\u5de5\u4f5c\u539f\u7406\u662f\u5bf9\u539f\u6765\u7684[0 1]\u8fd9\u79cd\u6807\u6ce8\u505a\u4e00\u4e2a\u6539\u52a8\uff0c\u5047\u8bbe\u6211\u4eec\u7ed9\u5b9aLabel Smoothing\u7684\u503c\u4e3a0.1\uff1a[0,1]\u00d7(1\u22120.1)+0.\u00bd=[0.05,0.95] \u516c\u5f0f\u539f\u7406\u8bb2\u89e3\uff1a \u6b63\u5e38\u4ea4\u53c9\u71b5\u53ef\u4ee5\u5199\u4f5c\uff1a $$ H(y, p) = \\sum_{k=1}^{K}{-y_{k}}log(p_{k}) $$ \u6807\u7b7e\u5e73\u6ed1\u5316\u540e\u53d8\u6210\uff1a y_{k}^{LS} = y_{k}(1 - \\alpha) + \\alpha / K y_{k}^{LS} = y_{k}(1 - \\alpha) + \\alpha / K \u7406\u89e3\uff1a \u6ca1\u6709\u6807\u7b7e\u5e73\u6ed1\u8ba1\u7b97\u7684\u635f\u5931\u53ea\u8003\u8651\u6b63\u786e\u6807\u7b7e\u4f4d\u7f6e\u7684\u635f\u5931\uff0c\u800c\u4e0d\u8003\u8651\u5176\u4ed6\u6807\u7b7e\u4f4d\u7f6e\u7684\u635f\u5931\uff0c\u8fd9\u5c31\u4f1a\u4f7f\u5f97\u6a21\u578b\u8fc7\u4e8e\u5173\u6ce8\u589e\u5927\u9884\u6d4b\u6b63\u786e\u6807\u7b7e\u7684\u6982\u7387\uff0c\u800c\u4e0d\u5173\u6ce8\u51cf \u5c11\u9884\u6d4b\u9519\u8bef\u6807\u7b7e\u7684\u6982\u7387\uff0c\u6700\u540e\u5bfc\u81f4\u7684\u7ed3\u679c\u662f\u6a21\u578b\u5728\u81ea\u5df1\u7684\u8bad\u7ec3\u96c6\u4e0a\u62df\u5408\u6548\u679c \u975e\u5e38\u826f\u597d\uff0c\u800c\u5728\u5176\u4ed6\u7684\u6d4b\u8bd5\u96c6\u7ed3\u679c\u8868\u73b0\u4e0d\u597d\uff0c\u5373\u8fc7\u62df\u5408\u3002 \u5e73\u6ed1\u8fc7\u540e\u7684\u6837\u672c\u4ea4\u53c9\u71b5\u635f\u5931\u5c31\u4e0d\u4ec5\u8003\u8651\u5230\u4e86\u8bad\u7ec3\u6837\u672c\u4e2d\u6b63\u786e\u7684\u6807\u7b7e\u4f4d\u7f6e (one-hot\u6807\u7b7e\u4e3a1\u7684\u4f4d\u7f6e)\u7684\u635f\u5931\uff0c\u4e5f\u7a0d\u5fae\u8003\u8651\u5230\u5176\u4ed6\u9519\u8bef\u6807\u7b7e\u4f4d\u7f6e(one- hot\u6807\u7b7e\u4e3a0\u7684\u4f4d\u7f6e)\u7684\u635f\u5931\uff0c\u5bfc\u81f4\u6700\u540e\u7684\u635f\u5931\u589e\u5927\uff0c\u5bfc\u81f4\u6a21\u578b\u7684\u5b66\u4e60\u80fd\u529b\u63d0 \u9ad8\uff0c\u5373\u8981\u4e0b\u964d\u5230\u539f\u6765\u7684\u635f\u5931\uff0c\u5c31\u5f97\u5b66\u4e60\u7684\u66f4\u597d\uff0c\u4e5f\u5c31\u662f\u8feb\u4f7f\u6a21\u578b\u5f80\u589e\u5927\u6b63\u786e \u5206\u7c7b\u6982\u7387\u5e76\u4e14\u540c\u65f6\u51cf\u5c0f\u9519\u8bef\u5206\u7c7b\u6982\u7387\u7684\u65b9\u5411\u524d\u8fdb\u3002 \u6765\u81ea\u4e8e\u8bba\u6587\uff1a\u8bba\u6587:Rethinking the Inception Architecture for ComputerVision \u6ce8\uff1a\u524d\u4e24\u5217\u7684\u6a21\u578b\u672a\u8fdb\u884c\u6807\u7b7e\u5e73\u6ed1\u5904\u7406\uff0c\u540e\u4e24 \u5217\u4f7f\u7528\u4e86\u6807\u7b7e\u5e73\u6ed1\u6280\u672f \u73b0\u8c61\uff1a\u53ef\u89c1\u6807\u7b7e\u5e73\u6ed1\u6280\u672f\u53ef\u4ee5\u4f7f\u5f97\u7f51\u7edc\u5012\u6570\u7b2c\u4e8c\u5c42\u6fc0\u6d3b\u51fd\u6570\u7684\u8868\u793a\u7684\u805a\u7c7b\u66f4\u52a0\u7d27\u5bc6\u3002 \u6807\u7b7e\u5e73\u6ed1\u63d0\u9ad8\u4e86\u6700\u7ec8\u7684\u7cbe\u5ea6 \u901a\u5e38\u7528\u4e8e\uff1a\u56fe\u7247\u5206\u7c7b\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u8bed\u97f3\u8bc6\u522b\u3002","title":"1\u3001\u6807\u7b7e\u5e73\u6ed1-Label Smoothing Regularization"},{"location":"tensorFlow/section9/#_5","text":"def smooth_labels ( y , smooth_factor = 0.1 ): assert len ( y . shape ) == 2 if 0 <= smooth_factor <= 1 : y *= 1 - smooth_factor y += smooth_factor / y . shape [ 1 ] else : raise Exception ( 'Invalid label smoothing factor: ' + str ( smooth_factor )) return y","title":"\u4ee3\u7801\u5b9e\u73b0"},{"location":"tensorFlow/section9/#2tfkerassequence","text":"\u9996\u5148\u4ecb\u7ecd\u4e00\u4e0bSequence\u4ee5\u53ca\u5176\u4ed6\u76f8\u5173\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u4e4b\u524d\u63a5\u89e6\u8fc7\u6709tf.data\u4ee5\u53catf.keras.preprocessing.image\u4e2d\u7684ImageDataGenerator\uff0c\u524d\u9762\u53ef\u4ee5\u6784\u9020\u81ea\u5b9a\u4e49\u6279\u6b21\u7b49\u7b49\uff0c\u540e\u8005\u63d0\u4f9b\u4e86\u9ed8\u8ba4\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5b9e\u73b0\u6279\u6b21\u6570\u636e\u8fed\u4ee3\u8fd4\u56de\u3002\u4f46\u662f\u5bf9\u4e8e\u5f88\u591a\u4efb\u52a1\u6765\u8bf4\u6211\u4eec\u9700\u8981\u505a\u66f4\u591a\u7684\u6709\u4e9b\u81ea\u5b9a\u4e49\u9884\u5904\u7406\uff0c\u5982\u6807\u7b7e\u5e73\u6ed1\uff0c\u968f\u673a\u64e6\u51fa\u7b49\u7b49\uff0c\u5728\u4e00\u4e2aAPI\u4e2d\u65e0\u6cd5\u5b8c\u5168\u5b9e\u73b0\uff0c\u73b0\u5728\u6211\u4eec\u4f1a\u4ecb\u7ecd\u4e00\u4e2a\u80fd\u5b9e\u73b0\u66f4\u81ea\u7531\u7684\u5404\u4e2a\u65f6\u95f4\u5185\u4fee\u6539\u6570\u636e\u96c6\u7684\u5de5\u5177Sequence tf.keras.utils.Sequence 1\u3001\u6bcf\u4e2a\u4eba\u90fd Sequence \u5fc5\u987b\u5b9e\u73b0 __getitem__ \u548c __len__ \u65b9\u6cd5\u3002\u5982\u679c\u60a8\u60f3\u5728\u5404\u4e2a\u65f6\u671f\u4e4b\u95f4\u4fee\u6539\u6570\u636e\u96c6\uff0c\u5219\u53ef\u4ee5\u5b9e\u73b0 on_epoch_end \u3002\u8be5\u65b9\u6cd5 __getitem__ \u5e94\u8fd4\u56de\u5b8c\u6574\u7684\u6279\u6b21\u3002\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u5176\u4ed6\u65b9\u6cd5\u4f9b\u4f7f\u7528 2\u3001\u7279\u70b9\uff1a Sequence \u662f\u8fdb\u884c\u591a\u5904\u7406\u7684\u66f4\u5b89\u5168\u65b9\u6cd5\u3002\u8fd9\u79cd\u7ed3\u6784\u4fdd\u8bc1\u4e86\u7f51\u7edc\u5728\u6bcf\u4e2a\u65f6\u95f4\u6bb5\u7684\u6bcf\u4e2a\u6837\u672c\u4e0a\u53ea\u4f1a\u8bad\u7ec3\u4e00\u6b21\uff0c\u800c\u751f\u6210\u5668\u5219\u4e0d\u4f1a\u3002 \u5b98\u7f51\u4f7f\u7528\u6848\u4f8b\uff1a from skimage.io import imread from skimage.transform import resize import numpy as np import math # Here, `x_set` is list of path to the images # and `y_set` are the associated classes. class CIFAR10Sequence ( Sequence ): def __init__ ( self , x_set , y_set , batch_size ): self . x , self . y = x_set , y_set self . batch_size = batch_size def __len__ ( self ): return math . ceil ( len ( self . x ) / self . batch_size ) def __getitem__ ( self , idx ): batch_x = self . x [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] batch_y = self . y [ idx * self . batch_size :( idx + 1 ) * self . batch_size ] return np . array ([ resize ( imread ( file_name ), ( 200 , 200 )) for file_name in batch_x ]), np . array ( batch_y )","title":"2\u3001tf.keras.Sequence\u7c7b\u5c01\u88c5\uff0c\u8fd4\u56de\u5e8f\u5217\u6570\u636e"},{"location":"tensorFlow/section9/#garbagedatasequence-sequence","text":"\u6784\u5efa\u4e86\u4e00\u4e2aGarbageDataSequence\u7c7b\u522b\uff0c \u7ee7\u627f\u57fa\u7c7bSequence class GarbageDataSequence ( Sequence ): \"\"\"\u6570\u636e\u6d41\u751f\u6210\u5668\uff0c\u6bcf\u6b21\u8fed\u4ee3\u8fd4\u56de\u4e00\u4e2abatch \u53ef\u76f4\u63a5\u7528\u4e8efit_generator\u7684generator\u53c2\u6570\uff0c\u80fd\u4fdd\u8bc1\u5728\u591a\u8fdb\u7a0b\u4e0b\u7684\u4e00\u4e2aepoch\u4e2d\u4e0d\u4f1a\u91cd\u590d\u53d6\u76f8\u540c\u7684\u6837\u672c \"\"\" def __init__ ( self , img_paths , labels , batch_size , img_size , use_aug ): # \u5f02\u5e38\u5224\u65ad self . x_y = np . hstack (( np . array ( img_paths ) . reshape ( len ( img_paths ), 1 ), np . array ( labels ))) self . batch_size = batch_size self . img_size = img_size self . alpha = 0.2 self . use_aug = use_aug self . eraser = get_random_eraser ( s_h = 0.3 , pixel_level = True ) def __len__ ( self ): return math . ceil ( len ( self . x_y ) / self . batch_size ) @staticmethod def center_img ( img , size = None , fill_value = 255 ): \"\"\"\u6539\u53d8\u56fe\u7247\u5c3a\u5bf8\u5230300x300\uff0c\u5e76\u4e14\u505a\u586b\u5145\u4f7f\u5f97\u56fe\u50cf\u5904\u4e8e\u4e2d\u95f4\u4f4d\u7f6e \"\"\" h , w = img . shape [: 2 ] if size is None : size = max ( h , w ) shape = ( size , size ) + img . shape [ 2 :] background = np . full ( shape , fill_value , np . uint8 ) center_x = ( size - w ) // 2 center_y = ( size - h ) // 2 background [ center_y : center_y + h , center_x : center_x + w ] = img return background def preprocess_img ( self , img_path ): \"\"\"\u56fe\u7247\u7684\u5904\u7406\u6d41\u7a0b\u51fd\u6570\uff0c\u6570\u636e\u589e\u5f3a\u3001center_img\u5904\u7406 \"\"\" # 1\u3001\u56fe\u50cf\u8bfb\u53d6\uff0c[180 , 200]-> \uff08200\uff09max(180, 200)->[300/200 * 180, 300/200 * 200] # \u8fd9\u6837\u505a\u4e3a\u4e86\u4e0d\u4f7f\u56fe\u5f62\u76f4\u63a5\u53d8\u5f62\uff0c\u540e\u7eed\u5728\u7edf\u4e00\u957f\u5bbd img = Image . open ( img_path ) resize_scale = self . img_size [ 0 ] / max ( img . size [: 2 ]) img = img . resize (( int ( img . size [ 0 ] * resize_scale ), int ( img . size [ 1 ] * resize_scale ))) img = img . convert ( 'RGB' ) img = np . array ( img ) # 2\u3001\u6570\u636e\u589e\u5f3a\uff1a\u5982\u679c\u662f\u8bad\u7ec3\u96c6\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u64cd\u4f5c # \u5148\u968f\u673a\u64e6\u9664\uff0c\u7136\u540e\u7ffb\u8f6c if self . use_aug : img = self . eraser ( img ) datagen = ImageDataGenerator ( width_shift_range = 0.05 , height_shift_range = 0.05 , horizontal_flip = True , vertical_flip = True , ) img = datagen . random_transform ( img ) # 3\u3001\u628a\u56fe\u7247\u5927\u5c0f\u8c03\u6574\u5230[300, 300, 3]\uff0c\u8c03\u6574\u7684\u65b9\u5f0f\u4e3a\u76f4\u63a5\u586b\u5145\u5c0f\u7684\u5750\u6807\u3002\u4e3a\u4e86\u6a21\u578b\u9700\u8981 img = self . center_img ( img , self . img_size [ 0 ]) return img def __getitem__ ( self , idx ): # 1\u3001\u5904\u7406\u56fe\u7247\u5927\u5c0f\u3001\u6570\u636e\u589e\u5f3a\u7b49\u8fc7\u7a0b print ( self . x_y ) batch_x = self . x_y [ idx * self . batch_size : ( idx + 1 ) * self . batch_size , 0 ] batch_y = self . x_y [ idx * self . batch_size : ( idx + 1 ) * self . batch_size , 1 :] batch_x = np . array ([ self . preprocess_img ( img_path ) for img_path in batch_x ]) batch_y = np . array ( batch_y ) . astype ( np . float32 ) # print(batch_y[1]) # 2\u3001mixup\u8fdb\u884c\u6784\u9020\u65b0\u7684\u6837\u672c\u5206\u5e03\u6570\u636e # batch_x, batch_y = self.mixup(batch_x, batch_y) # 3\u3001\u8f93\u5165\u6a21\u578b\u7684\u5f52\u4e00\u5316\u6570\u636e batch_x = self . preprocess_input ( batch_x ) return batch_x , batch_y def on_epoch_end ( self ): np . random . shuffle ( self . x_y ) def preprocess_input ( self , x ): \"\"\"\u5f52\u4e00\u5316\u5904\u7406\u6837\u672c\u7279\u5f81\u503c :param x: :return: \"\"\" assert x . ndim in ( 3 , 4 ) assert x . shape [ - 1 ] == 3 MEAN_RGB = [ 0.485 * 255 , 0.456 * 255 , 0.406 * 255 ] STDDEV_RGB = [ 0.229 * 255 , 0.224 * 255 , 0.225 * 255 ] x = x - np . array ( MEAN_RGB ) x = x / np . array ( STDDEV_RGB ) return x def mixup ( self , batch_x , batch_y ): \"\"\" \u6570\u636e\u6df7\u5408mixup :param batch_x: \u8981mixup\u7684batch_X :param batch_y: \u8981mixup\u7684batch_y :return: mixup\u540e\u7684\u6570\u636e \"\"\" size = self . batch_size l = np . random . beta ( self . alpha , self . alpha , size ) X_l = l . reshape ( size , 1 , 1 , 1 ) y_l = l . reshape ( size , 1 ) X1 = batch_x Y1 = batch_y X2 = batch_x [:: - 1 ] Y2 = batch_y [:: - 1 ] X = X1 * X_l + X2 * ( 1 - X_l ) Y = Y1 * y_l + Y2 * ( 1 - y_l ) return X , Y if __name__ == '__main__' : train_data_dir = '../data/garbage_classify/train_data' batch_size = 32 train_sequence , validation_sequence = data_from_sequence ( train_data_dir , batch_size , num_classes = 40 , input_size = 300 ) for i in range ( 100 ): print ( \"\u7b2c %d \u6279\u6b21\u6570\u636e\" % i ) batch_data , bacth_label = train_sequence . __getitem__ ( i ) print ( batch_data . shape , bacth_label . shape ) batch_data , bacth_label = validation_sequence . __getitem__ ( i )","title":"GarbageDataSequence-\u5783\u573e\u5206\u7c7b\u7684Sequence\u4ee3\u7801\u89e3\u6790"},{"location":"tensorFlow/section9/#1_7","text":"\u6784\u5efa\u4e86\u4e00\u5957\u590d\u6742\u4e14\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u6db5\u76d6\u51e0\u4f55\u53d8\u6362\u3001\u968f\u673a\u64e6\u9664\u3001Mixup\u7b56\u7565\u3002 \u7ec4\u5408\u7b56\u7565\u4ec5\u9700\u5c11\u91cf\u53c2\u6570\u8c03\u8282\u5373\u53ef\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u96c6\uff0c\u6548\u679c\u8d85\u8fc7\u8c37\u6b4c\u5728Imagenet\u4e0a\u641c\u7d22\u5f97\u5230\u7684Auto-augment\u7b56\u7565 \u66f4\u6709\u6548\u7684\u6355\u6349\u591a\u79cd\u5206\u8fa8\u7387\u3001\u591a\u5c3a\u5ea6\u3001\u591a\u7c92\u5ea6\u56fe\u7247\u7684\u8f6e\u5ed3\u3001\u7eb9 \u7406\u3001\u4f4d\u7f6e\u5206\u5e03\u7b49\u7279\u5f81","title":"\uff081\uff09\u6570\u636e\u589e\u5f3a\u9009\u62e9\u65b9\u6cd5"},{"location":"tensorFlow/section9/#1mixup-training","text":"Mixup\u662f\u4e00\u79cd\u975e\u5e38\u89c4\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e00\u4e2a\u548c\u6570\u636e\u65e0\u5173\u7684\u7b80\u5355\u6570\u636e\u589e\u5f3a\u539f\u5219\uff0c\u5176\u4ee5\u7ebf\u6027\u63d2\u503c\u7684\u65b9\u5f0f\u6765\u6784\u5efa\u65b0\u7684\u8bad\u7ec3\u6837\u672c\u548c\u6807\u7b7e\u3002 \u968f\u673a\u53d6\u4e24\u4e2a\u6837\u672c\uff0c\u901a\u8fc7\u52a0\u6743\u7ebf\u6027\u63d2\u503c\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u6837\u672c\u3002 \u65b0\u7684\u6837\u672c\u7684\u8f93\u5165\u548c\u771f\u5b9e\u6982\u7387\u5206\u5e03\u4e3a\uff1a \\hat{x} = \\lambda x_i + (1-\\lambda)x_j, \\hat{y} = \\lambda y_i + (1-\\lambda)y_j \\hat{x} = \\lambda x_i + (1-\\lambda)x_j, \\hat{y} = \\lambda y_i + (1-\\lambda)y_j mixup\u7b56\u7565\u5b9e\u73b0\uff0c\u5c01\u88c5\u5728 def mixup(self, batch_x, batch_y): \"\"\" \u6570\u636e\u6df7\u5408mixup :param batch_x: \u8981mixup\u7684batch_X :param batch_y: \u8981mixup\u7684batch_y :return: mixup\u540e\u7684\u6570\u636e \"\"\" size = self.batch_size l = np.random.beta(self.alpha, self.alpha, size) X_l = l.reshape(size, 1, 1, 1) y_l = l.reshape(size, 1) X1 = batch_x Y1 = batch_y X2 = batch_x[::-1] Y2 = batch_y[::-1] X = X1 * X_l + X2 * (1 - X_l) Y = Y1 * y_l + Y2 * (1 - y_l) return X, Y","title":"1\u3001\u6df7\u5408\u8bad\u7ec3\uff08Mixup Training\uff09"},{"location":"tensorFlow/section9/#2random-erasing","text":"\u8bad\u7ec3\u65f6\uff0c\u968f\u673a\u64e6\u9664\u65b9\u6cd5\u4f1a\u5728\u539f\u56fe\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u77e9 \u5f62\u533a\u57df\uff0c\u5c06\u8be5\u533a\u57df\u7684\u50cf\u7d20\u66ff\u6362\u4e3a\u968f\u673a\u503c\u3002\u8fd9\u4e2a\u8fc7 \u7a0b\u4e2d\uff0c\u53c2\u4e0e\u8bad\u7ec3\u7684\u56fe\u7247\u4f1a\u505a\u4e0d\u540c\u7a0b\u5ea6\u7684\u906e\u6321\uff0c\u8fd9 \u6837\u53ef\u4ee5\u964d\u4f4e\u8fc7\u62df\u5408\u7684\u98ce\u9669\u5e76\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002 \u968f\u673a\u64e6\u9664\u662f\u72ec\u7acb\u4e8e\u53c2\u6570\u5b66\u4e60\u8fc7\u7a0b\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u6574 \u5408\u5230\u4efb\u4f55\u57fa\u4e8eCNN\u7684\u8bc6\u522b\u6a21\u578b\u4e2d\u3002 \u5c01\u88c5\u5728random_eraser.py\u6587\u4ef6\u4e2d\u3002 import numpy as np import tensorflow as tf def get_random_eraser ( p = 0.5 , s_l = 0.02 , s_h = 0.4 , r_1 = 0.3 , r_2 = 1 / 0.3 , v_l = 0 , v_h = 255 , pixel_level = False ): def eraser ( input_img ): img_h , img_w , img_c = input_img . shape p_1 = np . random . rand () if p_1 > p : return input_img while True : s = np . random . uniform ( s_l , s_h ) * img_h * img_w r = np . random . uniform ( r_1 , r_2 ) w = int ( np . sqrt ( s / r )) h = int ( np . sqrt ( s * r )) left = np . random . randint ( 0 , img_w ) top = np . random . randint ( 0 , img_h ) if left + w <= img_w and top + h <= img_h : break if pixel_level : c = np . random . uniform ( v_l , v_h , ( h , w , img_c )) else : c = np . random . uniform ( v_l , v_h ) input_img [ top : top + h , left : left + w , :] = c return input_img return eraser \u6ce8\uff1a\u8fd9\u4e9b\u4ee3\u7801\u4e0d\u9700\u8981\u53bb\u5b9e\u73b0\uff0c\u6709\u5f88\u591a\u73b0\u6210\u5b9e\u73b0\u597d\u7684\u65b9\u6cd5","title":"2\u3001Random Erasing\u539f\u7406:"},{"location":"tensorFlow/section9/#3imagedatagenerator-","text":"\u5982\u4e0b\u4f7f\u7528\uff0c\u8fdb\u884c\u968f\u673a\u6c34\u5e73/\u5782\u76f4\u7ffb\u8f6c\u3002 datagen = ImageDataGenerator ( horizontal_flip = True , vertical_flip = True , ) \u6700\u540e\u5b9e\u73b0\u6d4b\u8bd5\u7ed3\u679c\uff1a ... \u7b2c 10 \u6279\u6b21\u6570\u636e ( 32 , 300 , 300 , 3 ) [[ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] ... [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ] [ 0.0025 0.0025 0.0025 ... 0.0025 0.0025 0.0025 ]]","title":"3\u3001ImageDataGenerator-\u63d0\u4f9b\u4e3b\u8981\u7ffb\u8f6c\u65b9\u6cd5"},{"location":"tensorFlow/section9/#495","text":"\u77e5\u9053\u5783\u573e\u5206\u7c7b\u76f8\u5173\u6bd4\u8d5b\u95ee\u9898 \u77e5\u9053\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u7684\u5e38\u89c1\u4f18\u5316(tricks) \u5e38\u7528\u5206\u7c7b\u95ee\u9898\u7684\u6570\u636e\u589e\u5f3a\u65b9\u5f0f mixup \u968f\u673a\u64e6\u9664 \u7ffb\u8f6c \u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316 \u5206\u7c7b\u5e38\u89c1\u6a21\u578b\u4ee5\u53ca\u6a21\u578b\u7b97\u6cd5\u4f18\u5316","title":"4.9.5 \u603b\u7ed3"}]}