


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>4.7 Tensorflow执行模式 - 深度学习与CV</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6e35a1a6.min.css">
      
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    <body dir="ltr">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#47-tensorflow" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="深度学习与CV" class="md-header-nav__button md-logo" aria-label="深度学习与CV">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            深度学习与CV
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              4.7 Tensorflow执行模式
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="深度学习与CV" class="md-nav__button md-logo" aria-label="深度学习与CV">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    深度学习与CV
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      课程介绍
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="课程介绍" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        课程介绍
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../introduction/section1/" title="深度学习" class="md-nav__link">
      深度学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../introduction/section2/" title="计算机视觉（CV）" class="md-nav__link">
      计算机视觉（CV）
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      tensorflow入门
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="tensorflow入门" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        tensorflow入门
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../section1/" title="tensorflow和keras简介" class="md-nav__link">
      tensorflow和keras简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../section2/" title="快速入门模型" class="md-nav__link">
      快速入门模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      深度神经网络
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="深度神经网络" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        深度神经网络
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section1/" title="神经网络简介" class="md-nav__link">
      神经网络简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section2/" title="常见的损失函数" class="md-nav__link">
      常见的损失函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section3/" title="深度学习的优化方法" class="md-nav__link">
      深度学习的优化方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section4/" title="深度学习的正则化" class="md-nav__link">
      深度学习的正则化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section5/" title="神经网络案例" class="md-nav__link">
      神经网络案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section6/" title="卷积神经网络CNN" class="md-nav__link">
      卷积神经网络CNN
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      图像分类
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="图像分类" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        图像分类
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section1/" title="图像分类简介" class="md-nav__link">
      图像分类简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section2/" title="AlexNet" class="md-nav__link">
      AlexNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section3/" title="VGG" class="md-nav__link">
      VGG
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section4/" title="GoogLeNet" class="md-nav__link">
      GoogLeNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section5/" title="ResNet" class="md-nav__link">
      ResNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section6/" title="图像增强方法" class="md-nav__link">
      图像增强方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section7/" title="模型微调" class="md-nav__link">
      模型微调
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      目标检测
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="目标检测" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        目标检测
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../objectdection/01.overview/" title="目标检测概述" class="md-nav__link">
      目标检测概述
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../objectdection/02.RCNN/" title="RCNN系列网络" class="md-nav__link">
      RCNN系列网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../objectdection/03.RCNN-demo/" title="Faster RCNN案例" class="md-nav__link">
      Faster RCNN案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../objectdection/04.yolo/" title="YOLO系列算法" class="md-nav__link">
      YOLO系列算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../objectdection/05.yolo-demo/" title="YOLOV3案例" class="md-nav__link">
      YOLOV3案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../objectdection/06.ssd/" title="SSD算法" class="md-nav__link">
      SSD算法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      目标分割
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="目标分割" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        目标分割
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section1/" title="目标分割介绍" class="md-nav__link">
      目标分割介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section2/" title="语义分割：FCN和UNet" class="md-nav__link">
      语义分割：FCN和UNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section3/" title="UNet案例" class="md-nav__link">
      UNet案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section4/" title="实例分割：Mask RCNN" class="md-nav__link">
      实例分割：Mask RCNN
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    学习目标
  </a>
  
    <nav class="md-nav" aria-label="学习目标">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#471-eager-executiongraph-execution" class="md-nav__link">
    4.7.1 Eager Execution与Graph Execution
  </a>
  
    <nav class="md-nav" aria-label="4.7.1 Eager Execution与Graph Execution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#4711-graph-execution" class="md-nav__link">
    4.7.1.1 Graph Execution（图模式）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4712-eager-execution" class="md-nav__link">
    4.7.1.2 Eager Execution（动态图模式）
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#472-tffunctiongraph-execution" class="md-nav__link">
    4.7.2 @tf.function实现Graph Execution 模式
  </a>
  
    <nav class="md-nav" aria-label="4.7.2 @tf.function实现Graph Execution 模式">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#4722-tffunction" class="md-nav__link">
    4.7.2.2 @tf.function 机制原理
  </a>
  
    <nav class="md-nav" aria-label="4.7.2.2 @tf.function 机制原理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1tffunction" class="md-nav__link">
    1、使用下面例子体现tf.function整个计算步骤：
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#printtfprint" class="md-nav__link">
    问题：如果打印字符串的print()替换成tf.print()，结果会是？
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#473-tfsession" class="md-nav__link">
    4.7.3 使用传统的 tf.Session（了解）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#474" class="md-nav__link">
    4.7.4 总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  
                
                
                <h1 id="47-tensorflow">4.7 Tensorflow执行模式<a class="headerlink" href="#47-tensorflow" title="Permanent link">&para;</a></h1>
<h2 id="_1">学习目标<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>目标</li>
<li>掌握tf的图执行模式原理与会话模式的区别</li>
<li>应用</li>
<li>无</li>
</ul>
<h3 id="471-eager-executiongraph-execution">4.7.1 Eager Execution与Graph Execution<a class="headerlink" href="#471-eager-executiongraph-execution" title="Permanent link">&para;</a></h3>
<h4 id="4711-graph-execution">4.7.1.1 Graph Execution（图模式）<a class="headerlink" href="#4711-graph-execution" title="Permanent link">&para;</a></h4>
<ul>
<li>特点:</li>
<li>预先定义计算图，运行时反复使用，不能改变</li>
<li>速度更快，适合大规模部署，适合嵌入式平台</li>
</ul>
<p>TensorFlow 的图执行模式是一个符号式的（基于计算图的）计算框架。简而言之，如果你需要进行一系列计算，则需要依次进行如下两步：</p>
<ul>
<li>
<p>1、建立一个 “计算图”，这个图描述了如何将输入数据通过一系列计算而得到输出；</p>
</li>
<li>
<p>2、建立一个会话，并在会话中与计算图进行交互，即向计算图传入计算所需的数据，并从计算图中获取结果。</p>
</li>
<li>Session 用来**给定 Graph 的输入，指定 Graph 中的结果获取方式， 并启动数据在 Graph 中的流动**</li>
<li>拥有并管理 Tensorflow 程序运行时的所有资源，资源包括:硬件(CPU,GPU)，数据</li>
</ul>
<p>使用计算图与会话进行基本运算，这里做一个最基本的运算示例。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow.compat.v1</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">disable_eager_execution</span><span class="p">()</span>

<span class="c1"># 1、定义了一个简单的“计算图”</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># 等价于 c = tf.add(a, b)，c是张量a和张量b通过 tf.add 这一操作（Operation）所形成的新张量</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>  

<span class="c1"># 2、# 实例化一个会话（Session）</span>
<span class="c1"># 通过会话的 run() 方法对计算图里的节点（张量）进行实际的计算</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>     
<span class="n">c_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">c_</span><span class="p">)</span>
</code></pre></div>

<p>注：为了使用图执行模式，需要使用 TensorFlow 1.X 的 API 进行操作，所以使用 <code>import tensorflow.compat.v1 as tf</code> 导入 TensorFlow，并通过 <code>tf.disable_eager_execution()</code> 禁用默认的即时执行模式。</p>
<h4 id="4712-eager-execution">4.7.1.2 Eager Execution（动态图模式）<a class="headerlink" href="#4712-eager-execution" title="Permanent link">&para;</a></h4>
<p>eager 模式是在 TF 1.4 版本之后引入的，在 TF 2.0之后将会把 eager 模式变为默认执行模式。TensorFlow 2.0 中的 Eager Execution 是一种命令式编程环境，可立即评估操作，无需构建图：操作会返回具体的值，而不是构建以后再运行的计算图。</p>
<p>Eager Execution 的优点如下：</p>
<ul>
<li>1、快速调试即刻的运行错误并通过 Python 工具进行整合</li>
<li>2、借助易于使用的 Python 控制流支持动态模型</li>
<li>3、为自定义和高阶梯度提供强大支持</li>
<li>4、适用于几乎所有可用的 TensorFlow 运算</li>
</ul>
<p>TensorFlow 2.0引入的eager提高了代码的简洁性，而且更容易debug。**但是对于性能来说，eager执行相比Graph模式会有一定的损失。毕竟原生的Graph模式是先构建好静态图，然后才真正执行。这对于 在分布式训练、性能优化和生产部署方面具有优势。**但是好在，TensorFlow 2.0引入了tf.function和AutoGraph来缩小eager执行和Graph模式的性能差距，其核心是将一系列的Python语法转化为高性能的graph操作。</p>
<div class="highlight"><pre><span></span><code>注：实际上，Eager Execution 在 1.x 的后期版本中也存在，但需要单独执行 tf.enable_eager_execution() 进行手动启用。
</code></pre></div>

<h3 id="472-tffunctiongraph-execution">4.7.2 @tf.function实现Graph Execution 模式<a class="headerlink" href="#472-tffunctiongraph-execution" title="Permanent link">&para;</a></h3>
<p>在 TensorFlow 2.0 中，推荐使用 @tf.function （而非 1.X 中的 tf.Session ）实现 Graph Execution，从而将模型转换为易于部署且高性能的 TensorFlow 图模型。只需要将我们希望以 Graph Execution 模式运行的代码封装在一个函数内，并在函数前加上 @tf.function 即可。</p>
<p>上面例子代码，可以通过基于 <code>tf.function</code> 的代码等价去执行图模式：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="nd">@tf.function</span>
<span class="k">def</span> <span class="nf">graph</span><span class="p">():</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 定义一个常量张量（Tensor）</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">c</span>

<span class="n">c_</span> <span class="o">=</span> <span class="n">graph</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">c_</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>

<ul>
<li>并不是任何函数都可以被 @tf.function 修饰！@tf.function 使用静态编译将函数内的代码转换成计算图，因此对函数内可使用的语句有一定限制，且需要函数内的操作本身能够被构建为计算图。</li>
<li>建议在函数内只使用TensorFlow 的原生操作，不要使用过于复杂的 Python 语句，函数参数只包括 TensorFlow 张量或 NumPy 数组，并最好是能够按照计算图的思想去构建函数。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="nd">@tf.function</span>
<span class="k">def</span> <span class="nf">train_one_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="c1"># 注意这里使用了TensorFlow内置的tf.print()</span>
        <span class="c1"># @tf.function不支持Python内置的print方法去当做计算节点</span>
        <span class="n">tf</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>  
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads_and_vars</span><span class="o">=</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">variables</span><span class="p">))</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">train_one_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>    
</code></pre></div>

<h4 id="4722-tffunction">4.7.2.2 @tf.function 机制原理<a class="headerlink" href="#4722-tffunction" title="Permanent link">&para;</a></h4>
<p>当被 @tf.function 修饰的函数第一次被调用的时候，进行以下操作：</p>
<ul>
<li>
<p>1、在 Eager Execution 模式关闭的环境下，函数内的代码依次运行。也就是说，每个 tf. 方法都只是定义了计算节点，而并没有进行任何实质的计算。这与 TensorFlow 1.X 的 Graph Execution 是一致的；</p>
</li>
<li>
<p>2、使用 AutoGraph 将函数中的 Python 控制流语句转换成 TensorFlow 计算图中的对应节点（比如说 while 和 for 语句转换为 tf.while ， if 语句转换为 tf.cond 等等；</p>
</li>
<li>
<p>3、基于上面的两步，建立函数内代码的计算图表示；然后运行一次这个计算图；</p>
</li>
<li>
<p>基于函数的名字和输入的函数参数的类型生成一个哈希值，并将建立的计算图缓存到一个哈希表中。</p>
</li>
<li>
<p>如果在被 @tf.function 修饰的函数之后再次被调用的时候，根据函数名和输入的函数参数的类型计算哈希值，检查哈希表中是否已经有了对应计算图的缓存。如果是，则直接使用已缓存的计算图，否则重新按上述步骤建立计算图。</p>
</li>
</ul>
<h5 id="1tffunction">1、使用下面例子体现tf.function整个计算步骤：<a class="headerlink" href="#1tffunction" title="Permanent link">&para;</a></h5>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="nd">@tf.function</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># 注意这里是print，不是tf.print</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;The function is running in Python&quot;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 运行过程</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">b_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">b_array</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="c1"># 对于Python的类型</span>
<span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p>上述程序的计算结果是？答案是:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Tensor类型</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">1</span>
<span class="mi">2</span>
<span class="mi">2</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mf">0.1</span>
<span class="mf">0.2</span>

<span class="c1"># Python类型</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">1</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">2</span>
<span class="mi">1</span>
</code></pre></div>

<p>当计算 f(a) 时，由于是第一次调用该函数，TensorFlow 进行了以下操作：</p>
<ul>
<li>
<p>1、将函数内的代码依次运行了一遍；</p>
</li>
<li>
<p>2、构建了计算图，然后运行了一次该计算图（因此输出了 1）。这里 tf.print(x) 可以作为计算图的节点，但 Python 内置的 print 则不能被转换成计算图的节点。</p>
</li>
<li>
<p>3、将该计算图缓存到了一个哈希表中（如果之后再有类型为 tf.int32 ，shape 为空的张量输入，则重复使用已构建的计算图）。</p>
</li>
</ul>
<p>接下来第二次计算之后</p>
<ul>
<li>
<p>一、计算 f(b) 时，由于 b 的类型与 a 相同，所以 TensorFlow 重复使用了之前已构建的计算图并运行（因此输出了 2）。这里由于并没有真正地逐行运行函数中的代码，所以函数第一行的文本输出代码没有运行。计算 f(b_array) 时，TensorFlow 自动将 numpy 的数据结构转换成了 TensorFlow 中的张量，因此依然能够复用之前已构建的计算图。</p>
</li>
<li>
<p>二、计算 f&copy; 时，虽然张量 c 的 shape 和 a 、 b 均相同，但类型为 tf.float32 ，因此 TensorFlow 重新运行了函数内代码（从而再次输出了文本）并建立了一个输入为 tf.float32 类型的计算图。</p>
</li>
<li>
<p>三、计算 f(d) 时，由于 d 和 c 的类型相同，所以 TensorFlow 复用了计算图，同理没有输出文本。</p>
</li>
</ul>
<h5 id="printtfprint">问题：如果打印字符串的print()替换成tf.print()，结果会是？<a class="headerlink" href="#printtfprint" title="Permanent link">&para;</a></h5>
<p>正常的按照顺序输出：</p>
<div class="highlight"><pre><span></span><code><span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">1</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">2</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">2</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mf">0.1</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mf">0.2</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">1</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">2</span>
<span class="n">The</span> <span class="n">function</span> <span class="ow">is</span> <span class="n">running</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="mi">1</span>
</code></pre></div>

<p>总结：之后的计算结果则显示出 @tf.function 对 Python 内置的整数和浮点数类型的处理方式。**只有当值完全一致的时候， @tf.function 才会复用之前建立的计算图，而并不会自动将 Python 内置的整数或浮点数等转换成张量。**一般而言，应当只在指定超参数等少数场合使用 Python 内置类型作为被 @tf.function 修饰的函数的参数。</p>
<h3 id="473-tfsession">4.7.3 使用传统的 tf.Session（了解）<a class="headerlink" href="#473-tfsession" title="Permanent link">&para;</a></h3>
<p>TensorFlow 2.0 提供了 tf.compat.v1 模块以支持 TensorFlow 1.X 版本的 API。同时，只要在编写模型的时候稍加注意，Keras 的模型是可以同时兼容 Eager Execution 模式和 Graph Execution 模式的。</p>
<p>例如，之前的MLP 或 CNN 模型去训练MNIST数据的代码如下：</p>
<div class="highlight"><pre><span></span><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">num_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">num_train_data</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_epochs</span><span class="p">)</span>
<span class="c1"># 1、建立计算图</span>
<span class="n">X_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_placeholder</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_placeholder</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">sparse_categorical_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>

<span class="c1"># 2、建立Session，并运行图计算</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
  <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
  <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="c1"># 使用Session.run()将数据送入计算图节点，进行训练以及计算损失函数</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">loss_value</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X_placeholder</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_placeholder</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;batch </span><span class="si">%d</span><span class="s2">: loss </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch_index</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">))</span>

    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">num_test_data</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
      <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span> <span class="o">=</span> <span class="n">batch_index</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span>
      <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">test_data</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span> <span class="n">end_index</span><span class="p">])</span>
<span class="c1"># 运行预测结果</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">sparse_categorical_accuracy</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">data_loader</span><span class="o">.</span><span class="n">test_label</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span> <span class="n">end_index</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">))</span>
      <span class="k">print</span><span class="p">(</span><span class="s2">&quot;test accuracy: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">sparse_categorical_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</code></pre></div>

<h3 id="474">4.7.4 总结<a class="headerlink" href="#474" title="Permanent link">&para;</a></h3>
<ul>
<li>tf的图执行模式原理与会话模式的区别</li>
<li>tf.function的作用和原理</li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>