


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>YOLO系列算法 - 深度学习与CV</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6e35a1a6.min.css">
      
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    <body dir="ltr">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#44yolo" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="深度学习与CV" class="md-header-nav__button md-logo" aria-label="深度学习与CV">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            深度学习与CV
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              YOLO系列算法
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="深度学习与CV" class="md-nav__button md-logo" aria-label="深度学习与CV">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    深度学习与CV
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      课程介绍
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="课程介绍" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        课程介绍
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../introduction/section1/" title="深度学习" class="md-nav__link">
      深度学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../introduction/section2/" title="计算机视觉（CV）" class="md-nav__link">
      计算机视觉（CV）
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      tensorflow入门
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="tensorflow入门" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        tensorflow入门
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../tensorFlow/section1/" title="tensorflow和keras简介" class="md-nav__link">
      tensorflow和keras简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../tensorFlow/section2/" title="快速入门模型" class="md-nav__link">
      快速入门模型
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      深度神经网络
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="深度神经网络" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        深度神经网络
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section1/" title="神经网络简介" class="md-nav__link">
      神经网络简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section2/" title="常见的损失函数" class="md-nav__link">
      常见的损失函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section3/" title="深度学习的优化方法" class="md-nav__link">
      深度学习的优化方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section4/" title="深度学习的正则化" class="md-nav__link">
      深度学习的正则化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section5/" title="神经网络案例" class="md-nav__link">
      神经网络案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deeplearning/section6/" title="卷积神经网络CNN" class="md-nav__link">
      卷积神经网络CNN
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      图像分类
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="图像分类" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        图像分类
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section1/" title="图像分类简介" class="md-nav__link">
      图像分类简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section2/" title="AlexNet" class="md-nav__link">
      AlexNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section3/" title="VGG" class="md-nav__link">
      VGG
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section4/" title="GoogLeNet" class="md-nav__link">
      GoogLeNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section5/" title="ResNet" class="md-nav__link">
      ResNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section6/" title="图像增强方法" class="md-nav__link">
      图像增强方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageClassification/section7/" title="模型微调" class="md-nav__link">
      模型微调
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      目标检测
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="目标检测" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        目标检测
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../01.overview/" title="目标检测概述" class="md-nav__link">
      目标检测概述
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../02.RCNN/" title="RCNN系列网络" class="md-nav__link">
      RCNN系列网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../03.RCNN-demo/" title="Faster RCNN案例" class="md-nav__link">
      Faster RCNN案例
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        YOLO系列算法
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="./" title="YOLO系列算法" class="md-nav__link md-nav__link--active">
      YOLO系列算法
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1yolo" class="md-nav__link">
    1.yolo算法
  </a>
  
    <nav class="md-nav" aria-label="1.yolo算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-yolo" class="md-nav__link">
    1.1 Yolo算法思想
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-yolo" class="md-nav__link">
    1.2 Yolo的网络结构
  </a>
  
    <nav class="md-nav" aria-label="1.2 Yolo的网络结构">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121" class="md-nav__link">
    1.2.1 网络输入
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122" class="md-nav__link">
    1.2.2 网络输出
  </a>
  
    <nav class="md-nav" aria-label="1.2.2 网络输出">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#17x7" class="md-nav__link">
    1.7x7网格
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#230" class="md-nav__link">
    2.30维向量
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13yolo" class="md-nav__link">
    1.3Yolo模型的训练
  </a>
  
    <nav class="md-nav" aria-label="1.3Yolo模型的训练">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131" class="md-nav__link">
    1.3.1训练样本的构建
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132" class="md-nav__link">
    1.3.2 损失函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133" class="md-nav__link">
    1.3.3 模型训练
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14" class="md-nav__link">
    1.4 模型预测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#15-yolo" class="md-nav__link">
    1.5 yolo总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2yolov2" class="md-nav__link">
    2.yoloV2
  </a>
  
    <nav class="md-nav" aria-label="2.yoloV2">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-better" class="md-nav__link">
    2.1 预测更准确（better）
  </a>
  
    <nav class="md-nav" aria-label="2.1 预测更准确（better）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#211-batch-normalization" class="md-nav__link">
    2.1.1 batch normalization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#212" class="md-nav__link">
    2.1.2 使用高分辨率图像微调分类模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#213-anchor-boxes" class="md-nav__link">
    2.1.3 采用Anchor Boxes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#224-anchor" class="md-nav__link">
    2.2.4 聚类提取anchor尺度
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#215" class="md-nav__link">
    2.1.5 边框位置的预测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#216" class="md-nav__link">
    2.1.6 细粒度特征融合
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#217" class="md-nav__link">
    2.1.7 多尺度训练
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-faster" class="md-nav__link">
    2.2 速度更快（Faster）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    2.3 识别对象更多
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3yolov3" class="md-nav__link">
    3.yoloV3
  </a>
  
    <nav class="md-nav" aria-label="3.yoloV3">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    3.1算法简介
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    3.2多尺度检测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    3.3网络模型结构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    3.4先验框
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-logistic" class="md-nav__link">
    3.5 logistic回归
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-yolov3" class="md-nav__link">
    3.6 yoloV3模型的输入与输出
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4yolov4" class="md-nav__link">
    4.yoloV4[了解]
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../05.yolo-demo/" title="YOLOV3案例" class="md-nav__link">
      YOLOV3案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../06.ssd/" title="SSD算法" class="md-nav__link">
      SSD算法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      目标分割
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="目标分割" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        目标分割
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section1/" title="目标分割介绍" class="md-nav__link">
      目标分割介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section2/" title="语义分割：FCN和UNet" class="md-nav__link">
      语义分割：FCN和UNet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section3/" title="UNet案例" class="md-nav__link">
      UNet案例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../imageSegmentation/section4/" title="实例分割：Mask RCNN" class="md-nav__link">
      实例分割：Mask RCNN
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1yolo" class="md-nav__link">
    1.yolo算法
  </a>
  
    <nav class="md-nav" aria-label="1.yolo算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-yolo" class="md-nav__link">
    1.1 Yolo算法思想
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-yolo" class="md-nav__link">
    1.2 Yolo的网络结构
  </a>
  
    <nav class="md-nav" aria-label="1.2 Yolo的网络结构">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121" class="md-nav__link">
    1.2.1 网络输入
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122" class="md-nav__link">
    1.2.2 网络输出
  </a>
  
    <nav class="md-nav" aria-label="1.2.2 网络输出">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#17x7" class="md-nav__link">
    1.7x7网格
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#230" class="md-nav__link">
    2.30维向量
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13yolo" class="md-nav__link">
    1.3Yolo模型的训练
  </a>
  
    <nav class="md-nav" aria-label="1.3Yolo模型的训练">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131" class="md-nav__link">
    1.3.1训练样本的构建
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132" class="md-nav__link">
    1.3.2 损失函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133" class="md-nav__link">
    1.3.3 模型训练
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14" class="md-nav__link">
    1.4 模型预测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#15-yolo" class="md-nav__link">
    1.5 yolo总结
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2yolov2" class="md-nav__link">
    2.yoloV2
  </a>
  
    <nav class="md-nav" aria-label="2.yoloV2">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-better" class="md-nav__link">
    2.1 预测更准确（better）
  </a>
  
    <nav class="md-nav" aria-label="2.1 预测更准确（better）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#211-batch-normalization" class="md-nav__link">
    2.1.1 batch normalization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#212" class="md-nav__link">
    2.1.2 使用高分辨率图像微调分类模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#213-anchor-boxes" class="md-nav__link">
    2.1.3 采用Anchor Boxes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#224-anchor" class="md-nav__link">
    2.2.4 聚类提取anchor尺度
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#215" class="md-nav__link">
    2.1.5 边框位置的预测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#216" class="md-nav__link">
    2.1.6 细粒度特征融合
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#217" class="md-nav__link">
    2.1.7 多尺度训练
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-faster" class="md-nav__link">
    2.2 速度更快（Faster）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    2.3 识别对象更多
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3yolov3" class="md-nav__link">
    3.yoloV3
  </a>
  
    <nav class="md-nav" aria-label="3.yoloV3">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    3.1算法简介
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    3.2多尺度检测
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    3.3网络模型结构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    3.4先验框
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-logistic" class="md-nav__link">
    3.5 logistic回归
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-yolov3" class="md-nav__link">
    3.6 yoloV3模型的输入与输出
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4yolov4" class="md-nav__link">
    4.yoloV4[了解]
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  
                
                
                <h1 id="44yolo">4.4.yolo系列<a class="headerlink" href="#44yolo" title="Permanent link">&para;</a></h1>
<p><strong>学习目标</strong></p>
<ul>
<li>知道yolo网络架构，理解其输入输出</li>
<li>知道yolo模型的训练样本构建的方法</li>
<li>理解yolo模型的损失函数</li>
<li>
<p>知道yoloV2模型的改进方法</p>
</li>
<li>
<p>知道yoloV3的多尺度检测方法</p>
</li>
<li>知道yoloV3模型的网络结构及网络输出</li>
<li>了解yoloV3模型先验框设计的方法</li>
<li>知道yoloV3模型为什么适用于多标签的目标分类</li>
<li>了解yoloV4模型</li>
</ul>
<hr />
<p><img alt="image-20200915142921616" src="../assets/image-20200915142921616.png" /></p>
<p>YOLO系列算法是一类典型的one-stage目标检测算法，其利用anchor box将分类与目标定位的回归问题结合起来，从而做到了高效、灵活和泛化性能好，所以在工业界也十分受欢迎，接下来我们介绍YOLO 系列算法。</p>
<h2 id="1yolo">1.yolo算法<a class="headerlink" href="#1yolo" title="Permanent link">&para;</a></h2>
<p>Yolo算法采用一个单独的CNN模型实现end-to-end的目标检测，核心思想就是利用整张图作为网络的输入，直接在输出层回归 bounding box（边界框） 的位置及其所属的类别，整个系统如下图所示：</p>
<p><img alt="image-20200915144129736" src="../assets/image-20200915144129736.png" /></p>
<p>首先将输入图片resize到448x448，然后送入CNN网络，最后处理网络预测结果得到检测的目标。相比R-CNN算法，其是一个统一的框架，其速度更快。</p>
<h3 id="11-yolo">1.1 Yolo算法思想<a class="headerlink" href="#11-yolo" title="Permanent link">&para;</a></h3>
<p>在介绍Yolo算法之前，我们回忆下RCNN模型，RCNN模型提出了候选区(Region Proposals)的方法，先从图片中搜索出一些可能存在对象的候选区（Selective Search），大概2000个左右，然后对每个候选区进行对象识别，但处理速度较慢。</p>
<p><img alt="image-20200915150333995" src="../assets/image-20200915150333995.png" /></p>
<p>Yolo意思是You Only Look Once，它并没有真正的去掉候选区域，而是创造性的将候选区和目标分类合二为一，看一眼图片就能知道有哪些对象以及它们的位置。</p>
<p>Yolo模型采用预定义预测区域的方法来完成目标检测，具体而言是将原始图像划分为 7x7=49 个网格（grid），每个网格允许预测出2个边框（bounding box，包含某个对象的矩形框），总共 49x2=98 个bounding box。我们将其理解为98个预测区，很粗略的覆盖了图片的整个区域，就在这98个预测区中进行目标检测。</p>
<p><img alt="image-20200915150718666" src="../assets/image-20200915150718666.png" /></p>
<p>只要得到这98个区域的目标分类和回归结果，再进行NMS就可以得到最终的目标检测结果。那具体要怎样实现呢？</p>
<h3 id="12-yolo">1.2 Yolo的网络结构<a class="headerlink" href="#12-yolo" title="Permanent link">&para;</a></h3>
<p>YOLO的结构非常简单，就是单纯的卷积、池化最后加了两层全连接，从网络结构上看，与前面介绍的CNN分类网络没有本质的区别，最大的差异是输出层用线性函数做激活函数，因为需要预测bounding box的位置（数值型），而不仅仅是对象的概率。所以粗略来说，YOLO的整个结构就是输入图片经过神经网络的变换得到一个输出的张量，如下图所示：</p>
<p><img alt="image-20200915151948836" src="../assets/image-20200915151948836.png" /></p>
<p>网络结构比较简单，重点是我们要理解网络输入与输出之间的关系。</p>
<h4 id="121">1.2.1 网络输入<a class="headerlink" href="#121" title="Permanent link">&para;</a></h4>
<p>网络的输入是原始图像，唯一的要求是缩放到448x448的大小。主要是因为Yolo的网络中，卷积层最后接了两个全连接层，全连接层是要求固定大小的向量作为输入，所以Yolo的输入图像的大小固定为448x448。</p>
<h4 id="122">1.2.2 网络输出<a class="headerlink" href="#122" title="Permanent link">&para;</a></h4>
<p>网络的输出就是一个7x7x30 的张量（tensor）。那这个输出结果我们要怎么理解那？</p>
<h5 id="17x7">1.7x7网格<a class="headerlink" href="#17x7" title="Permanent link">&para;</a></h5>
<p>根据YOLO的设计，输入图像被划分为 7x7 的网格（grid），输出张量中的 7x7 就对应着输入图像的 7x7 网格。或者我们把 7x7x30 的张量看作 7x7=49个30维的向量，也就是输入图像中的每个网格对应输出一个30维的向量。如下图所示，比如输入图像左上角的网格对应到输出张量中左上角的向量。</p>
<p><img alt="image-20200915152825629" src="../assets/image-20200915152825629.png" /></p>
<h5 id="230">2.30维向量<a class="headerlink" href="#230" title="Permanent link">&para;</a></h5>
<p>30维的向量包含：2个bbox的位置和置信度以及该网格属于20个类别的概率</p>
<p><img alt="image-20200915153123684" src="../assets/image-20200915153123684.png" /></p>
<ul>
<li>
<p><strong>2个bounding box的位置</strong>
   每个bounding box需要4个数值来表示其位置，(Center_x,Center_y,width,height)，即(bounding box的中心点的x坐标，y坐标，bounding box的宽度，高度)，2个bounding box共需要8个数值来表示其位置。</p>
</li>
<li>
<p><strong>2个bounding box的置信度</strong> bounding box的置信度 = 该bounding box内存在对象的概率 * 该bounding box与该对象实际bounding box的IOU，用公式表示就是：</p>
</li>
</ul>
<p><img alt="image-20200915153543735" src="../assets/image-20200915153543735.png" /></p>
<p>Pr(Object)是bounding box内存在对象的概率</p>
<ul>
<li><strong>20个对象分类的概率</strong></li>
</ul>
<p>Yolo支持识别20种不同的对象（人、鸟、猫、汽车、椅子等），所以这里有20个值表示该网格位置存在任一种对象的概率.</p>
<h3 id="13yolo">1.3Yolo模型的训练<a class="headerlink" href="#13yolo" title="Permanent link">&para;</a></h3>
<p>在进行模型训练时，我们需要构造训练样本和设计损失函数，才能利用梯度下降对网络进行训练。</p>
<h4 id="131">1.3.1训练样本的构建<a class="headerlink" href="#131" title="Permanent link">&para;</a></h4>
<p>将一幅图片输入到yolo模型中，对应的输出是一个7x7x30张量，构建标签label时对于原图像中的每一个网格grid都需要构建一个30维的向量。对照下图我们来构建目标向量：</p>
<p><img alt="image-20200915155204485" src="../assets/image-20200915155204485.png" /></p>
<ul>
<li><strong>20个对象分类的概率</strong></li>
</ul>
<p>对于输入图像中的每个对象，先找到其中心点。比如上图中自行车，其中心点在黄色圆点位置，中心点落在黄色网格内，所以这个黄色网格对应的30维向量中，自行车的概率是1，其它对象的概率是0。所有其它48个网格的30维向量中，该自行车的概率都是0。这就是所谓的"中心点所在的网格对预测该对象负责"。狗和汽车的分类概率也是同样的方法填写</p>
<ul>
<li><strong>2个bounding box的位置</strong></li>
</ul>
<p>训练样本的bbox位置应该填写对象真实的位置bbox，但一个对象对应了2个bounding box，该填哪一个呢？需要根据网络输出的bbox与对象实际bbox的IOU来选择，所以要在训练过程中动态决定到底填哪一个bbox。</p>
<ul>
<li><strong>2个bounding box的置信度</strong></li>
</ul>
<p>预测置信度的公式为：</p>
<p><img alt="image-20200915155812745" src="../assets/image-20200915155812745.png" /></p>
<p><span><span class="MathJax_Preview">IOU_{pred}^{truth}</span><script type="math/tex">IOU_{pred}^{truth}</script></span>利用网络输出的2个bounding box与对象真实bounding box计算出来。然后看这2个bounding box的IOU，哪个比较大，就由哪个bounding box来负责预测该对象是否存在，即该bounding box的Pr(Object)=1，同时对象真实bounding box的位置也就填入该bounding box。另一个不负责预测的bounding box的Pr(Object)=0。</p>
<p>上图中自行车所在的grid对应的结果如下图所示：</p>
<p><img alt="image-20200915160053996" src="../assets/image-20200915160053996.png" /></p>
<h4 id="132">1.3.2 损失函数<a class="headerlink" href="#132" title="Permanent link">&para;</a></h4>
<p>损失就是网络实际输出值与样本标签值之间的偏差：</p>
<p><img alt="image-20200915160218266" src="../assets/image-20200915160218266.png" /></p>
<p>yolo给出的损失函数：</p>
<p><img alt="image-20200915160632201" src="../assets/image-20200915160632201.png" /></p>
<p>注：其中<span><span class="MathJax_Preview">1_{i}^{obj}</span><script type="math/tex">1_{i}^{obj}</script></span>表示目标是否出现在网格单元i中，<span><span class="MathJax_Preview">1_{ij}^{obj}</span><script type="math/tex">1_{ij}^{obj}</script></span>表示单元格i中的第j个边界框预测器负责该预测，YOLO设置  <span><span class="MathJax_Preview">\lambda_{coord} = 5</span><script type="math/tex">\lambda_{coord} = 5</script></span> 来调高位置误差的权重， <span><span class="MathJax_Preview">\lambda_{noobj} = 0.5</span><script type="math/tex">\lambda_{noobj} = 0.5</script></span> 即调低不存在对象的bounding box的置信度误差的权重。</p>
<p><img alt="image-20200915160850102" src="../assets/image-20200915160850102.png" /></p>
<h4 id="133">1.3.3 模型训练<a class="headerlink" href="#133" title="Permanent link">&para;</a></h4>
<p>Yolo先使用ImageNet数据集对前20层卷积网络进行预训练，然后使用完整的网络，在PASCAL VOC数据集上进行对象识别和定位的训练。</p>
<p>Yolo的最后一层采用线性激活函数，其它层都是Leaky ReLU。训练中采用了drop out和数据增强（data augmentation）来防止过拟合.</p>
<h3 id="14">1.4 模型预测<a class="headerlink" href="#14" title="Permanent link">&para;</a></h3>
<p>将图片resize成448x448的大小，送入到yolo网络中，输出一个 7x7x30 的张量（tensor）来表示图片中所有网格包含的对象（概率）以及该对象可能的2个位置（bounding box）和可信程度（置信度）。在采用NMS（Non-maximal suppression，非极大值抑制）算法选出最有可能是目标的结果。</p>
<h3 id="15-yolo">1.5 yolo总结<a class="headerlink" href="#15-yolo" title="Permanent link">&para;</a></h3>
<p><strong>优点</strong></p>
<ul>
<li>速度非常快，处理速度可以达到45fps，其快速版本（网络较小）甚至可以达到155fps。</li>
<li>训练和预测可以端到端的进行，非常简便。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>准确率会打折扣</li>
<li>对于小目标和靠的很近的目标检测效果并不好</li>
</ul>
<h2 id="2yolov2">2.yoloV2<a class="headerlink" href="#2yolov2" title="Permanent link">&para;</a></h2>
<p>YOLOv2相对v1版本，在继续保持处理速度的基础上，从预测更准确（Better），速度更快（Faster），识别对象更多（Stronger）这三个方面进行了改进。其中识别更多对象也就是扩展到能够检测9000种不同对象，称之为YOLO9000。 下面我们看下yoloV2的都做了哪些改进？</p>
<h3 id="21-better">2.1 预测更准确（better）<a class="headerlink" href="#21-better" title="Permanent link">&para;</a></h3>
<p><img alt="image-20200915164503590" src="../assets/image-20200915164503590.png" /></p>
<h4 id="211-batch-normalization">2.1.1 batch normalization<a class="headerlink" href="#211-batch-normalization" title="Permanent link">&para;</a></h4>
<p>批标准化有助于解决反向传播过程中的梯度消失和梯度爆炸问题，降低对一些超参数的敏感性，并且每个batch分别进行归一化的时候，起到了一定的正则化效果，从而能够获得更好的收敛速度和收敛效果。在yoloV2中卷积后全部加入Batch Normalization，网络会提升2%的mAP。</p>
<h4 id="212">2.1.2 使用高分辨率图像微调分类模型<a class="headerlink" href="#212" title="Permanent link">&para;</a></h4>
<p>YOLO v1使用ImageNet的图像分类样本采用 224x224 作为输入，来训练CNN卷积层。然后在训练对象检测时，检测用的图像样本采用更高分辨率的 448x448 的图像作为输入。但这样切换对模型性能有一定影响。</p>
<p><img alt="image-20200915165005595" src="../assets/image-20200915165005595.png" /></p>
<p>YOLOV2在采用 224x224 图像进行分类模型预训练后，再采用 448x448 的高分辨率样本对分类模型进行微调（10个epoch），使网络特征逐渐适应 448x448 的分辨率。然后再使用 448x448 的检测样本进行训练，缓解了分辨率突然切换造成的影响。</p>
<p><img alt="image-20200915165015860" src="../assets/image-20200915165015860.png" /></p>
<p>使用该技巧后网络的mAP提升了约4%。</p>
<h4 id="213-anchor-boxes">2.1.3 采用Anchor Boxes<a class="headerlink" href="#213-anchor-boxes" title="Permanent link">&para;</a></h4>
<p>YOLO1并没有采用先验框，并且每个grid只预测两个bounding box，整个图像98个。YOLO2如果每个grid采用5个先验框，总共有13x13x5=845个先验框。通过引入anchor boxes，使得预测的box数量更多（13x13xn）。</p>
<h4 id="224-anchor">2.2.4 聚类提取anchor尺度<a class="headerlink" href="#224-anchor" title="Permanent link">&para;</a></h4>
<p>Faster-rcnn选择的anchor比例都是手动指定的，但是不一定完全适合数据集。YOLO2尝试统计出更符合样本中对象尺寸的先验框，这样就可以减少网络微调先验框到实际位置的难度。YOLO2的做法是对训练集中标注的边框进行聚类分析，以寻找尽可能匹配样本的边框尺寸。</p>
<p><img alt="image-20200915165616802" src="../assets/image-20200915165616802.png" /></p>
<p>YoloV2选择了聚类的五种尺寸最为anchor box。</p>
<h4 id="215">2.1.5 边框位置的预测<a class="headerlink" href="#215" title="Permanent link">&para;</a></h4>
<p>Yolov2中将边框的结果约束在特定的网格中：</p>
<p><img alt="image-20200915171150105" src="../assets/image-20200915171150105.png" /></p>
<p>其中，</p>
<p><span><span class="MathJax_Preview">b_x,b_y,b_w,b_h</span><script type="math/tex">b_x,b_y,b_w,b_h</script></span>是预测边框的中心和宽高。
 <span><span class="MathJax_Preview">Pr(object)∗IOU(b,object)</span><script type="math/tex">Pr(object)∗IOU(b,object)</script></span>是预测边框的置信度，YOLO1是直接预测置信度的值，这里对预测参数<span><span class="MathJax_Preview">t_o</span><script type="math/tex">t_o</script></span>进行σ变换后作为置信度的值。
 <span><span class="MathJax_Preview">c_x,c_y</span><script type="math/tex">c_x,c_y</script></span>是当前网格左上角到图像左上角的距离，要先将网格大小归一化，即令一个网格的宽=1，高=1。
 <span><span class="MathJax_Preview">p_w,p_h</span><script type="math/tex">p_w,p_h</script></span>是先验框的宽和高。
 σ是sigmoid函数。
 <span><span class="MathJax_Preview">t_x,t_y,t_w,t_h,t_o</span><script type="math/tex">t_x,t_y,t_w,t_h,t_o</script></span>是要学习的参数，分别用于预测边框的中心和宽高，以及置信度。</p>
<p>如下图所示：</p>
<p><img alt="image-20200915171632888" src="../assets/image-20200915171632888.png" /></p>
<p>由于σ函数将 <span><span class="MathJax_Preview">t_x,t_y</span><script type="math/tex">t_x,t_y</script></span>约束在(0,1)范围内，预测边框的蓝色中心点被约束在蓝色背景的网格内。约束边框位置使得模型更容易学习，且预测更为稳定。</p>
<p>假设网络预测值为：</p>
<p><img alt="image-20200915171823875" src="../assets/image-20200915171823875.png" /></p>
<p>anchor框为：</p>
<p><img alt="image-20200915171844683" src="../assets/image-20200915171844683.png" /></p>
<p>则目标在特征图中的位置：</p>
<p><img alt="image-20200915171906489" src="../assets/image-20200915171906489.png" /></p>
<p>在原图像中的位置：</p>
<p><img alt="image-20200915171925122" src="../assets/image-20200915171925122.png" /></p>
<h4 id="216">2.1.6 细粒度特征融合<a class="headerlink" href="#216" title="Permanent link">&para;</a></h4>
<p>图像中对象会有大有小，输入图像经过多层网络提取特征，最后输出的特征图中，较小的对象可能特征已经不明显甚至被忽略掉了。为了更好的检测出一些比较小的对象，最后输出的特征图需要保留一些更细节的信息。</p>
<p>YOLO2引入一种称为passthrough层的方法在特征图中保留一些细节信息。具体来说，就是在最后一个pooling之前，特征图的大小是26x26x512，将其1拆4，直接传递（passthrough）到pooling后（并且又经过一组卷积）的特征图，两者叠加到一起作为输出的特征图。</p>
<p><img alt="image-20200915172541517" src="../assets/image-20200915172541517.png" /></p>
<p>具体的拆分方法如下所示：</p>
<p><img alt="image-20200915172504922" src="../assets/image-20200915172504922.png" /></p>
<h4 id="217">2.1.7 多尺度训练<a class="headerlink" href="#217" title="Permanent link">&para;</a></h4>
<p>YOLO2中没有全连接层，可以输入任何尺寸的图像。因为整个网络下采样倍数是32，采用了{320,352,...,608}等10种输入图像的尺寸，这些尺寸的输入图像对应输出的特征图宽和高是{10,11,...19}。训练时每10个batch就随机更换一种尺寸，使网络能够适应各种大小的对象检测。</p>
<p><img alt="image-20200915172724192" src="../assets/image-20200915172724192.png" /></p>
<h3 id="22-faster">2.2 速度更快（Faster）<a class="headerlink" href="#22-faster" title="Permanent link">&para;</a></h3>
<p>yoloV2提出了Darknet-19（有19个卷积层和5个MaxPooling层）网络结构作为特征提取网络。DarkNet-19比VGG-16小一些，精度不弱于VGG-16，但浮点运算量减少到约&#8533;，以保证更快的运算速度。</p>
<p><img alt="image-20200915173047956" src="../assets/image-20200915173047956.png" /></p>
<p>yoloV2的网络中只有卷积+pooling，从416x416x3 变换到 13x13x5x25。增加了batch normalization，增加了一个passthrough层，去掉了全连接层，以及采用了5个先验框,网络的输出如下图所示：</p>
<p><img alt="image-20200915173440874" src="../assets/image-20200915173440874.png" /></p>
<h3 id="23">2.3 识别对象更多<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<p>VOC数据集可以检测20种对象，但实际上对象的种类非常多，只是缺少相应的用于对象检测的训练样本。YOLO2尝试利用ImageNet非常大量的分类样本，联合COCO的对象检测数据集一起训练，使得YOLO2即使没有学过很多对象的检测样本，也能检测出这些对象。</p>
<h2 id="3yolov3">3.yoloV3<a class="headerlink" href="#3yolov3" title="Permanent link">&para;</a></h2>
<p>yoloV3以V1，V2为基础进行的改进，主要有：利用多尺度特征进行目标检测；先验框更丰富；调整了网络结构；对象分类使用logistic代替了softmax,更适用于多标签分类任务。</p>
<h3 id="31">3.1算法简介<a class="headerlink" href="#31" title="Permanent link">&para;</a></h3>
<p>YOLOv3是YOLO (You Only Look Once)系列目标检测算法中的第三版，相比之前的算法，尤其是针对小目标，精度有显著提升。</p>
<p><img alt="image-20200502103836394" src="../assets/image-20200502103836394.png" /></p>
<p>yoloV3的流程如下图所示，对于每一幅输入图像，YOLOv3会预测三个不同尺度的输出，目的是检测出不同大小的目标。</p>
<p><img alt="image-20200502104048380" src="../assets/image-20200502104048380.png" /></p>
<h3 id="32">3.2多尺度检测<a class="headerlink" href="#32" title="Permanent link">&para;</a></h3>
<p>通常一幅图像包含各种不同的物体，并且有大有小。比较理想的是一次就可以将所有大小的物体同时检测出来。因此，网络必须具备能够“看到”不同大小的物体的能力。因为网络越深，特征图就会越小，所以网络越深小的物体也就越难检测出来。</p>
<p>在实际的feature map中，随着网络深度的加深，浅层的feature map中主要包含低级的信息（物体边缘，颜色，初级位置信息等），深层的feature map中包含高等信息（例如物体的语义信息：狗，猫，汽车等等）。因此在不同级别的feature map对应不同的scale，所以我们可以在不同级别的特征图中进行目标检测。如下图展示了多种scale变换的经典方法。</p>
<p><img alt="image-20200502104855459" src="../assets/image-20200502104855459.png" /></p>
<p>(a) 这种方法首先建立图像金字塔，不同尺度的金字塔图像被输入到对应的网络当中，用于不同scale物体的检测。但这样做的结果就是每个级别的金字塔都需要进行一次处理，速度很慢。</p>
<p>(b) 检测只在最后一层feature map阶段进行，这个结构无法检测不同大小的物体</p>
<p>&copy; 对不同深度的feature map分别进行目标检测。SSD中采用的便是这样的结构。这样小的物体会在浅层的feature map中被检测出来，而大的物体会在深层的feature map被检测出来，从而达到对应不同scale的物体的目的，缺点是每一个feature map获得的信息仅来源于之前的层，之后的层的特征信息无法获取并加以利用。</p>
<p>(d) 与&copy;很接近，但不同的是，当前层的feature map会对未来层的feature map进行上采样，并加以利用。因为有了这样一个结构，当前的feature map就可以获得“未来”层的信息，这样的话低阶特征与高阶特征就有机融合起来了，提升检测精度。在YOLOv3中，就是采用这种方式来实现目标多尺度的变换的。</p>
<h3 id="33">3.3网络模型结构<a class="headerlink" href="#33" title="Permanent link">&para;</a></h3>
<p>在基本的图像特征提取方面，YOLO3采用了Darknet-53的网络结构（含有53个卷积层），它借鉴了残差网络ResNet的做法，在层之间设置了shortcut，来解决深层网络梯度的问题，shortcut如下图所示：包含两个卷积层和一个shortcut connections。</p>
<p><img alt="image-20200502110956252" src="../assets/image-20200502110956252.png" /></p>
<p>yoloV3的模型结构如下所示：整个v3结构里面，没有池化层和全连接层，网络的下采样是通过设置卷积的stride为2来达到的，每当通过这个卷积层之后图像的尺寸就会减小到一半。</p>
<p><img alt="image-20200915175032596" src="../assets/image-20200915175032596.png" /></p>
<p>下面我们看下网络结构：</p>
<ul>
<li>基本组件：蓝色方框内部分</li>
</ul>
<p>1、CBL：Yolov3网络结构中的最小组件，由Conv+Bn+Leaky_relu激活函数三者组成。
  2、Res unit：借鉴Resnet网络中的残差结构，让网络可以构建的更深。
  3、ResX：由一个CBL和X个残差组件构成，是Yolov3中的大组件。每个Res模块前面的CBL都起到下采样的作用，因此经过5次Res模块后，得到的特征图是608-&gt;304-&gt;152-&gt;76-&gt;38-&gt;19大小。</p>
<ul>
<li>其他基础操作：</li>
</ul>
<p>1、Concat：张量拼接，会扩充两个张量的维度，例如26×26×256和26×26×512两个张量拼接，结果是26×26×768。</p>
<p>2、Add：张量相加，张量直接相加，不会扩充维度，例如104×104×128和104×104×128相加，结果还是104×104×128。</p>
<ul>
<li>Backbone中卷积层的数量：</li>
</ul>
<p>每个ResX中包含1+2×X个卷积层，因此整个主干网络Backbone中一共包含1+（1+2×1）+（1+2×2）+（1+2×8）+（1+2×8）+（1+2×4）=52，再加上一个FC全连接层，即可以组成一个Darknet53分类网络。不过在目标检测Yolov3中，去掉FC层，仍然把Yolov3的主干网络叫做Darknet53结构。</p>
<h3 id="34">3.4先验框<a class="headerlink" href="#34" title="Permanent link">&para;</a></h3>
<p>yoloV3采用K-means聚类得到先验框的尺寸，为每种尺度设定3种先验框，总共聚类出9种尺寸的先验框。</p>
<p><img alt="image-20200502103458654" src="../assets/image-20200502103458654.png" /></p>
<p>在COCO数据集这9个先验框是：(10x13)，(16x30)，(33x23)，(30x61)，(62x45)，(59x119)，(116x90)，(156x198)，(373x326)。在最小的(13x13)特征图上（有最大的感受野）应用较大的先验框(116x90)，(156x198)，(373x326)，适合检测较大的对象。中等的(26x26)特征图上（中等感受野）应用中等的先验框(30x61)，(62x45)，(59x119)，适合检测中等大小的对象。较大的(52x52)特征图上（较小的感受野）应用,其中较小的先验框(10x13)，(16x30)，(33x23)，适合检测较小的对象。</p>
<p>直观上感受9种先验框的尺寸，下图中蓝色框为聚类得到的先验框。黄色框式ground truth，红框是对象中心点所在的网格。</p>
<p><img alt="image-20200502103442569" src="../assets/image-20200502103442569.png" /></p>
<h3 id="35-logistic">3.5 logistic回归<a class="headerlink" href="#35-logistic" title="Permanent link">&para;</a></h3>
<p>预测对象类别时不使用softmax，而是被替换为一个1x1的卷积层+logistic激活函数的结构。使用softmax层的时候其实已经假设每个输出仅对应某一个单个的class，但是在某些class存在重叠情况（例如woman和person）的数据集中，使用softmax就不能使网络对数据进行很好的预测。</p>
<p><img alt="image-20200502112750112" src="../assets/image-20200502112750112.png" /></p>
<h3 id="36-yolov3">3.6 yoloV3模型的输入与输出<a class="headerlink" href="#36-yolov3" title="Permanent link">&para;</a></h3>
<p>YoloV3的输入输出形式如下图所示：
<img alt="image-20200502111721372" src="../assets/image-20200502111721372.png" /></p>
<p>输入416×416×3的图像，通过darknet网络得到三种不同尺度的预测结果，每个尺度都对应N个通道，包含着预测的信息；</p>
<p>每个网格每个尺寸的anchors的预测结果。</p>
<p>YOLOv3共有13×13×3 + 26×26×3  + 52×52×3个预测 。每个预测对应85维，分别是4（坐标值）、1（置信度分数）、80（coco类别概率）。</p>
<h2 id="4yolov4">4.yoloV4[了解]<a class="headerlink" href="#4yolov4" title="Permanent link">&para;</a></h2>
<p>YOLO之父在2020年初宣布退出CV界，YOLOv4 的作者并不是YOLO系列 的原作者。YOLO V4是YOLO系列一个重大的更新，其在COCO数据集上的平均精度(AP)和帧率精度(FPS)分别提高了10% 和12%，并得到了Joseph Redmon的官方认可，被认为是当前最强的实时对象检测模型之一。</p>
<p>yoloV4总结了大部分检测技巧，然后经过筛选，排列组合，挨个实验（ablation study）哪些方法有效，总体来说，Yolov4并没有创造新的改进，而是使用了大量的目标检测的技巧。在这里我们主要给大家看下它的网络架构：</p>
<p><img alt="image-20200915180225300" src="../assets/image-20200915180225300.png" /></p>
<p>Yolov4的结构图和Yolov3是相似的，不过使用各种新的算法思想对各个子结构都进行了改进。
先整理下Yolov4的结构组件</p>
<ul>
<li>
<p>基本组件：</p>
</li>
<li>
<p>CBM：Yolov4网络结构中的最小组件，由Conv+Bn+Mish激活函数三者组成。</p>
</li>
<li>CBL：由Conv+Bn+Leaky_relu激活函数三者组成。</li>
<li>Res unit：借鉴Resnet网络中的残差结构，让网络可以构建的更深。</li>
<li>CSPX：由三个卷积层和X个Res unint模块Concate组成。</li>
<li>
<p>SPP：采用1×1，5×5，9×9，13×13的最大池化的方式，进行多尺度融合。</p>
</li>
<li>
<p>其他基础操作：</p>
</li>
<li>
<p>Concat：张量拼接，维度会扩充，和Yolov3中的解释一样，对应于cfg文件中的route操作。</p>
</li>
<li>
<p>Add：张量相加，不会扩充维度，对应于cfg文件中的shortcut操作。</p>
</li>
<li>
<p>Backbone中卷积层的数量：
  每个CSPX中包含3+2×X个卷积层，因此整个主干网络Backbone中一共包含2+（3+2×1）+2+（3+2×2）+2+（3+2×8）+2+（3+2×8）+2+（3+2×4）+1=72。</p>
</li>
</ul>
<p><strong>注意：</strong></p>
<p>网络的输入大小不是固定的，在yoloV3中输入默认是416×416，在yoloV4中默认是608×608，在实际项目中也可以根据需要修改，比如320×320，一般是32的倍数。 输入图像的大小和最后的三个特征图的大小也是对应的，比如416×416的输入，最后的三个特征图大小是13×13，26×26，52×52， 如果是608×608，最后的三个特征图大小则是19×19，38×38，76×76。</p>
<hr />
<p><strong>总结</strong></p>
<ul>
<li>知道yolo网络架构，理解其输入输出</li>
</ul>
<p>YOLO的整个结构就是输入图片经过神经网络的变换得到一个输出的张量</p>
<ul>
<li>知道yolo模型的训练样本构建的方法</li>
</ul>
<p>对于原图像中的每一个网格grid都需要构建一个30维的向量：分类，置信度，回归的目标值</p>
<ul>
<li>理解yolo模型的损失函数</li>
</ul>
<p>损失函数分为3部分：分类损失，回归损失，置信度损失</p>
<ul>
<li>知道yoloV2模型的改进方法</li>
</ul>
<p>使用了BN层，高分辨率训练，采用Anchorbox，聚类得到anchorbox的尺寸，改进边界框预测的方法，特征融合，多尺度训练，网络模型使用darknet19，利用imagenet数据集识别更多的目标</p>
<ul>
<li>yoloV3的多尺度检测方法</li>
</ul>
<p>在YOLOv3中采用FPN结构来提高对应多尺度目标检测的精度，当前的feature map利用“未来”层的信息，将低阶特征与高阶特征进行融合，提升检测精度。</p>
<ul>
<li>yoloV3模型的网络结构</li>
</ul>
<p>以darknet-53为基础，借鉴resnet的思想，在网络中加入了残差模块，利于解决深层次网络的梯度问题</p>
<p>整个v3结构里面，没有池化层和全连接层，只有卷积层</p>
<p>网络的下采样是通过设置卷积的stride为2来达到的</p>
<ul>
<li>yoloV3模型先验框设计的方法</li>
</ul>
<p>采用K-means聚类得到先验框的尺寸，为每种尺度设定3种先验框，总共聚类出9种尺寸的先验框。</p>
<ul>
<li>yoloV3模型为什么适用于多标签的目标分类</li>
</ul>
<p>预测对象类别时不使用softmax，而是使用logistic的输出进行预测</p>
<ul>
<li>yoloV3模型的输入输出</li>
</ul>
<p>对于416×416×3的输入图像，在每个尺度的特征图的每个网格设置3个先验框，总共有 13×13×3 + 26×26×3  + 52×52×3 = 10647 个预测。每一个预测是一个(4+1+80)=85维向量，这个85维向量包含边框坐标（4个数值），边框置信度（1个数值），对象类别的概率（对于COCO数据集，有80种对象）。</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../03.RCNN-demo/" title="Faster RCNN案例" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Faster RCNN案例
              </div>
            </div>
          </a>
        
        
          <a href="../05.yolo-demo/" title="YOLOV3案例" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                YOLOV3案例
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>